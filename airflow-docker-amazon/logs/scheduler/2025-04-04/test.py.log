[2025-04-04T20:13:33.737+0000] {processor.py:186} INFO - Started process (PID=7022) to work on /opt/airflow/dags/test.py
[2025-04-04T20:13:33.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:13:33.741+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:33.740+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:13:33.844+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:13:34.218+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.216+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:process_csv_dag
[2025-04-04T20:13:34.254+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.254+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:process_csv_dag
[2025-04-04T20:13:34.275+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.275+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:process_csv_dag
[2025-04-04T20:13:34.295+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.295+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:process_csv_dag
[2025-04-04T20:13:34.307+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.307+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:process_csv_dag
[2025-04-04T20:13:34.322+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.321+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:process_csv_dag
[2025-04-04T20:13:34.362+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.361+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:process_csv_dag
[2025-04-04T20:13:34.364+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:13:34.397+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.396+0000] {dag.py:3262} INFO - Creating ORM DAG for process_csv_dag
[2025-04-04T20:13:34.402+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:13:34.402+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:13:34.444+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.716 seconds
[2025-04-04T20:14:04.726+0000] {processor.py:186} INFO - Started process (PID=7089) to work on /opt/airflow/dags/test.py
[2025-04-04T20:14:04.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:14:04.730+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:14:04.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:14:04.780+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:14:04.820+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:14:04.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:14:04.868+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:14:04.868+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:14:04.931+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.216 seconds
[2025-04-04T20:14:35.409+0000] {processor.py:186} INFO - Started process (PID=7150) to work on /opt/airflow/dags/test.py
[2025-04-04T20:14:35.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:14:35.412+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:14:35.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:14:35.446+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:14:35.475+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:14:35.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:14:35.495+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:14:35.495+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:14:35.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T20:15:05.675+0000] {processor.py:186} INFO - Started process (PID=7215) to work on /opt/airflow/dags/test.py
[2025-04-04T20:15:05.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:15:05.679+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:05.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:15:05.724+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:15:05.753+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:05.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:15:05.773+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:05.773+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:15:05.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.136 seconds
[2025-04-04T20:15:35.965+0000] {processor.py:186} INFO - Started process (PID=7280) to work on /opt/airflow/dags/test.py
[2025-04-04T20:15:35.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:15:35.973+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:35.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:15:36.005+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:15:36.037+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:36.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:15:36.059+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:36.058+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:15:36.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-04T20:15:53.546+0000] {processor.py:186} INFO - Started process (PID=7323) to work on /opt/airflow/dags/test.py
[2025-04-04T20:15:53.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:15:53.549+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:53.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:15:53.588+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:15:53.762+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:53.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:15:53.782+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:15:53.782+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:15:53.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.281 seconds
[2025-04-04T20:16:24.210+0000] {processor.py:186} INFO - Started process (PID=7389) to work on /opt/airflow/dags/test.py
[2025-04-04T20:16:24.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:16:24.215+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:16:24.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:16:24.259+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:16:24.309+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:16:24.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:16:24.334+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:16:24.334+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:16:24.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.169 seconds
[2025-04-04T20:16:54.711+0000] {processor.py:186} INFO - Started process (PID=7454) to work on /opt/airflow/dags/test.py
[2025-04-04T20:16:54.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:16:54.715+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:16:54.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:16:54.760+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:16:54.810+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:16:54.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:16:54.831+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:16:54.830+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:16:54.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.166 seconds
[2025-04-04T20:17:25.018+0000] {processor.py:186} INFO - Started process (PID=7518) to work on /opt/airflow/dags/test.py
[2025-04-04T20:17:25.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:17:25.021+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:17:25.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:17:25.065+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:17:25.110+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:17:25.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:17:25.129+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:17:25.129+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:17:25.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.149 seconds
[2025-04-04T20:17:55.520+0000] {processor.py:186} INFO - Started process (PID=7583) to work on /opt/airflow/dags/test.py
[2025-04-04T20:17:55.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:17:55.523+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:17:55.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:17:55.562+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:17:55.612+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:17:55.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:17:55.629+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:17:55.629+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:17:55.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.146 seconds
[2025-04-04T20:18:26.227+0000] {processor.py:186} INFO - Started process (PID=7648) to work on /opt/airflow/dags/test.py
[2025-04-04T20:18:26.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:18:26.230+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:18:26.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:18:26.270+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:18:26.318+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:18:26.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:18:26.338+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:18:26.338+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:18:26.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.149 seconds
[2025-04-04T20:18:56.835+0000] {processor.py:186} INFO - Started process (PID=7713) to work on /opt/airflow/dags/test.py
[2025-04-04T20:18:56.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:18:56.839+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:18:56.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:18:56.886+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:18:56.944+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:18:56.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:18:56.970+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:18:56.969+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:18:56.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.173 seconds
[2025-04-04T20:19:27.140+0000] {processor.py:186} INFO - Started process (PID=7778) to work on /opt/airflow/dags/test.py
[2025-04-04T20:19:27.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:19:27.144+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:19:27.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:19:27.186+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:19:27.246+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:19:27.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:19:27.270+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:19:27.270+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:19:27.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.170 seconds
[2025-04-04T20:19:57.491+0000] {processor.py:186} INFO - Started process (PID=7843) to work on /opt/airflow/dags/test.py
[2025-04-04T20:19:57.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:19:57.496+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:19:57.496+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:19:57.545+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:19:57.593+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:19:57.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:19:57.618+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:19:57.618+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:19:57.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.182 seconds
[2025-04-04T20:20:28.062+0000] {processor.py:186} INFO - Started process (PID=7909) to work on /opt/airflow/dags/test.py
[2025-04-04T20:20:28.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:20:28.065+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:20:28.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:20:28.100+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:20:28.148+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:20:28.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:20:28.175+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:20:28.174+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:20:28.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.159 seconds
[2025-04-04T20:20:58.673+0000] {processor.py:186} INFO - Started process (PID=7974) to work on /opt/airflow/dags/test.py
[2025-04-04T20:20:58.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:20:58.678+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:20:58.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:20:58.727+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:20:58.788+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:20:58.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:20:58.818+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:20:58.817+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:20:58.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.194 seconds
[2025-04-04T20:21:29.742+0000] {processor.py:186} INFO - Started process (PID=8038) to work on /opt/airflow/dags/test.py
[2025-04-04T20:21:29.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:21:29.746+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:21:29.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:21:29.783+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:21:29.826+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:21:29.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:21:29.844+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:21:29.844+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:21:29.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.141 seconds
[2025-04-04T20:22:00.345+0000] {processor.py:186} INFO - Started process (PID=8103) to work on /opt/airflow/dags/test.py
[2025-04-04T20:22:00.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:22:00.349+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:22:00.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:22:00.388+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:22:00.437+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:22:00.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:22:00.464+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:22:00.463+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:22:00.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.165 seconds
[2025-04-04T20:22:30.793+0000] {processor.py:186} INFO - Started process (PID=8168) to work on /opt/airflow/dags/test.py
[2025-04-04T20:22:30.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:22:30.798+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:22:30.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:22:30.839+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:22:30.888+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:22:30.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:22:30.908+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:22:30.908+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:22:30.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.154 seconds
[2025-04-04T20:23:01.178+0000] {processor.py:186} INFO - Started process (PID=8231) to work on /opt/airflow/dags/test.py
[2025-04-04T20:23:01.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:23:01.182+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:23:01.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:23:01.224+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:23:01.352+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:23:01.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:23:01.373+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:23:01.373+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:23:01.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.235 seconds
[2025-04-04T20:23:31.910+0000] {processor.py:186} INFO - Started process (PID=8296) to work on /opt/airflow/dags/test.py
[2025-04-04T20:23:31.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:23:31.914+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:23:31.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:23:31.950+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:23:31.996+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:23:31.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:23:32.019+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:23:32.019+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:23:32.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.160 seconds
[2025-04-04T20:24:02.764+0000] {processor.py:186} INFO - Started process (PID=8361) to work on /opt/airflow/dags/test.py
[2025-04-04T20:24:02.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:24:02.767+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:24:02.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:24:02.804+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:24:02.853+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:24:02.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:24:02.874+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:24:02.874+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:24:02.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.152 seconds
[2025-04-04T20:24:33.131+0000] {processor.py:186} INFO - Started process (PID=8425) to work on /opt/airflow/dags/test.py
[2025-04-04T20:24:33.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:24:33.134+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:24:33.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:24:33.183+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:24:33.233+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:24:33.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:24:33.256+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:24:33.256+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:24:33.285+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.165 seconds
[2025-04-04T20:25:03.505+0000] {processor.py:186} INFO - Started process (PID=8490) to work on /opt/airflow/dags/test.py
[2025-04-04T20:25:03.507+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:25:03.510+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:25:03.509+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:25:03.551+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:25:03.612+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:25:03.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:25:03.638+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:25:03.638+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:25:03.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.185 seconds
[2025-04-04T20:25:33.805+0000] {processor.py:186} INFO - Started process (PID=8555) to work on /opt/airflow/dags/test.py
[2025-04-04T20:25:33.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:25:33.808+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:25:33.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:25:33.848+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:25:33.897+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:25:33.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:25:33.917+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:25:33.916+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:25:33.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.149 seconds
[2025-04-04T20:26:04.370+0000] {processor.py:186} INFO - Started process (PID=8622) to work on /opt/airflow/dags/test.py
[2025-04-04T20:26:04.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:26:04.373+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:26:04.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:26:04.410+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:26:04.453+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:26:04.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:26:04.471+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:26:04.471+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:26:04.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.144 seconds
[2025-04-04T20:26:35.560+0000] {processor.py:186} INFO - Started process (PID=8688) to work on /opt/airflow/dags/test.py
[2025-04-04T20:26:35.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:26:35.563+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:26:35.563+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:26:35.607+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:26:35.669+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:26:35.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:26:35.692+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:26:35.691+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:26:35.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.237 seconds
[2025-04-04T20:27:06.138+0000] {processor.py:186} INFO - Started process (PID=8754) to work on /opt/airflow/dags/test.py
[2025-04-04T20:27:06.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:27:06.142+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:27:06.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:27:06.186+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:27:06.229+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:27:06.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:27:06.248+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:27:06.248+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:27:06.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.156 seconds
[2025-04-04T20:27:36.399+0000] {processor.py:186} INFO - Started process (PID=8819) to work on /opt/airflow/dags/test.py
[2025-04-04T20:27:36.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:27:36.401+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:27:36.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:27:36.434+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:27:36.479+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:27:36.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:27:36.501+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:27:36.501+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:27:36.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.144 seconds
[2025-04-04T20:28:06.876+0000] {processor.py:186} INFO - Started process (PID=8885) to work on /opt/airflow/dags/test.py
[2025-04-04T20:28:06.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:28:06.888+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:28:06.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:28:06.941+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:28:07.068+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:28:07.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:28:07.108+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:28:07.107+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:28:07.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.296 seconds
[2025-04-04T20:28:37.711+0000] {processor.py:186} INFO - Started process (PID=8950) to work on /opt/airflow/dags/test.py
[2025-04-04T20:28:37.713+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:28:37.716+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:28:37.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:28:37.746+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:28:37.785+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:28:37.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:28:37.802+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:28:37.802+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:28:37.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.169 seconds
[2025-04-04T20:29:08.398+0000] {processor.py:186} INFO - Started process (PID=9015) to work on /opt/airflow/dags/test.py
[2025-04-04T20:29:08.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:29:08.403+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:29:08.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:29:08.441+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:29:08.495+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:29:08.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:29:08.519+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:29:08.519+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:29:08.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.165 seconds
[2025-04-04T20:29:38.726+0000] {processor.py:186} INFO - Started process (PID=9080) to work on /opt/airflow/dags/test.py
[2025-04-04T20:29:38.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:29:38.730+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:29:38.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:29:38.787+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:29:38.862+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:29:38.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:29:38.891+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:29:38.891+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:29:38.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.216 seconds
[2025-04-04T20:30:09.075+0000] {processor.py:186} INFO - Started process (PID=9146) to work on /opt/airflow/dags/test.py
[2025-04-04T20:30:09.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:30:09.078+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:30:09.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:30:09.112+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:30:09.157+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:30:09.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:30:09.179+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:30:09.178+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:30:09.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.142 seconds
[2025-04-04T20:30:39.680+0000] {processor.py:186} INFO - Started process (PID=9207) to work on /opt/airflow/dags/test.py
[2025-04-04T20:30:39.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:30:39.683+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:30:39.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:30:39.722+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:30:39.785+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:30:39.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:30:39.809+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:30:39.809+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:30:39.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.175 seconds
[2025-04-04T20:31:10.246+0000] {processor.py:186} INFO - Started process (PID=9270) to work on /opt/airflow/dags/test.py
[2025-04-04T20:31:10.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:31:10.250+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:31:10.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:31:10.289+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:31:10.333+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:31:10.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:31:10.351+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:31:10.351+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:31:10.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.147 seconds
[2025-04-04T20:31:40.786+0000] {processor.py:186} INFO - Started process (PID=9336) to work on /opt/airflow/dags/test.py
[2025-04-04T20:31:40.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:31:40.790+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:31:40.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:31:40.836+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:31:40.887+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:31:40.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:31:40.916+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:31:40.916+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:31:40.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.178 seconds
[2025-04-04T20:32:11.159+0000] {processor.py:186} INFO - Started process (PID=9401) to work on /opt/airflow/dags/test.py
[2025-04-04T20:32:11.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:32:11.161+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:32:11.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:32:11.196+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:32:11.240+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:32:11.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:32:11.258+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:32:11.258+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:32:11.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-04T20:32:41.465+0000] {processor.py:186} INFO - Started process (PID=9466) to work on /opt/airflow/dags/test.py
[2025-04-04T20:32:41.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:32:41.469+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:32:41.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:32:41.502+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:32:41.549+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:32:41.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:32:41.571+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:32:41.571+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:32:41.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.142 seconds
[2025-04-04T20:33:11.765+0000] {processor.py:186} INFO - Started process (PID=9531) to work on /opt/airflow/dags/test.py
[2025-04-04T20:33:11.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:33:11.768+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:33:11.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:33:11.802+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:33:11.847+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:33:11.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:33:11.865+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:33:11.865+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:33:11.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.141 seconds
[2025-04-04T20:33:42.451+0000] {processor.py:186} INFO - Started process (PID=9595) to work on /opt/airflow/dags/test.py
[2025-04-04T20:33:42.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:33:42.453+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:33:42.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:33:42.497+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:33:42.556+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:33:42.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:33:42.580+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:33:42.579+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:33:42.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.172 seconds
[2025-04-04T20:34:12.811+0000] {processor.py:186} INFO - Started process (PID=9660) to work on /opt/airflow/dags/test.py
[2025-04-04T20:34:12.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:34:12.814+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:34:12.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:34:12.848+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:34:12.888+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:34:12.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:34:12.905+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:34:12.905+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:34:12.937+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T20:34:43.005+0000] {processor.py:186} INFO - Started process (PID=9726) to work on /opt/airflow/dags/test.py
[2025-04-04T20:34:43.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:34:43.008+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:34:43.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:34:43.043+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:34:43.091+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:34:43.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:34:43.111+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:34:43.111+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:34:43.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.148 seconds
[2025-04-04T20:35:13.420+0000] {processor.py:186} INFO - Started process (PID=9791) to work on /opt/airflow/dags/test.py
[2025-04-04T20:35:13.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:35:13.423+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:35:13.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:35:13.461+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:35:13.524+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:35:13.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:35:13.546+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:35:13.546+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:35:13.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.168 seconds
[2025-04-04T20:35:43.824+0000] {processor.py:186} INFO - Started process (PID=9857) to work on /opt/airflow/dags/test.py
[2025-04-04T20:35:43.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:35:43.827+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:35:43.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:35:43.859+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:35:43.903+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:35:43.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:35:43.920+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:35:43.920+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:35:43.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.142 seconds
[2025-04-04T20:36:14.086+0000] {processor.py:186} INFO - Started process (PID=9922) to work on /opt/airflow/dags/test.py
[2025-04-04T20:36:14.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:36:14.092+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:36:14.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:36:14.127+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:36:14.176+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:36:14.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:36:14.193+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:36:14.193+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:36:14.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.152 seconds
[2025-04-04T20:36:44.467+0000] {processor.py:186} INFO - Started process (PID=9987) to work on /opt/airflow/dags/test.py
[2025-04-04T20:36:44.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:36:44.471+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:36:44.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:36:44.510+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:36:44.565+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:36:44.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:36:44.584+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:36:44.584+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:36:44.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.160 seconds
[2025-04-04T20:37:15.070+0000] {processor.py:186} INFO - Started process (PID=10052) to work on /opt/airflow/dags/test.py
[2025-04-04T20:37:15.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:37:15.074+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:37:15.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:37:15.112+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:37:15.163+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:37:15.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:37:15.190+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:37:15.189+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:37:15.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.161 seconds
[2025-04-04T20:37:45.497+0000] {processor.py:186} INFO - Started process (PID=10117) to work on /opt/airflow/dags/test.py
[2025-04-04T20:37:45.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:37:45.500+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:37:45.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:37:45.546+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:37:45.600+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:37:45.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:37:45.623+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:37:45.622+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:37:45.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.171 seconds
[2025-04-04T20:38:16.018+0000] {processor.py:186} INFO - Started process (PID=10183) to work on /opt/airflow/dags/test.py
[2025-04-04T20:38:16.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:38:16.021+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:38:16.021+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:38:16.060+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:38:16.113+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:38:16.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:38:16.133+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:38:16.132+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:38:16.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.161 seconds
[2025-04-04T20:38:47.063+0000] {processor.py:186} INFO - Started process (PID=10249) to work on /opt/airflow/dags/test.py
[2025-04-04T20:38:47.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:38:47.066+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:38:47.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:38:47.102+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:38:47.151+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:38:47.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:38:47.170+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:38:47.170+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:38:47.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.141 seconds
[2025-04-04T20:39:17.718+0000] {processor.py:186} INFO - Started process (PID=10312) to work on /opt/airflow/dags/test.py
[2025-04-04T20:39:17.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:39:17.723+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:39:17.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:39:17.762+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:39:17.813+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:39:17.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:39:17.835+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:39:17.835+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:39:17.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.157 seconds
[2025-04-04T20:39:48.662+0000] {processor.py:186} INFO - Started process (PID=10377) to work on /opt/airflow/dags/test.py
[2025-04-04T20:39:48.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:39:48.666+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:39:48.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:39:48.713+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:39:48.770+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:39:48.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:39:48.793+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:39:48.793+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:39:48.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.166 seconds
[2025-04-04T20:40:19.465+0000] {processor.py:186} INFO - Started process (PID=10440) to work on /opt/airflow/dags/test.py
[2025-04-04T20:40:19.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:40:19.469+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:40:19.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:40:19.508+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:40:19.577+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:40:19.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:40:19.610+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:40:19.609+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:40:19.637+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.182 seconds
[2025-04-04T20:40:49.823+0000] {processor.py:186} INFO - Started process (PID=10505) to work on /opt/airflow/dags/test.py
[2025-04-04T20:40:49.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:40:49.826+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:40:49.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:40:49.887+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:40:50.096+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:40:50.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:40:50.119+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:40:50.119+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:40:50.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.339 seconds
[2025-04-04T20:41:21.023+0000] {processor.py:186} INFO - Started process (PID=10570) to work on /opt/airflow/dags/test.py
[2025-04-04T20:41:21.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:41:21.027+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:41:21.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:41:21.064+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:41:21.110+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:41:21.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:41:21.129+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:41:21.129+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:41:21.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.152 seconds
[2025-04-04T20:41:51.435+0000] {processor.py:186} INFO - Started process (PID=10635) to work on /opt/airflow/dags/test.py
[2025-04-04T20:41:51.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:41:51.439+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:41:51.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:41:51.485+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:41:51.536+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:41:51.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:41:51.554+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:41:51.554+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:41:51.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.158 seconds
[2025-04-04T20:42:21.668+0000] {processor.py:186} INFO - Started process (PID=10700) to work on /opt/airflow/dags/test.py
[2025-04-04T20:42:21.670+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:42:21.673+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:42:21.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:42:21.711+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:42:21.757+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:42:21.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:42:21.779+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:42:21.779+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:42:21.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.157 seconds
[2025-04-04T20:42:52.525+0000] {processor.py:186} INFO - Started process (PID=10765) to work on /opt/airflow/dags/test.py
[2025-04-04T20:42:52.526+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:42:52.530+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:42:52.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:42:52.564+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:42:52.615+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:42:52.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:42:52.636+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:42:52.636+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:42:52.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.153 seconds
[2025-04-04T20:43:22.802+0000] {processor.py:186} INFO - Started process (PID=10831) to work on /opt/airflow/dags/test.py
[2025-04-04T20:43:22.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:43:22.805+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:43:22.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:43:22.843+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:43:22.898+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:43:22.898+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:43:22.924+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:43:22.923+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:43:22.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.171 seconds
[2025-04-04T20:43:53.385+0000] {processor.py:186} INFO - Started process (PID=10902) to work on /opt/airflow/dags/test.py
[2025-04-04T20:43:53.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:43:53.389+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:43:53.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:43:53.424+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:43:53.470+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:43:53.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:43:53.489+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:43:53.489+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:43:53.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.148 seconds
[2025-04-04T20:44:24.065+0000] {processor.py:186} INFO - Started process (PID=10967) to work on /opt/airflow/dags/test.py
[2025-04-04T20:44:24.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:44:24.068+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:44:24.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:44:24.100+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:44:24.157+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:44:24.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:44:24.190+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:44:24.190+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:44:24.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.167 seconds
[2025-04-04T20:44:54.712+0000] {processor.py:186} INFO - Started process (PID=11032) to work on /opt/airflow/dags/test.py
[2025-04-04T20:44:54.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:44:54.716+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:44:54.715+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:44:54.751+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:44:54.792+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:44:54.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:44:54.810+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:44:54.810+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:44:54.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.142 seconds
[2025-04-04T20:45:19.983+0000] {processor.py:186} INFO - Started process (PID=11081) to work on /opt/airflow/dags/test.py
[2025-04-04T20:45:19.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:45:19.986+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:19.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:45:20.036+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:20.028+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:45:20.037+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:45:20.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-04T20:45:25.377+0000] {processor.py:186} INFO - Started process (PID=11099) to work on /opt/airflow/dags/test.py
[2025-04-04T20:45:25.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:45:25.380+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:25.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:45:25.431+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:25.421+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:45:25.433+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:45:25.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-04T20:45:26.022+0000] {processor.py:186} INFO - Started process (PID=11104) to work on /opt/airflow/dags/test.py
[2025-04-04T20:45:26.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:45:26.025+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:26.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:45:26.065+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:26.054+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:45:26.066+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:45:26.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-04T20:45:56.465+0000] {processor.py:186} INFO - Started process (PID=11165) to work on /opt/airflow/dags/test.py
[2025-04-04T20:45:56.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:45:56.469+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:56.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:45:56.505+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:45:56.496+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:45:56.506+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:45:56.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.079 seconds
[2025-04-04T20:46:26.888+0000] {processor.py:186} INFO - Started process (PID=11230) to work on /opt/airflow/dags/test.py
[2025-04-04T20:46:26.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:46:26.891+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:46:26.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:46:26.921+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:46:26.913+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:46:26.922+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:46:26.952+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.073 seconds
[2025-04-04T20:46:57.145+0000] {processor.py:186} INFO - Started process (PID=11296) to work on /opt/airflow/dags/test.py
[2025-04-04T20:46:57.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:46:57.148+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:46:57.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:46:57.181+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:46:57.173+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:46:57.182+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:46:57.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.076 seconds
[2025-04-04T20:47:27.356+0000] {processor.py:186} INFO - Started process (PID=11361) to work on /opt/airflow/dags/test.py
[2025-04-04T20:47:27.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:47:27.359+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:47:27.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:47:27.399+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:47:27.390+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:47:27.401+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:47:27.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.085 seconds
[2025-04-04T20:47:57.566+0000] {processor.py:186} INFO - Started process (PID=11423) to work on /opt/airflow/dags/test.py
[2025-04-04T20:47:57.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:47:57.569+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:47:57.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:47:57.609+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:47:57.601+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:47:57.610+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:47:57.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.084 seconds
[2025-04-04T20:48:27.795+0000] {processor.py:186} INFO - Started process (PID=11488) to work on /opt/airflow/dags/test.py
[2025-04-04T20:48:27.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:48:27.798+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:48:27.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:48:27.833+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:48:27.823+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:48:27.835+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:48:27.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.082 seconds
[2025-04-04T20:48:58.667+0000] {processor.py:186} INFO - Started process (PID=11552) to work on /opt/airflow/dags/test.py
[2025-04-04T20:48:58.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:48:58.671+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:48:58.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:48:58.707+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:48:58.698+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:48:58.709+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:48:58.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.089 seconds
[2025-04-04T20:49:29.037+0000] {processor.py:186} INFO - Started process (PID=11617) to work on /opt/airflow/dags/test.py
[2025-04-04T20:49:29.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:49:29.041+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:49:29.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:49:29.093+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:49:29.083+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:49:29.094+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:49:29.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T20:49:59.675+0000] {processor.py:186} INFO - Started process (PID=11683) to work on /opt/airflow/dags/test.py
[2025-04-04T20:49:59.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:49:59.678+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:49:59.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:49:59.712+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:49:59.703+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:49:59.713+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:49:59.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.074 seconds
[2025-04-04T20:50:30.357+0000] {processor.py:186} INFO - Started process (PID=11748) to work on /opt/airflow/dags/test.py
[2025-04-04T20:50:30.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:50:30.359+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:50:30.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:50:30.394+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:50:30.384+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    department, sub_department, url = row['Department'], row['Sub Department'], row['URL']
                                                         ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:50:30.396+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:50:30.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.079 seconds
[2025-04-04T20:50:38.077+0000] {processor.py:186} INFO - Started process (PID=11779) to work on /opt/airflow/dags/test.py
[2025-04-04T20:50:38.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:50:38.080+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:50:38.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:50:38.135+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:50:38.466+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:50:38.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:50:38.480+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:50:38.480+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:50:38.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.455 seconds
[2025-04-04T20:51:08.786+0000] {processor.py:186} INFO - Started process (PID=11844) to work on /opt/airflow/dags/test.py
[2025-04-04T20:51:08.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:51:08.789+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:51:08.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:51:08.824+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:51:08.854+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:51:08.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:51:08.877+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:51:08.876+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:51:08.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.135 seconds
[2025-04-04T20:51:39.179+0000] {processor.py:186} INFO - Started process (PID=11909) to work on /opt/airflow/dags/test.py
[2025-04-04T20:51:39.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:51:39.183+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:51:39.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:51:39.228+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:51:39.263+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:51:39.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:51:39.291+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:51:39.290+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:51:39.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.178 seconds
[2025-04-04T20:52:09.413+0000] {processor.py:186} INFO - Started process (PID=11965) to work on /opt/airflow/dags/test.py
[2025-04-04T20:52:09.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:52:09.418+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:52:09.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:52:09.490+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:52:09.568+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:52:09.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:52:09.598+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:52:09.597+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:52:09.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.235 seconds
[2025-04-04T20:52:40.401+0000] {processor.py:186} INFO - Started process (PID=12031) to work on /opt/airflow/dags/test.py
[2025-04-04T20:52:40.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:52:40.404+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:52:40.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:52:40.441+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:52:40.469+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:52:40.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:52:40.491+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:52:40.490+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:52:40.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T20:53:11.290+0000] {processor.py:186} INFO - Started process (PID=12097) to work on /opt/airflow/dags/test.py
[2025-04-04T20:53:11.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:53:11.293+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:53:11.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:53:11.330+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:53:11.360+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:53:11.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:53:11.395+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:53:11.395+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:53:11.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.151 seconds
[2025-04-04T20:53:41.603+0000] {processor.py:186} INFO - Started process (PID=12162) to work on /opt/airflow/dags/test.py
[2025-04-04T20:53:41.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:53:41.606+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:53:41.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:53:41.639+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:53:41.671+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:53:41.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:53:41.691+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:53:41.691+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:53:41.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T20:54:12.102+0000] {processor.py:186} INFO - Started process (PID=12225) to work on /opt/airflow/dags/test.py
[2025-04-04T20:54:12.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:54:12.105+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:54:12.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:54:12.138+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:54:12.169+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:54:12.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:54:12.192+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:54:12.192+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:54:12.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-04T20:54:42.684+0000] {processor.py:186} INFO - Started process (PID=12291) to work on /opt/airflow/dags/test.py
[2025-04-04T20:54:42.686+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:54:42.688+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:54:42.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:54:42.726+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:54:42.756+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:54:42.756+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:54:42.774+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:54:42.774+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:54:42.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.131 seconds
[2025-04-04T20:55:13.037+0000] {processor.py:186} INFO - Started process (PID=12356) to work on /opt/airflow/dags/test.py
[2025-04-04T20:55:13.039+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:55:13.042+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:13.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:55:13.079+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:55:13.110+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:13.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:55:13.128+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:13.128+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:55:13.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.129 seconds
[2025-04-04T20:55:42.860+0000] {processor.py:186} INFO - Started process (PID=12421) to work on /opt/airflow/dags/test.py
[2025-04-04T20:55:42.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:55:42.864+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:42.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:55:42.932+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:42.913+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:55:42.933+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:55:42.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-04T20:55:44.993+0000] {processor.py:186} INFO - Started process (PID=12422) to work on /opt/airflow/dags/test.py
[2025-04-04T20:55:44.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:55:44.997+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:44.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:55:45.054+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:55:45.044+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:55:45.055+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:55:45.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T20:56:02.168+0000] {processor.py:186} INFO - Started process (PID=12460) to work on /opt/airflow/dags/test.py
[2025-04-04T20:56:02.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:56:02.171+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:02.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:56:02.227+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:02.219+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:56:02.228+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:56:02.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-04T20:56:03.008+0000] {processor.py:186} INFO - Started process (PID=12464) to work on /opt/airflow/dags/test.py
[2025-04-04T20:56:03.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:56:03.011+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:03.011+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:56:03.069+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:03.059+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:56:03.071+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:56:03.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T20:56:33.589+0000] {processor.py:186} INFO - Started process (PID=12526) to work on /opt/airflow/dags/test.py
[2025-04-04T20:56:33.590+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:56:33.592+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:33.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:56:33.630+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:33.621+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:56:33.632+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:56:33.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.085 seconds
[2025-04-04T20:56:58.540+0000] {processor.py:186} INFO - Started process (PID=12584) to work on /opt/airflow/dags/test.py
[2025-04-04T20:56:58.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:56:58.544+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:58.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:56:58.586+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:56:58.579+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:56:58.587+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:56:58.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.088 seconds
[2025-04-04T20:57:06.967+0000] {processor.py:186} INFO - Started process (PID=12597) to work on /opt/airflow/dags/test.py
[2025-04-04T20:57:06.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:57:06.970+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:57:06.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:57:07.023+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:57:07.015+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['sub_department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:57:07.025+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:57:07.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-04T20:57:27.087+0000] {processor.py:186} INFO - Started process (PID=12647) to work on /opt/airflow/dags/test.py
[2025-04-04T20:57:27.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:57:27.090+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:57:27.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:57:27.135+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:57:27.127+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['Sub Department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:57:27.136+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:57:27.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-04T20:57:57.360+0000] {processor.py:186} INFO - Started process (PID=12712) to work on /opt/airflow/dags/test.py
[2025-04-04T20:57:57.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:57:57.365+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:57:57.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:57:57.416+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:57:57.404+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row['Sub Department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'Sub Department'
[2025-04-04T20:57:57.418+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:57:57.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.170 seconds
[2025-04-04T20:58:00.749+0000] {processor.py:186} INFO - Started process (PID=12716) to work on /opt/airflow/dags/test.py
[2025-04-04T20:58:00.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:58:00.760+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:58:00.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:58:00.848+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:58:00.824+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: ' Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row[' Sub Department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: ' Sub Department'
[2025-04-04T20:58:00.850+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:58:00.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.195 seconds
[2025-04-04T20:58:31.519+0000] {processor.py:186} INFO - Started process (PID=12782) to work on /opt/airflow/dags/test.py
[2025-04-04T20:58:31.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:58:31.522+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:58:31.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:58:31.564+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:58:31.554+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: ' Sub Department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    task_id=f"process_{row[' Sub Department']}_{index}",  # t ID task theo sub_department
                       ~~~^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: ' Sub Department'
[2025-04-04T20:58:31.565+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:58:31.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.087 seconds
[2025-04-04T20:58:33.162+0000] {processor.py:186} INFO - Started process (PID=12788) to work on /opt/airflow/dags/test.py
[2025-04-04T20:58:33.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:58:33.164+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:58:33.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:58:33.207+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:58:33.200+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 29, in <module>
    task = PythonOperator(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 960, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'process_Car Care_0' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-04-04T20:58:33.210+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:58:33.242+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.089 seconds
[2025-04-04T20:59:03.604+0000] {processor.py:186} INFO - Started process (PID=12849) to work on /opt/airflow/dags/test.py
[2025-04-04T20:59:03.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:59:03.607+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:03.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:59:03.650+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:03.643+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 29, in <module>
    task = PythonOperator(
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 222, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 501, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 960, in __init__
    validate_key(task_id)
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/helpers.py", line 57, in validate_key
    raise AirflowException(
airflow.exceptions.AirflowException: The key 'process_Car Care_0' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2025-04-04T20:59:03.651+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:59:03.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-04T20:59:10.036+0000] {processor.py:186} INFO - Started process (PID=12860) to work on /opt/airflow/dags/test.py
[2025-04-04T20:59:10.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:59:10.039+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:10.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:59:10.090+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:10.084+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 30, in <module>
    sanitized_sub_department = re.sub(r'[^a-zA-Z0-9_-]', '_', row['sub_department'])
                               ^^
NameError: name 're' is not defined. Did you forget to import 're'
[2025-04-04T20:59:10.093+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:59:10.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-04T20:59:14.011+0000] {processor.py:186} INFO - Started process (PID=12879) to work on /opt/airflow/dags/test.py
[2025-04-04T20:59:14.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:59:14.017+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:14.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:59:14.103+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:14.088+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3791, in get_loc
    return self._engine.get_loc(casted_key)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "index.pyx", line 152, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 181, in pandas._libs.index.IndexEngine.get_loc
  File "pandas/_libs/hashtable_class_helper.pxi", line 7080, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas/_libs/hashtable_class_helper.pxi", line 7088, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'sub_department'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test.py", line 31, in <module>
    sanitized_sub_department = re.sub(r'[^a-zA-Z0-9_-]', '_', row['sub_department'])
                                                              ~~~^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1040, in __getitem__
    return self._get_value(key)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/series.py", line 1156, in _get_value
    loc = self.index.get_loc(label)
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/indexes/base.py", line 3798, in get_loc
    raise KeyError(key) from err
KeyError: 'sub_department'
[2025-04-04T20:59:14.104+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:59:14.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.165 seconds
[2025-04-04T20:59:29.406+0000] {processor.py:186} INFO - Started process (PID=12911) to work on /opt/airflow/dags/test.py
[2025-04-04T20:59:29.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T20:59:29.414+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:29.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T20:59:29.529+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T20:59:30.020+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:30.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T20:59:30.037+0000] {logging_mixin.py:190} INFO - [2025-04-04T20:59:30.037+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T20:59:30.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.692 seconds
[2025-04-04T21:00:00.201+0000] {processor.py:186} INFO - Started process (PID=12977) to work on /opt/airflow/dags/test.py
[2025-04-04T21:00:00.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:00:00.205+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:00:00.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:00:00.251+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:00:00.292+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:00:00.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:00:00.309+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:00:00.309+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:00:00.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.153 seconds
[2025-04-04T21:00:30.447+0000] {processor.py:186} INFO - Started process (PID=13044) to work on /opt/airflow/dags/test.py
[2025-04-04T21:00:30.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:00:30.451+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:00:30.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:00:30.500+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:00:30.552+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:00:30.552+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:00:30.576+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:00:30.576+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:00:30.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.176 seconds
[2025-04-04T21:01:01.013+0000] {processor.py:186} INFO - Started process (PID=13106) to work on /opt/airflow/dags/test.py
[2025-04-04T21:01:01.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:01:01.017+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:01:01.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:01:01.061+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:01:01.124+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:01:01.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:01:01.150+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:01:01.149+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:01:01.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.187 seconds
[2025-04-04T21:01:31.620+0000] {processor.py:186} INFO - Started process (PID=13171) to work on /opt/airflow/dags/test.py
[2025-04-04T21:01:31.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:01:31.623+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:01:31.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:01:31.664+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:01:31.871+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:01:31.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:01:31.891+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:01:31.891+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:01:31.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.309 seconds
[2025-04-04T21:02:02.042+0000] {processor.py:186} INFO - Started process (PID=13235) to work on /opt/airflow/dags/test.py
[2025-04-04T21:02:02.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:02:02.046+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:02:02.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:02:02.090+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:02:02.140+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:02:02.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:02:02.173+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:02:02.173+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:02:02.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.175 seconds
[2025-04-04T21:02:32.399+0000] {processor.py:186} INFO - Started process (PID=13300) to work on /opt/airflow/dags/test.py
[2025-04-04T21:02:32.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:02:32.402+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:02:32.402+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:02:32.443+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:02:32.491+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:02:32.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:02:32.512+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:02:32.511+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:02:32.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.154 seconds
[2025-04-04T21:03:03.099+0000] {processor.py:186} INFO - Started process (PID=13363) to work on /opt/airflow/dags/test.py
[2025-04-04T21:03:03.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:03:03.102+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:03:03.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:03:03.141+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:03:03.183+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:03:03.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:03:03.202+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:03:03.202+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:03:03.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.139 seconds
[2025-04-04T21:03:33.934+0000] {processor.py:186} INFO - Started process (PID=13428) to work on /opt/airflow/dags/test.py
[2025-04-04T21:03:33.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:03:33.937+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:03:33.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:03:33.973+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:03:34.016+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:03:34.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:03:34.035+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:03:34.034+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:03:34.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-04T21:04:04.496+0000] {processor.py:186} INFO - Started process (PID=13494) to work on /opt/airflow/dags/test.py
[2025-04-04T21:04:04.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:04:04.499+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:04:04.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:04:04.546+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:04:04.604+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:04:04.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:04:04.628+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:04:04.627+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:04:04.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.183 seconds
[2025-04-04T21:04:34.969+0000] {processor.py:186} INFO - Started process (PID=13559) to work on /opt/airflow/dags/test.py
[2025-04-04T21:04:34.971+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:04:34.973+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:04:34.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:04:35.014+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:04:35.055+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:04:35.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:04:35.079+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:04:35.078+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:04:35.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.152 seconds
[2025-04-04T21:05:05.697+0000] {processor.py:186} INFO - Started process (PID=13624) to work on /opt/airflow/dags/test.py
[2025-04-04T21:05:05.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:05:05.701+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:05:05.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:05:05.741+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:05:05.789+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:05:05.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:05:05.810+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:05:05.810+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:05:05.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.158 seconds
[2025-04-04T21:05:36.161+0000] {processor.py:186} INFO - Started process (PID=13689) to work on /opt/airflow/dags/test.py
[2025-04-04T21:05:36.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:05:36.164+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:05:36.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:05:36.202+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:05:36.256+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:05:36.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:05:36.282+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:05:36.281+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:05:36.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.167 seconds
[2025-04-04T21:06:06.759+0000] {processor.py:186} INFO - Started process (PID=13755) to work on /opt/airflow/dags/test.py
[2025-04-04T21:06:06.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:06:06.762+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:06.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:06:06.798+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:06:06.859+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:06.859+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:06:06.886+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:06.886+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:06:06.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.179 seconds
[2025-04-04T21:06:07.155+0000] {processor.py:186} INFO - Started process (PID=13759) to work on /opt/airflow/dags/test.py
[2025-04-04T21:06:07.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:06:07.157+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:07.157+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:06:07.201+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:06:07.241+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:07.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:06:07.260+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:07.260+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:06:07.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.146 seconds
[2025-04-04T21:06:37.510+0000] {processor.py:186} INFO - Started process (PID=13824) to work on /opt/airflow/dags/test.py
[2025-04-04T21:06:37.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:06:37.514+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:37.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:06:37.553+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:06:37.613+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:37.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:06:37.636+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:06:37.635+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:06:37.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.172 seconds
[2025-04-04T21:07:07.797+0000] {processor.py:186} INFO - Started process (PID=13888) to work on /opt/airflow/dags/test.py
[2025-04-04T21:07:07.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:07:07.801+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:07:07.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:07:07.837+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:07:07.877+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:07:07.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:07:07.896+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:07:07.896+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:07:07.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-04T21:07:38.093+0000] {processor.py:186} INFO - Started process (PID=13953) to work on /opt/airflow/dags/test.py
[2025-04-04T21:07:38.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:07:38.096+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:07:38.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:07:38.133+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:07:38.179+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:07:38.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:07:38.201+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:07:38.201+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:07:38.232+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.147 seconds
[2025-04-04T21:08:08.638+0000] {processor.py:186} INFO - Started process (PID=14014) to work on /opt/airflow/dags/test.py
[2025-04-04T21:08:08.639+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:08:08.642+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:08:08.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:08:08.680+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:08:08.739+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:08:08.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:08:08.768+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:08:08.768+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:08:08.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.182 seconds
[2025-04-04T21:08:39.558+0000] {processor.py:186} INFO - Started process (PID=14079) to work on /opt/airflow/dags/test.py
[2025-04-04T21:08:39.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:08:39.561+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:08:39.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:08:39.605+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:08:39.654+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:08:39.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:08:39.677+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:08:39.676+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:08:39.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.182 seconds
[2025-04-04T21:09:10.558+0000] {processor.py:186} INFO - Started process (PID=14143) to work on /opt/airflow/dags/test.py
[2025-04-04T21:09:10.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:09:10.561+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:10.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:09:10.602+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:09:10.651+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:10.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:09:10.696+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:10.696+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:09:10.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.211 seconds
[2025-04-04T21:09:41.070+0000] {processor.py:186} INFO - Started process (PID=14209) to work on /opt/airflow/dags/test.py
[2025-04-04T21:09:41.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:09:41.072+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:41.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:09:41.117+0000] {processor.py:925} INFO - DAG(s) 'process_csv_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:09:41.160+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:41.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:09:41.181+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:41.181+0000] {dag.py:4180} INFO - Setting next_dagrun for process_csv_dag to None, run_after=None
[2025-04-04T21:09:41.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.150 seconds
[2025-04-04T21:09:45.925+0000] {processor.py:186} INFO - Started process (PID=14220) to work on /opt/airflow/dags/test.py
[2025-04-04T21:09:45.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:09:45.927+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:45.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:09:45.962+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:45.961+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:09:45.967+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:09:46.106+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:46.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:09:46.123+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:46.123+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-04T21:09:46.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.236 seconds
[2025-04-04T21:09:54.183+0000] {processor.py:186} INFO - Started process (PID=14235) to work on /opt/airflow/dags/test.py
[2025-04-04T21:09:54.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:09:54.186+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:09:54.213+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.213+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:09:54.217+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:09:54.362+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.361+0000] {override.py:1911} INFO - Created Permission View: can edit on DAG:scrape_amazon_dag_test
[2025-04-04T21:09:54.377+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.377+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG:scrape_amazon_dag_test
[2025-04-04T21:09:54.388+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.387+0000] {override.py:1911} INFO - Created Permission View: can read on DAG:scrape_amazon_dag_test
[2025-04-04T21:09:54.405+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.404+0000] {override.py:1911} INFO - Created Permission View: can create on DAG Run:scrape_amazon_dag_test
[2025-04-04T21:09:54.421+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.421+0000] {override.py:1911} INFO - Created Permission View: menu access on DAG Run:scrape_amazon_dag_test
[2025-04-04T21:09:54.431+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.431+0000] {override.py:1911} INFO - Created Permission View: can delete on DAG Run:scrape_amazon_dag_test
[2025-04-04T21:09:54.443+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.443+0000] {override.py:1911} INFO - Created Permission View: can read on DAG Run:scrape_amazon_dag_test
[2025-04-04T21:09:54.444+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:09:54.461+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.461+0000] {dag.py:3262} INFO - Creating ORM DAG for scrape_amazon_dag_test
[2025-04-04T21:09:54.462+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:09:54.462+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:09:54.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.316 seconds
[2025-04-04T21:10:24.569+0000] {processor.py:186} INFO - Started process (PID=14301) to work on /opt/airflow/dags/test.py
[2025-04-04T21:10:24.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:10:24.572+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:24.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:10:24.589+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:24.589+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:10:24.593+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:10:24.615+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:24.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:10:24.632+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:24.632+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:10:24.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-04T21:10:55.240+0000] {processor.py:186} INFO - Started process (PID=14365) to work on /opt/airflow/dags/test.py
[2025-04-04T21:10:55.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:10:55.243+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:55.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:10:55.261+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:55.261+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:10:55.265+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:10:55.288+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:55.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:10:55.306+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:10:55.306+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:10:55.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-04T21:11:26.121+0000] {processor.py:186} INFO - Started process (PID=14430) to work on /opt/airflow/dags/test.py
[2025-04-04T21:11:26.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:11:26.124+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:26.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:11:26.141+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:26.141+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:11:26.145+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:11:26.173+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:26.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:11:26.196+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:26.195+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:11:26.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:11:56.550+0000] {processor.py:186} INFO - Started process (PID=14496) to work on /opt/airflow/dags/test.py
[2025-04-04T21:11:56.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:11:56.552+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:56.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:11:56.572+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:56.572+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:11:56.577+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:11:56.602+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:56.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:11:56.623+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:11:56.623+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:11:56.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-04T21:12:27.151+0000] {processor.py:186} INFO - Started process (PID=14562) to work on /opt/airflow/dags/test.py
[2025-04-04T21:12:27.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:12:27.154+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:27.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:12:27.173+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:27.173+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:12:27.178+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:12:27.200+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:27.200+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:12:27.223+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:27.222+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:12:27.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-04T21:12:57.396+0000] {processor.py:186} INFO - Started process (PID=14627) to work on /opt/airflow/dags/test.py
[2025-04-04T21:12:57.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:12:57.399+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:57.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:12:57.423+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:57.423+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:12:57.430+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:12:57.463+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:57.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:12:57.492+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:12:57.492+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:12:57.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.141 seconds
[2025-04-04T21:13:27.790+0000] {processor.py:186} INFO - Started process (PID=14692) to work on /opt/airflow/dags/test.py
[2025-04-04T21:13:27.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:13:27.793+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:27.792+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:13:27.810+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:27.809+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:13:27.814+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:13:27.839+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:27.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:13:27.865+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:27.864+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:13:27.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-04T21:13:59.723+0000] {processor.py:186} INFO - Started process (PID=14764) to work on /opt/airflow/dags/test.py
[2025-04-04T21:13:59.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:13:59.726+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:59.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:13:59.746+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:59.746+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:13:59.752+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:13:59.776+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:59.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:13:59.798+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:13:59.797+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:13:59.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:14:30.331+0000] {processor.py:186} INFO - Started process (PID=14825) to work on /opt/airflow/dags/test.py
[2025-04-04T21:14:30.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:14:30.335+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:14:30.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:14:30.354+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:14:30.353+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:14:30.358+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:14:30.383+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:14:30.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:14:30.408+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:14:30.407+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:14:30.440+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-04T21:15:00.600+0000] {processor.py:186} INFO - Started process (PID=14890) to work on /opt/airflow/dags/test.py
[2025-04-04T21:15:00.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:15:00.604+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:00.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:15:00.630+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:00.629+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:15:00.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:15:00.659+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:00.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:15:00.684+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:00.684+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:15:00.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.130 seconds
[2025-04-04T21:15:30.859+0000] {processor.py:186} INFO - Started process (PID=14955) to work on /opt/airflow/dags/test.py
[2025-04-04T21:15:30.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:15:30.862+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:30.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:15:30.877+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:30.877+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:15:30.881+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:15:30.910+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:30.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:15:30.935+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:15:30.935+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:15:30.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-04T21:16:01.479+0000] {processor.py:186} INFO - Started process (PID=15015) to work on /opt/airflow/dags/test.py
[2025-04-04T21:16:01.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:16:01.483+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:01.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:16:01.504+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:01.503+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:16:01.507+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:16:01.533+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:01.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:16:01.556+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:01.556+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:16:01.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.172 seconds
[2025-04-04T21:16:31.822+0000] {processor.py:186} INFO - Started process (PID=15079) to work on /opt/airflow/dags/test.py
[2025-04-04T21:16:31.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:16:31.826+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:31.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:16:31.844+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:31.844+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:16:31.848+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:16:31.872+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:31.872+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:16:31.899+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:16:31.899+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:16:31.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.139 seconds
[2025-04-04T21:17:02.116+0000] {processor.py:186} INFO - Started process (PID=15144) to work on /opt/airflow/dags/test.py
[2025-04-04T21:17:02.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:17:02.119+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:02.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:17:02.139+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:02.139+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:17:02.146+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:17:02.171+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:02.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:17:02.193+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:02.192+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:17:02.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:17:32.556+0000] {processor.py:186} INFO - Started process (PID=15209) to work on /opt/airflow/dags/test.py
[2025-04-04T21:17:32.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:17:32.559+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:32.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:17:32.576+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:32.576+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:17:32.580+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:17:32.602+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:32.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:17:32.619+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:17:32.618+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:17:32.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-04T21:18:02.715+0000] {processor.py:186} INFO - Started process (PID=15274) to work on /opt/airflow/dags/test.py
[2025-04-04T21:18:02.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:18:02.717+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:02.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:18:02.735+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:02.735+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:18:02.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:18:02.763+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:02.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:18:02.784+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:02.784+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:18:02.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T21:18:32.987+0000] {processor.py:186} INFO - Started process (PID=15334) to work on /opt/airflow/dags/test.py
[2025-04-04T21:18:32.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:18:32.994+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:32.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:18:33.026+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:33.026+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:18:33.030+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:18:33.063+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:33.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:18:33.082+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:18:33.082+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:18:33.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.233 seconds
[2025-04-04T21:19:03.582+0000] {processor.py:186} INFO - Started process (PID=15399) to work on /opt/airflow/dags/test.py
[2025-04-04T21:19:03.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:19:03.585+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:03.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:19:03.606+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:03.605+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:19:03.610+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:19:03.633+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:03.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:19:03.653+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:03.653+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:19:03.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-04T21:19:33.936+0000] {processor.py:186} INFO - Started process (PID=15465) to work on /opt/airflow/dags/test.py
[2025-04-04T21:19:33.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:19:33.939+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:33.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:19:33.960+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:33.959+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:19:33.964+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:19:33.986+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:33.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:19:34.006+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:19:34.005+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:19:34.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-04T21:20:04.541+0000] {processor.py:186} INFO - Started process (PID=15531) to work on /opt/airflow/dags/test.py
[2025-04-04T21:20:04.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:20:04.544+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:04.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:20:04.562+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:04.562+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:20:04.567+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:20:04.589+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:04.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:20:04.606+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:04.606+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:20:04.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-04T21:20:34.864+0000] {processor.py:186} INFO - Started process (PID=15598) to work on /opt/airflow/dags/test.py
[2025-04-04T21:20:34.866+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:20:34.868+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:34.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:20:34.892+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:34.892+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:20:34.899+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:20:34.924+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:34.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:20:34.944+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:20:34.944+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:20:34.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-04T21:21:05.179+0000] {processor.py:186} INFO - Started process (PID=15664) to work on /opt/airflow/dags/test.py
[2025-04-04T21:21:05.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:21:05.182+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:05.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:21:05.203+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:05.203+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:21:05.208+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:21:05.229+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:05.228+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:21:05.247+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:05.246+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:21:05.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T21:21:35.670+0000] {processor.py:186} INFO - Started process (PID=15730) to work on /opt/airflow/dags/test.py
[2025-04-04T21:21:35.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:21:35.673+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:35.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:21:35.692+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:35.692+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:21:35.696+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:21:35.721+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:35.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:21:35.741+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:21:35.741+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:21:35.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T21:22:06.272+0000] {processor.py:186} INFO - Started process (PID=15797) to work on /opt/airflow/dags/test.py
[2025-04-04T21:22:06.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:22:06.275+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:06.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:22:06.291+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:06.290+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:22:06.296+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:22:06.316+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:06.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:22:06.339+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:06.338+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:22:06.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T21:22:37.016+0000] {processor.py:186} INFO - Started process (PID=15864) to work on /opt/airflow/dags/test.py
[2025-04-04T21:22:37.018+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:22:37.020+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:37.019+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:22:37.069+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:37.069+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:22:37.073+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:22:37.096+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:37.095+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:22:37.115+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:22:37.115+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:22:37.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.144 seconds
[2025-04-04T21:23:07.802+0000] {processor.py:186} INFO - Started process (PID=15931) to work on /opt/airflow/dags/test.py
[2025-04-04T21:23:07.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:23:07.807+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:07.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:23:07.852+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:07.852+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:23:07.858+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:23:07.883+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:07.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:23:07.903+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:07.903+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:23:07.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.150 seconds
[2025-04-04T21:23:38.928+0000] {processor.py:186} INFO - Started process (PID=15997) to work on /opt/airflow/dags/test.py
[2025-04-04T21:23:38.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:23:38.931+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:38.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:23:38.949+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:38.949+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:23:38.954+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:23:38.977+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:38.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:23:39.001+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:23:39.001+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:23:39.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-04T21:24:09.598+0000] {processor.py:186} INFO - Started process (PID=16062) to work on /opt/airflow/dags/test.py
[2025-04-04T21:24:09.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:24:09.602+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:09.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:24:09.621+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:09.621+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:24:09.626+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:24:09.649+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:09.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:24:09.667+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:09.666+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:24:09.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-04T21:24:39.924+0000] {processor.py:186} INFO - Started process (PID=16129) to work on /opt/airflow/dags/test.py
[2025-04-04T21:24:39.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:24:39.927+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:39.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:24:39.944+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:39.943+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:24:39.948+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:24:39.971+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:39.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:24:39.990+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:24:39.990+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:24:40.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T21:25:10.677+0000] {processor.py:186} INFO - Started process (PID=16195) to work on /opt/airflow/dags/test.py
[2025-04-04T21:25:10.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:25:10.682+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:10.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:25:10.713+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:10.711+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:25:10.727+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:25:10.774+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:10.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:25:10.806+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:10.805+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:25:10.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.208 seconds
[2025-04-04T21:25:41.181+0000] {processor.py:186} INFO - Started process (PID=16261) to work on /opt/airflow/dags/test.py
[2025-04-04T21:25:41.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:25:41.184+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:41.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:25:41.209+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:41.209+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:25:41.214+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:25:41.239+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:41.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:25:41.260+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:25:41.259+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:25:41.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-04T21:26:11.559+0000] {processor.py:186} INFO - Started process (PID=16327) to work on /opt/airflow/dags/test.py
[2025-04-04T21:26:11.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:26:11.562+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:11.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:26:11.582+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:11.581+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:26:11.586+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:26:11.613+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:11.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:26:11.634+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:11.633+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:26:11.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-04T21:26:42.236+0000] {processor.py:186} INFO - Started process (PID=16393) to work on /opt/airflow/dags/test.py
[2025-04-04T21:26:42.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:26:42.239+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:42.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:26:42.259+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:42.259+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:26:42.263+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:26:42.284+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:42.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:26:42.307+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:26:42.307+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:26:42.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T21:27:13.043+0000] {processor.py:186} INFO - Started process (PID=16459) to work on /opt/airflow/dags/test.py
[2025-04-04T21:27:13.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:27:13.046+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:13.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:27:13.063+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:13.063+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:27:13.067+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:27:13.090+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:13.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:27:13.110+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:13.109+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:27:13.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T21:27:43.858+0000] {processor.py:186} INFO - Started process (PID=16524) to work on /opt/airflow/dags/test.py
[2025-04-04T21:27:43.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:27:43.862+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:43.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:27:43.887+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:43.886+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:27:43.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:27:43.912+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:43.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:27:43.930+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:27:43.930+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:27:43.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-04T21:28:14.212+0000] {processor.py:186} INFO - Started process (PID=16590) to work on /opt/airflow/dags/test.py
[2025-04-04T21:28:14.215+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:28:14.217+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:14.216+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:28:14.241+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:14.241+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:28:14.247+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:28:14.273+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:14.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:28:14.297+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:14.297+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:28:14.332+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-04T21:28:44.785+0000] {processor.py:186} INFO - Started process (PID=16656) to work on /opt/airflow/dags/test.py
[2025-04-04T21:28:44.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:28:44.788+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:44.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:28:44.807+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:44.807+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:28:44.813+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:28:44.836+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:44.836+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:28:44.856+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:28:44.856+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:28:44.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T21:29:15.350+0000] {processor.py:186} INFO - Started process (PID=16721) to work on /opt/airflow/dags/test.py
[2025-04-04T21:29:15.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:29:15.354+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:15.354+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:29:15.375+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:15.374+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:29:15.380+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:29:15.401+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:15.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:29:15.423+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:15.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:29:15.461+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-04T21:29:46.043+0000] {processor.py:186} INFO - Started process (PID=16787) to work on /opt/airflow/dags/test.py
[2025-04-04T21:29:46.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:29:46.046+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:46.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:29:46.064+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:46.064+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:29:46.069+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:29:46.094+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:46.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:29:46.115+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:29:46.114+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:29:46.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-04T21:30:16.424+0000] {processor.py:186} INFO - Started process (PID=16853) to work on /opt/airflow/dags/test.py
[2025-04-04T21:30:16.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:30:16.427+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:16.426+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:30:16.449+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:16.449+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:30:16.457+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:30:16.484+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:16.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:30:16.515+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:16.515+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:30:16.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-04T21:30:46.637+0000] {processor.py:186} INFO - Started process (PID=16919) to work on /opt/airflow/dags/test.py
[2025-04-04T21:30:46.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:30:46.651+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:46.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:30:46.671+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:46.671+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:30:46.683+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:30:46.742+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:46.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:30:46.796+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:30:46.796+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:30:46.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.249 seconds
[2025-04-04T21:31:17.768+0000] {processor.py:186} INFO - Started process (PID=16985) to work on /opt/airflow/dags/test.py
[2025-04-04T21:31:17.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:31:17.771+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:17.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:31:17.787+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:17.787+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:31:17.792+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:31:17.818+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:17.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:31:17.840+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:17.840+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:31:17.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T21:31:48.807+0000] {processor.py:186} INFO - Started process (PID=17051) to work on /opt/airflow/dags/test.py
[2025-04-04T21:31:48.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:31:48.810+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:48.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:31:48.831+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:48.831+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:31:48.836+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:31:48.857+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:48.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:31:48.880+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:31:48.880+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:31:48.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-04T21:32:19.713+0000] {processor.py:186} INFO - Started process (PID=17117) to work on /opt/airflow/dags/test.py
[2025-04-04T21:32:19.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:32:19.717+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:19.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:32:19.742+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:19.741+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:32:19.747+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:32:19.777+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:19.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:32:19.803+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:19.803+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:32:19.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T21:32:49.976+0000] {processor.py:186} INFO - Started process (PID=17183) to work on /opt/airflow/dags/test.py
[2025-04-04T21:32:49.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:32:49.979+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:49.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:32:49.997+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:49.997+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:32:50.002+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:32:50.028+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:50.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:32:50.053+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:32:50.052+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:32:50.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-04T21:33:20.458+0000] {processor.py:186} INFO - Started process (PID=17249) to work on /opt/airflow/dags/test.py
[2025-04-04T21:33:20.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:33:20.461+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:20.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:33:20.478+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:20.478+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:33:20.483+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:33:20.507+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:20.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:33:20.526+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:20.526+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:33:20.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-04T21:33:50.654+0000] {processor.py:186} INFO - Started process (PID=17311) to work on /opt/airflow/dags/test.py
[2025-04-04T21:33:50.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:33:50.658+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:50.657+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:33:50.678+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:50.677+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:33:50.682+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:33:50.707+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:50.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:33:50.729+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:33:50.728+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:33:50.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-04T21:34:21.349+0000] {processor.py:186} INFO - Started process (PID=17377) to work on /opt/airflow/dags/test.py
[2025-04-04T21:34:21.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:34:21.352+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:21.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:34:21.365+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:21.365+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:34:21.370+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:34:21.390+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:21.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:34:21.407+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:21.406+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:34:21.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-04T21:34:52.170+0000] {processor.py:186} INFO - Started process (PID=17443) to work on /opt/airflow/dags/test.py
[2025-04-04T21:34:52.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:34:52.175+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:52.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:34:52.198+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:52.197+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:34:52.205+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:34:52.305+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:52.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:34:52.342+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:34:52.341+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:34:52.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.217 seconds
[2025-04-04T21:35:22.526+0000] {processor.py:186} INFO - Started process (PID=17508) to work on /opt/airflow/dags/test.py
[2025-04-04T21:35:22.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:35:22.528+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:22.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:35:22.548+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:22.547+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:35:22.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:35:22.579+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:22.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:35:22.600+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:22.600+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:35:22.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T21:35:52.951+0000] {processor.py:186} INFO - Started process (PID=17574) to work on /opt/airflow/dags/test.py
[2025-04-04T21:35:52.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:35:52.954+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:52.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:35:52.975+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:52.975+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:35:52.979+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:35:53.007+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:53.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:35:53.033+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:35:53.033+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:35:53.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T21:36:23.501+0000] {processor.py:186} INFO - Started process (PID=17640) to work on /opt/airflow/dags/test.py
[2025-04-04T21:36:23.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:36:23.504+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:23.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:36:23.526+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:23.526+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:36:23.531+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:36:23.551+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:23.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:36:23.569+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:23.569+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:36:23.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-04T21:36:54.389+0000] {processor.py:186} INFO - Started process (PID=17706) to work on /opt/airflow/dags/test.py
[2025-04-04T21:36:54.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:36:54.392+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:54.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:36:54.410+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:54.410+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:36:54.414+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:36:54.441+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:54.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:36:54.462+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:36:54.462+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:36:54.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:37:24.821+0000] {processor.py:186} INFO - Started process (PID=17772) to work on /opt/airflow/dags/test.py
[2025-04-04T21:37:24.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:37:24.825+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:24.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:37:24.852+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:24.852+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:37:24.856+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:37:24.887+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:24.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:37:24.910+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:24.909+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:37:24.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-04T21:37:55.615+0000] {processor.py:186} INFO - Started process (PID=17838) to work on /opt/airflow/dags/test.py
[2025-04-04T21:37:55.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:37:55.618+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:55.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:37:55.640+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:55.639+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:37:55.643+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:37:55.666+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:55.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:37:55.683+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:37:55.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:37:55.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-04T21:38:26.226+0000] {processor.py:186} INFO - Started process (PID=17904) to work on /opt/airflow/dags/test.py
[2025-04-04T21:38:26.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:38:26.229+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:26.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:38:26.250+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:26.250+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:38:26.254+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:38:26.276+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:26.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:38:26.294+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:26.294+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:38:26.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T21:38:56.808+0000] {processor.py:186} INFO - Started process (PID=17970) to work on /opt/airflow/dags/test.py
[2025-04-04T21:38:56.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:38:56.811+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:56.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:38:56.827+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:56.826+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:38:56.831+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:38:56.854+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:56.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:38:56.874+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:38:56.874+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:38:56.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-04T21:39:27.191+0000] {processor.py:186} INFO - Started process (PID=18037) to work on /opt/airflow/dags/test.py
[2025-04-04T21:39:27.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:39:27.194+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:27.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:39:27.213+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:27.213+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:39:27.217+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:39:27.243+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:27.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:39:27.265+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:27.264+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:39:27.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:39:57.653+0000] {processor.py:186} INFO - Started process (PID=18103) to work on /opt/airflow/dags/test.py
[2025-04-04T21:39:57.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:39:57.657+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:57.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:39:57.675+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:57.675+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:39:57.679+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:39:57.699+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:57.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:39:57.718+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:39:57.718+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:39:57.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-04T21:40:28.346+0000] {processor.py:186} INFO - Started process (PID=18168) to work on /opt/airflow/dags/test.py
[2025-04-04T21:40:28.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:40:28.352+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:28.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:40:28.382+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:28.381+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:40:28.389+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:40:28.437+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:28.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:40:28.500+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:28.499+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:40:28.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.255 seconds
[2025-04-04T21:40:58.775+0000] {processor.py:186} INFO - Started process (PID=18234) to work on /opt/airflow/dags/test.py
[2025-04-04T21:40:58.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:40:58.779+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:58.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:40:58.803+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:58.802+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:40:58.807+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:40:58.830+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:58.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:40:58.850+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:40:58.850+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:40:58.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-04T21:41:29.502+0000] {processor.py:186} INFO - Started process (PID=18300) to work on /opt/airflow/dags/test.py
[2025-04-04T21:41:29.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:41:29.522+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:29.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:41:29.550+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:29.550+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:41:29.554+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:41:29.585+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:29.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:41:29.608+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:29.608+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:41:29.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.162 seconds
[2025-04-04T21:41:59.903+0000] {processor.py:186} INFO - Started process (PID=18366) to work on /opt/airflow/dags/test.py
[2025-04-04T21:41:59.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:41:59.906+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:59.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:41:59.923+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:59.923+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:41:59.927+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:41:59.958+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:59.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:41:59.979+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:41:59.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:42:00.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-04T21:42:30.150+0000] {processor.py:186} INFO - Started process (PID=18432) to work on /opt/airflow/dags/test.py
[2025-04-04T21:42:30.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:42:30.153+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:42:30.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:42:30.168+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:42:30.168+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:42:30.172+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:42:30.194+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:42:30.194+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:42:30.214+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:42:30.214+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:42:30.247+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-04T21:43:00.422+0000] {processor.py:186} INFO - Started process (PID=18497) to work on /opt/airflow/dags/test.py
[2025-04-04T21:43:00.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:43:00.432+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:00.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:43:00.530+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:00.530+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:43:00.542+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:43:00.576+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:00.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:43:00.628+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:00.628+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:43:00.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.250 seconds
[2025-04-04T21:43:31.059+0000] {processor.py:186} INFO - Started process (PID=18562) to work on /opt/airflow/dags/test.py
[2025-04-04T21:43:31.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:43:31.062+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:31.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:43:31.084+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:31.084+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:43:31.089+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:43:31.113+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:31.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:43:31.135+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:43:31.135+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:43:31.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:44:01.578+0000] {processor.py:186} INFO - Started process (PID=18628) to work on /opt/airflow/dags/test.py
[2025-04-04T21:44:01.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:44:01.582+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:01.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:44:01.609+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:01.609+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:44:01.615+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:44:01.652+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:01.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:44:01.683+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:01.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:44:01.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.156 seconds
[2025-04-04T21:44:32.563+0000] {processor.py:186} INFO - Started process (PID=18694) to work on /opt/airflow/dags/test.py
[2025-04-04T21:44:32.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:44:32.566+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:32.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:44:32.589+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:32.588+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:44:32.594+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:44:32.618+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:32.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:44:32.641+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:44:32.640+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:44:32.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T21:45:03.090+0000] {processor.py:186} INFO - Started process (PID=18759) to work on /opt/airflow/dags/test.py
[2025-04-04T21:45:03.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:45:03.093+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:03.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:45:03.110+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:03.109+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:45:03.114+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:45:03.139+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:03.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:45:03.160+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:03.160+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:45:03.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.318 seconds
[2025-04-04T21:45:33.521+0000] {processor.py:186} INFO - Started process (PID=18825) to work on /opt/airflow/dags/test.py
[2025-04-04T21:45:33.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:45:33.527+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:33.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:45:33.547+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:33.547+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:45:33.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:45:33.578+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:33.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:45:33.604+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:45:33.603+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:45:33.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T21:46:03.983+0000] {processor.py:186} INFO - Started process (PID=18891) to work on /opt/airflow/dags/test.py
[2025-04-04T21:46:03.984+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:46:03.986+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:03.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:46:04.008+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:04.008+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:46:04.013+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:46:04.037+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:04.036+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:46:04.062+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:04.061+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:46:04.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-04T21:46:34.267+0000] {processor.py:186} INFO - Started process (PID=18957) to work on /opt/airflow/dags/test.py
[2025-04-04T21:46:34.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:46:34.270+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:34.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:46:34.290+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:34.290+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:46:34.295+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:46:34.322+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:34.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:46:34.343+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:46:34.342+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:46:34.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-04T21:47:04.562+0000] {processor.py:186} INFO - Started process (PID=19023) to work on /opt/airflow/dags/test.py
[2025-04-04T21:47:04.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:47:04.565+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:04.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:47:04.582+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:04.582+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:47:04.587+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:47:04.607+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:04.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:47:04.624+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:04.624+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:47:04.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-04T21:47:35.398+0000] {processor.py:186} INFO - Started process (PID=19096) to work on /opt/airflow/dags/test.py
[2025-04-04T21:47:35.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:47:35.402+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:35.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:47:35.421+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:35.421+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:47:35.426+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:47:35.448+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:35.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:47:35.466+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:47:35.466+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:47:35.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-04T21:48:05.727+0000] {processor.py:186} INFO - Started process (PID=19162) to work on /opt/airflow/dags/test.py
[2025-04-04T21:48:05.728+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:48:05.730+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:05.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:48:05.756+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:05.756+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:48:05.761+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:48:05.789+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:05.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:48:05.811+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:05.810+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:48:05.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-04T21:48:36.125+0000] {processor.py:186} INFO - Started process (PID=19228) to work on /opt/airflow/dags/test.py
[2025-04-04T21:48:36.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:48:36.128+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:36.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:48:36.144+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:36.143+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:48:36.148+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:48:36.168+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:36.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:48:36.190+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:48:36.190+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:48:36.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-04T21:49:06.997+0000] {processor.py:186} INFO - Started process (PID=19292) to work on /opt/airflow/dags/test.py
[2025-04-04T21:49:06.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:49:07.001+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:07.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:49:07.022+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:07.022+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:49:07.026+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:49:07.052+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:07.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:49:07.077+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:07.076+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:49:07.115+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-04T21:49:37.722+0000] {processor.py:186} INFO - Started process (PID=19358) to work on /opt/airflow/dags/test.py
[2025-04-04T21:49:37.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:49:37.727+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:37.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:49:37.754+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:37.753+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:49:37.761+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:49:37.791+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:37.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:49:37.825+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:49:37.825+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:49:37.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.161 seconds
[2025-04-04T21:50:08.368+0000] {processor.py:186} INFO - Started process (PID=19424) to work on /opt/airflow/dags/test.py
[2025-04-04T21:50:08.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:50:08.371+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:08.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:50:08.435+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:08.434+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:50:08.449+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:50:08.489+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:08.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:50:08.513+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:08.512+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:50:08.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.186 seconds
[2025-04-04T21:50:39.346+0000] {processor.py:186} INFO - Started process (PID=19488) to work on /opt/airflow/dags/test.py
[2025-04-04T21:50:39.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:50:39.349+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:39.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:50:39.374+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:39.374+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:50:39.379+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:50:39.407+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:39.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:50:39.428+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:50:39.428+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:50:39.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-04T21:51:09.951+0000] {processor.py:186} INFO - Started process (PID=19554) to work on /opt/airflow/dags/test.py
[2025-04-04T21:51:09.952+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:51:09.954+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:09.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:51:09.970+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:09.970+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:51:09.976+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:51:10.006+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:10.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:51:10.026+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:10.026+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:51:10.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-04T21:51:40.358+0000] {processor.py:186} INFO - Started process (PID=19619) to work on /opt/airflow/dags/test.py
[2025-04-04T21:51:40.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:51:40.362+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:40.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:51:40.388+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:40.387+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:51:40.392+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:51:40.422+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:40.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:51:40.450+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:51:40.449+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:51:40.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.145 seconds
[2025-04-04T21:52:10.652+0000] {processor.py:186} INFO - Started process (PID=19684) to work on /opt/airflow/dags/test.py
[2025-04-04T21:52:10.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:52:10.655+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:10.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:52:10.677+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:10.677+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:52:10.681+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:52:10.708+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:10.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:52:10.733+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:10.733+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:52:10.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T21:52:41.030+0000] {processor.py:186} INFO - Started process (PID=19751) to work on /opt/airflow/dags/test.py
[2025-04-04T21:52:41.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:52:41.033+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:41.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:52:41.050+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:41.050+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:52:41.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:52:41.076+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:41.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:52:41.095+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:52:41.095+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:52:41.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T21:53:11.290+0000] {processor.py:186} INFO - Started process (PID=19814) to work on /opt/airflow/dags/test.py
[2025-04-04T21:53:11.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:53:11.295+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:11.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:53:11.318+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:11.318+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:53:11.325+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:53:11.350+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:11.349+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:53:11.378+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:11.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:53:11.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.138 seconds
[2025-04-04T21:53:41.540+0000] {processor.py:186} INFO - Started process (PID=19880) to work on /opt/airflow/dags/test.py
[2025-04-04T21:53:41.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:53:41.544+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:41.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:53:41.564+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:41.564+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:53:41.569+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:53:41.590+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:41.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:53:41.608+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:53:41.608+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:53:41.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-04T21:54:12.107+0000] {processor.py:186} INFO - Started process (PID=19946) to work on /opt/airflow/dags/test.py
[2025-04-04T21:54:12.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:54:12.111+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:12.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:54:12.134+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:12.133+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:54:12.139+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:54:12.167+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:12.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:54:12.196+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:12.195+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:54:12.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-04T21:54:42.711+0000] {processor.py:186} INFO - Started process (PID=20012) to work on /opt/airflow/dags/test.py
[2025-04-04T21:54:42.712+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:54:42.714+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:42.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:54:42.739+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:42.739+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:54:42.744+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:54:42.772+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:42.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:54:42.796+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:54:42.795+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:54:42.860+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.160 seconds
[2025-04-04T21:55:13.181+0000] {processor.py:186} INFO - Started process (PID=20078) to work on /opt/airflow/dags/test.py
[2025-04-04T21:55:13.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:55:13.184+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:13.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:55:13.202+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:13.202+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:55:13.206+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:55:13.232+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:13.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:55:13.257+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:13.257+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:55:13.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-04T21:55:43.501+0000] {processor.py:186} INFO - Started process (PID=20143) to work on /opt/airflow/dags/test.py
[2025-04-04T21:55:43.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:55:43.503+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:43.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:55:43.520+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:43.520+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:55:43.525+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:55:43.547+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:43.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:55:43.565+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:55:43.565+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:55:43.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-04T21:56:13.665+0000] {processor.py:186} INFO - Started process (PID=20208) to work on /opt/airflow/dags/test.py
[2025-04-04T21:56:13.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:56:13.668+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:13.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:56:13.689+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:13.688+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:56:13.694+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:56:13.718+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:13.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:56:13.741+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:13.740+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:56:13.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-04T21:56:44.384+0000] {processor.py:186} INFO - Started process (PID=20271) to work on /opt/airflow/dags/test.py
[2025-04-04T21:56:44.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:56:44.387+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:44.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:56:44.406+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:44.405+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:56:44.410+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:56:44.434+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:44.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:56:44.454+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:56:44.454+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:56:44.488+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T21:57:14.793+0000] {processor.py:186} INFO - Started process (PID=20337) to work on /opt/airflow/dags/test.py
[2025-04-04T21:57:14.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:57:14.796+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:14.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:57:14.819+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:14.819+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:57:14.823+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:57:14.843+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:14.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:57:14.862+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:14.861+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:57:14.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-04T21:57:45.165+0000] {processor.py:186} INFO - Started process (PID=20403) to work on /opt/airflow/dags/test.py
[2025-04-04T21:57:45.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:57:45.170+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:45.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:57:45.190+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:45.190+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:57:45.194+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:57:45.221+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:45.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:57:45.241+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:57:45.241+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:57:45.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T21:58:15.445+0000] {processor.py:186} INFO - Started process (PID=20469) to work on /opt/airflow/dags/test.py
[2025-04-04T21:58:15.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:58:15.447+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:15.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:58:15.464+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:15.463+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:58:15.467+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:58:15.490+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:15.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:58:15.513+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:15.513+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:58:15.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-04T21:58:45.685+0000] {processor.py:186} INFO - Started process (PID=20533) to work on /opt/airflow/dags/test.py
[2025-04-04T21:58:45.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:58:45.689+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:45.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:58:45.709+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:45.709+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:58:45.713+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:58:45.739+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:45.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:58:45.762+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:58:45.761+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:58:45.791+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-04T21:59:16.461+0000] {processor.py:186} INFO - Started process (PID=20600) to work on /opt/airflow/dags/test.py
[2025-04-04T21:59:16.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:59:16.465+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:16.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:59:16.485+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:16.484+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:59:16.489+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:59:16.513+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:16.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:59:16.532+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:16.531+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:59:16.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-04T21:59:47.313+0000] {processor.py:186} INFO - Started process (PID=20667) to work on /opt/airflow/dags/test.py
[2025-04-04T21:59:47.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T21:59:47.316+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:47.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T21:59:47.340+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:47.339+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T21:59:47.346+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T21:59:47.375+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:47.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T21:59:47.400+0000] {logging_mixin.py:190} INFO - [2025-04-04T21:59:47.399+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T21:59:47.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.130 seconds
[2025-04-04T22:00:18.033+0000] {processor.py:186} INFO - Started process (PID=20733) to work on /opt/airflow/dags/test.py
[2025-04-04T22:00:18.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:00:18.037+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:18.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:00:18.063+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:18.062+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:00:18.066+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:00:18.090+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:18.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:00:18.109+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:18.109+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:00:18.141+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-04T22:00:48.819+0000] {processor.py:186} INFO - Started process (PID=20799) to work on /opt/airflow/dags/test.py
[2025-04-04T22:00:48.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:00:48.824+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:48.823+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:00:48.845+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:48.845+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:00:48.850+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:00:48.875+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:48.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:00:49.125+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:00:49.125+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:00:49.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.347 seconds
[2025-04-04T22:01:19.691+0000] {processor.py:186} INFO - Started process (PID=20865) to work on /opt/airflow/dags/test.py
[2025-04-04T22:01:19.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:01:19.694+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:19.693+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:01:19.714+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:19.713+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:01:19.717+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:01:19.740+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:19.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:01:19.759+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:19.759+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:01:19.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.309 seconds
[2025-04-04T22:01:50.261+0000] {processor.py:186} INFO - Started process (PID=20931) to work on /opt/airflow/dags/test.py
[2025-04-04T22:01:50.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:01:50.264+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:50.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:01:50.285+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:50.284+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:01:50.289+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:01:50.313+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:50.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:01:50.332+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:01:50.332+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:01:50.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.413 seconds
[2025-04-04T22:02:20.795+0000] {processor.py:186} INFO - Started process (PID=20997) to work on /opt/airflow/dags/test.py
[2025-04-04T22:02:20.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:02:20.799+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:20.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:02:20.816+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:20.815+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:02:20.820+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:02:20.845+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:20.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:02:20.864+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:20.864+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:02:20.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-04T22:02:53.775+0000] {processor.py:186} INFO - Started process (PID=21063) to work on /opt/airflow/dags/test.py
[2025-04-04T22:02:53.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:02:53.840+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:53.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:02:53.912+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:53.912+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:02:53.930+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:02:53.985+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:53.984+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:02:54.013+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:02:54.013+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:02:54.047+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.285 seconds
[2025-04-04T22:03:24.947+0000] {processor.py:186} INFO - Started process (PID=21129) to work on /opt/airflow/dags/test.py
[2025-04-04T22:03:24.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:03:24.950+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:24.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:03:24.968+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:24.968+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:03:24.972+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:03:25.006+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:25.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:03:25.025+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:25.025+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:03:25.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-04T22:03:55.239+0000] {processor.py:186} INFO - Started process (PID=21195) to work on /opt/airflow/dags/test.py
[2025-04-04T22:03:55.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:03:55.269+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:55.266+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:03:55.365+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:55.365+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:03:55.376+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:03:55.432+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:55.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:03:55.487+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:03:55.487+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:03:55.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.329 seconds
[2025-04-04T22:04:25.802+0000] {processor.py:186} INFO - Started process (PID=21262) to work on /opt/airflow/dags/test.py
[2025-04-04T22:04:25.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:04:25.805+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:25.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:04:25.820+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:25.819+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:04:25.824+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:04:25.844+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:25.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:04:25.862+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:25.862+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:04:25.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.092 seconds
[2025-04-04T22:04:56.531+0000] {processor.py:186} INFO - Started process (PID=21329) to work on /opt/airflow/dags/test.py
[2025-04-04T22:04:56.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:04:56.535+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:56.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:04:56.561+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:56.561+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:04:56.566+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:04:56.594+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:56.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:04:56.617+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:04:56.617+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:04:56.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-04T22:05:27.568+0000] {processor.py:186} INFO - Started process (PID=21395) to work on /opt/airflow/dags/test.py
[2025-04-04T22:05:27.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:05:27.571+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:27.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:05:27.589+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:27.588+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:05:27.593+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:05:27.614+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:27.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:05:27.632+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:27.632+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:05:27.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-04T22:05:57.772+0000] {processor.py:186} INFO - Started process (PID=21461) to work on /opt/airflow/dags/test.py
[2025-04-04T22:05:57.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:05:57.775+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:57.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:05:57.796+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:57.795+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:05:57.801+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:05:57.823+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:57.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:05:57.844+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:05:57.844+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:05:57.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-04T22:06:28.337+0000] {processor.py:186} INFO - Started process (PID=21530) to work on /opt/airflow/dags/test.py
[2025-04-04T22:06:28.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:06:28.342+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:28.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:06:28.360+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:28.359+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:06:28.364+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:06:28.386+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:28.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:06:28.408+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:28.407+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:06:28.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-04T22:06:58.599+0000] {processor.py:186} INFO - Started process (PID=21595) to work on /opt/airflow/dags/test.py
[2025-04-04T22:06:58.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:06:58.603+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:58.602+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:06:58.622+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:58.622+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:06:58.627+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:06:58.650+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:58.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:06:58.668+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:06:58.668+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:06:58.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.248 seconds
[2025-04-04T22:07:41.854+0000] {processor.py:186} INFO - Started process (PID=21657) to work on /opt/airflow/dags/test.py
[2025-04-04T22:07:41.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:07:41.933+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:07:41.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:07:42.041+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:07:42.040+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:07:42.090+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:07:48.173+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:07:48.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:07:48.441+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:07:48.441+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:07:49.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 7.283 seconds
[2025-04-04T22:08:19.529+0000] {processor.py:186} INFO - Started process (PID=21700) to work on /opt/airflow/dags/test.py
[2025-04-04T22:08:19.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:08:19.552+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:19.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:08:19.624+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:19.623+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:08:19.630+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:08:19.714+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:19.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:08:19.772+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:19.771+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:08:19.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.344 seconds
[2025-04-04T22:08:51.005+0000] {processor.py:186} INFO - Started process (PID=21766) to work on /opt/airflow/dags/test.py
[2025-04-04T22:08:51.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:08:51.008+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:51.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:08:51.022+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:51.022+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:08:51.026+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:08:51.050+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:51.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:08:51.072+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:08:51.071+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:08:51.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T22:09:21.216+0000] {processor.py:186} INFO - Started process (PID=21832) to work on /opt/airflow/dags/test.py
[2025-04-04T22:09:21.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:09:21.219+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:21.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:09:21.236+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:21.236+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:09:21.241+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:09:21.267+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:21.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:09:21.289+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:21.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:09:21.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.131 seconds
[2025-04-04T22:09:51.497+0000] {processor.py:186} INFO - Started process (PID=21898) to work on /opt/airflow/dags/test.py
[2025-04-04T22:09:51.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:09:51.499+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:51.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:09:51.521+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:51.520+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:09:51.525+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:09:51.546+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:51.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:09:51.568+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:09:51.567+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:09:51.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-04T22:10:21.754+0000] {processor.py:186} INFO - Started process (PID=21961) to work on /opt/airflow/dags/test.py
[2025-04-04T22:10:21.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:10:21.757+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:21.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:10:21.774+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:21.774+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:10:21.779+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:10:21.802+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:21.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:10:21.820+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:21.820+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:10:21.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-04T22:10:52.311+0000] {processor.py:186} INFO - Started process (PID=22025) to work on /opt/airflow/dags/test.py
[2025-04-04T22:10:52.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:10:52.314+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:52.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:10:52.333+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:52.333+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:10:52.337+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:10:52.359+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:52.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:10:52.378+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:10:52.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:10:52.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-04T22:11:22.600+0000] {processor.py:186} INFO - Started process (PID=22085) to work on /opt/airflow/dags/test.py
[2025-04-04T22:11:22.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:11:22.603+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:22.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:11:22.626+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:22.625+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:11:22.630+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:11:22.652+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:22.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:11:22.671+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:22.671+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:11:22.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T22:11:53.127+0000] {processor.py:186} INFO - Started process (PID=22151) to work on /opt/airflow/dags/test.py
[2025-04-04T22:11:53.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:11:53.131+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:53.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:11:53.154+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:53.153+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:11:53.159+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:11:53.183+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:53.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:11:53.202+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:11:53.202+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:11:53.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-04T22:12:23.520+0000] {processor.py:186} INFO - Started process (PID=22216) to work on /opt/airflow/dags/test.py
[2025-04-04T22:12:23.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:12:23.532+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:23.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:12:23.557+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:23.557+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:12:23.561+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:12:23.582+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:23.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:12:23.602+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:23.602+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:12:23.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-04T22:12:53.766+0000] {processor.py:186} INFO - Started process (PID=22282) to work on /opt/airflow/dags/test.py
[2025-04-04T22:12:53.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:12:53.774+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:53.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:12:53.795+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:53.794+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:12:53.802+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:12:53.827+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:53.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:12:53.858+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:12:53.857+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:12:53.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-04T22:13:24.158+0000] {processor.py:186} INFO - Started process (PID=22361) to work on /opt/airflow/dags/test.py
[2025-04-04T22:13:24.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:13:24.162+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:24.161+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:13:24.189+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:24.189+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:13:24.197+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:13:24.237+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:24.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:13:24.268+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:24.267+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:13:24.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.165 seconds
[2025-04-04T22:13:54.528+0000] {processor.py:186} INFO - Started process (PID=22427) to work on /opt/airflow/dags/test.py
[2025-04-04T22:13:54.530+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:13:54.535+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:54.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:13:54.558+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:54.558+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:13:54.563+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:13:54.593+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:54.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:13:54.618+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:13:54.618+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:13:54.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.139 seconds
[2025-04-04T22:14:24.776+0000] {processor.py:186} INFO - Started process (PID=22493) to work on /opt/airflow/dags/test.py
[2025-04-04T22:14:24.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:14:24.779+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:24.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:14:24.804+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:24.804+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:14:24.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:14:24.832+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:24.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:14:24.858+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:24.858+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:14:24.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.130 seconds
[2025-04-04T22:14:55.056+0000] {processor.py:186} INFO - Started process (PID=22559) to work on /opt/airflow/dags/test.py
[2025-04-04T22:14:55.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:14:55.060+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:55.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:14:55.080+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:55.079+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:14:55.085+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:14:55.113+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:55.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:14:55.134+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:14:55.133+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:14:55.164+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-04T22:15:25.399+0000] {processor.py:186} INFO - Started process (PID=22625) to work on /opt/airflow/dags/test.py
[2025-04-04T22:15:25.400+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:15:25.402+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:25.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:15:25.423+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:25.423+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:15:25.429+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:15:25.451+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:25.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:15:25.493+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:25.492+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:15:25.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.160 seconds
[2025-04-04T22:15:55.935+0000] {processor.py:186} INFO - Started process (PID=22691) to work on /opt/airflow/dags/test.py
[2025-04-04T22:15:55.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:15:55.938+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:55.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:15:55.957+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:55.957+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:15:55.966+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:15:55.996+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:55.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:15:56.024+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:15:56.024+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:15:56.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-04T22:16:26.927+0000] {processor.py:186} INFO - Started process (PID=22758) to work on /opt/airflow/dags/test.py
[2025-04-04T22:16:26.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:16:26.931+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:26.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:16:26.953+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:26.953+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:16:26.957+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:16:26.980+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:26.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:16:27.003+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:27.002+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:16:27.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-04T22:16:57.254+0000] {processor.py:186} INFO - Started process (PID=22824) to work on /opt/airflow/dags/test.py
[2025-04-04T22:16:57.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:16:57.259+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:57.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:16:57.277+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:57.277+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:16:57.284+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:16:57.311+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:57.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:16:57.335+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:16:57.335+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:16:57.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.567 seconds
[2025-04-04T22:17:28.688+0000] {processor.py:186} INFO - Started process (PID=22890) to work on /opt/airflow/dags/test.py
[2025-04-04T22:17:28.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:17:28.692+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:28.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:17:28.713+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:28.712+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:17:28.718+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:17:28.741+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:28.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:17:28.768+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:28.768+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:17:28.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-04T22:17:59.459+0000] {processor.py:186} INFO - Started process (PID=22956) to work on /opt/airflow/dags/test.py
[2025-04-04T22:17:59.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:17:59.462+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:59.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:17:59.479+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:59.479+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:17:59.486+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:17:59.510+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:59.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:17:59.529+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:17:59.529+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:17:59.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T22:18:29.837+0000] {processor.py:186} INFO - Started process (PID=23022) to work on /opt/airflow/dags/test.py
[2025-04-04T22:18:29.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:18:29.840+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:18:29.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:18:29.875+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:18:29.874+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:18:29.881+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:18:29.907+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:18:29.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:18:29.930+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:18:29.929+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:18:29.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.139 seconds
[2025-04-04T22:19:00.200+0000] {processor.py:186} INFO - Started process (PID=23089) to work on /opt/airflow/dags/test.py
[2025-04-04T22:19:00.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:19:00.203+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:00.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:19:00.222+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:00.222+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:19:00.226+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:19:00.251+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:00.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:19:00.271+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:00.271+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:19:00.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-04T22:19:30.902+0000] {processor.py:186} INFO - Started process (PID=23156) to work on /opt/airflow/dags/test.py
[2025-04-04T22:19:30.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:19:30.905+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:30.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:19:30.927+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:30.926+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:19:30.931+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:19:30.954+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:30.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:19:30.974+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:19:30.974+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:19:31.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-04T22:20:01.470+0000] {processor.py:186} INFO - Started process (PID=23223) to work on /opt/airflow/dags/test.py
[2025-04-04T22:20:01.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:20:01.474+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:01.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:20:01.496+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:01.496+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:20:01.503+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:20:01.536+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:01.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:20:01.562+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:01.562+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:20:01.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-04T22:20:31.962+0000] {processor.py:186} INFO - Started process (PID=23291) to work on /opt/airflow/dags/test.py
[2025-04-04T22:20:31.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:20:31.965+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:31.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:20:31.988+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:31.988+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:20:31.992+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:20:32.021+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:32.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:20:32.048+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:20:32.047+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:20:32.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T22:21:02.327+0000] {processor.py:186} INFO - Started process (PID=23359) to work on /opt/airflow/dags/test.py
[2025-04-04T22:21:02.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:21:02.330+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:02.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:21:02.347+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:02.347+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:21:02.352+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:21:02.377+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:02.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:21:02.397+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:02.397+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:21:02.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-04T22:21:32.549+0000] {processor.py:186} INFO - Started process (PID=23426) to work on /opt/airflow/dags/test.py
[2025-04-04T22:21:32.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:21:32.553+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:32.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:21:32.574+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:32.573+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:21:32.578+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:21:32.604+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:32.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:21:32.623+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:21:32.622+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:21:32.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-04T22:22:03.139+0000] {processor.py:186} INFO - Started process (PID=23494) to work on /opt/airflow/dags/test.py
[2025-04-04T22:22:03.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:22:03.144+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:03.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:22:03.169+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:03.168+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:22:03.175+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:22:03.205+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:03.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:22:03.230+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:03.230+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:22:03.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-04T22:22:34.182+0000] {processor.py:186} INFO - Started process (PID=23563) to work on /opt/airflow/dags/test.py
[2025-04-04T22:22:34.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:22:34.185+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:34.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:22:34.203+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:34.202+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:22:34.206+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:22:34.228+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:34.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:22:34.248+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:22:34.248+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:22:34.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-04T22:23:04.876+0000] {processor.py:186} INFO - Started process (PID=23629) to work on /opt/airflow/dags/test.py
[2025-04-04T22:23:04.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:23:04.880+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:04.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:23:04.899+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:04.899+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:23:04.904+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:23:04.928+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:04.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:23:04.948+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:04.948+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:23:04.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-04T22:23:35.717+0000] {processor.py:186} INFO - Started process (PID=23698) to work on /opt/airflow/dags/test.py
[2025-04-04T22:23:35.718+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:23:35.720+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:35.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:23:35.735+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:35.735+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:23:35.739+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:23:35.764+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:35.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:23:35.783+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:23:35.783+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:23:35.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T22:24:05.983+0000] {processor.py:186} INFO - Started process (PID=23763) to work on /opt/airflow/dags/test.py
[2025-04-04T22:24:05.985+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:24:05.988+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:05.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:24:06.010+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:06.009+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:24:06.024+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:24:06.048+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:06.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:24:06.073+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:06.073+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:24:06.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T22:24:36.434+0000] {processor.py:186} INFO - Started process (PID=23830) to work on /opt/airflow/dags/test.py
[2025-04-04T22:24:36.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:24:36.437+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:36.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:24:36.461+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:36.461+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:24:36.465+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:24:36.490+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:36.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:24:36.509+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:24:36.509+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:24:36.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-04T22:25:06.899+0000] {processor.py:186} INFO - Started process (PID=23897) to work on /opt/airflow/dags/test.py
[2025-04-04T22:25:06.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:25:06.903+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:06.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:25:06.921+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:06.921+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:25:06.925+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:25:06.947+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:06.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:25:06.965+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:06.964+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:25:06.996+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-04T22:25:37.871+0000] {processor.py:186} INFO - Started process (PID=23966) to work on /opt/airflow/dags/test.py
[2025-04-04T22:25:37.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:25:37.874+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:37.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:25:37.894+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:37.893+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:25:37.899+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:25:37.923+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:37.922+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:25:37.947+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:25:37.947+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:25:37.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-04T22:26:08.285+0000] {processor.py:186} INFO - Started process (PID=24032) to work on /opt/airflow/dags/test.py
[2025-04-04T22:26:08.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:26:08.288+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:08.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:26:08.315+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:08.315+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:26:08.321+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:26:08.350+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:08.350+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:26:08.374+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:08.374+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:26:08.409+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-04T22:26:38.676+0000] {processor.py:186} INFO - Started process (PID=24097) to work on /opt/airflow/dags/test.py
[2025-04-04T22:26:38.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:26:38.680+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:38.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:26:38.706+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:38.706+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:26:38.712+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:26:38.741+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:38.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:26:38.762+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:26:38.762+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:26:38.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-04T22:27:09.152+0000] {processor.py:186} INFO - Started process (PID=24164) to work on /opt/airflow/dags/test.py
[2025-04-04T22:27:09.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:27:09.155+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:09.154+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:27:09.176+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:09.175+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:27:09.181+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:27:09.212+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:09.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:27:09.239+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:09.239+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:27:09.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.135 seconds
[2025-04-04T22:27:39.763+0000] {processor.py:186} INFO - Started process (PID=24230) to work on /opt/airflow/dags/test.py
[2025-04-04T22:27:39.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:27:39.766+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:39.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:27:39.783+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:39.783+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:27:39.787+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:27:39.809+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:39.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:27:39.827+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:27:39.827+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:27:39.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-04T22:28:10.347+0000] {processor.py:186} INFO - Started process (PID=24296) to work on /opt/airflow/dags/test.py
[2025-04-04T22:28:10.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:28:10.353+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:10.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:28:10.380+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:10.380+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:28:10.392+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:28:10.436+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:10.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:28:10.487+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:10.487+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:28:10.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.253 seconds
[2025-04-04T22:28:40.827+0000] {processor.py:186} INFO - Started process (PID=24363) to work on /opt/airflow/dags/test.py
[2025-04-04T22:28:40.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:28:40.830+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:40.829+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:28:40.846+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:40.846+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:28:40.851+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:28:40.878+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:40.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:28:40.902+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:28:40.902+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:28:40.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-04T22:29:11.433+0000] {processor.py:186} INFO - Started process (PID=24429) to work on /opt/airflow/dags/test.py
[2025-04-04T22:29:11.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:29:11.436+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:11.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:29:11.457+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:11.456+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:29:11.461+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:29:11.489+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:11.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:29:11.516+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:11.515+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:29:11.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-04T22:29:41.961+0000] {processor.py:186} INFO - Started process (PID=24496) to work on /opt/airflow/dags/test.py
[2025-04-04T22:29:41.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:29:41.964+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:41.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:29:41.980+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:41.980+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:29:41.985+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:29:42.007+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:42.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:29:42.025+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:29:42.025+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:29:42.054+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-04T22:30:12.452+0000] {processor.py:186} INFO - Started process (PID=24563) to work on /opt/airflow/dags/test.py
[2025-04-04T22:30:12.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:30:12.455+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:12.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:30:12.476+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:12.476+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:30:12.482+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:30:12.511+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:12.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:30:12.542+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:12.542+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:30:12.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.131 seconds
[2025-04-04T22:30:43.161+0000] {processor.py:186} INFO - Started process (PID=24631) to work on /opt/airflow/dags/test.py
[2025-04-04T22:30:43.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:30:43.164+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:43.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:30:43.184+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:43.184+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:30:43.189+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:30:43.211+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:43.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:30:43.230+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:30:43.229+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:30:43.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-04T22:31:13.962+0000] {processor.py:186} INFO - Started process (PID=24699) to work on /opt/airflow/dags/test.py
[2025-04-04T22:31:13.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:31:13.964+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:13.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:31:13.983+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:13.983+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:31:13.987+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:31:14.012+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:14.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:31:14.032+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:14.032+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:31:14.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-04T22:31:44.159+0000] {processor.py:186} INFO - Started process (PID=24766) to work on /opt/airflow/dags/test.py
[2025-04-04T22:31:44.160+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:31:44.162+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:44.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:31:44.178+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:44.178+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:31:44.183+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:31:44.214+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:44.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:31:44.243+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:31:44.243+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:31:44.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-04T22:32:14.835+0000] {processor.py:186} INFO - Started process (PID=24833) to work on /opt/airflow/dags/test.py
[2025-04-04T22:32:14.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:32:14.839+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:14.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:32:14.858+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:14.858+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:32:14.864+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:32:14.892+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:14.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:32:14.950+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:14.949+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:32:14.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.158 seconds
[2025-04-04T22:32:45.175+0000] {processor.py:186} INFO - Started process (PID=24901) to work on /opt/airflow/dags/test.py
[2025-04-04T22:32:45.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:32:45.178+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:45.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:32:45.199+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:45.199+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:32:45.203+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:32:45.226+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:45.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:32:45.244+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:32:45.244+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:32:45.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T22:33:15.385+0000] {processor.py:186} INFO - Started process (PID=24968) to work on /opt/airflow/dags/test.py
[2025-04-04T22:33:15.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:33:15.388+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:15.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:33:15.406+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:15.406+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:33:15.410+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:33:15.433+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:15.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:33:15.450+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:15.450+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:33:15.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-04T22:33:48.633+0000] {processor.py:186} INFO - Started process (PID=25042) to work on /opt/airflow/dags/test.py
[2025-04-04T22:33:48.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:33:48.637+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:48.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:33:48.666+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:48.665+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:33:48.672+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:33:48.697+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:48.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:33:48.716+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:33:48.715+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:33:48.746+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-04T22:34:18.932+0000] {processor.py:186} INFO - Started process (PID=25108) to work on /opt/airflow/dags/test.py
[2025-04-04T22:34:18.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:34:18.937+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:18.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:34:18.964+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:18.964+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:34:18.971+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:34:19.001+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:19.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:34:19.033+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:19.032+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:34:19.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.177 seconds
[2025-04-04T22:34:49.673+0000] {processor.py:186} INFO - Started process (PID=25176) to work on /opt/airflow/dags/test.py
[2025-04-04T22:34:49.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:34:49.678+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:49.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:34:49.705+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:49.705+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:34:49.711+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:34:49.739+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:49.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:34:49.767+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:34:49.766+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:34:49.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-04T22:35:19.900+0000] {processor.py:186} INFO - Started process (PID=25243) to work on /opt/airflow/dags/test.py
[2025-04-04T22:35:19.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:35:19.910+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:19.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:35:19.936+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:19.935+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:35:19.941+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:35:19.966+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:19.966+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:35:19.988+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:19.988+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:35:20.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-04T22:35:50.814+0000] {processor.py:186} INFO - Started process (PID=25310) to work on /opt/airflow/dags/test.py
[2025-04-04T22:35:50.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:35:50.819+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:50.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:35:50.849+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:50.849+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:35:50.856+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:35:50.879+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:50.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:35:50.897+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:35:50.897+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:35:50.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.130 seconds
[2025-04-04T22:36:21.924+0000] {processor.py:186} INFO - Started process (PID=25377) to work on /opt/airflow/dags/test.py
[2025-04-04T22:36:21.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:36:21.927+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:21.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:36:21.943+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:21.943+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:36:21.947+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:36:21.969+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:21.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:36:21.987+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:21.986+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:36:22.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.279 seconds
[2025-04-04T22:36:52.311+0000] {processor.py:186} INFO - Started process (PID=25445) to work on /opt/airflow/dags/test.py
[2025-04-04T22:36:52.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:36:52.314+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:52.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:36:52.333+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:52.332+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:36:52.336+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:36:52.359+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:52.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:36:52.378+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:36:52.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:36:52.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-04T22:37:22.770+0000] {processor.py:186} INFO - Started process (PID=25512) to work on /opt/airflow/dags/test.py
[2025-04-04T22:37:22.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:37:22.773+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:22.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:37:22.789+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:22.788+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:37:22.793+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:37:22.816+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:22.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:37:22.835+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:22.835+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:37:22.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-04T22:37:53.190+0000] {processor.py:186} INFO - Started process (PID=25579) to work on /opt/airflow/dags/test.py
[2025-04-04T22:37:53.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:37:53.194+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:53.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:37:53.213+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:53.213+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:37:53.217+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:37:53.237+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:53.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:37:53.256+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:37:53.255+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:37:53.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-04T22:38:23.450+0000] {processor.py:186} INFO - Started process (PID=25646) to work on /opt/airflow/dags/test.py
[2025-04-04T22:38:23.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:38:23.454+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:23.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:38:23.476+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:23.475+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:38:23.481+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:38:23.507+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:23.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:38:23.533+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:23.533+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:38:23.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-04T22:38:53.877+0000] {processor.py:186} INFO - Started process (PID=25713) to work on /opt/airflow/dags/test.py
[2025-04-04T22:38:53.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-04T22:38:53.881+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:53.880+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-04T22:38:53.906+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:53.906+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-04T22:38:53.913+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-04T22:38:53.943+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:53.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-04T22:38:53.970+0000] {logging_mixin.py:190} INFO - [2025-04-04T22:38:53.970+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-04T22:38:54.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.141 seconds
