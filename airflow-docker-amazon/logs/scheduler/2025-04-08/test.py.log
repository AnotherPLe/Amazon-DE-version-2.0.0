[2025-04-08T03:13:33.096+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/test.py
[2025-04-08T03:13:33.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:13:33.106+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:33.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:13:33.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:33.124+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:13:33.130+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:13:33.161+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:33.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:13:33.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:33.188+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:13:33.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.242 seconds
[2025-04-08T03:14:03.730+0000] {processor.py:186} INFO - Started process (PID=159) to work on /opt/airflow/dags/test.py
[2025-04-08T03:14:03.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:14:03.735+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:03.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:14:03.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:03.748+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:14:03.752+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:14:03.775+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:03.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:14:03.796+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:03.796+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:14:03.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T03:14:33.946+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/test.py
[2025-04-08T03:14:33.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:14:33.953+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:33.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:14:33.970+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:33.970+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:14:33.976+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:14:34.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:34.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:14:34.019+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:34.019+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:14:34.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T03:15:04.198+0000] {processor.py:186} INFO - Started process (PID=296) to work on /opt/airflow/dags/test.py
[2025-04-08T03:15:04.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:15:04.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:04.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:15:04.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:04.217+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:15:04.222+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:15:04.245+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:04.245+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:15:04.266+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:04.266+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:15:04.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-08T03:15:34.740+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/test.py
[2025-04-08T03:15:34.741+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:15:34.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:34.746+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:15:34.766+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:34.766+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:15:34.770+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:15:34.797+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:34.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:15:34.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:34.814+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:15:34.841+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T03:16:05.419+0000] {processor.py:186} INFO - Started process (PID=434) to work on /opt/airflow/dags/test.py
[2025-04-08T03:16:05.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:16:05.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:05.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:16:05.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:05.445+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:16:05.451+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:16:05.477+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:05.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:16:05.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:05.498+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:16:05.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-08T03:16:36.581+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/test.py
[2025-04-08T03:16:36.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:16:36.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:36.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:16:36.600+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:36.600+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:16:36.604+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:16:36.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:36.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:16:36.643+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:36.642+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:16:36.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T03:17:07.180+0000] {processor.py:186} INFO - Started process (PID=572) to work on /opt/airflow/dags/test.py
[2025-04-08T03:17:07.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:17:07.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:07.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:17:07.205+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:07.204+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:17:07.212+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:17:07.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:07.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:17:07.278+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:07.278+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:17:07.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.142 seconds
[2025-04-08T03:17:37.791+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/test.py
[2025-04-08T03:17:37.793+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:17:37.797+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:37.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:17:37.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:37.819+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:17:37.826+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:17:37.847+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:37.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:17:37.868+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:37.868+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:17:37.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-08T03:18:27.570+0000] {processor.py:186} INFO - Started process (PID=720) to work on /opt/airflow/dags/test.py
[2025-04-08T03:18:27.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:18:27.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:27.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:18:27.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:27.621+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:18:27.625+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:18:27.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:27.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:18:27.668+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:27.668+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:18:27.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.294 seconds
[2025-04-08T03:18:57.953+0000] {processor.py:186} INFO - Started process (PID=788) to work on /opt/airflow/dags/test.py
[2025-04-08T03:18:57.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:18:57.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:57.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:18:57.975+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:57.974+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:18:57.978+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:18:57.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:57.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:18:58.018+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:58.018+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:18:58.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T03:19:28.980+0000] {processor.py:186} INFO - Started process (PID=848) to work on /opt/airflow/dags/test.py
[2025-04-08T03:19:28.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:19:28.985+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:28.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:19:29.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:29.004+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:19:29.010+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:19:29.033+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:29.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:19:29.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:29.062+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:19:29.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T03:19:59.877+0000] {processor.py:186} INFO - Started process (PID=915) to work on /opt/airflow/dags/test.py
[2025-04-08T03:19:59.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:19:59.885+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:59.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:19:59.924+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:59.924+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:19:59.932+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:19:59.966+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:59.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:19:59.993+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:59.993+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:20:00.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.162 seconds
[2025-04-08T03:20:30.224+0000] {processor.py:186} INFO - Started process (PID=990) to work on /opt/airflow/dags/test.py
[2025-04-08T03:20:30.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:20:30.231+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:30.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:20:30.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:30.254+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:20:30.261+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:20:30.292+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:30.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:20:30.316+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:30.316+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:20:30.340+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T03:21:00.954+0000] {processor.py:186} INFO - Started process (PID=1059) to work on /opt/airflow/dags/test.py
[2025-04-08T03:21:00.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:21:00.965+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:00.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:21:00.990+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:00.989+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:21:01.002+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:21:01.050+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:01.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:21:01.092+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:01.092+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:21:01.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.213 seconds
[2025-04-08T03:21:31.385+0000] {processor.py:186} INFO - Started process (PID=1128) to work on /opt/airflow/dags/test.py
[2025-04-08T03:21:31.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:21:31.390+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:31.390+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:21:31.411+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:31.411+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:21:31.416+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:21:31.468+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:31.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:21:31.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:31.518+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:21:31.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.203 seconds
[2025-04-08T03:22:01.798+0000] {processor.py:186} INFO - Started process (PID=1198) to work on /opt/airflow/dags/test.py
[2025-04-08T03:22:01.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:22:01.805+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:01.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:22:01.824+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:01.823+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:22:01.830+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:22:01.863+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:01.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:22:01.897+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:01.896+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:22:01.925+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-08T03:22:32.342+0000] {processor.py:186} INFO - Started process (PID=1267) to work on /opt/airflow/dags/test.py
[2025-04-08T03:22:32.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:22:32.349+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:32.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:22:32.367+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:32.366+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:22:32.373+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:22:32.399+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:32.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:22:32.422+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:32.422+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:22:32.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-08T03:23:03.068+0000] {processor.py:186} INFO - Started process (PID=1337) to work on /opt/airflow/dags/test.py
[2025-04-08T03:23:03.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:23:03.077+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:03.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:23:03.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:03.107+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:23:03.115+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:23:03.154+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:03.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:23:03.185+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:03.185+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:23:03.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.181 seconds
[2025-04-08T03:23:33.457+0000] {processor.py:186} INFO - Started process (PID=1406) to work on /opt/airflow/dags/test.py
[2025-04-08T03:23:33.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:23:33.466+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:33.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:23:33.489+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:33.488+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:23:33.494+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:23:33.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:33.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:23:33.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:33.536+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:23:33.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.239 seconds
[2025-04-08T03:24:04.631+0000] {processor.py:186} INFO - Started process (PID=1475) to work on /opt/airflow/dags/test.py
[2025-04-08T03:24:04.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:24:04.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:04.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:24:04.654+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:04.654+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:24:04.658+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:24:04.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:04.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:24:04.699+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:04.699+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:24:05.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.430 seconds
[2025-04-08T03:24:35.867+0000] {processor.py:186} INFO - Started process (PID=1544) to work on /opt/airflow/dags/test.py
[2025-04-08T03:24:35.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:24:35.872+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:35.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:24:35.887+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:35.886+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:24:35.892+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:24:35.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:35.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:24:35.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:35.933+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:24:35.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T03:25:06.448+0000] {processor.py:186} INFO - Started process (PID=1612) to work on /opt/airflow/dags/test.py
[2025-04-08T03:25:06.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:25:06.454+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:06.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:25:06.483+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:06.482+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:25:06.490+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:25:06.521+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:06.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:25:06.546+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:06.545+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:25:06.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.150 seconds
[2025-04-08T03:25:37.508+0000] {processor.py:186} INFO - Started process (PID=1681) to work on /opt/airflow/dags/test.py
[2025-04-08T03:25:37.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:25:37.513+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:37.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:25:37.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:37.536+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:25:37.543+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:25:37.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:37.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:25:37.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:37.586+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:25:37.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T03:26:07.780+0000] {processor.py:186} INFO - Started process (PID=1750) to work on /opt/airflow/dags/test.py
[2025-04-08T03:26:07.788+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:26:07.797+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:07.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:26:07.845+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:07.844+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:26:07.852+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:26:07.879+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:07.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:26:07.902+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:07.902+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:26:07.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.160 seconds
[2025-04-08T03:26:38.018+0000] {processor.py:186} INFO - Started process (PID=1819) to work on /opt/airflow/dags/test.py
[2025-04-08T03:26:38.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:26:38.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:38.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:26:38.043+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:38.042+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:26:38.047+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:26:38.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:38.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:26:38.095+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:38.094+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:26:38.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T03:27:08.315+0000] {processor.py:186} INFO - Started process (PID=1889) to work on /opt/airflow/dags/test.py
[2025-04-08T03:27:08.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:27:08.321+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:08.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:27:08.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:08.338+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:27:08.343+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:27:08.370+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:08.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:27:08.393+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:08.392+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:27:08.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-08T03:27:38.815+0000] {processor.py:186} INFO - Started process (PID=1959) to work on /opt/airflow/dags/test.py
[2025-04-08T03:27:38.816+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:27:38.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:38.819+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:27:38.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:38.839+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:27:38.843+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:27:38.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:38.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:27:38.886+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:38.886+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:27:38.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T03:28:09.031+0000] {processor.py:186} INFO - Started process (PID=2028) to work on /opt/airflow/dags/test.py
[2025-04-08T03:28:09.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:28:09.037+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:09.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:28:09.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:09.055+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:28:09.059+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:28:09.085+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:09.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:28:09.106+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:09.106+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:28:09.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T03:28:39.299+0000] {processor.py:186} INFO - Started process (PID=2097) to work on /opt/airflow/dags/test.py
[2025-04-08T03:28:39.300+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:28:39.303+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:39.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:28:39.324+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:39.323+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:28:39.329+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:28:39.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:39.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:28:39.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:39.371+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:28:39.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T03:29:10.173+0000] {processor.py:186} INFO - Started process (PID=2166) to work on /opt/airflow/dags/test.py
[2025-04-08T03:29:10.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:29:10.178+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:10.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:29:10.196+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:10.196+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:29:10.203+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:29:10.237+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:10.237+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:29:10.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:10.260+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:29:10.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-08T03:29:40.472+0000] {processor.py:186} INFO - Started process (PID=2235) to work on /opt/airflow/dags/test.py
[2025-04-08T03:29:40.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:29:40.477+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:40.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:29:40.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:40.498+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:29:40.502+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:29:40.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:40.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:29:40.541+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:40.541+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:29:40.570+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T03:30:10.952+0000] {processor.py:186} INFO - Started process (PID=2304) to work on /opt/airflow/dags/test.py
[2025-04-08T03:30:10.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:30:10.956+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:10.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:30:10.974+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:10.974+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:30:10.978+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:30:10.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:10.998+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:30:11.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:11.023+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:30:11.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T03:30:41.515+0000] {processor.py:186} INFO - Started process (PID=2373) to work on /opt/airflow/dags/test.py
[2025-04-08T03:30:41.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:30:41.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:41.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:30:41.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:41.536+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:30:41.540+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:30:41.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:41.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:30:41.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:41.749+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:30:41.788+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.280 seconds
[2025-04-08T03:31:11.964+0000] {processor.py:186} INFO - Started process (PID=2442) to work on /opt/airflow/dags/test.py
[2025-04-08T03:31:11.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:31:11.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:11.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:31:11.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:11.989+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:31:11.993+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:31:12.015+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:12.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:31:12.220+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:12.220+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:31:12.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.298 seconds
[2025-04-08T03:31:42.618+0000] {processor.py:186} INFO - Started process (PID=2510) to work on /opt/airflow/dags/test.py
[2025-04-08T03:31:42.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:31:42.622+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:42.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:31:42.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:42.637+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:31:42.641+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:31:42.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:42.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:31:42.678+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:42.678+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:31:42.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T03:32:12.807+0000] {processor.py:186} INFO - Started process (PID=2580) to work on /opt/airflow/dags/test.py
[2025-04-08T03:32:12.809+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:32:12.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:12.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:32:12.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:12.829+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:32:12.833+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:32:12.854+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:12.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:32:12.875+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:12.874+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:32:12.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T03:32:43.526+0000] {processor.py:186} INFO - Started process (PID=2649) to work on /opt/airflow/dags/test.py
[2025-04-08T03:32:43.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:32:43.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:43.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:32:43.563+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:43.563+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:32:43.570+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:32:43.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:43.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:32:43.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:43.656+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:32:43.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.436 seconds
[2025-04-08T03:33:15.241+0000] {processor.py:186} INFO - Started process (PID=2718) to work on /opt/airflow/dags/test.py
[2025-04-08T03:33:15.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:33:15.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:15.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:33:15.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:15.281+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:33:15.285+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:33:15.306+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:15.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:33:15.323+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:15.323+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:33:15.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.342 seconds
[2025-04-08T03:33:45.696+0000] {processor.py:186} INFO - Started process (PID=2786) to work on /opt/airflow/dags/test.py
[2025-04-08T03:33:45.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:33:45.701+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:45.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:33:45.715+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:45.715+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:33:45.719+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:33:45.739+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:45.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:33:45.757+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:45.757+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:33:45.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T03:34:15.890+0000] {processor.py:186} INFO - Started process (PID=2854) to work on /opt/airflow/dags/test.py
[2025-04-08T03:34:15.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:34:15.895+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:15.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:34:15.921+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:15.920+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:34:15.924+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:34:15.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:15.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:34:15.964+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:15.964+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:34:15.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T03:34:46.506+0000] {processor.py:186} INFO - Started process (PID=2922) to work on /opt/airflow/dags/test.py
[2025-04-08T03:34:46.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:34:46.512+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:46.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:34:46.531+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:46.531+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:34:46.537+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:34:46.558+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:46.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:34:46.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:46.577+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:34:46.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-08T03:35:17.573+0000] {processor.py:186} INFO - Started process (PID=2991) to work on /opt/airflow/dags/test.py
[2025-04-08T03:35:17.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:35:17.584+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:17.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:35:17.625+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:17.623+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:35:17.643+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:35:17.731+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:17.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:35:17.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:17.786+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:35:17.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.312 seconds
[2025-04-08T03:35:48.259+0000] {processor.py:186} INFO - Started process (PID=3060) to work on /opt/airflow/dags/test.py
[2025-04-08T03:35:48.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:35:48.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:48.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:35:48.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:48.288+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:35:48.293+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:35:48.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:48.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:35:48.349+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:48.348+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:35:49.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.770 seconds
[2025-04-08T03:36:19.148+0000] {processor.py:186} INFO - Started process (PID=3129) to work on /opt/airflow/dags/test.py
[2025-04-08T03:36:19.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:36:19.154+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:19.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:36:19.178+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:19.178+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:36:19.183+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:36:19.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:19.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:36:19.225+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:19.225+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:36:19.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T03:36:49.375+0000] {processor.py:186} INFO - Started process (PID=3198) to work on /opt/airflow/dags/test.py
[2025-04-08T03:36:49.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:36:49.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:49.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:36:49.404+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:49.403+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:36:49.409+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:36:49.444+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:49.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:36:49.477+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:49.477+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:36:49.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.527 seconds
[2025-04-08T03:37:20.355+0000] {processor.py:186} INFO - Started process (PID=3267) to work on /opt/airflow/dags/test.py
[2025-04-08T03:37:20.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:37:20.362+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:20.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:37:20.392+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:20.392+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:37:20.397+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:37:20.433+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:20.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:37:20.467+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:20.467+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:37:20.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.153 seconds
[2025-04-08T03:37:51.205+0000] {processor.py:186} INFO - Started process (PID=3337) to work on /opt/airflow/dags/test.py
[2025-04-08T03:37:51.207+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:37:51.211+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:51.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:37:51.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:51.229+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:37:51.235+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:37:51.257+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:51.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:37:51.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:51.279+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:37:51.310+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T03:38:22.025+0000] {processor.py:186} INFO - Started process (PID=3406) to work on /opt/airflow/dags/test.py
[2025-04-08T03:38:22.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:38:22.030+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:22.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:38:22.047+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:22.047+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:38:22.051+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:38:22.072+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:22.072+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:38:22.092+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:22.091+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:38:22.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T03:38:52.334+0000] {processor.py:186} INFO - Started process (PID=3475) to work on /opt/airflow/dags/test.py
[2025-04-08T03:38:52.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:38:52.341+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:52.340+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:38:52.361+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:52.361+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:38:52.367+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:38:52.392+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:52.391+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:38:52.415+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:52.415+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:38:52.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-08T03:39:23.361+0000] {processor.py:186} INFO - Started process (PID=3562) to work on /opt/airflow/dags/test.py
[2025-04-08T03:39:23.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:39:23.377+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:23.376+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:39:23.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:23.446+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:39:23.478+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:39:23.524+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:23.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:39:23.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:23.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:39:23.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.327 seconds
[2025-04-08T03:39:53.938+0000] {processor.py:186} INFO - Started process (PID=3631) to work on /opt/airflow/dags/test.py
[2025-04-08T03:39:53.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:39:53.949+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:53.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:39:53.970+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:53.970+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:39:53.980+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:39:54.016+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:54.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:39:54.048+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:54.048+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:39:54.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.172 seconds
[2025-04-08T03:40:24.904+0000] {processor.py:186} INFO - Started process (PID=3700) to work on /opt/airflow/dags/test.py
[2025-04-08T03:40:24.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:40:24.909+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:24.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:40:24.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:24.929+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:40:24.935+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:40:24.957+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:24.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:40:24.978+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:24.978+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:40:25.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T03:40:55.738+0000] {processor.py:186} INFO - Started process (PID=3769) to work on /opt/airflow/dags/test.py
[2025-04-08T03:40:55.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:40:55.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:55.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:40:55.760+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:55.760+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:40:55.768+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:40:55.788+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:55.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:40:55.806+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:55.806+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:40:55.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T03:41:26.267+0000] {processor.py:186} INFO - Started process (PID=3838) to work on /opt/airflow/dags/test.py
[2025-04-08T03:41:26.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:41:26.272+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:26.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:41:26.290+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:26.289+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:41:26.299+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:41:26.325+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:26.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:41:26.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:26.342+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:41:26.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T03:41:56.564+0000] {processor.py:186} INFO - Started process (PID=3907) to work on /opt/airflow/dags/test.py
[2025-04-08T03:41:56.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:41:56.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:56.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:41:56.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:56.586+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:41:56.591+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:41:56.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:56.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:41:56.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:56.635+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:41:56.666+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T03:42:26.854+0000] {processor.py:186} INFO - Started process (PID=3975) to work on /opt/airflow/dags/test.py
[2025-04-08T03:42:26.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:42:26.860+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:26.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:42:26.883+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:26.882+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:42:26.887+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:42:26.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:26.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:42:26.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:26.930+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:42:26.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T03:42:57.074+0000] {processor.py:186} INFO - Started process (PID=4044) to work on /opt/airflow/dags/test.py
[2025-04-08T03:42:57.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:42:57.078+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:57.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:42:57.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:57.090+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:42:57.094+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:42:57.113+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:57.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:42:57.130+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:57.130+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:42:57.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.088 seconds
[2025-04-08T03:43:27.937+0000] {processor.py:186} INFO - Started process (PID=4113) to work on /opt/airflow/dags/test.py
[2025-04-08T03:43:27.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:43:27.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:27.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:43:27.961+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:27.961+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:43:27.966+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:43:27.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:27.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:43:28.009+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:28.008+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:43:28.035+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T03:43:58.181+0000] {processor.py:186} INFO - Started process (PID=4182) to work on /opt/airflow/dags/test.py
[2025-04-08T03:43:58.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:43:58.186+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:58.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:43:58.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:58.202+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:43:58.206+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:43:58.227+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:58.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:43:58.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:58.246+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:43:58.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T03:44:28.776+0000] {processor.py:186} INFO - Started process (PID=4251) to work on /opt/airflow/dags/test.py
[2025-04-08T03:44:28.778+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:44:28.782+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:28.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:44:28.803+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:28.803+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:44:28.808+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:44:28.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:28.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:44:28.862+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:28.862+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:44:28.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.138 seconds
[2025-04-08T03:44:59.174+0000] {processor.py:186} INFO - Started process (PID=4319) to work on /opt/airflow/dags/test.py
[2025-04-08T03:44:59.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:44:59.178+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:59.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:44:59.190+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:59.190+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:44:59.194+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:44:59.217+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:59.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:44:59.236+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:59.236+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:44:59.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T03:45:30.467+0000] {processor.py:186} INFO - Started process (PID=4388) to work on /opt/airflow/dags/test.py
[2025-04-08T03:45:30.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:45:30.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:30.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:45:30.491+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:30.491+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:45:30.497+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:45:30.522+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:30.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:45:30.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:30.541+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:45:30.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.235 seconds
[2025-04-08T03:46:00.929+0000] {processor.py:186} INFO - Started process (PID=4457) to work on /opt/airflow/dags/test.py
[2025-04-08T03:46:00.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:46:00.935+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:00.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:46:00.957+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:00.957+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:46:00.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:46:00.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:00.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:46:01.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:01.000+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:46:01.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T03:46:31.178+0000] {processor.py:186} INFO - Started process (PID=4526) to work on /opt/airflow/dags/test.py
[2025-04-08T03:46:31.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:46:31.185+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:31.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:46:31.211+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:31.210+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:46:31.218+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:46:31.248+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:31.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:46:31.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:31.278+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:46:31.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.164 seconds
[2025-04-08T03:47:02.004+0000] {processor.py:186} INFO - Started process (PID=4595) to work on /opt/airflow/dags/test.py
[2025-04-08T03:47:02.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:47:02.009+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:02.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:47:02.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:02.041+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:47:02.045+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:47:02.068+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:02.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:47:02.099+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:02.098+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:47:02.144+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.153 seconds
[2025-04-08T03:47:32.377+0000] {processor.py:186} INFO - Started process (PID=4664) to work on /opt/airflow/dags/test.py
[2025-04-08T03:47:32.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:47:32.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:32.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:47:32.399+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:32.399+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:47:32.403+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:47:32.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:32.424+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:47:32.443+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:32.443+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:47:32.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T03:48:02.700+0000] {processor.py:186} INFO - Started process (PID=4731) to work on /opt/airflow/dags/test.py
[2025-04-08T03:48:02.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:48:02.705+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:02.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:48:02.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:02.722+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:48:02.728+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:48:02.765+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:02.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:48:02.795+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:02.795+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:48:02.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-08T03:48:33.315+0000] {processor.py:186} INFO - Started process (PID=4799) to work on /opt/airflow/dags/test.py
[2025-04-08T03:48:33.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:48:33.320+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:33.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:48:33.334+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:33.334+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:48:33.340+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:48:33.373+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:33.373+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:48:33.399+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:33.399+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:48:33.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-08T03:49:03.554+0000] {processor.py:186} INFO - Started process (PID=4863) to work on /opt/airflow/dags/test.py
[2025-04-08T03:49:03.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:49:03.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:03.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:49:03.580+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:03.579+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:49:03.587+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:49:03.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:03.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:49:03.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:03.632+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:49:03.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T03:49:34.169+0000] {processor.py:186} INFO - Started process (PID=4938) to work on /opt/airflow/dags/test.py
[2025-04-08T03:49:34.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:49:34.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:34.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:49:34.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:34.194+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:49:34.200+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:49:34.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:34.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:49:34.242+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:34.241+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:49:34.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T03:50:04.893+0000] {processor.py:186} INFO - Started process (PID=5007) to work on /opt/airflow/dags/test.py
[2025-04-08T03:50:04.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:50:04.897+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:04.897+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:50:04.913+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:04.913+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:50:04.917+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:50:04.936+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:04.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:50:04.953+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:04.952+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:50:04.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T03:50:38.600+0000] {processor.py:186} INFO - Started process (PID=5076) to work on /opt/airflow/dags/test.py
[2025-04-08T03:50:38.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:50:38.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:38.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:50:38.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:38.624+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:50:38.629+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:50:38.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:38.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:50:38.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:38.670+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:50:38.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.168 seconds
[2025-04-08T03:51:09.403+0000] {processor.py:186} INFO - Started process (PID=5143) to work on /opt/airflow/dags/test.py
[2025-04-08T03:51:09.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:51:09.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:09.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:51:09.422+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:09.422+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:51:09.427+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:51:09.447+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:09.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:51:09.466+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:09.466+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:51:09.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T03:51:39.608+0000] {processor.py:186} INFO - Started process (PID=5212) to work on /opt/airflow/dags/test.py
[2025-04-08T03:51:39.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:51:39.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:39.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:51:39.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:39.633+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:51:39.638+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:51:39.660+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:39.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:51:39.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:39.679+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:51:39.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T03:52:10.002+0000] {processor.py:186} INFO - Started process (PID=5281) to work on /opt/airflow/dags/test.py
[2025-04-08T03:52:10.003+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:52:10.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:10.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:52:10.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:10.027+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:52:10.031+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:52:10.053+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:10.052+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:52:10.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:10.069+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:52:10.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T03:52:40.626+0000] {processor.py:186} INFO - Started process (PID=5350) to work on /opt/airflow/dags/test.py
[2025-04-08T03:52:40.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:52:40.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:40.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:52:40.646+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:40.646+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:52:40.650+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:52:40.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:40.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:52:40.687+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:40.687+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:52:40.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T03:53:11.201+0000] {processor.py:186} INFO - Started process (PID=5419) to work on /opt/airflow/dags/test.py
[2025-04-08T03:53:11.203+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:53:11.207+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:11.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:53:11.236+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:11.236+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:53:11.242+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:53:11.268+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:11.267+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:53:11.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:11.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:53:11.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-08T03:53:41.497+0000] {processor.py:186} INFO - Started process (PID=5487) to work on /opt/airflow/dags/test.py
[2025-04-08T03:53:41.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:53:41.502+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:41.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:53:41.517+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:41.516+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:53:41.521+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:53:41.549+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:41.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:53:41.580+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:41.580+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:53:41.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-08T03:54:12.243+0000] {processor.py:186} INFO - Started process (PID=5552) to work on /opt/airflow/dags/test.py
[2025-04-08T03:54:12.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:54:12.248+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:12.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:54:12.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:12.261+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:54:12.266+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:54:12.290+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:12.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:54:12.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:12.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:54:12.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T03:54:42.419+0000] {processor.py:186} INFO - Started process (PID=5621) to work on /opt/airflow/dags/test.py
[2025-04-08T03:54:42.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:54:42.423+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:42.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:54:42.445+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:42.445+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:54:42.450+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:54:42.473+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:42.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:54:42.492+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:42.492+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:54:42.521+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T03:55:13.168+0000] {processor.py:186} INFO - Started process (PID=5690) to work on /opt/airflow/dags/test.py
[2025-04-08T03:55:13.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:55:13.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:13.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:55:13.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:13.191+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:55:13.195+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:55:13.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:13.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:55:13.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:13.254+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:55:13.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-08T03:55:44.003+0000] {processor.py:186} INFO - Started process (PID=5758) to work on /opt/airflow/dags/test.py
[2025-04-08T03:55:44.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:55:44.008+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:44.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:55:44.022+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:44.022+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:55:44.026+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:55:44.049+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:44.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:55:44.066+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:44.066+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:55:44.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T03:56:14.471+0000] {processor.py:186} INFO - Started process (PID=5823) to work on /opt/airflow/dags/test.py
[2025-04-08T03:56:14.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:56:14.475+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:14.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:56:14.492+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:14.492+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:56:14.497+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:56:14.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:14.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:56:14.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:14.536+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:56:14.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T03:56:45.589+0000] {processor.py:186} INFO - Started process (PID=5891) to work on /opt/airflow/dags/test.py
[2025-04-08T03:56:45.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:56:45.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:45.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:56:45.617+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:45.616+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:56:45.622+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:56:45.654+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:45.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:56:45.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:45.676+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:56:45.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-08T03:57:16.643+0000] {processor.py:186} INFO - Started process (PID=5956) to work on /opt/airflow/dags/test.py
[2025-04-08T03:57:16.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:57:16.647+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:16.647+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:57:16.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:16.665+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:57:16.669+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:57:16.692+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:16.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:57:16.710+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:16.709+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:57:16.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T03:57:47.812+0000] {processor.py:186} INFO - Started process (PID=6023) to work on /opt/airflow/dags/test.py
[2025-04-08T03:57:47.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:57:47.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:47.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:57:47.833+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:47.833+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:57:47.837+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:57:47.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:47.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:57:47.874+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:47.874+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:57:47.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T03:58:18.210+0000] {processor.py:186} INFO - Started process (PID=6092) to work on /opt/airflow/dags/test.py
[2025-04-08T03:58:18.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:58:18.214+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:18.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:58:18.233+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:18.232+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:58:18.238+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:58:18.257+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:18.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:58:18.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:18.275+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:58:18.301+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T03:58:48.599+0000] {processor.py:186} INFO - Started process (PID=6157) to work on /opt/airflow/dags/test.py
[2025-04-08T03:58:48.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:58:48.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:48.605+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:58:48.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:48.618+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:58:48.624+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:58:48.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:48.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:58:48.666+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:48.666+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:58:48.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T03:59:20.229+0000] {processor.py:186} INFO - Started process (PID=6225) to work on /opt/airflow/dags/test.py
[2025-04-08T03:59:20.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:59:20.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:20.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:59:20.263+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:20.263+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:59:20.269+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:59:20.301+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:20.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:59:20.332+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:20.332+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:59:20.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.153 seconds
[2025-04-08T03:59:51.599+0000] {processor.py:186} INFO - Started process (PID=6294) to work on /opt/airflow/dags/test.py
[2025-04-08T03:59:51.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T03:59:51.603+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:51.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T03:59:51.620+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:51.620+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T03:59:51.624+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T03:59:51.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:51.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:59:51.666+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:51.666+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T03:59:51.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T04:00:22.985+0000] {processor.py:186} INFO - Started process (PID=6363) to work on /opt/airflow/dags/test.py
[2025-04-08T04:00:22.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:00:22.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:22.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:00:23.012+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:23.012+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:00:23.017+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:00:23.039+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:23.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:00:23.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:23.056+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:00:23.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T04:00:54.021+0000] {processor.py:186} INFO - Started process (PID=6432) to work on /opt/airflow/dags/test.py
[2025-04-08T04:00:54.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:00:54.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:54.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:00:54.047+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:54.047+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:00:54.051+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:00:54.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:54.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:00:54.093+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:54.092+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:00:54.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T04:01:25.646+0000] {processor.py:186} INFO - Started process (PID=6501) to work on /opt/airflow/dags/test.py
[2025-04-08T04:01:25.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:01:25.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:25.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:01:25.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:25.662+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:01:25.666+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:01:25.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:25.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:01:25.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:25.705+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:01:25.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T04:01:56.774+0000] {processor.py:186} INFO - Started process (PID=6570) to work on /opt/airflow/dags/test.py
[2025-04-08T04:01:56.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:01:56.780+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:56.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:01:56.803+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:56.802+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:01:56.807+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:01:56.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:56.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:01:56.849+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:56.848+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:01:56.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-08T04:02:28.085+0000] {processor.py:186} INFO - Started process (PID=6639) to work on /opt/airflow/dags/test.py
[2025-04-08T04:02:28.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:02:28.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:28.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:02:28.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:28.107+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:02:28.111+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:02:28.134+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:28.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:02:28.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:28.153+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:02:28.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T04:03:04.259+0000] {processor.py:186} INFO - Started process (PID=6714) to work on /opt/airflow/dags/test.py
[2025-04-08T04:03:04.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:03:04.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:04.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:03:04.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:04.380+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:03:04.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:03:04.495+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:04.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:03:04.552+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:04.552+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:03:04.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.447 seconds
[2025-04-08T04:03:57.084+0000] {processor.py:186} INFO - Started process (PID=6770) to work on /opt/airflow/dags/test.py
[2025-04-08T04:03:57.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:03:57.110+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:57.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:03:57.144+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:57.144+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:03:57.155+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:03:57.225+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:57.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:03:57.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:57.298+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:03:57.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.339 seconds
[2025-04-08T04:04:27.848+0000] {processor.py:186} INFO - Started process (PID=6838) to work on /opt/airflow/dags/test.py
[2025-04-08T04:04:27.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:04:27.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:27.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:04:27.883+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:27.882+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:04:27.893+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:04:27.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:27.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:04:27.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:27.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:04:28.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.214 seconds
[2025-04-08T04:04:58.758+0000] {processor.py:186} INFO - Started process (PID=6906) to work on /opt/airflow/dags/test.py
[2025-04-08T04:04:58.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:04:58.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:58.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:04:58.798+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:58.797+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:04:58.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:04:58.890+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:58.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:04:58.942+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:58.941+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:04:59.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.271 seconds
[2025-04-08T04:05:34.527+0000] {processor.py:186} INFO - Started process (PID=6976) to work on /opt/airflow/dags/test.py
[2025-04-08T04:05:34.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:05:34.537+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:34.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:05:34.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:34.561+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:05:34.569+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:05:34.853+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:34.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:05:34.908+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:34.908+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:05:35.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.890 seconds
[2025-04-08T04:06:05.564+0000] {processor.py:186} INFO - Started process (PID=7044) to work on /opt/airflow/dags/test.py
[2025-04-08T04:06:05.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:06:05.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:05.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:06:05.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:05.593+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:06:05.598+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:06:05.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:05.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:06:05.654+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:05.654+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:06:05.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.141 seconds
[2025-04-08T04:06:36.184+0000] {processor.py:186} INFO - Started process (PID=7113) to work on /opt/airflow/dags/test.py
[2025-04-08T04:06:36.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:06:36.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:36.188+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:06:36.207+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:36.206+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:06:36.210+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:06:36.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:36.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:06:36.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:36.246+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:06:36.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:07:06.658+0000] {processor.py:186} INFO - Started process (PID=7182) to work on /opt/airflow/dags/test.py
[2025-04-08T04:07:06.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:07:06.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:06.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:07:06.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:06.683+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:07:06.687+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:07:06.707+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:06.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:07:06.723+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:06.723+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:07:06.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:07:36.925+0000] {processor.py:186} INFO - Started process (PID=7251) to work on /opt/airflow/dags/test.py
[2025-04-08T04:07:36.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:07:36.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:36.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:07:36.948+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:36.948+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:07:36.952+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:07:36.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:36.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:07:36.987+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:36.987+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:07:37.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:08:07.393+0000] {processor.py:186} INFO - Started process (PID=7320) to work on /opt/airflow/dags/test.py
[2025-04-08T04:08:07.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:08:07.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:07.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:08:07.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:07.417+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:08:07.421+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:08:07.441+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:07.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:08:07.456+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:07.456+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:08:07.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:08:38.199+0000] {processor.py:186} INFO - Started process (PID=7389) to work on /opt/airflow/dags/test.py
[2025-04-08T04:08:38.201+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:08:38.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:38.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:08:38.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:38.223+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:08:38.226+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:08:38.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:38.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:08:38.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:38.261+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:08:38.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:09:08.558+0000] {processor.py:186} INFO - Started process (PID=7458) to work on /opt/airflow/dags/test.py
[2025-04-08T04:09:08.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:09:08.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:08.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:09:08.581+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:08.581+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:09:08.584+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:09:08.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:08.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:09:08.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:08.621+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:09:08.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:09:39.070+0000] {processor.py:186} INFO - Started process (PID=7527) to work on /opt/airflow/dags/test.py
[2025-04-08T04:09:39.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:09:39.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:39.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:09:39.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:39.089+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:09:39.094+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:09:39.115+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:39.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:09:39.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:39.132+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:09:39.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T04:10:09.243+0000] {processor.py:186} INFO - Started process (PID=7595) to work on /opt/airflow/dags/test.py
[2025-04-08T04:10:09.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:10:09.247+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:09.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:10:09.266+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:09.266+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:10:09.270+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:10:09.291+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:09.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:10:09.306+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:09.306+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:10:09.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:10:39.720+0000] {processor.py:186} INFO - Started process (PID=7663) to work on /opt/airflow/dags/test.py
[2025-04-08T04:10:39.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:10:39.724+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:39.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:10:39.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:39.741+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:10:39.745+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:10:39.768+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:39.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:10:39.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:39.785+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:10:39.818+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T04:11:10.325+0000] {processor.py:186} INFO - Started process (PID=7731) to work on /opt/airflow/dags/test.py
[2025-04-08T04:11:10.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:11:10.332+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:10.332+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:11:10.356+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:10.355+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:11:10.359+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:11:10.378+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:10.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:11:10.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:10.394+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:11:10.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T04:11:40.621+0000] {processor.py:186} INFO - Started process (PID=7800) to work on /opt/airflow/dags/test.py
[2025-04-08T04:11:40.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:11:40.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:40.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:11:40.643+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:40.643+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:11:40.646+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:11:40.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:40.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:11:40.680+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:40.680+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:11:40.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:12:11.132+0000] {processor.py:186} INFO - Started process (PID=7869) to work on /opt/airflow/dags/test.py
[2025-04-08T04:12:11.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:12:11.136+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:11.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:12:11.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:11.153+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:12:11.157+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:12:11.176+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:11.176+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:12:11.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:11.191+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:12:11.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T04:12:41.410+0000] {processor.py:186} INFO - Started process (PID=7938) to work on /opt/airflow/dags/test.py
[2025-04-08T04:12:41.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:12:41.414+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:12:41.440+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.439+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:12:41.446+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:12:41.475+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:12:41.501+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.501+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:12:41.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T04:13:12.361+0000] {processor.py:186} INFO - Started process (PID=8012) to work on /opt/airflow/dags/test.py
[2025-04-08T04:13:12.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:13:12.365+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:13:12.379+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.378+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:13:12.383+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:13:12.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:13:12.422+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.422+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:13:12.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:13:42.694+0000] {processor.py:186} INFO - Started process (PID=8080) to work on /opt/airflow/dags/test.py
[2025-04-08T04:13:42.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:13:42.699+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:42.698+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:13:42.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:42.718+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:13:42.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:13:42.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:42.762+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:13:42.788+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:42.787+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:13:42.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.143 seconds
[2025-04-08T04:14:12.997+0000] {processor.py:186} INFO - Started process (PID=8149) to work on /opt/airflow/dags/test.py
[2025-04-08T04:14:12.999+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:14:13.005+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:13.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:14:13.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:13.023+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:14:13.026+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:14:13.046+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:13.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:14:13.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:13.063+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:14:13.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T04:14:43.178+0000] {processor.py:186} INFO - Started process (PID=8218) to work on /opt/airflow/dags/test.py
[2025-04-08T04:14:43.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:14:43.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:43.183+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:14:43.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:43.202+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:14:43.205+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:14:43.225+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:43.225+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:14:43.243+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:43.243+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:14:43.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:15:13.569+0000] {processor.py:186} INFO - Started process (PID=8287) to work on /opt/airflow/dags/test.py
[2025-04-08T04:15:13.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:15:13.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:13.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:15:13.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:13.590+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:15:13.595+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:15:13.617+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:13.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:15:13.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:13.633+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:15:13.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:15:43.920+0000] {processor.py:186} INFO - Started process (PID=8356) to work on /opt/airflow/dags/test.py
[2025-04-08T04:15:43.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:15:43.925+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:43.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:15:43.942+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:43.941+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:15:43.945+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:15:43.964+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:43.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:15:43.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:43.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:15:44.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:16:14.201+0000] {processor.py:186} INFO - Started process (PID=8425) to work on /opt/airflow/dags/test.py
[2025-04-08T04:16:14.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:16:14.205+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:14.204+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:16:14.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:14.221+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:16:14.226+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:16:14.247+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:14.247+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:16:14.264+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:14.264+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:16:14.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:16:44.430+0000] {processor.py:186} INFO - Started process (PID=8488) to work on /opt/airflow/dags/test.py
[2025-04-08T04:16:44.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:16:44.434+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:44.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:16:44.449+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:44.448+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:16:44.453+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:16:44.473+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:44.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:16:44.490+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:44.490+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:16:44.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:17:14.701+0000] {processor.py:186} INFO - Started process (PID=8557) to work on /opt/airflow/dags/test.py
[2025-04-08T04:17:14.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:17:14.707+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:14.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:17:14.728+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:14.728+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:17:14.732+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:17:14.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:14.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:17:14.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:14.771+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:17:14.796+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:17:45.472+0000] {processor.py:186} INFO - Started process (PID=8626) to work on /opt/airflow/dags/test.py
[2025-04-08T04:17:45.473+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:17:45.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:45.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:17:45.492+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:45.491+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:17:45.497+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:17:45.517+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:45.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:17:45.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:45.535+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:17:45.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:18:16.096+0000] {processor.py:186} INFO - Started process (PID=8695) to work on /opt/airflow/dags/test.py
[2025-04-08T04:18:16.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:18:16.101+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:16.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:18:16.119+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:16.119+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:18:16.123+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:18:16.144+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:16.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:18:16.161+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:16.161+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:18:16.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T04:18:46.310+0000] {processor.py:186} INFO - Started process (PID=8764) to work on /opt/airflow/dags/test.py
[2025-04-08T04:18:46.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:18:46.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:46.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:18:46.334+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:46.334+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:18:46.338+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:18:46.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:46.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:18:46.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:46.374+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:18:46.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:19:16.666+0000] {processor.py:186} INFO - Started process (PID=8833) to work on /opt/airflow/dags/test.py
[2025-04-08T04:19:16.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:19:16.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:16.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:19:16.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:16.688+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:19:16.692+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:19:16.711+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:16.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:19:16.728+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:16.728+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:19:16.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:19:47.020+0000] {processor.py:186} INFO - Started process (PID=8902) to work on /opt/airflow/dags/test.py
[2025-04-08T04:19:47.021+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:19:47.024+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:47.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:19:47.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:47.040+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:19:47.044+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:19:47.064+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:47.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:19:47.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:47.080+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:19:47.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:20:17.278+0000] {processor.py:186} INFO - Started process (PID=8970) to work on /opt/airflow/dags/test.py
[2025-04-08T04:20:17.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:20:17.283+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:17.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:20:17.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:17.298+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:20:17.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:20:17.323+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:17.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:20:17.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:17.340+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:20:17.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:20:48.104+0000] {processor.py:186} INFO - Started process (PID=9039) to work on /opt/airflow/dags/test.py
[2025-04-08T04:20:48.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:20:48.110+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:48.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:20:48.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:48.132+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:20:48.136+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:20:48.157+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:48.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:20:48.173+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:48.173+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:20:48.201+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T04:21:18.476+0000] {processor.py:186} INFO - Started process (PID=9108) to work on /opt/airflow/dags/test.py
[2025-04-08T04:21:18.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:21:18.481+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:18.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:21:18.496+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:18.496+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:21:18.500+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:21:18.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:18.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:21:18.539+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:18.539+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:21:18.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:21:48.762+0000] {processor.py:186} INFO - Started process (PID=9177) to work on /opt/airflow/dags/test.py
[2025-04-08T04:21:48.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:21:48.766+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:48.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:21:48.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:48.783+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:21:48.787+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:21:48.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:48.807+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:21:48.825+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:48.825+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:21:48.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:22:19.592+0000] {processor.py:186} INFO - Started process (PID=9246) to work on /opt/airflow/dags/test.py
[2025-04-08T04:22:19.593+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:22:19.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:19.597+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:22:19.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:19.616+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:22:19.620+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:22:19.639+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:19.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:22:19.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:19.655+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:22:19.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:22:49.978+0000] {processor.py:186} INFO - Started process (PID=9315) to work on /opt/airflow/dags/test.py
[2025-04-08T04:22:49.979+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:22:49.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:49.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:22:49.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:49.997+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:22:50.001+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:22:50.022+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:50.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:22:50.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:50.040+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:22:50.068+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:23:20.351+0000] {processor.py:186} INFO - Started process (PID=9384) to work on /opt/airflow/dags/test.py
[2025-04-08T04:23:20.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:23:20.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:20.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:23:20.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:20.374+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:23:20.378+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:23:20.397+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:20.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:23:20.413+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:20.413+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:23:20.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T04:23:50.546+0000] {processor.py:186} INFO - Started process (PID=9453) to work on /opt/airflow/dags/test.py
[2025-04-08T04:23:50.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:23:50.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:50.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:23:50.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:50.569+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:23:50.573+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:23:50.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:50.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:23:50.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:50.611+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:23:50.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:24:20.884+0000] {processor.py:186} INFO - Started process (PID=9522) to work on /opt/airflow/dags/test.py
[2025-04-08T04:24:20.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:24:20.889+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:20.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:24:20.907+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:20.907+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:24:20.911+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:24:20.930+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:20.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:24:20.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:20.946+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:24:20.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:24:51.142+0000] {processor.py:186} INFO - Started process (PID=9591) to work on /opt/airflow/dags/test.py
[2025-04-08T04:24:51.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:24:51.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:51.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:24:51.165+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:51.165+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:24:51.169+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:24:51.189+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:51.188+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:24:51.205+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:51.205+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:24:51.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:25:21.964+0000] {processor.py:186} INFO - Started process (PID=9660) to work on /opt/airflow/dags/test.py
[2025-04-08T04:25:21.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:25:21.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:21.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:25:21.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:21.984+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:25:21.988+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:25:22.011+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:22.011+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:25:22.029+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:22.029+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:25:22.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:25:52.780+0000] {processor.py:186} INFO - Started process (PID=9729) to work on /opt/airflow/dags/test.py
[2025-04-08T04:25:52.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:25:52.785+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:52.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:25:52.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:52.802+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:25:52.806+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:25:52.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:52.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:25:52.842+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:52.842+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:25:52.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:26:23.056+0000] {processor.py:186} INFO - Started process (PID=9798) to work on /opt/airflow/dags/test.py
[2025-04-08T04:26:23.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:26:23.061+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:23.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:26:23.077+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:23.077+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:26:23.081+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:26:23.103+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:23.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:26:23.120+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:23.120+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:26:23.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:26:53.293+0000] {processor.py:186} INFO - Started process (PID=9867) to work on /opt/airflow/dags/test.py
[2025-04-08T04:26:53.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:26:53.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:53.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:26:53.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:53.315+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:26:53.319+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:26:53.341+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:53.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:26:53.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:53.357+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:26:53.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:27:24.106+0000] {processor.py:186} INFO - Started process (PID=9936) to work on /opt/airflow/dags/test.py
[2025-04-08T04:27:24.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:27:24.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:24.109+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:27:24.126+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:24.125+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:27:24.129+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:27:24.150+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:24.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:27:24.169+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:24.169+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:27:24.194+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:27:54.342+0000] {processor.py:186} INFO - Started process (PID=10005) to work on /opt/airflow/dags/test.py
[2025-04-08T04:27:54.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:27:54.346+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:54.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:27:54.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:54.364+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:27:54.368+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:27:54.389+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:54.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:27:54.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:54.406+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:27:54.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:28:24.941+0000] {processor.py:186} INFO - Started process (PID=10074) to work on /opt/airflow/dags/test.py
[2025-04-08T04:28:24.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:28:24.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:24.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:28:24.964+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:24.963+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:28:24.967+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:28:24.987+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:24.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:28:25.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:25.003+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:28:25.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T04:28:55.707+0000] {processor.py:186} INFO - Started process (PID=10143) to work on /opt/airflow/dags/test.py
[2025-04-08T04:28:55.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:28:55.712+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:55.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:28:55.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:55.727+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:28:55.732+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:28:55.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:55.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:28:55.772+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:55.772+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:28:55.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:29:26.661+0000] {processor.py:186} INFO - Started process (PID=10212) to work on /opt/airflow/dags/test.py
[2025-04-08T04:29:26.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:29:26.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:26.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:29:26.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:26.683+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:29:26.688+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:29:26.710+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:26.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:29:26.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:26.726+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:29:26.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:29:57.075+0000] {processor.py:186} INFO - Started process (PID=10281) to work on /opt/airflow/dags/test.py
[2025-04-08T04:29:57.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:29:57.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:57.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:29:57.096+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:57.096+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:29:57.100+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:29:57.120+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:57.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:29:57.137+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:57.137+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:29:57.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:30:27.621+0000] {processor.py:186} INFO - Started process (PID=10350) to work on /opt/airflow/dags/test.py
[2025-04-08T04:30:27.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:30:27.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:27.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:30:27.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:27.640+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:30:27.645+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:30:27.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:27.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:30:27.682+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:27.682+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:30:27.708+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:30:58.190+0000] {processor.py:186} INFO - Started process (PID=10419) to work on /opt/airflow/dags/test.py
[2025-04-08T04:30:58.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:30:58.195+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:58.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:30:58.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:58.210+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:30:58.214+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:30:58.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:58.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:30:58.251+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:58.251+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:30:58.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T04:31:28.689+0000] {processor.py:186} INFO - Started process (PID=10488) to work on /opt/airflow/dags/test.py
[2025-04-08T04:31:28.690+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:31:28.694+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:28.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:31:28.710+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:28.710+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:31:28.714+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:31:28.735+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:28.735+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:31:28.752+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:28.751+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:31:28.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:31:58.977+0000] {processor.py:186} INFO - Started process (PID=10557) to work on /opt/airflow/dags/test.py
[2025-04-08T04:31:58.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:31:58.981+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:58.981+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:31:58.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:58.998+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:31:59.002+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:31:59.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:59.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:31:59.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:59.041+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:31:59.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T04:32:30.003+0000] {processor.py:186} INFO - Started process (PID=10625) to work on /opt/airflow/dags/test.py
[2025-04-08T04:32:30.005+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:32:30.008+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:30.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:32:30.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:30.023+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:32:30.027+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:32:30.047+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:30.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:32:30.068+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:30.068+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:32:30.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:33:00.864+0000] {processor.py:186} INFO - Started process (PID=10694) to work on /opt/airflow/dags/test.py
[2025-04-08T04:33:00.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:33:00.868+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:00.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:33:00.889+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:00.889+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:33:00.893+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:33:00.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:00.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:33:00.935+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:00.934+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:33:00.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T04:33:31.903+0000] {processor.py:186} INFO - Started process (PID=10763) to work on /opt/airflow/dags/test.py
[2025-04-08T04:33:31.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:33:31.908+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:31.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:33:31.922+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:31.921+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:33:31.925+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:33:31.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:31.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:33:31.961+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:31.961+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:33:31.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.091 seconds
[2025-04-08T04:34:02.539+0000] {processor.py:186} INFO - Started process (PID=10832) to work on /opt/airflow/dags/test.py
[2025-04-08T04:34:02.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:34:02.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:02.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:34:02.563+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:02.562+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:34:02.567+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:34:02.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:02.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:34:02.608+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:02.608+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:34:02.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T04:34:32.754+0000] {processor.py:186} INFO - Started process (PID=10901) to work on /opt/airflow/dags/test.py
[2025-04-08T04:34:32.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:34:32.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:32.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:34:32.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:32.772+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:34:32.778+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:34:32.798+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:32.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:34:32.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:32.815+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:34:32.840+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T04:35:03.241+0000] {processor.py:186} INFO - Started process (PID=10968) to work on /opt/airflow/dags/test.py
[2025-04-08T04:35:03.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:35:03.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:03.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:35:03.263+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:03.263+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:35:03.268+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:35:03.290+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:03.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:35:03.308+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:03.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:35:03.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:35:33.473+0000] {processor.py:186} INFO - Started process (PID=11037) to work on /opt/airflow/dags/test.py
[2025-04-08T04:35:33.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:35:33.478+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:33.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:35:33.494+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:33.494+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:35:33.499+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:35:33.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:33.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:35:33.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:33.536+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:35:33.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:36:04.536+0000] {processor.py:186} INFO - Started process (PID=11106) to work on /opt/airflow/dags/test.py
[2025-04-08T04:36:04.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:36:04.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:04.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:36:04.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:04.559+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:36:04.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:36:04.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:04.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:36:04.606+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:04.605+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:36:04.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T04:36:35.272+0000] {processor.py:186} INFO - Started process (PID=11175) to work on /opt/airflow/dags/test.py
[2025-04-08T04:36:35.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:36:35.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:35.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:36:35.292+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:35.291+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:36:35.295+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:36:35.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:35.315+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:36:35.332+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:35.332+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:36:35.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T04:37:07.899+0000] {processor.py:186} INFO - Started process (PID=11244) to work on /opt/airflow/dags/test.py
[2025-04-08T04:37:07.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:37:07.904+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:07.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:37:07.922+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:07.922+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:37:07.926+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:37:07.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:07.945+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:37:07.963+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:07.963+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:37:08.432+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.544 seconds
[2025-04-08T04:37:38.740+0000] {processor.py:186} INFO - Started process (PID=11313) to work on /opt/airflow/dags/test.py
[2025-04-08T04:37:38.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:37:38.745+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:38.744+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:37:38.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:38.763+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:37:38.768+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:37:38.789+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:38.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:37:38.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:38.806+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:37:38.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T04:38:09.250+0000] {processor.py:186} INFO - Started process (PID=11382) to work on /opt/airflow/dags/test.py
[2025-04-08T04:38:09.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:38:09.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:09.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:38:09.271+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:09.270+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:38:09.275+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:38:09.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:09.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:38:09.313+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:09.313+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:38:09.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:38:39.697+0000] {processor.py:186} INFO - Started process (PID=11451) to work on /opt/airflow/dags/test.py
[2025-04-08T04:38:39.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:38:39.702+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:39.702+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:38:39.725+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:39.725+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:38:39.730+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:38:39.751+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:39.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:38:39.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:39.769+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:38:39.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T04:39:10.175+0000] {processor.py:186} INFO - Started process (PID=11520) to work on /opt/airflow/dags/test.py
[2025-04-08T04:39:10.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:39:10.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:10.179+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:39:10.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:10.194+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:39:10.199+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:39:10.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:10.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:39:10.235+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:10.235+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:39:10.260+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T04:39:40.378+0000] {processor.py:186} INFO - Started process (PID=11589) to work on /opt/airflow/dags/test.py
[2025-04-08T04:39:40.379+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:39:40.382+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:40.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:39:40.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:40.398+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:39:40.402+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:39:40.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:40.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:39:40.437+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:40.437+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:39:40.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T04:40:11.259+0000] {processor.py:186} INFO - Started process (PID=11658) to work on /opt/airflow/dags/test.py
[2025-04-08T04:40:11.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:40:11.263+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:11.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:40:11.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:11.277+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:40:11.281+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:40:11.302+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:11.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:40:11.318+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:11.317+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:40:11.344+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.092 seconds
[2025-04-08T04:40:41.552+0000] {processor.py:186} INFO - Started process (PID=11727) to work on /opt/airflow/dags/test.py
[2025-04-08T04:40:41.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:40:41.557+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:41.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:40:41.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:41.572+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:40:41.577+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:40:41.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:41.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:40:41.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:41.614+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:40:41.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:41:12.538+0000] {processor.py:186} INFO - Started process (PID=11796) to work on /opt/airflow/dags/test.py
[2025-04-08T04:41:12.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:41:12.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:12.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:41:12.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:12.560+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:41:12.564+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:41:12.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:12.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:41:12.610+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:12.610+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:41:12.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T04:41:43.241+0000] {processor.py:186} INFO - Started process (PID=11863) to work on /opt/airflow/dags/test.py
[2025-04-08T04:41:43.242+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:41:43.245+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:43.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:41:43.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:43.261+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:41:43.265+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:41:43.285+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:43.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:41:43.302+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:43.301+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:41:43.327+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T04:42:13.887+0000] {processor.py:186} INFO - Started process (PID=11932) to work on /opt/airflow/dags/test.py
[2025-04-08T04:42:13.888+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:42:13.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:13.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:42:13.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:13.911+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:42:13.915+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:42:13.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:13.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:42:13.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:13.957+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:42:13.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T04:42:44.712+0000] {processor.py:186} INFO - Started process (PID=12001) to work on /opt/airflow/dags/test.py
[2025-04-08T04:42:44.714+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:42:44.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:44.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:42:44.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:44.733+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:42:44.738+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:42:44.759+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:44.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:42:44.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:44.776+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:42:44.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T04:43:15.188+0000] {processor.py:186} INFO - Started process (PID=12070) to work on /opt/airflow/dags/test.py
[2025-04-08T04:43:15.189+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:43:15.193+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:15.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:43:15.207+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:15.207+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:43:15.211+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:43:15.231+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:15.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:43:15.248+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:15.247+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:43:15.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:43:45.404+0000] {processor.py:186} INFO - Started process (PID=12139) to work on /opt/airflow/dags/test.py
[2025-04-08T04:43:45.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:43:45.409+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:45.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:43:45.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:45.425+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:43:45.429+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:43:45.448+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:45.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:43:45.465+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:45.465+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:43:45.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:44:15.846+0000] {processor.py:186} INFO - Started process (PID=12215) to work on /opt/airflow/dags/test.py
[2025-04-08T04:44:15.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:44:15.850+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:15.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:44:15.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:15.865+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:44:15.869+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:44:15.889+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:15.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:44:15.906+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:15.905+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:44:15.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.092 seconds
[2025-04-08T04:44:46.221+0000] {processor.py:186} INFO - Started process (PID=12284) to work on /opt/airflow/dags/test.py
[2025-04-08T04:44:46.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:44:46.225+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:46.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:44:46.238+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:46.237+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:44:46.242+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:44:46.262+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:46.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:44:46.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:46.279+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:44:46.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.091 seconds
[2025-04-08T04:45:16.918+0000] {processor.py:186} INFO - Started process (PID=12353) to work on /opt/airflow/dags/test.py
[2025-04-08T04:45:16.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:45:16.923+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:16.922+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:45:16.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:16.939+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:45:16.943+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:45:16.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:16.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:45:16.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:16.980+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:45:17.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T04:45:47.805+0000] {processor.py:186} INFO - Started process (PID=12421) to work on /opt/airflow/dags/test.py
[2025-04-08T04:45:47.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:45:47.810+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:47.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:45:47.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:47.826+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:45:47.831+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:45:47.852+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:47.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:45:47.869+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:47.869+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:45:47.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:46:18.470+0000] {processor.py:186} INFO - Started process (PID=12490) to work on /opt/airflow/dags/test.py
[2025-04-08T04:46:18.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:46:18.474+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:18.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:46:18.491+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:18.491+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:46:18.494+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:46:18.513+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:18.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:46:18.530+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:18.530+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:46:18.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.092 seconds
[2025-04-08T04:46:49.168+0000] {processor.py:186} INFO - Started process (PID=12559) to work on /opt/airflow/dags/test.py
[2025-04-08T04:46:49.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:46:49.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:49.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:46:49.195+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:49.194+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:46:49.198+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:46:49.217+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:49.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:46:49.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:49.234+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:46:49.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:47:19.977+0000] {processor.py:186} INFO - Started process (PID=12628) to work on /opt/airflow/dags/test.py
[2025-04-08T04:47:19.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:47:19.981+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:19.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:47:20.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:20.000+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:47:20.004+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:47:20.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:20.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:47:20.039+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:20.039+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:47:20.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:47:50.947+0000] {processor.py:186} INFO - Started process (PID=12697) to work on /opt/airflow/dags/test.py
[2025-04-08T04:47:50.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:47:50.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:50.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:47:50.967+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:50.967+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:47:50.972+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:47:50.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:50.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:47:51.008+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:51.008+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:47:51.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:48:21.504+0000] {processor.py:186} INFO - Started process (PID=12766) to work on /opt/airflow/dags/test.py
[2025-04-08T04:48:21.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:48:21.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:21.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:48:21.525+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:21.525+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:48:21.529+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:48:21.548+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:21.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:48:21.565+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:21.565+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:48:21.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:48:52.546+0000] {processor.py:186} INFO - Started process (PID=12835) to work on /opt/airflow/dags/test.py
[2025-04-08T04:48:52.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:48:52.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:52.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:48:52.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:52.569+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:48:52.573+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:48:52.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:52.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:48:52.610+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:52.610+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:48:52.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:49:23.467+0000] {processor.py:186} INFO - Started process (PID=12904) to work on /opt/airflow/dags/test.py
[2025-04-08T04:49:23.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:49:23.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:23.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:49:23.484+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:23.484+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:49:23.489+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:49:23.509+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:23.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:49:23.526+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:23.525+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:49:23.556+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:49:54.547+0000] {processor.py:186} INFO - Started process (PID=12973) to work on /opt/airflow/dags/test.py
[2025-04-08T04:49:54.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:49:54.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:54.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:49:54.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:54.566+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:49:54.571+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:49:54.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:54.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:49:54.606+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:54.606+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:49:54.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:50:25.513+0000] {processor.py:186} INFO - Started process (PID=13042) to work on /opt/airflow/dags/test.py
[2025-04-08T04:50:25.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:50:25.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:25.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:50:25.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:25.535+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:50:25.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:50:25.558+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:25.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:50:25.575+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:25.575+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:50:25.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:50:55.710+0000] {processor.py:186} INFO - Started process (PID=13111) to work on /opt/airflow/dags/test.py
[2025-04-08T04:50:55.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:50:55.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:55.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:50:55.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:55.729+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:50:55.733+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:50:55.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:55.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:50:55.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:55.770+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:50:55.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T04:51:26.561+0000] {processor.py:186} INFO - Started process (PID=13180) to work on /opt/airflow/dags/test.py
[2025-04-08T04:51:26.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:51:26.566+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:26.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:51:26.581+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:26.581+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:51:26.587+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:51:26.613+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:26.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:51:26.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:26.631+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:51:26.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T04:51:57.556+0000] {processor.py:186} INFO - Started process (PID=13249) to work on /opt/airflow/dags/test.py
[2025-04-08T04:51:57.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:51:57.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:57.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:51:57.579+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:57.579+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:51:57.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:51:57.604+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:57.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:51:57.620+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:57.620+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:51:57.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T04:52:28.499+0000] {processor.py:186} INFO - Started process (PID=13318) to work on /opt/airflow/dags/test.py
[2025-04-08T04:52:28.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:52:28.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:28.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:52:28.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:28.518+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:52:28.522+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:52:28.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:28.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:52:28.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:28.560+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:52:28.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:52:59.437+0000] {processor.py:186} INFO - Started process (PID=13387) to work on /opt/airflow/dags/test.py
[2025-04-08T04:52:59.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:52:59.442+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:59.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:52:59.458+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:59.457+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:52:59.462+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:52:59.482+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:59.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:52:59.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:59.498+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:52:59.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:53:29.885+0000] {processor.py:186} INFO - Started process (PID=13456) to work on /opt/airflow/dags/test.py
[2025-04-08T04:53:29.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:53:29.890+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:29.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:53:29.907+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:29.907+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:53:29.911+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:53:29.930+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:29.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:53:29.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:29.947+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:53:29.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:54:00.064+0000] {processor.py:186} INFO - Started process (PID=13526) to work on /opt/airflow/dags/test.py
[2025-04-08T04:54:00.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:54:00.068+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:00.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:54:00.085+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:00.085+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:54:00.089+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:54:00.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:00.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:54:00.126+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:00.126+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:54:00.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T04:54:31.739+0000] {processor.py:186} INFO - Started process (PID=13595) to work on /opt/airflow/dags/test.py
[2025-04-08T04:54:31.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:54:31.744+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:31.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:54:31.759+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:31.758+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:54:31.763+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:54:31.782+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:31.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:54:31.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:31.801+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:54:31.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T04:55:02.607+0000] {processor.py:186} INFO - Started process (PID=13654) to work on /opt/airflow/dags/test.py
[2025-04-08T04:55:02.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:55:02.611+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:02.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:55:02.627+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:02.627+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:55:02.631+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:55:02.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:02.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:55:02.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:02.667+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:55:02.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.248 seconds
[2025-04-08T04:55:33.193+0000] {processor.py:186} INFO - Started process (PID=13721) to work on /opt/airflow/dags/test.py
[2025-04-08T04:55:33.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:55:33.198+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:33.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:55:33.216+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:33.215+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:55:33.219+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:55:33.239+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:33.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:55:33.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:33.256+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:55:33.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T04:56:03.622+0000] {processor.py:186} INFO - Started process (PID=13788) to work on /opt/airflow/dags/test.py
[2025-04-08T04:56:03.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:56:03.627+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:03.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:56:03.647+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:03.647+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:56:03.653+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:56:03.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:03.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:56:03.698+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:03.698+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:56:03.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T04:56:34.410+0000] {processor.py:186} INFO - Started process (PID=13854) to work on /opt/airflow/dags/test.py
[2025-04-08T04:56:34.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:56:34.414+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:34.414+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:56:34.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:34.428+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:56:34.433+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:56:34.452+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:34.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:56:34.468+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:34.468+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:56:34.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:57:04.762+0000] {processor.py:186} INFO - Started process (PID=13922) to work on /opt/airflow/dags/test.py
[2025-04-08T04:57:04.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:57:04.765+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:04.765+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:57:04.779+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:04.778+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:57:04.782+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:57:04.806+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:04.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:57:04.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:04.828+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:57:04.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T04:57:34.996+0000] {processor.py:186} INFO - Started process (PID=13978) to work on /opt/airflow/dags/test.py
[2025-04-08T04:57:34.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:57:35.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:35.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:57:35.017+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:35.017+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:57:35.021+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:57:35.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:35.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:57:35.060+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:35.060+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:57:35.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T04:58:05.889+0000] {processor.py:186} INFO - Started process (PID=14046) to work on /opt/airflow/dags/test.py
[2025-04-08T04:58:05.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:58:05.893+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:05.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:58:05.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:05.910+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:58:05.914+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:58:05.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:05.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:58:05.950+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:05.950+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:58:05.994+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T04:58:36.449+0000] {processor.py:186} INFO - Started process (PID=14111) to work on /opt/airflow/dags/test.py
[2025-04-08T04:58:36.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:58:36.453+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:36.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:58:36.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:36.471+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:58:36.477+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:58:36.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:36.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:58:36.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:36.516+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:58:36.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T04:59:06.978+0000] {processor.py:186} INFO - Started process (PID=14178) to work on /opt/airflow/dags/test.py
[2025-04-08T04:59:06.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:59:06.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:06.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:59:06.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:06.997+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:59:07.002+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:59:07.022+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:07.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:59:07.039+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:07.039+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:59:07.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T04:59:37.751+0000] {processor.py:186} INFO - Started process (PID=14243) to work on /opt/airflow/dags/test.py
[2025-04-08T04:59:37.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T04:59:37.755+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:37.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T04:59:37.772+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:37.771+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T04:59:37.776+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T04:59:37.796+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:37.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:59:37.813+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:37.812+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T04:59:37.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T05:00:08.152+0000] {processor.py:186} INFO - Started process (PID=14312) to work on /opt/airflow/dags/test.py
[2025-04-08T05:00:08.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:00:08.157+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:08.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:00:08.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:08.172+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:00:08.176+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:00:08.199+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:08.199+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:00:08.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:08.218+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:00:08.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T05:00:39.359+0000] {processor.py:186} INFO - Started process (PID=14381) to work on /opt/airflow/dags/test.py
[2025-04-08T05:00:39.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:00:39.362+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:39.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:00:39.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:39.380+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:00:39.384+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:00:39.404+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:39.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:00:39.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:39.421+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:00:39.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T05:01:10.100+0000] {processor.py:186} INFO - Started process (PID=14450) to work on /opt/airflow/dags/test.py
[2025-04-08T05:01:10.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:01:10.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:10.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:01:10.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:10.124+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:01:10.129+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:01:10.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:10.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:01:10.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:10.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:01:10.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:01:40.364+0000] {processor.py:186} INFO - Started process (PID=14517) to work on /opt/airflow/dags/test.py
[2025-04-08T05:01:40.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:01:40.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:40.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:01:40.385+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:40.384+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:01:40.388+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:01:40.409+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:40.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:01:40.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:40.425+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:01:40.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T05:02:11.526+0000] {processor.py:186} INFO - Started process (PID=14584) to work on /opt/airflow/dags/test.py
[2025-04-08T05:02:11.527+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:02:11.530+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:11.530+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:02:11.545+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:11.545+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:02:11.549+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:02:11.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:11.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:02:11.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:11.586+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:02:11.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T05:02:42.381+0000] {processor.py:186} INFO - Started process (PID=14653) to work on /opt/airflow/dags/test.py
[2025-04-08T05:02:42.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:02:42.385+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:42.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:02:42.403+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:42.402+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:02:42.406+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:02:42.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:42.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:02:42.442+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:42.442+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:02:42.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T05:03:12.954+0000] {processor.py:186} INFO - Started process (PID=14722) to work on /opt/airflow/dags/test.py
[2025-04-08T05:03:12.955+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:03:12.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:12.958+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:03:12.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:12.971+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:03:12.975+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:03:12.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:12.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:03:13.015+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:13.015+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:03:13.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T05:03:44.035+0000] {processor.py:186} INFO - Started process (PID=14791) to work on /opt/airflow/dags/test.py
[2025-04-08T05:03:44.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:03:44.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:44.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:03:44.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:44.057+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:03:44.062+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:03:44.083+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:44.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:03:44.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:44.104+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:03:44.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T05:04:15.058+0000] {processor.py:186} INFO - Started process (PID=14860) to work on /opt/airflow/dags/test.py
[2025-04-08T05:04:15.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:04:15.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:15.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:04:15.079+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:15.079+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:04:15.083+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:04:15.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:15.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:04:15.122+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:15.122+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:04:15.149+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T05:04:46.103+0000] {processor.py:186} INFO - Started process (PID=14929) to work on /opt/airflow/dags/test.py
[2025-04-08T05:04:46.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:04:46.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:46.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:04:46.128+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:46.128+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:04:46.132+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:04:46.152+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:46.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:04:46.170+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:46.170+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:04:46.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T05:05:17.138+0000] {processor.py:186} INFO - Started process (PID=14998) to work on /opt/airflow/dags/test.py
[2025-04-08T05:05:17.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:05:17.143+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:17.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:05:17.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:17.162+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:05:17.167+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:05:17.186+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:17.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:05:17.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:17.202+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:05:17.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:05:47.551+0000] {processor.py:186} INFO - Started process (PID=15067) to work on /opt/airflow/dags/test.py
[2025-04-08T05:05:47.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:05:47.556+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:47.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:05:47.574+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:47.573+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:05:47.577+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:05:47.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:47.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:05:47.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:47.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:05:47.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:06:18.171+0000] {processor.py:186} INFO - Started process (PID=15136) to work on /opt/airflow/dags/test.py
[2025-04-08T05:06:18.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:06:18.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:18.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:06:18.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:18.191+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:06:18.195+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:06:18.215+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:18.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:06:18.231+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:18.231+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:06:18.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:06:48.803+0000] {processor.py:186} INFO - Started process (PID=15211) to work on /opt/airflow/dags/test.py
[2025-04-08T05:06:48.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:06:48.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:06:48.827+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.827+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:06:48.831+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:06:48.851+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.851+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:06:48.868+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.868+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:06:48.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T05:07:19.233+0000] {processor.py:186} INFO - Started process (PID=15280) to work on /opt/airflow/dags/test.py
[2025-04-08T05:07:19.235+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:07:19.238+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:19.237+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:07:19.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:19.254+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:07:19.258+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:07:19.278+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:19.278+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:07:19.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:19.295+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:07:19.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T05:07:50.504+0000] {processor.py:186} INFO - Started process (PID=15349) to work on /opt/airflow/dags/test.py
[2025-04-08T05:07:50.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:07:50.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:50.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:07:50.526+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:50.526+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:07:50.530+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:07:50.550+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:50.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:07:50.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:50.567+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:07:50.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T05:08:21.237+0000] {processor.py:186} INFO - Started process (PID=15418) to work on /opt/airflow/dags/test.py
[2025-04-08T05:08:21.239+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:08:21.242+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:21.241+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:08:21.258+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:21.258+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:08:21.262+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:08:21.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:21.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:08:21.299+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:21.299+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:08:21.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T05:08:52.362+0000] {processor.py:186} INFO - Started process (PID=15487) to work on /opt/airflow/dags/test.py
[2025-04-08T05:08:52.363+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:08:52.366+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:52.365+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:08:52.383+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:52.383+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:08:52.387+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:08:52.407+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:52.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:08:52.423+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:52.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:08:52.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T05:09:23.470+0000] {processor.py:186} INFO - Started process (PID=15556) to work on /opt/airflow/dags/test.py
[2025-04-08T05:09:23.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:09:23.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:23.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:09:23.494+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:23.493+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:09:23.498+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:09:23.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:23.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:09:23.539+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:23.539+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:09:23.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T05:09:54.511+0000] {processor.py:186} INFO - Started process (PID=15625) to work on /opt/airflow/dags/test.py
[2025-04-08T05:09:54.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:09:54.515+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:54.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:09:54.532+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:54.531+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:09:54.536+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:09:54.556+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:54.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:09:54.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:54.573+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:09:54.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T05:10:25.077+0000] {processor.py:186} INFO - Started process (PID=15694) to work on /opt/airflow/dags/test.py
[2025-04-08T05:10:25.079+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:10:25.081+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:25.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:10:25.095+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:25.095+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:10:25.099+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:10:25.118+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:25.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:10:25.136+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:25.136+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:10:25.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:10:56.166+0000] {processor.py:186} INFO - Started process (PID=15763) to work on /opt/airflow/dags/test.py
[2025-04-08T05:10:56.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:10:56.170+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:56.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:10:56.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:56.188+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:10:56.191+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:10:56.211+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:56.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:10:56.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:56.228+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:10:56.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:11:26.468+0000] {processor.py:186} INFO - Started process (PID=15832) to work on /opt/airflow/dags/test.py
[2025-04-08T05:11:26.469+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:11:26.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:26.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:11:26.487+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:26.487+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:11:26.490+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:11:26.510+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:26.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:11:26.526+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:26.526+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:11:26.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T05:11:57.642+0000] {processor.py:186} INFO - Started process (PID=15901) to work on /opt/airflow/dags/test.py
[2025-04-08T05:11:57.644+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:11:57.647+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:57.646+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:11:57.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:57.665+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:11:57.668+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:11:57.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:57.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:11:57.705+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:57.705+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:11:57.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:12:28.658+0000] {processor.py:186} INFO - Started process (PID=15970) to work on /opt/airflow/dags/test.py
[2025-04-08T05:12:28.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:12:28.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:28.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:12:28.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:28.677+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:12:28.681+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:12:28.702+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:28.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:12:28.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:28.718+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:12:28.750+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:12:59.230+0000] {processor.py:186} INFO - Started process (PID=16039) to work on /opt/airflow/dags/test.py
[2025-04-08T05:12:59.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:12:59.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:59.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:12:59.252+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:59.251+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:12:59.256+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:12:59.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:59.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:12:59.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:59.296+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:12:59.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:13:29.571+0000] {processor.py:186} INFO - Started process (PID=16108) to work on /opt/airflow/dags/test.py
[2025-04-08T05:13:29.572+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:13:29.576+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:29.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:13:29.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:29.593+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:13:29.598+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:13:29.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:29.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:13:29.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:29.635+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:13:29.661+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:14:00.574+0000] {processor.py:186} INFO - Started process (PID=16177) to work on /opt/airflow/dags/test.py
[2025-04-08T05:14:00.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:14:00.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:00.578+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:14:00.596+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:00.596+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:14:00.600+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:14:00.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:00.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:14:00.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:00.637+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:14:00.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T05:14:31.632+0000] {processor.py:186} INFO - Started process (PID=16246) to work on /opt/airflow/dags/test.py
[2025-04-08T05:14:31.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:14:31.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:31.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:14:31.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:31.652+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:14:31.657+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:14:31.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:31.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:14:31.693+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:31.693+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:14:31.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T05:15:02.596+0000] {processor.py:186} INFO - Started process (PID=16315) to work on /opt/airflow/dags/test.py
[2025-04-08T05:15:02.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:15:02.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:02.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:15:02.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:02.622+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:15:02.628+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:15:02.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:02.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:15:02.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:02.670+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:15:02.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T05:15:33.870+0000] {processor.py:186} INFO - Started process (PID=16384) to work on /opt/airflow/dags/test.py
[2025-04-08T05:15:33.871+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:15:33.875+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:33.874+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:15:33.890+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:33.890+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:15:33.894+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:15:33.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:33.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:15:33.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:33.933+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:15:33.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:16:04.872+0000] {processor.py:186} INFO - Started process (PID=16453) to work on /opt/airflow/dags/test.py
[2025-04-08T05:16:04.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:16:04.876+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:04.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:16:04.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:04.892+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:16:04.896+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:16:04.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:04.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:16:04.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:04.934+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:16:04.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T05:16:35.799+0000] {processor.py:186} INFO - Started process (PID=16522) to work on /opt/airflow/dags/test.py
[2025-04-08T05:16:35.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:16:35.805+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:16:35.822+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.822+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:16:35.826+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:16:35.846+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:16:35.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.866+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:16:35.901+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T05:17:06.804+0000] {processor.py:186} INFO - Started process (PID=16591) to work on /opt/airflow/dags/test.py
[2025-04-08T05:17:06.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:17:06.808+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:17:06.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.828+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:17:06.832+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:17:06.853+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:17:06.877+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.877+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:17:06.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T05:17:37.488+0000] {processor.py:186} INFO - Started process (PID=16660) to work on /opt/airflow/dags/test.py
[2025-04-08T05:17:37.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:17:37.492+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:37.491+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:17:37.511+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:37.510+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:17:37.514+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:17:37.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:37.536+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:17:37.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:37.553+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:17:37.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:18:08.369+0000] {processor.py:186} INFO - Started process (PID=16729) to work on /opt/airflow/dags/test.py
[2025-04-08T05:18:08.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:18:08.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:08.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:18:08.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:08.393+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:18:08.397+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:18:08.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:08.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:18:08.436+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:08.436+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:18:08.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T05:18:38.892+0000] {processor.py:186} INFO - Started process (PID=16798) to work on /opt/airflow/dags/test.py
[2025-04-08T05:18:38.893+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:18:38.896+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:18:38.912+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.912+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:18:38.916+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:18:38.937+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:18:38.953+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.952+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:18:38.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:19:09.873+0000] {processor.py:186} INFO - Started process (PID=16867) to work on /opt/airflow/dags/test.py
[2025-04-08T05:19:09.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:19:09.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:09.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:19:09.897+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:09.897+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:19:09.901+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:19:09.924+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:09.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:19:09.942+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:09.941+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:19:09.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T05:19:40.941+0000] {processor.py:186} INFO - Started process (PID=16936) to work on /opt/airflow/dags/test.py
[2025-04-08T05:19:40.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:19:40.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:40.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:19:40.964+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:40.963+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:19:40.968+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:19:40.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:40.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:19:41.006+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:41.006+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:19:41.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T05:20:11.724+0000] {processor.py:186} INFO - Started process (PID=17004) to work on /opt/airflow/dags/test.py
[2025-04-08T05:20:11.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:20:11.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:11.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:20:11.744+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:11.744+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:20:11.748+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:20:11.768+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:11.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:20:11.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:11.786+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:20:11.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T05:20:42.735+0000] {processor.py:186} INFO - Started process (PID=17073) to work on /opt/airflow/dags/test.py
[2025-04-08T05:20:42.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:20:42.739+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:42.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:20:42.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:42.754+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:20:42.758+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:20:42.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:42.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:20:42.794+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:42.794+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:20:42.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T05:21:13.707+0000] {processor.py:186} INFO - Started process (PID=17142) to work on /opt/airflow/dags/test.py
[2025-04-08T05:21:13.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:21:13.711+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:13.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:21:13.730+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:13.729+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:21:13.733+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:21:13.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:13.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:21:13.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:13.770+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:21:13.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T05:21:44.730+0000] {processor.py:186} INFO - Started process (PID=17211) to work on /opt/airflow/dags/test.py
[2025-04-08T05:21:44.731+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:21:44.734+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:44.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:21:44.752+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:44.752+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:21:44.756+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:21:44.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:44.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:21:44.791+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:44.791+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:21:44.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T05:22:15.300+0000] {processor.py:186} INFO - Started process (PID=17280) to work on /opt/airflow/dags/test.py
[2025-04-08T05:22:15.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:22:15.304+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:15.303+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:22:15.321+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:15.321+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:22:15.325+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:22:15.345+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:15.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:22:15.360+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:15.360+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:22:15.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T05:22:46.828+0000] {processor.py:186} INFO - Started process (PID=17350) to work on /opt/airflow/dags/test.py
[2025-04-08T05:22:46.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:22:46.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:46.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:22:46.850+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:46.849+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:22:46.853+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:22:46.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:46.873+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:22:46.888+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:46.888+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:22:46.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T05:23:17.446+0000] {processor.py:186} INFO - Started process (PID=17418) to work on /opt/airflow/dags/test.py
[2025-04-08T05:23:17.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:23:17.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:17.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:23:17.467+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:17.466+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:23:17.471+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:23:17.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:17.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:23:17.513+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:17.513+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:23:17.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T05:23:48.180+0000] {processor.py:186} INFO - Started process (PID=17486) to work on /opt/airflow/dags/test.py
[2025-04-08T05:23:48.181+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:23:48.185+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:48.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:23:48.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:48.204+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:23:48.209+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:23:48.233+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:48.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:23:48.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:48.254+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:23:48.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-08T05:24:18.594+0000] {processor.py:186} INFO - Started process (PID=17554) to work on /opt/airflow/dags/test.py
[2025-04-08T05:24:18.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:24:18.600+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:18.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:24:18.622+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:18.622+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:24:18.626+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:24:18.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:18.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:24:18.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:18.673+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:24:18.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-08T05:24:49.423+0000] {processor.py:186} INFO - Started process (PID=17624) to work on /opt/airflow/dags/test.py
[2025-04-08T05:24:49.425+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:24:49.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:49.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:24:49.447+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:49.447+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:24:49.452+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:24:49.480+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:49.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:24:49.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:49.500+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:24:49.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-08T05:25:19.965+0000] {processor.py:186} INFO - Started process (PID=17693) to work on /opt/airflow/dags/test.py
[2025-04-08T05:25:19.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:25:19.970+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:19.970+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:25:19.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:19.988+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:25:19.993+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:25:20.017+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:20.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:25:20.037+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:20.037+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:25:20.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T05:25:51.296+0000] {processor.py:186} INFO - Started process (PID=17768) to work on /opt/airflow/dags/test.py
[2025-04-08T05:25:51.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:25:51.301+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:51.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:25:51.318+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:51.317+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:25:51.322+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:25:51.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:51.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:25:51.370+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:51.370+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:25:51.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.158 seconds
[2025-04-08T05:26:21.672+0000] {processor.py:186} INFO - Started process (PID=17835) to work on /opt/airflow/dags/test.py
[2025-04-08T05:26:21.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:26:21.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:21.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:26:21.698+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:21.698+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:26:21.702+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:26:21.728+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:21.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:26:21.750+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:21.750+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:26:21.786+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-08T05:26:52.310+0000] {processor.py:186} INFO - Started process (PID=17904) to work on /opt/airflow/dags/test.py
[2025-04-08T05:26:52.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:26:52.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:52.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:26:52.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:52.339+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:26:52.343+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:26:52.365+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:52.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:26:52.383+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:52.383+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:26:52.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T05:27:24.016+0000] {processor.py:186} INFO - Started process (PID=17974) to work on /opt/airflow/dags/test.py
[2025-04-08T05:27:24.017+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:27:24.021+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:24.020+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:27:24.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:24.041+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:27:24.046+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:27:24.070+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:24.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:27:24.087+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:24.087+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:27:24.119+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T05:27:54.581+0000] {processor.py:186} INFO - Started process (PID=18044) to work on /opt/airflow/dags/test.py
[2025-04-08T05:27:54.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:27:54.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:54.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:27:54.604+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:54.604+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:27:54.608+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:27:54.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:54.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:27:54.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:54.650+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:27:54.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T05:28:25.230+0000] {processor.py:186} INFO - Started process (PID=18113) to work on /opt/airflow/dags/test.py
[2025-04-08T05:28:25.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:28:25.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:25.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:28:25.253+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:25.253+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:28:25.257+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:28:25.282+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:25.282+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:28:25.300+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:25.300+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:28:25.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-08T05:28:55.753+0000] {processor.py:186} INFO - Started process (PID=18182) to work on /opt/airflow/dags/test.py
[2025-04-08T05:28:55.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:28:55.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:28:55.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.777+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:28:55.781+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:28:55.803+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:28:55.821+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.821+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:28:55.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T05:29:26.289+0000] {processor.py:186} INFO - Started process (PID=18250) to work on /opt/airflow/dags/test.py
[2025-04-08T05:29:26.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:29:26.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:26.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:29:26.314+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:26.314+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:29:26.318+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:29:26.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:26.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:29:26.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:26.357+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:29:26.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T05:29:57.054+0000] {processor.py:186} INFO - Started process (PID=18319) to work on /opt/airflow/dags/test.py
[2025-04-08T05:29:57.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:29:57.059+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:57.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:29:57.086+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:57.086+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:29:57.091+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:29:57.114+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:57.113+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:29:57.133+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:57.132+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:29:57.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T05:30:27.715+0000] {processor.py:186} INFO - Started process (PID=18388) to work on /opt/airflow/dags/test.py
[2025-04-08T05:30:27.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:30:27.720+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:30:27.743+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.743+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:30:27.747+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:30:27.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:30:27.791+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.790+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:30:27.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T05:30:58.444+0000] {processor.py:186} INFO - Started process (PID=18457) to work on /opt/airflow/dags/test.py
[2025-04-08T05:30:58.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:30:58.449+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:30:58.470+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.469+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:30:58.474+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:30:58.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:30:58.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.517+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:30:58.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T05:31:29.099+0000] {processor.py:186} INFO - Started process (PID=18526) to work on /opt/airflow/dags/test.py
[2025-04-08T05:31:29.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:31:29.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:29.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:31:29.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:29.125+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:31:29.129+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:31:29.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:29.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:31:29.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:29.171+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:31:29.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T05:31:59.680+0000] {processor.py:186} INFO - Started process (PID=18595) to work on /opt/airflow/dags/test.py
[2025-04-08T05:31:59.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:31:59.685+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:31:59.709+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.708+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:31:59.717+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:31:59.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.745+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:31:59.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.763+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:31:59.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-08T05:32:31.487+0000] {processor.py:186} INFO - Started process (PID=18665) to work on /opt/airflow/dags/test.py
[2025-04-08T05:32:31.488+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:32:31.491+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:31.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:32:31.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:31.507+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:32:31.511+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:32:31.533+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:31.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:32:31.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:31.551+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:32:31.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T05:33:02.795+0000] {processor.py:186} INFO - Started process (PID=18734) to work on /opt/airflow/dags/test.py
[2025-04-08T05:33:02.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:33:02.799+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:02.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:33:02.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:02.816+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:33:02.820+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:33:02.845+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:02.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:33:02.864+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:02.864+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:33:02.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T05:33:33.962+0000] {processor.py:186} INFO - Started process (PID=18803) to work on /opt/airflow/dags/test.py
[2025-04-08T05:33:33.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:33:33.966+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:33.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:33:33.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:33.983+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:33:33.987+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:33:34.009+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:34.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:33:34.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:34.026+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:33:34.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.281 seconds
[2025-04-08T05:34:04.970+0000] {processor.py:186} INFO - Started process (PID=18872) to work on /opt/airflow/dags/test.py
[2025-04-08T05:34:04.972+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:34:04.976+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:04.975+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:34:04.993+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:04.993+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:34:04.997+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:34:05.020+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:05.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:34:05.039+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:05.038+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:34:05.069+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T05:34:35.527+0000] {processor.py:186} INFO - Started process (PID=18940) to work on /opt/airflow/dags/test.py
[2025-04-08T05:34:35.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:34:35.531+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:34:35.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.550+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:34:35.555+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:34:35.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:34:35.595+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.595+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:34:35.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T05:35:06.239+0000] {processor.py:186} INFO - Started process (PID=19010) to work on /opt/airflow/dags/test.py
[2025-04-08T05:35:06.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:35:06.243+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:06.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:35:06.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:06.260+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:35:06.266+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:35:06.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:06.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:35:06.307+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:06.306+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:35:06.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T05:35:37.968+0000] {processor.py:186} INFO - Started process (PID=19080) to work on /opt/airflow/dags/test.py
[2025-04-08T05:35:37.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:35:37.973+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:37.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:35:37.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:37.990+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:35:37.995+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:35:38.021+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:38.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:35:38.044+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:38.043+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:35:38.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-08T05:36:09.260+0000] {processor.py:186} INFO - Started process (PID=19149) to work on /opt/airflow/dags/test.py
[2025-04-08T05:36:09.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:36:09.268+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:09.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:36:09.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:09.295+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:36:09.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:36:09.335+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:09.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:36:09.356+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:09.356+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:36:09.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.353 seconds
[2025-04-08T05:36:39.759+0000] {processor.py:186} INFO - Started process (PID=19218) to work on /opt/airflow/dags/test.py
[2025-04-08T05:36:39.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:36:39.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:36:39.780+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.780+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:36:39.784+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:36:39.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.804+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:36:39.820+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.820+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:36:39.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:37:10.845+0000] {processor.py:186} INFO - Started process (PID=19287) to work on /opt/airflow/dags/test.py
[2025-04-08T05:37:10.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:37:10.849+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:37:10.868+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.867+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:37:10.871+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:37:10.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:37:10.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.909+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:37:10.935+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:37:41.706+0000] {processor.py:186} INFO - Started process (PID=19356) to work on /opt/airflow/dags/test.py
[2025-04-08T05:37:41.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:37:41.710+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:41.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:37:41.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:41.729+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:37:41.733+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:37:41.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:41.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:37:41.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:41.769+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:37:41.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:38:12.611+0000] {processor.py:186} INFO - Started process (PID=19425) to work on /opt/airflow/dags/test.py
[2025-04-08T05:38:12.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:38:12.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:12.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:38:12.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:12.631+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:38:12.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:38:12.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:12.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:38:12.671+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:12.671+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:38:12.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:38:43.101+0000] {processor.py:186} INFO - Started process (PID=19494) to work on /opt/airflow/dags/test.py
[2025-04-08T05:38:43.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:38:43.105+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:43.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:38:43.122+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:43.121+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:38:43.125+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:38:43.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:43.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:38:43.162+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:43.162+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:38:43.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:39:13.973+0000] {processor.py:186} INFO - Started process (PID=19563) to work on /opt/airflow/dags/test.py
[2025-04-08T05:39:13.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:39:13.977+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:13.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:39:13.996+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:13.996+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:39:14.000+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:39:14.019+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:14.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:39:14.036+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:14.035+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:39:14.066+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:39:44.702+0000] {processor.py:186} INFO - Started process (PID=19632) to work on /opt/airflow/dags/test.py
[2025-04-08T05:39:44.703+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:39:44.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:44.705+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:39:44.723+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:44.723+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:39:44.727+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:39:44.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:44.752+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:39:44.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:44.770+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:39:44.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T05:40:15.661+0000] {processor.py:186} INFO - Started process (PID=19701) to work on /opt/airflow/dags/test.py
[2025-04-08T05:40:15.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:40:15.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:15.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:40:15.682+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:15.681+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:40:15.685+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:40:15.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:15.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:40:15.723+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:15.723+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:40:15.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T05:40:46.514+0000] {processor.py:186} INFO - Started process (PID=19770) to work on /opt/airflow/dags/test.py
[2025-04-08T05:40:46.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:40:46.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:46.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:40:46.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:46.534+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:40:46.538+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:40:46.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:46.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:40:46.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:46.578+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:40:46.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T05:41:17.671+0000] {processor.py:186} INFO - Started process (PID=19839) to work on /opt/airflow/dags/test.py
[2025-04-08T05:41:17.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:41:17.676+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:17.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:41:17.693+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:17.693+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:41:17.697+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:41:17.717+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:17.717+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:41:17.734+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:17.734+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:41:17.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T05:41:48.329+0000] {processor.py:186} INFO - Started process (PID=19908) to work on /opt/airflow/dags/test.py
[2025-04-08T05:41:48.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:41:48.333+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:48.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:41:48.353+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:48.353+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:41:48.357+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:41:48.378+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:48.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:41:48.395+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:48.395+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:41:48.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T05:42:18.816+0000] {processor.py:186} INFO - Started process (PID=19977) to work on /opt/airflow/dags/test.py
[2025-04-08T05:42:18.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:42:18.820+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:42:18.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.838+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:42:18.843+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:42:18.866+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:42:18.884+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.883+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:42:18.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T05:42:49.652+0000] {processor.py:186} INFO - Started process (PID=20046) to work on /opt/airflow/dags/test.py
[2025-04-08T05:42:49.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:42:49.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:49.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:42:49.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:49.670+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:42:49.674+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:42:49.696+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:49.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:42:49.713+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:49.713+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:42:49.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:43:20.104+0000] {processor.py:186} INFO - Started process (PID=20115) to work on /opt/airflow/dags/test.py
[2025-04-08T05:43:20.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:43:20.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:20.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:43:20.127+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:20.126+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:43:20.130+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:43:20.152+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:20.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:43:20.171+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:20.171+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:43:20.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T05:43:50.652+0000] {processor.py:186} INFO - Started process (PID=20184) to work on /opt/airflow/dags/test.py
[2025-04-08T05:43:50.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:43:50.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:43:50.671+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.671+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:43:50.675+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:43:50.696+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:43:50.713+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.713+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:43:50.743+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T05:44:21.021+0000] {processor.py:186} INFO - Started process (PID=20252) to work on /opt/airflow/dags/test.py
[2025-04-08T05:44:21.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:44:21.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:21.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:44:21.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:21.040+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:44:21.044+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:44:21.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:21.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:44:21.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:21.080+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:44:21.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:44:51.713+0000] {processor.py:186} INFO - Started process (PID=20321) to work on /opt/airflow/dags/test.py
[2025-04-08T05:44:51.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:44:51.717+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.717+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:44:51.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.736+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:44:51.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:44:51.760+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:44:51.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.777+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:44:51.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:45:22.960+0000] {processor.py:186} INFO - Started process (PID=20390) to work on /opt/airflow/dags/test.py
[2025-04-08T05:45:22.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:45:22.964+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:22.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:45:22.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:22.978+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:45:22.982+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:45:23.002+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:23.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:45:23.018+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:23.018+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:45:23.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T05:45:53.768+0000] {processor.py:186} INFO - Started process (PID=20466) to work on /opt/airflow/dags/test.py
[2025-04-08T05:45:53.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:45:53.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:45:53.791+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.791+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:45:53.795+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:45:53.817+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:45:53.836+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.836+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:45:53.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T05:46:25.586+0000] {processor.py:186} INFO - Started process (PID=20536) to work on /opt/airflow/dags/test.py
[2025-04-08T05:46:25.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:46:25.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:25.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:46:25.606+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:25.605+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:46:25.609+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:46:25.632+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:25.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:46:25.649+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:25.649+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:46:25.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T05:46:56.234+0000] {processor.py:186} INFO - Started process (PID=20605) to work on /opt/airflow/dags/test.py
[2025-04-08T05:46:56.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:46:56.238+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:56.238+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:46:56.257+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:56.257+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:46:56.261+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:46:56.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:56.281+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:46:56.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:56.296+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:46:56.325+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T05:47:27.052+0000] {processor.py:186} INFO - Started process (PID=20674) to work on /opt/airflow/dags/test.py
[2025-04-08T05:47:27.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:47:27.056+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:27.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:47:27.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:27.075+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:47:27.080+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:47:27.100+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:27.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:47:27.116+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:27.116+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:47:27.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T05:47:58.023+0000] {processor.py:186} INFO - Started process (PID=20743) to work on /opt/airflow/dags/test.py
[2025-04-08T05:47:58.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:47:58.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:58.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:47:58.043+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:58.043+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:47:58.047+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:47:58.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:58.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:47:58.085+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:58.085+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:47:58.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T05:48:29.087+0000] {processor.py:186} INFO - Started process (PID=20812) to work on /opt/airflow/dags/test.py
[2025-04-08T05:48:29.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:48:29.092+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:29.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:48:29.113+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:29.113+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:48:29.119+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:48:29.140+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:29.140+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:48:29.156+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:29.156+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:48:29.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T05:48:59.710+0000] {processor.py:186} INFO - Started process (PID=20881) to work on /opt/airflow/dags/test.py
[2025-04-08T05:48:59.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:48:59.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:59.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:48:59.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:59.728+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:48:59.733+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:48:59.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:59.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:48:59.772+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:59.772+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:48:59.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T05:49:30.731+0000] {processor.py:186} INFO - Started process (PID=20950) to work on /opt/airflow/dags/test.py
[2025-04-08T05:49:30.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:49:30.735+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:30.734+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:49:30.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:30.753+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:49:30.756+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:49:30.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:30.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:49:30.792+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:30.792+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:49:30.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:50:01.676+0000] {processor.py:186} INFO - Started process (PID=21020) to work on /opt/airflow/dags/test.py
[2025-04-08T05:50:01.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:50:01.681+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:01.681+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:50:01.697+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:01.697+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:50:01.701+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:50:01.724+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:01.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:50:01.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:01.741+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:50:01.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T05:50:32.418+0000] {processor.py:186} INFO - Started process (PID=21089) to work on /opt/airflow/dags/test.py
[2025-04-08T05:50:32.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:50:32.422+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:32.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:50:32.442+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:32.442+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:50:32.446+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:50:32.467+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:32.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:50:32.484+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:32.484+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:50:32.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T05:51:02.925+0000] {processor.py:186} INFO - Started process (PID=21158) to work on /opt/airflow/dags/test.py
[2025-04-08T05:51:02.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:51:02.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.929+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:51:02.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.946+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:51:02.950+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:51:02.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:51:02.990+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.989+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:51:03.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T05:51:33.773+0000] {processor.py:186} INFO - Started process (PID=21227) to work on /opt/airflow/dags/test.py
[2025-04-08T05:51:33.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:51:33.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:51:33.793+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.793+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:51:33.797+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:51:33.821+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:51:33.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.839+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:51:33.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T05:52:04.456+0000] {processor.py:186} INFO - Started process (PID=21296) to work on /opt/airflow/dags/test.py
[2025-04-08T05:52:04.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:52:04.460+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:04.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:52:04.475+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:04.475+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:52:04.479+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:52:04.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:04.503+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:52:04.522+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:04.522+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:52:04.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T05:52:34.924+0000] {processor.py:186} INFO - Started process (PID=21365) to work on /opt/airflow/dags/test.py
[2025-04-08T05:52:34.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:52:34.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:52:34.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.944+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:52:34.949+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:52:34.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:52:34.988+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.988+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:52:35.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T05:53:05.600+0000] {processor.py:186} INFO - Started process (PID=21433) to work on /opt/airflow/dags/test.py
[2025-04-08T05:53:05.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:53:05.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:53:05.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.621+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:53:05.625+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:53:05.654+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:53:05.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.674+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:53:05.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T05:53:36.312+0000] {processor.py:186} INFO - Started process (PID=21502) to work on /opt/airflow/dags/test.py
[2025-04-08T05:53:36.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:53:36.316+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:36.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:53:36.337+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:36.336+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:53:36.340+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:53:36.362+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:36.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:53:36.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:36.380+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:53:36.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:54:06.936+0000] {processor.py:186} INFO - Started process (PID=21571) to work on /opt/airflow/dags/test.py
[2025-04-08T05:54:06.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:54:06.940+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:54:06.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.958+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:54:06.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:54:06.981+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:54:06.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.996+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:54:07.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T05:54:37.566+0000] {processor.py:186} INFO - Started process (PID=21640) to work on /opt/airflow/dags/test.py
[2025-04-08T05:54:37.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:54:37.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.570+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:54:37.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.587+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:54:37.591+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:54:37.613+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:54:37.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.631+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:54:37.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T05:55:08.837+0000] {processor.py:186} INFO - Started process (PID=21710) to work on /opt/airflow/dags/test.py
[2025-04-08T05:55:08.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:55:08.840+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:55:08.857+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.856+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:55:08.860+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:55:08.881+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:55:08.899+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.898+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:55:08.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:55:39.884+0000] {processor.py:186} INFO - Started process (PID=21779) to work on /opt/airflow/dags/test.py
[2025-04-08T05:55:39.885+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:55:39.887+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:55:39.903+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.903+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:55:39.907+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:55:39.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:55:39.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.945+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:55:39.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:56:10.750+0000] {processor.py:186} INFO - Started process (PID=21848) to work on /opt/airflow/dags/test.py
[2025-04-08T05:56:10.751+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:56:10.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:10.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:56:10.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:10.769+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:56:10.773+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:56:10.794+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:10.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:56:10.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:10.811+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:56:10.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T05:56:41.457+0000] {processor.py:186} INFO - Started process (PID=21917) to work on /opt/airflow/dags/test.py
[2025-04-08T05:56:41.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:56:41.461+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:41.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:56:41.478+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:41.477+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:56:41.482+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:56:41.504+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:41.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:56:41.521+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:41.521+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:56:41.554+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T05:57:11.855+0000] {processor.py:186} INFO - Started process (PID=21986) to work on /opt/airflow/dags/test.py
[2025-04-08T05:57:11.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:57:11.859+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:57:11.875+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.874+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:57:11.878+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:57:11.899+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:57:11.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.916+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:57:11.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T05:57:42.597+0000] {processor.py:186} INFO - Started process (PID=22055) to work on /opt/airflow/dags/test.py
[2025-04-08T05:57:42.599+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:57:42.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:42.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:57:42.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:42.618+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:57:42.621+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:57:42.642+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:42.642+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:57:42.658+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:42.658+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:57:42.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T05:58:13.873+0000] {processor.py:186} INFO - Started process (PID=22124) to work on /opt/airflow/dags/test.py
[2025-04-08T05:58:13.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:58:13.877+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:13.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:58:13.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:13.892+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:58:13.897+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:58:13.919+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:13.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:58:13.937+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:13.937+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:58:13.968+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T05:58:44.394+0000] {processor.py:186} INFO - Started process (PID=22192) to work on /opt/airflow/dags/test.py
[2025-04-08T05:58:44.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:58:44.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:44.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:58:44.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:44.417+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:58:44.422+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:58:44.443+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:44.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:58:44.460+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:44.460+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:58:44.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T05:59:15.548+0000] {processor.py:186} INFO - Started process (PID=22261) to work on /opt/airflow/dags/test.py
[2025-04-08T05:59:15.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:59:15.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:15.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:59:15.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:15.569+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:59:15.573+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:59:15.593+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:15.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:59:15.609+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:15.609+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:59:15.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T05:59:46.244+0000] {processor.py:186} INFO - Started process (PID=22330) to work on /opt/airflow/dags/test.py
[2025-04-08T05:59:46.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T05:59:46.249+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:46.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T05:59:46.264+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:46.264+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T05:59:46.268+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T05:59:46.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:46.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:59:46.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:46.305+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T05:59:46.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:00:17.407+0000] {processor.py:186} INFO - Started process (PID=22399) to work on /opt/airflow/dags/test.py
[2025-04-08T06:00:17.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:00:17.411+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:17.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:00:17.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:17.425+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:00:17.428+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:00:17.450+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:17.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:00:17.466+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:17.466+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:00:17.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:00:47.926+0000] {processor.py:186} INFO - Started process (PID=22468) to work on /opt/airflow/dags/test.py
[2025-04-08T06:00:47.927+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:00:47.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:47.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:00:47.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:47.944+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:00:47.948+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:00:47.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:47.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:00:47.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:47.984+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:00:48.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:01:18.914+0000] {processor.py:186} INFO - Started process (PID=22537) to work on /opt/airflow/dags/test.py
[2025-04-08T06:01:18.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:01:18.918+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:18.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:01:18.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:18.931+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:01:18.934+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:01:18.955+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:18.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:01:18.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:18.972+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:01:19.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:01:49.646+0000] {processor.py:186} INFO - Started process (PID=22606) to work on /opt/airflow/dags/test.py
[2025-04-08T06:01:49.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:01:49.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:49.651+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:01:49.666+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:49.665+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:01:49.669+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:01:49.689+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:49.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:01:49.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:49.706+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:01:49.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:02:19.882+0000] {processor.py:186} INFO - Started process (PID=22674) to work on /opt/airflow/dags/test.py
[2025-04-08T06:02:19.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:02:19.886+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:19.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:02:19.905+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:19.905+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:02:19.909+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:02:19.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:19.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:02:19.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:19.945+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:02:19.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:02:50.531+0000] {processor.py:186} INFO - Started process (PID=22743) to work on /opt/airflow/dags/test.py
[2025-04-08T06:02:50.532+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:02:50.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:50.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:02:50.549+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:50.549+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:02:50.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:02:50.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:50.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:02:50.589+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:50.588+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:02:50.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:03:21.151+0000] {processor.py:186} INFO - Started process (PID=22812) to work on /opt/airflow/dags/test.py
[2025-04-08T06:03:21.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:03:21.155+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:21.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:03:21.170+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:21.169+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:03:21.173+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:03:21.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:21.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:03:21.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:21.210+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:03:21.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:03:51.663+0000] {processor.py:186} INFO - Started process (PID=22881) to work on /opt/airflow/dags/test.py
[2025-04-08T06:03:51.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:03:51.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:51.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:03:51.681+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:51.680+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:03:51.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:03:51.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:51.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:03:51.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:51.722+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:03:51.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:04:22.210+0000] {processor.py:186} INFO - Started process (PID=22950) to work on /opt/airflow/dags/test.py
[2025-04-08T06:04:22.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:04:22.215+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:22.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:04:22.227+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:22.226+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:04:22.230+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:04:22.251+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:22.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:04:22.269+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:22.269+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:04:22.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:04:52.357+0000] {processor.py:186} INFO - Started process (PID=23018) to work on /opt/airflow/dags/test.py
[2025-04-08T06:04:52.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:04:52.361+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:52.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:04:52.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:52.380+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:04:52.384+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:04:52.402+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:52.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:04:52.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:52.418+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:04:52.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:05:23.058+0000] {processor.py:186} INFO - Started process (PID=23087) to work on /opt/airflow/dags/test.py
[2025-04-08T06:05:23.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:05:23.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:23.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:05:23.078+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:23.078+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:05:23.082+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:05:23.103+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:23.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:05:23.119+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:23.119+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:05:23.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:05:54.512+0000] {processor.py:186} INFO - Started process (PID=23157) to work on /opt/airflow/dags/test.py
[2025-04-08T06:05:54.514+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:05:54.517+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:54.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:05:54.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:54.535+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:05:54.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:05:54.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:54.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:05:54.575+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:54.575+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:05:54.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:06:26.225+0000] {processor.py:186} INFO - Started process (PID=23232) to work on /opt/airflow/dags/test.py
[2025-04-08T06:06:26.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:06:26.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:26.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:06:26.248+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:26.248+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:06:26.252+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:06:26.273+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:26.273+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:06:26.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:26.293+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:06:26.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T06:06:57.088+0000] {processor.py:186} INFO - Started process (PID=23301) to work on /opt/airflow/dags/test.py
[2025-04-08T06:06:57.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:06:57.092+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:57.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:06:57.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:57.109+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:06:57.113+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:06:57.134+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:57.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:06:57.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:57.150+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:06:57.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:07:27.960+0000] {processor.py:186} INFO - Started process (PID=23370) to work on /opt/airflow/dags/test.py
[2025-04-08T06:07:27.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:07:27.965+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:27.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:07:27.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:27.982+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:07:27.986+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:07:28.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:28.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:07:28.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:28.025+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:07:28.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:07:58.189+0000] {processor.py:186} INFO - Started process (PID=23438) to work on /opt/airflow/dags/test.py
[2025-04-08T06:07:58.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:07:58.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:58.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:07:58.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:58.210+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:07:58.214+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:07:58.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:58.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:07:58.250+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:58.250+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:07:58.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:08:29.173+0000] {processor.py:186} INFO - Started process (PID=23506) to work on /opt/airflow/dags/test.py
[2025-04-08T06:08:29.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:08:29.177+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:29.176+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:08:29.197+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:29.197+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:08:29.202+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:08:29.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:29.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:08:29.240+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:29.240+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:08:29.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T06:09:00.244+0000] {processor.py:186} INFO - Started process (PID=23575) to work on /opt/airflow/dags/test.py
[2025-04-08T06:09:00.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:09:00.248+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:00.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:09:00.267+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:00.266+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:09:00.272+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:09:00.291+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:00.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:09:00.308+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:00.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:09:00.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:09:31.562+0000] {processor.py:186} INFO - Started process (PID=23644) to work on /opt/airflow/dags/test.py
[2025-04-08T06:09:31.563+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:09:31.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:09:31.580+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.580+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:09:31.584+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:09:31.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:09:31.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.621+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:09:31.651+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:10:02.981+0000] {processor.py:186} INFO - Started process (PID=23714) to work on /opt/airflow/dags/test.py
[2025-04-08T06:10:02.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:10:02.985+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:02.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:10:03.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:03.000+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:10:03.004+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:10:03.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:03.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:10:03.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:03.041+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:10:03.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:10:33.837+0000] {processor.py:186} INFO - Started process (PID=23782) to work on /opt/airflow/dags/test.py
[2025-04-08T06:10:33.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:10:33.841+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:33.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:10:33.860+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:33.859+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:10:33.863+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:10:33.882+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:33.882+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:10:33.898+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:33.898+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:10:33.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:11:04.975+0000] {processor.py:186} INFO - Started process (PID=23851) to work on /opt/airflow/dags/test.py
[2025-04-08T06:11:04.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:11:04.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:04.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:11:04.995+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:04.995+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:11:04.999+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:11:05.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:05.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:11:05.047+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:05.047+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:11:05.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T06:11:35.765+0000] {processor.py:186} INFO - Started process (PID=23920) to work on /opt/airflow/dags/test.py
[2025-04-08T06:11:35.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:11:35.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:35.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:11:35.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:35.786+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:11:35.790+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:11:35.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:35.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:11:35.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:35.828+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:11:35.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:12:05.941+0000] {processor.py:186} INFO - Started process (PID=23987) to work on /opt/airflow/dags/test.py
[2025-04-08T06:12:05.942+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:12:05.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:05.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:12:05.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:05.961+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:12:05.965+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:12:05.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:05.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:12:06.010+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:06.009+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:12:06.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T06:12:36.122+0000] {processor.py:186} INFO - Started process (PID=24055) to work on /opt/airflow/dags/test.py
[2025-04-08T06:12:36.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:12:36.126+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:36.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:12:36.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:36.141+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:12:36.145+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:12:36.165+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:36.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:12:36.182+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:36.182+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:12:36.213+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:13:06.389+0000] {processor.py:186} INFO - Started process (PID=24124) to work on /opt/airflow/dags/test.py
[2025-04-08T06:13:06.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:13:06.393+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:13:06.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.408+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:13:06.412+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:13:06.432+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.431+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:13:06.447+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.447+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:13:06.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T06:13:36.801+0000] {processor.py:186} INFO - Started process (PID=24192) to work on /opt/airflow/dags/test.py
[2025-04-08T06:13:36.802+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:13:36.806+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:36.805+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:13:36.824+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:36.824+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:13:36.827+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:13:36.846+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:36.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:13:36.862+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:36.862+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:13:36.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:14:07.561+0000] {processor.py:186} INFO - Started process (PID=24262) to work on /opt/airflow/dags/test.py
[2025-04-08T06:14:07.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:14:07.564+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:14:07.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.578+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:14:07.582+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:14:07.602+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:14:07.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.618+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:14:07.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:14:38.337+0000] {processor.py:186} INFO - Started process (PID=24331) to work on /opt/airflow/dags/test.py
[2025-04-08T06:14:38.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:14:38.342+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:14:38.360+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.360+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:14:38.364+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:14:38.385+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:14:38.403+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.403+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:14:38.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:15:08.907+0000] {processor.py:186} INFO - Started process (PID=24400) to work on /opt/airflow/dags/test.py
[2025-04-08T06:15:08.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:15:08.912+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:08.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:15:08.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:08.926+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:15:08.931+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:15:08.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:08.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:15:08.967+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:08.967+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:15:08.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:15:39.227+0000] {processor.py:186} INFO - Started process (PID=24468) to work on /opt/airflow/dags/test.py
[2025-04-08T06:15:39.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:15:39.233+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:15:39.251+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.251+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:15:39.255+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:15:39.274+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:15:39.291+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.291+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:15:39.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:16:09.602+0000] {processor.py:186} INFO - Started process (PID=24537) to work on /opt/airflow/dags/test.py
[2025-04-08T06:16:09.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:16:09.607+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:09.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:16:09.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:09.625+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:16:09.629+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:16:09.649+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:09.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:16:09.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:09.664+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:16:09.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:16:40.282+0000] {processor.py:186} INFO - Started process (PID=24606) to work on /opt/airflow/dags/test.py
[2025-04-08T06:16:40.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:16:40.286+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:40.285+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:16:40.304+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:40.304+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:16:40.308+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:16:40.328+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:40.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:16:40.347+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:40.346+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:16:40.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:17:10.889+0000] {processor.py:186} INFO - Started process (PID=24675) to work on /opt/airflow/dags/test.py
[2025-04-08T06:17:10.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:17:10.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:10.892+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:17:10.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:10.910+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:17:10.914+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:17:10.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:10.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:17:10.950+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:10.950+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:17:10.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T06:17:41.116+0000] {processor.py:186} INFO - Started process (PID=24744) to work on /opt/airflow/dags/test.py
[2025-04-08T06:17:41.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:17:41.121+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:41.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:17:41.144+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:41.144+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:17:41.148+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:17:41.167+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:41.167+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:17:41.183+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:41.183+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:17:41.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:18:11.586+0000] {processor.py:186} INFO - Started process (PID=24813) to work on /opt/airflow/dags/test.py
[2025-04-08T06:18:11.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:18:11.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:11.589+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:18:11.608+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:11.608+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:18:11.612+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:18:11.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:11.631+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:18:11.647+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:11.647+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:18:11.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:18:41.888+0000] {processor.py:186} INFO - Started process (PID=24882) to work on /opt/airflow/dags/test.py
[2025-04-08T06:18:41.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:18:41.894+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:41.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:18:41.912+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:41.912+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:18:41.916+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:18:41.936+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:41.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:18:41.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:41.951+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:18:41.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:19:12.139+0000] {processor.py:186} INFO - Started process (PID=24951) to work on /opt/airflow/dags/test.py
[2025-04-08T06:19:12.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:19:12.144+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:12.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:19:12.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:12.163+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:19:12.167+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:19:12.186+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:12.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:19:12.201+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:12.201+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:19:12.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T06:19:42.538+0000] {processor.py:186} INFO - Started process (PID=25020) to work on /opt/airflow/dags/test.py
[2025-04-08T06:19:42.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:19:42.543+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:42.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:19:42.564+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:42.563+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:19:42.568+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:19:42.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:42.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:19:42.603+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:42.602+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:19:42.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:20:12.942+0000] {processor.py:186} INFO - Started process (PID=25089) to work on /opt/airflow/dags/test.py
[2025-04-08T06:20:12.943+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:20:12.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:12.945+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:20:12.966+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:12.965+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:20:12.969+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:20:12.988+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:12.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:20:13.003+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:13.003+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:20:13.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:20:43.550+0000] {processor.py:186} INFO - Started process (PID=25158) to work on /opt/airflow/dags/test.py
[2025-04-08T06:20:43.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:20:43.554+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:43.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:20:43.572+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:43.572+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:20:43.576+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:20:43.595+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:43.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:20:43.611+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:43.611+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:20:43.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:21:14.389+0000] {processor.py:186} INFO - Started process (PID=25227) to work on /opt/airflow/dags/test.py
[2025-04-08T06:21:14.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:21:14.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:14.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:21:14.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:14.418+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:21:14.423+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:21:14.448+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:14.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:21:14.464+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:14.464+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:21:14.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T06:21:44.796+0000] {processor.py:186} INFO - Started process (PID=25296) to work on /opt/airflow/dags/test.py
[2025-04-08T06:21:44.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:21:44.800+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:44.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:21:44.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:44.814+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:21:44.818+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:21:44.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:44.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:21:44.855+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:44.854+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:21:44.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:22:15.028+0000] {processor.py:186} INFO - Started process (PID=25365) to work on /opt/airflow/dags/test.py
[2025-04-08T06:22:15.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:22:15.032+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:15.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:22:15.049+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:15.048+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:22:15.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:22:15.073+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:15.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:22:15.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:15.089+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:22:15.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:22:45.328+0000] {processor.py:186} INFO - Started process (PID=25434) to work on /opt/airflow/dags/test.py
[2025-04-08T06:22:45.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:22:45.334+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:45.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:22:45.354+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:45.353+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:22:45.358+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:22:45.378+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:45.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:22:45.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:45.394+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:22:45.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T06:23:15.563+0000] {processor.py:186} INFO - Started process (PID=25503) to work on /opt/airflow/dags/test.py
[2025-04-08T06:23:15.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:23:15.570+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:15.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:23:15.593+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:15.592+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:23:15.596+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:23:15.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:15.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:23:15.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:15.631+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:23:15.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:23:45.769+0000] {processor.py:186} INFO - Started process (PID=25572) to work on /opt/airflow/dags/test.py
[2025-04-08T06:23:45.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:23:45.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:45.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:23:45.788+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:45.788+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:23:45.792+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:23:45.812+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:45.812+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:23:45.829+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:45.828+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:23:45.858+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T06:24:16.443+0000] {processor.py:186} INFO - Started process (PID=25641) to work on /opt/airflow/dags/test.py
[2025-04-08T06:24:16.444+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:24:16.448+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:16.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:24:16.470+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:16.470+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:24:16.474+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:24:16.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:16.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:24:16.509+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:16.509+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:24:16.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:24:46.781+0000] {processor.py:186} INFO - Started process (PID=25710) to work on /opt/airflow/dags/test.py
[2025-04-08T06:24:46.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:24:46.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:46.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:24:46.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:46.807+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:24:46.811+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:24:46.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:46.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:24:46.846+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:46.846+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:24:46.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T06:25:17.312+0000] {processor.py:186} INFO - Started process (PID=25779) to work on /opt/airflow/dags/test.py
[2025-04-08T06:25:17.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:25:17.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:17.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:25:17.332+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:17.331+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:25:17.335+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:25:17.355+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:17.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:25:17.372+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:17.371+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:25:17.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:25:47.684+0000] {processor.py:186} INFO - Started process (PID=25847) to work on /opt/airflow/dags/test.py
[2025-04-08T06:25:47.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:25:47.689+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:47.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:25:47.715+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:47.715+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:25:47.719+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:25:47.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:47.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:25:47.759+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:47.759+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:25:47.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T06:26:17.929+0000] {processor.py:186} INFO - Started process (PID=25916) to work on /opt/airflow/dags/test.py
[2025-04-08T06:26:17.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:26:17.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:17.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:26:17.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:17.952+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:26:17.956+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:26:17.974+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:17.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:26:17.990+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:17.990+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:26:18.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T06:26:48.585+0000] {processor.py:186} INFO - Started process (PID=25985) to work on /opt/airflow/dags/test.py
[2025-04-08T06:26:48.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:26:48.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:48.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:26:48.609+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:48.609+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:26:48.613+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:26:48.632+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:48.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:26:48.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:48.647+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:26:48.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:27:19.538+0000] {processor.py:186} INFO - Started process (PID=26054) to work on /opt/airflow/dags/test.py
[2025-04-08T06:27:19.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:27:19.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:19.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:27:19.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:19.561+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:27:19.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:27:19.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:19.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:27:19.602+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:19.602+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:27:19.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T06:27:50.012+0000] {processor.py:186} INFO - Started process (PID=26123) to work on /opt/airflow/dags/test.py
[2025-04-08T06:27:50.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:27:50.015+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:50.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:27:50.032+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:50.031+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:27:50.036+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:27:50.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:50.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:27:50.071+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:50.071+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:27:50.099+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T06:28:20.353+0000] {processor.py:186} INFO - Started process (PID=26191) to work on /opt/airflow/dags/test.py
[2025-04-08T06:28:20.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:28:20.356+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:20.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:28:20.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:20.371+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:28:20.374+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:28:20.395+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:20.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:28:20.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:20.412+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:28:20.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:28:50.528+0000] {processor.py:186} INFO - Started process (PID=26260) to work on /opt/airflow/dags/test.py
[2025-04-08T06:28:50.529+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:28:50.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:50.535+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:28:50.566+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:50.566+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:28:50.571+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:28:50.596+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:50.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:28:50.617+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:50.616+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:28:50.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-08T06:29:21.160+0000] {processor.py:186} INFO - Started process (PID=26328) to work on /opt/airflow/dags/test.py
[2025-04-08T06:29:21.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:29:21.164+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:21.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:29:21.181+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:21.181+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:29:21.185+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:29:21.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:21.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:29:21.222+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:21.222+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:29:21.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:29:52.004+0000] {processor.py:186} INFO - Started process (PID=26397) to work on /opt/airflow/dags/test.py
[2025-04-08T06:29:52.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:29:52.010+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:52.009+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:29:52.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:52.025+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:29:52.030+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:29:52.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:52.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:29:52.067+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:52.067+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:29:52.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:30:22.908+0000] {processor.py:186} INFO - Started process (PID=26466) to work on /opt/airflow/dags/test.py
[2025-04-08T06:30:22.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:30:22.913+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:22.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:30:22.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:22.931+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:30:22.935+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:30:22.956+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:22.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:30:22.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:22.972+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:30:23.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:30:53.252+0000] {processor.py:186} INFO - Started process (PID=26535) to work on /opt/airflow/dags/test.py
[2025-04-08T06:30:53.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:30:53.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:53.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:30:53.270+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:53.270+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:30:53.274+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:30:53.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:53.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:30:53.308+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:53.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:30:53.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T06:31:23.629+0000] {processor.py:186} INFO - Started process (PID=26604) to work on /opt/airflow/dags/test.py
[2025-04-08T06:31:23.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:31:23.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:23.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:31:23.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:23.648+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:31:23.652+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:31:23.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:23.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:31:23.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:23.688+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:31:23.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T06:31:53.920+0000] {processor.py:186} INFO - Started process (PID=26673) to work on /opt/airflow/dags/test.py
[2025-04-08T06:31:53.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:31:53.925+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:53.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:31:53.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:53.945+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:31:53.950+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:31:53.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:53.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:31:53.988+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:53.988+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:31:54.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:32:24.408+0000] {processor.py:186} INFO - Started process (PID=26742) to work on /opt/airflow/dags/test.py
[2025-04-08T06:32:24.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:32:24.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:24.412+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:32:24.430+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:24.430+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:32:24.434+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:32:24.454+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:24.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:32:24.470+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:24.470+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:32:24.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:32:55.359+0000] {processor.py:186} INFO - Started process (PID=26811) to work on /opt/airflow/dags/test.py
[2025-04-08T06:32:55.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:32:55.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:55.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:32:55.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:55.381+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:32:55.385+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:32:55.404+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:55.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:32:55.420+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:55.420+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:32:55.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:33:25.930+0000] {processor.py:186} INFO - Started process (PID=26880) to work on /opt/airflow/dags/test.py
[2025-04-08T06:33:25.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:33:25.935+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:25.935+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:33:25.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:25.954+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:33:25.958+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:33:25.978+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:25.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:33:25.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:25.996+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:33:26.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T06:33:56.754+0000] {processor.py:186} INFO - Started process (PID=26949) to work on /opt/airflow/dags/test.py
[2025-04-08T06:33:56.756+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:33:56.759+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:56.758+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:33:56.779+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:56.778+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:33:56.782+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:33:56.800+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:56.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:33:56.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:56.816+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:33:56.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:34:27.641+0000] {processor.py:186} INFO - Started process (PID=27018) to work on /opt/airflow/dags/test.py
[2025-04-08T06:34:27.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:34:27.644+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:27.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:34:27.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:27.664+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:34:27.668+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:34:27.690+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:27.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:34:27.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:27.708+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:34:27.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:34:57.798+0000] {processor.py:186} INFO - Started process (PID=27087) to work on /opt/airflow/dags/test.py
[2025-04-08T06:34:57.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:34:57.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:57.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:34:57.817+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:57.816+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:34:57.820+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:34:57.841+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:57.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:34:57.859+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:57.859+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:34:57.890+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:35:28.562+0000] {processor.py:186} INFO - Started process (PID=27156) to work on /opt/airflow/dags/test.py
[2025-04-08T06:35:28.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:35:28.568+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:28.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:35:28.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:28.588+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:35:28.592+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:35:28.611+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:28.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:35:28.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:28.626+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:35:28.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T06:35:58.728+0000] {processor.py:186} INFO - Started process (PID=27225) to work on /opt/airflow/dags/test.py
[2025-04-08T06:35:58.729+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:35:58.732+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:58.731+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:35:58.756+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:58.756+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:35:58.760+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:35:58.785+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:58.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:35:58.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:58.802+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:35:58.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:36:29.671+0000] {processor.py:186} INFO - Started process (PID=27292) to work on /opt/airflow/dags/test.py
[2025-04-08T06:36:29.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:36:29.676+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:29.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:36:29.691+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:29.691+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:36:29.695+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:36:29.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:29.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:36:29.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:29.736+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:36:29.766+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:37:00.537+0000] {processor.py:186} INFO - Started process (PID=27367) to work on /opt/airflow/dags/test.py
[2025-04-08T06:37:00.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:37:00.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:00.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:37:00.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:00.561+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:37:00.566+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:37:00.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:00.586+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:37:00.603+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:00.602+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:37:00.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:37:30.990+0000] {processor.py:186} INFO - Started process (PID=27436) to work on /opt/airflow/dags/test.py
[2025-04-08T06:37:30.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:37:30.994+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:30.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:37:31.010+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:31.010+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:37:31.013+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:37:31.033+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:31.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:37:31.048+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:31.047+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:37:31.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T06:38:01.631+0000] {processor.py:186} INFO - Started process (PID=27505) to work on /opt/airflow/dags/test.py
[2025-04-08T06:38:01.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:38:01.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:01.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:38:01.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:01.650+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:38:01.654+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:38:01.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:01.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:38:01.690+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:01.689+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:38:01.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T06:38:32.177+0000] {processor.py:186} INFO - Started process (PID=27574) to work on /opt/airflow/dags/test.py
[2025-04-08T06:38:32.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:38:32.182+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:32.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:38:32.197+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:32.197+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:38:32.200+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:38:32.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:32.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:38:32.243+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:32.242+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:38:32.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:39:02.681+0000] {processor.py:186} INFO - Started process (PID=27643) to work on /opt/airflow/dags/test.py
[2025-04-08T06:39:02.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:39:02.686+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:02.685+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:39:02.700+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:02.700+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:39:02.704+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:39:02.724+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:02.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:39:02.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:02.740+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:39:02.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:39:33.307+0000] {processor.py:186} INFO - Started process (PID=27712) to work on /opt/airflow/dags/test.py
[2025-04-08T06:39:33.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:39:33.312+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:33.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:39:33.330+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:33.330+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:39:33.334+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:39:33.353+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:33.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:39:33.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:33.368+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:39:33.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T06:40:04.066+0000] {processor.py:186} INFO - Started process (PID=27781) to work on /opt/airflow/dags/test.py
[2025-04-08T06:40:04.068+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:40:04.071+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:04.071+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:40:04.088+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:04.088+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:40:04.092+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:40:04.113+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:04.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:40:04.130+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:04.129+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:40:04.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:40:34.530+0000] {processor.py:186} INFO - Started process (PID=27850) to work on /opt/airflow/dags/test.py
[2025-04-08T06:40:34.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:40:34.533+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:34.533+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:40:34.552+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:34.551+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:40:34.555+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:40:34.574+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:34.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:40:34.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:34.590+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:40:34.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:41:05.341+0000] {processor.py:186} INFO - Started process (PID=27919) to work on /opt/airflow/dags/test.py
[2025-04-08T06:41:05.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:41:05.345+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:05.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:41:05.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:05.363+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:41:05.368+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:41:05.390+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:05.390+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:41:05.409+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:05.409+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:41:05.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T06:41:35.792+0000] {processor.py:186} INFO - Started process (PID=27988) to work on /opt/airflow/dags/test.py
[2025-04-08T06:41:35.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:41:35.798+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:35.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:41:35.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:35.815+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:41:35.819+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:41:35.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:35.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:41:35.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:35.858+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:41:35.891+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T06:42:06.172+0000] {processor.py:186} INFO - Started process (PID=28057) to work on /opt/airflow/dags/test.py
[2025-04-08T06:42:06.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:42:06.177+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:06.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:42:06.196+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:06.196+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:42:06.199+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:42:06.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:06.218+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:42:06.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:06.234+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:42:06.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:42:37.088+0000] {processor.py:186} INFO - Started process (PID=28126) to work on /opt/airflow/dags/test.py
[2025-04-08T06:42:37.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:42:37.094+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:37.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:42:37.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:37.111+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:42:37.115+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:42:37.133+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:37.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:42:37.148+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:37.148+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:42:37.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:43:07.363+0000] {processor.py:186} INFO - Started process (PID=28195) to work on /opt/airflow/dags/test.py
[2025-04-08T06:43:07.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:43:07.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:07.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:43:07.390+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:07.390+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:43:07.394+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:43:07.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:07.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:43:07.428+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:07.427+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:43:07.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:43:37.822+0000] {processor.py:186} INFO - Started process (PID=28264) to work on /opt/airflow/dags/test.py
[2025-04-08T06:43:37.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:43:37.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:37.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:43:37.861+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:37.860+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:43:37.864+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:43:37.884+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:37.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:43:37.899+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:37.899+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:43:37.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T06:44:08.207+0000] {processor.py:186} INFO - Started process (PID=28333) to work on /opt/airflow/dags/test.py
[2025-04-08T06:44:08.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:44:08.211+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:08.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:44:08.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:08.230+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:44:08.234+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:44:08.252+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:08.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:44:08.267+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:08.267+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:44:08.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T06:44:39.235+0000] {processor.py:186} INFO - Started process (PID=28402) to work on /opt/airflow/dags/test.py
[2025-04-08T06:44:39.237+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:44:39.240+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:39.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:44:39.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:39.255+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:44:39.259+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:44:39.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:39.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:44:39.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:39.294+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:44:39.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T06:45:09.511+0000] {processor.py:186} INFO - Started process (PID=28470) to work on /opt/airflow/dags/test.py
[2025-04-08T06:45:09.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:45:09.515+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:09.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:45:09.533+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:09.533+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:45:09.537+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:45:09.556+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:09.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:45:09.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:09.573+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:45:09.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T06:45:40.515+0000] {processor.py:186} INFO - Started process (PID=28539) to work on /opt/airflow/dags/test.py
[2025-04-08T06:45:40.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:45:40.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:40.519+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:45:40.534+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:40.533+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:45:40.537+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:45:40.555+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:40.555+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:45:40.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:40.570+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:45:40.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.091 seconds
[2025-04-08T06:46:10.804+0000] {processor.py:186} INFO - Started process (PID=28608) to work on /opt/airflow/dags/test.py
[2025-04-08T06:46:10.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:46:10.808+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:10.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:46:10.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:10.826+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:46:10.830+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:46:10.847+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:10.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:46:10.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:10.865+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:46:10.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T06:46:41.099+0000] {processor.py:186} INFO - Started process (PID=28677) to work on /opt/airflow/dags/test.py
[2025-04-08T06:46:41.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:46:41.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:41.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:46:41.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:41.124+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:46:41.128+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:46:41.147+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:41.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:46:41.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:41.162+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:46:41.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T06:47:11.275+0000] {processor.py:186} INFO - Started process (PID=28746) to work on /opt/airflow/dags/test.py
[2025-04-08T06:47:11.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:47:11.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:11.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:47:11.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:11.298+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:47:11.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:47:11.322+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:11.322+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:47:11.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:11.342+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:47:11.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T06:47:41.981+0000] {processor.py:186} INFO - Started process (PID=28815) to work on /opt/airflow/dags/test.py
[2025-04-08T06:47:41.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:47:41.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:41.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:47:42.002+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:42.002+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:47:42.006+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:47:42.026+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:42.026+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:47:42.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:42.042+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:47:42.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:48:12.405+0000] {processor.py:186} INFO - Started process (PID=28884) to work on /opt/airflow/dags/test.py
[2025-04-08T06:48:12.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:48:12.410+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:12.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:48:12.427+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:12.427+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:48:12.430+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:48:12.453+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:12.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:48:12.469+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:12.469+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:48:12.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:48:42.901+0000] {processor.py:186} INFO - Started process (PID=28953) to work on /opt/airflow/dags/test.py
[2025-04-08T06:48:42.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:48:42.905+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:42.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:48:42.924+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:42.924+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:48:42.928+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:48:42.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:42.947+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:48:42.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:42.962+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:48:42.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T06:49:13.059+0000] {processor.py:186} INFO - Started process (PID=29022) to work on /opt/airflow/dags/test.py
[2025-04-08T06:49:13.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:49:13.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:13.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:49:13.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:13.082+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:49:13.086+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:49:13.105+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:13.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:49:13.121+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:13.120+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:49:13.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:49:43.721+0000] {processor.py:186} INFO - Started process (PID=29091) to work on /opt/airflow/dags/test.py
[2025-04-08T06:49:43.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:49:43.726+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:43.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:49:43.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:43.741+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:49:43.745+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:49:43.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:43.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:49:43.780+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:43.780+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:49:43.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:50:14.360+0000] {processor.py:186} INFO - Started process (PID=29160) to work on /opt/airflow/dags/test.py
[2025-04-08T06:50:14.362+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:50:14.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:14.364+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:50:14.386+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:14.385+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:50:14.389+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:50:14.409+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:14.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:50:14.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:14.425+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:50:14.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:50:44.660+0000] {processor.py:186} INFO - Started process (PID=29229) to work on /opt/airflow/dags/test.py
[2025-04-08T06:50:44.661+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:50:44.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:44.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:50:44.682+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:44.682+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:50:44.686+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:50:44.705+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:44.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:50:44.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:44.722+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:50:44.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:51:15.608+0000] {processor.py:186} INFO - Started process (PID=29296) to work on /opt/airflow/dags/test.py
[2025-04-08T06:51:15.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:51:15.611+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:15.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:51:15.632+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:15.631+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:51:15.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:51:15.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:15.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:51:15.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:15.673+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:51:15.703+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T06:51:46.450+0000] {processor.py:186} INFO - Started process (PID=29365) to work on /opt/airflow/dags/test.py
[2025-04-08T06:51:46.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:51:46.454+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:46.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:51:46.469+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:46.468+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:51:46.473+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:51:46.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:46.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:51:46.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:46.518+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:51:46.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T06:52:16.665+0000] {processor.py:186} INFO - Started process (PID=29434) to work on /opt/airflow/dags/test.py
[2025-04-08T06:52:16.667+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:52:16.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:16.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:52:16.691+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:16.691+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:52:16.695+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:52:16.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:16.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:52:16.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:16.729+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:52:16.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T06:52:46.811+0000] {processor.py:186} INFO - Started process (PID=29503) to work on /opt/airflow/dags/test.py
[2025-04-08T06:52:46.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:52:46.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:46.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:52:46.829+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:46.828+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:52:46.832+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:52:46.849+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:46.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:52:46.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:46.865+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:52:46.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.092 seconds
[2025-04-08T06:53:16.979+0000] {processor.py:186} INFO - Started process (PID=29572) to work on /opt/airflow/dags/test.py
[2025-04-08T06:53:16.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:53:16.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:16.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:53:16.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:16.999+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:53:17.003+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:53:17.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:17.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:53:17.044+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:17.044+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:53:17.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:53:47.652+0000] {processor.py:186} INFO - Started process (PID=29633) to work on /opt/airflow/dags/test.py
[2025-04-08T06:53:47.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:53:47.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:47.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:53:47.671+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:47.671+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:53:47.675+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:53:47.697+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:47.697+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:53:47.715+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:47.714+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:53:47.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:54:18.578+0000] {processor.py:186} INFO - Started process (PID=29702) to work on /opt/airflow/dags/test.py
[2025-04-08T06:54:18.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:54:18.582+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:18.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:54:18.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:18.601+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:54:18.605+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:54:18.628+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:18.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:54:18.645+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:18.645+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:54:18.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:54:48.810+0000] {processor.py:186} INFO - Started process (PID=29760) to work on /opt/airflow/dags/test.py
[2025-04-08T06:54:48.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:54:48.814+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:48.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:54:48.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:48.831+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:54:48.836+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:54:48.857+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:48.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:54:48.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:48.873+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:54:48.904+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:55:19.765+0000] {processor.py:186} INFO - Started process (PID=29826) to work on /opt/airflow/dags/test.py
[2025-04-08T06:55:19.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:55:19.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:19.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:55:19.791+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:19.790+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:55:19.794+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:55:19.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:19.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:55:19.834+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:19.833+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:55:19.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:55:50.354+0000] {processor.py:186} INFO - Started process (PID=29886) to work on /opt/airflow/dags/test.py
[2025-04-08T06:55:50.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:55:50.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:50.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:55:50.376+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:50.375+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:55:50.379+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:55:50.400+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:50.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:55:50.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:50.417+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:55:50.445+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:56:21.833+0000] {processor.py:186} INFO - Started process (PID=29950) to work on /opt/airflow/dags/test.py
[2025-04-08T06:56:21.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:56:21.837+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:21.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:56:21.853+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:21.853+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:56:21.857+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:56:21.880+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:21.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:56:21.897+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:21.897+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:56:21.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T06:56:52.242+0000] {processor.py:186} INFO - Started process (PID=30015) to work on /opt/airflow/dags/test.py
[2025-04-08T06:56:52.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:56:52.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:52.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:56:52.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:52.264+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:56:52.270+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:56:52.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:52.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:56:52.311+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:52.310+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:56:52.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T06:57:22.554+0000] {processor.py:186} INFO - Started process (PID=30077) to work on /opt/airflow/dags/test.py
[2025-04-08T06:57:22.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:57:22.558+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:22.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:57:22.575+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:22.575+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:57:22.579+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:57:22.599+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:22.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:57:22.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:22.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:57:22.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T06:57:53.051+0000] {processor.py:186} INFO - Started process (PID=30146) to work on /opt/airflow/dags/test.py
[2025-04-08T06:57:53.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:57:53.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:53.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:57:53.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:53.074+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:57:53.078+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:57:53.097+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:53.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:57:53.113+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:53.113+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:57:53.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T06:58:23.334+0000] {processor.py:186} INFO - Started process (PID=30215) to work on /opt/airflow/dags/test.py
[2025-04-08T06:58:23.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:58:23.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:23.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:58:23.352+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:23.352+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:58:23.356+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:58:23.376+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:23.376+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:58:23.392+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:23.392+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:58:23.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T06:58:53.614+0000] {processor.py:186} INFO - Started process (PID=30284) to work on /opt/airflow/dags/test.py
[2025-04-08T06:58:53.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:58:53.620+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:53.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:58:53.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:53.639+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:58:53.644+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:58:53.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:53.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:58:53.682+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:53.681+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:58:53.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T06:59:24.255+0000] {processor.py:186} INFO - Started process (PID=30353) to work on /opt/airflow/dags/test.py
[2025-04-08T06:59:24.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:59:24.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:24.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:59:24.274+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:24.274+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:59:24.278+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:59:24.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:24.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:59:24.314+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:24.314+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:59:24.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T06:59:55.136+0000] {processor.py:186} INFO - Started process (PID=30422) to work on /opt/airflow/dags/test.py
[2025-04-08T06:59:55.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T06:59:55.140+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:55.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T06:59:55.157+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:55.157+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T06:59:55.161+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T06:59:55.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:55.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:59:55.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:55.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T06:59:55.241+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T07:00:25.780+0000] {processor.py:186} INFO - Started process (PID=30491) to work on /opt/airflow/dags/test.py
[2025-04-08T07:00:25.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:00:25.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:25.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:00:25.805+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:25.804+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:00:25.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:00:25.835+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:25.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:00:25.855+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:25.855+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:00:25.886+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T07:00:56.146+0000] {processor.py:186} INFO - Started process (PID=30560) to work on /opt/airflow/dags/test.py
[2025-04-08T07:00:56.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:00:56.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:56.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:00:56.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:56.167+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:00:56.172+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:00:56.192+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:56.192+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:00:56.208+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:56.208+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:00:56.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T07:01:26.719+0000] {processor.py:186} INFO - Started process (PID=30630) to work on /opt/airflow/dags/test.py
[2025-04-08T07:01:26.720+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:01:26.724+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:26.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:01:26.745+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:26.745+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:01:26.750+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:01:26.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:26.771+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:01:26.788+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:26.788+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:01:26.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:01:57.710+0000] {processor.py:186} INFO - Started process (PID=30696) to work on /opt/airflow/dags/test.py
[2025-04-08T07:01:57.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:01:57.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:57.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:01:57.726+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:57.726+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:01:57.730+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:01:57.751+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:57.750+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:01:57.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:57.771+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:01:57.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:02:27.906+0000] {processor.py:186} INFO - Started process (PID=30758) to work on /opt/airflow/dags/test.py
[2025-04-08T07:02:27.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:02:27.909+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:02:27.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.929+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:02:27.933+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:02:27.953+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:02:27.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.971+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:02:28.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:02:59.073+0000] {processor.py:186} INFO - Started process (PID=30827) to work on /opt/airflow/dags/test.py
[2025-04-08T07:02:59.074+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:02:59.077+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:59.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:02:59.094+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:59.094+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:02:59.097+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:02:59.117+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:59.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:02:59.134+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:59.134+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:02:59.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:03:29.769+0000] {processor.py:186} INFO - Started process (PID=30895) to work on /opt/airflow/dags/test.py
[2025-04-08T07:03:29.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:03:29.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:03:29.790+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.790+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:03:29.794+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:03:29.814+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.814+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:03:29.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.830+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:03:29.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:04:00.965+0000] {processor.py:186} INFO - Started process (PID=30964) to work on /opt/airflow/dags/test.py
[2025-04-08T07:04:00.966+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:04:00.969+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:00.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:04:00.985+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:00.985+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:04:00.989+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:04:01.014+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:01.014+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:04:01.031+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:01.031+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:04:01.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T07:04:32.306+0000] {processor.py:186} INFO - Started process (PID=31033) to work on /opt/airflow/dags/test.py
[2025-04-08T07:04:32.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:04:32.310+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:32.309+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:04:32.328+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:32.328+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:04:32.332+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:04:32.352+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:32.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:04:32.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:32.368+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:04:32.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:05:03.226+0000] {processor.py:186} INFO - Started process (PID=31102) to work on /opt/airflow/dags/test.py
[2025-04-08T07:05:03.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:05:03.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:03.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:05:03.243+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:03.243+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:05:03.247+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:05:03.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:03.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:05:03.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:03.281+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:05:03.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-08T07:05:34.476+0000] {processor.py:186} INFO - Started process (PID=31177) to work on /opt/airflow/dags/test.py
[2025-04-08T07:05:34.477+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:05:34.479+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.479+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:05:34.499+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.499+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:05:34.503+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:05:34.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:05:34.540+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.540+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:05:34.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:06:04.891+0000] {processor.py:186} INFO - Started process (PID=31246) to work on /opt/airflow/dags/test.py
[2025-04-08T07:06:04.892+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:06:04.896+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:06:04.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.915+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:06:04.920+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:06:04.942+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:06:04.960+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.960+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:06:04.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T07:06:36.140+0000] {processor.py:186} INFO - Started process (PID=31315) to work on /opt/airflow/dags/test.py
[2025-04-08T07:06:36.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:06:36.144+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:36.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:06:36.162+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:36.162+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:06:36.167+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:06:36.187+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:36.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:06:36.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:36.202+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:06:36.231+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:07:07.051+0000] {processor.py:186} INFO - Started process (PID=31384) to work on /opt/airflow/dags/test.py
[2025-04-08T07:07:07.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:07:07.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:07.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:07:07.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:07.069+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:07:07.073+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:07:07.098+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:07.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:07:07.117+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:07.117+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:07:07.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T07:07:37.615+0000] {processor.py:186} INFO - Started process (PID=31453) to work on /opt/airflow/dags/test.py
[2025-04-08T07:07:37.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:07:37.619+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:07:37.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.633+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:07:37.637+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:07:37.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:07:37.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.673+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:07:37.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:08:08.555+0000] {processor.py:186} INFO - Started process (PID=31522) to work on /opt/airflow/dags/test.py
[2025-04-08T07:08:08.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:08:08.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:08:08.576+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.576+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:08:08.580+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:08:08.600+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:08:08.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:08:08.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:08:39.220+0000] {processor.py:186} INFO - Started process (PID=31591) to work on /opt/airflow/dags/test.py
[2025-04-08T07:08:39.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:08:39.224+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:39.224+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:08:39.236+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:39.236+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:08:39.240+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:08:39.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:39.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:08:39.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:39.277+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:08:39.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T07:09:10.250+0000] {processor.py:186} INFO - Started process (PID=31660) to work on /opt/airflow/dags/test.py
[2025-04-08T07:09:10.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:09:10.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:10.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:09:10.272+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:10.272+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:09:10.276+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:09:10.297+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:10.297+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:09:10.314+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:10.314+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:09:10.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:09:41.538+0000] {processor.py:186} INFO - Started process (PID=31729) to work on /opt/airflow/dags/test.py
[2025-04-08T07:09:41.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:09:41.541+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:09:41.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.560+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:09:41.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:09:41.584+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:09:41.600+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.600+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:09:41.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:10:12.562+0000] {processor.py:186} INFO - Started process (PID=31798) to work on /opt/airflow/dags/test.py
[2025-04-08T07:10:12.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:10:12.566+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:10:12.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.586+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:10:12.590+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:10:12.610+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:10:12.628+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.627+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:10:12.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:10:43.813+0000] {processor.py:186} INFO - Started process (PID=31867) to work on /opt/airflow/dags/test.py
[2025-04-08T07:10:43.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:10:43.817+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:10:43.841+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.840+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:10:43.845+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:10:43.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:10:43.882+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.882+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:10:43.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T07:11:14.931+0000] {processor.py:186} INFO - Started process (PID=31936) to work on /opt/airflow/dags/test.py
[2025-04-08T07:11:14.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:11:14.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:11:14.953+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.953+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:11:14.957+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:11:14.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:11:14.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.999+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:11:15.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T07:11:45.388+0000] {processor.py:186} INFO - Started process (PID=32005) to work on /opt/airflow/dags/test.py
[2025-04-08T07:11:45.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:11:45.392+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:11:45.407+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.406+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:11:45.411+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:11:45.430+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.430+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:11:45.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.446+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:11:45.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T07:12:16.406+0000] {processor.py:186} INFO - Started process (PID=32074) to work on /opt/airflow/dags/test.py
[2025-04-08T07:12:16.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:12:16.410+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:12:16.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.426+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:12:16.430+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:12:16.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:12:16.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.470+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:12:16.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:12:47.171+0000] {processor.py:186} INFO - Started process (PID=32143) to work on /opt/airflow/dags/test.py
[2025-04-08T07:12:47.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:12:47.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:47.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:12:47.193+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:47.193+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:12:47.197+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:12:47.216+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:47.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:12:47.232+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:47.232+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:12:47.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:13:18.631+0000] {processor.py:186} INFO - Started process (PID=32213) to work on /opt/airflow/dags/test.py
[2025-04-08T07:13:18.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:13:18.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:18.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:13:18.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:18.651+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:13:18.655+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:13:18.676+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:18.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:13:18.694+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:18.694+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:13:18.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:13:49.563+0000] {processor.py:186} INFO - Started process (PID=32282) to work on /opt/airflow/dags/test.py
[2025-04-08T07:13:49.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:13:49.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:49.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:13:49.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:49.592+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:13:49.597+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:13:49.620+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:49.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:13:49.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:49.639+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:13:49.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-08T07:14:20.199+0000] {processor.py:186} INFO - Started process (PID=32351) to work on /opt/airflow/dags/test.py
[2025-04-08T07:14:20.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:14:20.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:20.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:14:20.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:20.217+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:14:20.222+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:14:20.244+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:20.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:14:20.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:20.260+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:14:20.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:14:50.556+0000] {processor.py:186} INFO - Started process (PID=32420) to work on /opt/airflow/dags/test.py
[2025-04-08T07:14:50.557+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:14:50.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.560+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:14:50.580+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.580+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:14:50.584+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:14:50.607+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:14:50.625+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.624+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:14:50.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T07:15:21.020+0000] {processor.py:186} INFO - Started process (PID=32488) to work on /opt/airflow/dags/test.py
[2025-04-08T07:15:21.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:15:21.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:21.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:15:21.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:21.041+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:15:21.046+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:15:21.064+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:21.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:15:21.081+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:21.081+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:15:21.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:15:51.922+0000] {processor.py:186} INFO - Started process (PID=32558) to work on /opt/airflow/dags/test.py
[2025-04-08T07:15:51.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:15:51.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:15:51.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.945+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:15:51.949+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:15:51.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.972+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:15:51.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.988+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:15:52.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T07:16:22.923+0000] {processor.py:186} INFO - Started process (PID=32627) to work on /opt/airflow/dags/test.py
[2025-04-08T07:16:22.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:16:22.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:16:22.942+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.941+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:16:22.945+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:16:22.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:16:22.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.984+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:16:23.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:16:53.459+0000] {processor.py:186} INFO - Started process (PID=32696) to work on /opt/airflow/dags/test.py
[2025-04-08T07:16:53.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:16:53.462+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:53.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:16:53.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:53.476+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:16:53.480+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:16:53.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:53.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:16:53.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:53.519+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:16:53.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T07:17:24.210+0000] {processor.py:186} INFO - Started process (PID=32765) to work on /opt/airflow/dags/test.py
[2025-04-08T07:17:24.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:17:24.214+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:24.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:17:24.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:24.228+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:17:24.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:17:24.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:24.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:17:24.270+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:24.270+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:17:24.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:17:54.783+0000] {processor.py:186} INFO - Started process (PID=32834) to work on /opt/airflow/dags/test.py
[2025-04-08T07:17:54.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:17:54.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:17:54.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.804+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:17:54.808+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:17:54.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:17:54.845+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.845+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:17:54.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:18:25.679+0000] {processor.py:186} INFO - Started process (PID=32903) to work on /opt/airflow/dags/test.py
[2025-04-08T07:18:25.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:18:25.683+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:25.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:18:25.699+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:25.699+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:18:25.703+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:18:25.724+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:25.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:18:25.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:25.741+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:18:25.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:18:56.630+0000] {processor.py:186} INFO - Started process (PID=32972) to work on /opt/airflow/dags/test.py
[2025-04-08T07:18:56.631+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:18:56.634+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:56.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:18:56.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:56.651+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:18:56.656+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:18:56.678+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:56.678+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:18:56.696+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:56.696+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:18:56.728+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T07:19:27.129+0000] {processor.py:186} INFO - Started process (PID=33041) to work on /opt/airflow/dags/test.py
[2025-04-08T07:19:27.130+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:19:27.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:27.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:19:27.147+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:27.147+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:19:27.151+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:19:27.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:27.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:19:27.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:27.188+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:19:27.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T07:19:57.886+0000] {processor.py:186} INFO - Started process (PID=33110) to work on /opt/airflow/dags/test.py
[2025-04-08T07:19:57.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:19:57.890+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:19:57.909+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.908+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:19:57.913+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:19:57.932+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:19:57.948+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.948+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:19:57.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:20:29.107+0000] {processor.py:186} INFO - Started process (PID=33179) to work on /opt/airflow/dags/test.py
[2025-04-08T07:20:29.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:20:29.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:29.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:20:29.127+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:29.127+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:20:29.131+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:20:29.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:29.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:20:29.167+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:29.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:20:29.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:20:59.640+0000] {processor.py:186} INFO - Started process (PID=33248) to work on /opt/airflow/dags/test.py
[2025-04-08T07:20:59.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:20:59.645+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:59.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:20:59.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:59.662+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:20:59.666+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:20:59.691+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:59.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:20:59.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:59.708+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:20:59.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T07:21:30.426+0000] {processor.py:186} INFO - Started process (PID=33317) to work on /opt/airflow/dags/test.py
[2025-04-08T07:21:30.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:21:30.430+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:30.430+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:21:30.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:30.446+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:21:30.449+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:21:30.469+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:30.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:21:30.484+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:30.484+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:21:30.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T07:22:00.760+0000] {processor.py:186} INFO - Started process (PID=33386) to work on /opt/airflow/dags/test.py
[2025-04-08T07:22:00.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:22:00.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:22:00.785+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.785+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:22:00.789+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:22:00.809+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:22:00.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.826+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:22:00.856+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:22:31.663+0000] {processor.py:186} INFO - Started process (PID=33454) to work on /opt/airflow/dags/test.py
[2025-04-08T07:22:31.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:22:31.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:22:31.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.684+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:22:31.687+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:22:31.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:22:31.723+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.723+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:22:31.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:23:02.485+0000] {processor.py:186} INFO - Started process (PID=33523) to work on /opt/airflow/dags/test.py
[2025-04-08T07:23:02.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:23:02.489+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:02.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:23:02.506+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:02.506+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:23:02.509+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:23:02.529+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:02.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:23:02.545+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:02.544+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:23:02.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:23:33.369+0000] {processor.py:186} INFO - Started process (PID=33593) to work on /opt/airflow/dags/test.py
[2025-04-08T07:23:33.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:23:33.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:33.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:23:33.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:33.394+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:23:33.398+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:23:33.419+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:33.419+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:23:33.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:33.438+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:23:33.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T07:24:04.080+0000] {processor.py:186} INFO - Started process (PID=33662) to work on /opt/airflow/dags/test.py
[2025-04-08T07:24:04.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:24:04.084+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:04.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:24:04.097+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:04.097+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:24:04.100+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:24:04.122+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:04.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:24:04.142+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:04.142+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:24:04.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:24:34.935+0000] {processor.py:186} INFO - Started process (PID=33731) to work on /opt/airflow/dags/test.py
[2025-04-08T07:24:34.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:24:34.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:24:34.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.954+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:24:34.958+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:24:34.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:24:34.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.996+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:24:35.029+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:25:06.083+0000] {processor.py:186} INFO - Started process (PID=33806) to work on /opt/airflow/dags/test.py
[2025-04-08T07:25:06.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:25:06.087+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:06.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:25:06.103+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:06.102+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:25:06.106+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:25:06.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:06.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:25:06.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:06.141+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:25:06.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T07:25:36.754+0000] {processor.py:186} INFO - Started process (PID=33875) to work on /opt/airflow/dags/test.py
[2025-04-08T07:25:36.755+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:25:36.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:25:36.774+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.774+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:25:36.778+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:25:36.798+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:25:36.813+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.813+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:25:36.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T07:26:07.635+0000] {processor.py:186} INFO - Started process (PID=33944) to work on /opt/airflow/dags/test.py
[2025-04-08T07:26:07.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:26:07.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:26:07.655+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.655+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:26:07.659+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:26:07.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.679+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:26:07.695+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.695+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:26:07.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T07:26:38.339+0000] {processor.py:186} INFO - Started process (PID=34013) to work on /opt/airflow/dags/test.py
[2025-04-08T07:26:38.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:26:38.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:38.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:26:38.357+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:38.357+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:26:38.361+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:26:38.382+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:38.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:26:38.402+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:38.402+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:26:38.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T07:27:08.936+0000] {processor.py:186} INFO - Started process (PID=34082) to work on /opt/airflow/dags/test.py
[2025-04-08T07:27:08.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:27:08.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:08.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:27:08.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:08.958+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:27:08.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:27:08.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:08.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:27:08.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:08.999+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:27:09.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T07:27:39.843+0000] {processor.py:186} INFO - Started process (PID=34151) to work on /opt/airflow/dags/test.py
[2025-04-08T07:27:39.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:27:39.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:27:39.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.865+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:27:39.869+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:27:39.889+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.888+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:27:39.907+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.907+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:27:39.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:28:10.916+0000] {processor.py:186} INFO - Started process (PID=34220) to work on /opt/airflow/dags/test.py
[2025-04-08T07:28:10.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:28:10.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:28:10.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.939+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:28:10.942+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:28:10.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:28:10.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:28:11.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:28:41.834+0000] {processor.py:186} INFO - Started process (PID=34289) to work on /opt/airflow/dags/test.py
[2025-04-08T07:28:41.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:28:41.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:28:41.853+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.853+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:28:41.857+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:28:41.877+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:28:41.893+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.893+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:28:41.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:29:12.996+0000] {processor.py:186} INFO - Started process (PID=34358) to work on /opt/airflow/dags/test.py
[2025-04-08T07:29:12.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:29:13.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:13.000+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:29:13.015+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:13.015+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:29:13.019+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:29:13.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:13.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:29:13.056+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:13.055+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:29:13.084+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:29:43.841+0000] {processor.py:186} INFO - Started process (PID=34427) to work on /opt/airflow/dags/test.py
[2025-04-08T07:29:43.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:29:43.844+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:29:43.859+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.859+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:29:43.863+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:29:43.882+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.881+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:29:43.900+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.899+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:29:43.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T07:30:14.369+0000] {processor.py:186} INFO - Started process (PID=34496) to work on /opt/airflow/dags/test.py
[2025-04-08T07:30:14.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:30:14.373+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:14.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:30:14.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:14.394+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:30:14.398+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:30:14.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:14.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:30:14.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:14.437+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:30:14.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:30:44.888+0000] {processor.py:186} INFO - Started process (PID=34565) to work on /opt/airflow/dags/test.py
[2025-04-08T07:30:44.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:30:44.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:30:44.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.909+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:30:44.913+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:30:44.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:30:44.948+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.948+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:30:44.978+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:31:15.310+0000] {processor.py:186} INFO - Started process (PID=34634) to work on /opt/airflow/dags/test.py
[2025-04-08T07:31:15.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:31:15.314+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:15.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:31:15.328+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:15.328+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:31:15.332+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:31:15.352+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:15.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:31:15.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:15.368+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:31:15.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T07:31:45.687+0000] {processor.py:186} INFO - Started process (PID=34702) to work on /opt/airflow/dags/test.py
[2025-04-08T07:31:45.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:31:45.691+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:45.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:31:45.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:45.706+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:31:45.710+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:31:45.730+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:45.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:31:45.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:45.745+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:31:45.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:32:16.277+0000] {processor.py:186} INFO - Started process (PID=34771) to work on /opt/airflow/dags/test.py
[2025-04-08T07:32:16.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:32:16.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:32:16.297+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.296+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:32:16.301+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:32:16.321+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:32:16.337+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.337+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:32:16.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:32:46.420+0000] {processor.py:186} INFO - Started process (PID=34838) to work on /opt/airflow/dags/test.py
[2025-04-08T07:32:46.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:32:46.424+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:46.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:32:46.439+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:46.438+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:32:46.443+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:32:46.462+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:46.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:32:46.480+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:46.479+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:32:46.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:33:16.574+0000] {processor.py:186} INFO - Started process (PID=34907) to work on /opt/airflow/dags/test.py
[2025-04-08T07:33:16.575+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:33:16.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:16.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:33:16.598+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:16.597+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:33:16.601+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:33:16.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:16.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:33:16.639+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:16.638+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:33:16.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T07:33:46.772+0000] {processor.py:186} INFO - Started process (PID=34976) to work on /opt/airflow/dags/test.py
[2025-04-08T07:33:46.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:33:46.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:46.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:33:46.795+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:46.794+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:33:46.798+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:33:46.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:46.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:33:46.836+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:46.836+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:33:46.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T07:34:17.006+0000] {processor.py:186} INFO - Started process (PID=35044) to work on /opt/airflow/dags/test.py
[2025-04-08T07:34:17.008+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:34:17.010+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:17.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:34:17.028+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:17.028+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:34:17.034+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:34:17.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:17.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:34:17.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:17.075+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:34:17.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T07:34:47.745+0000] {processor.py:186} INFO - Started process (PID=35113) to work on /opt/airflow/dags/test.py
[2025-04-08T07:34:47.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:34:47.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:47.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:34:47.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:47.770+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:34:47.775+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:34:47.796+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:47.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:34:47.812+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:47.812+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:34:47.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T07:35:18.696+0000] {processor.py:186} INFO - Started process (PID=35181) to work on /opt/airflow/dags/test.py
[2025-04-08T07:35:18.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:35:18.701+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:18.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:35:18.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:18.718+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:35:18.722+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:35:18.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:18.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:35:18.757+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:18.757+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:35:18.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T07:35:48.964+0000] {processor.py:186} INFO - Started process (PID=35250) to work on /opt/airflow/dags/test.py
[2025-04-08T07:35:48.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:35:48.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:48.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:35:48.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:48.984+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:35:48.988+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:35:49.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:49.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:35:49.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:49.022+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:35:49.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T07:36:19.540+0000] {processor.py:186} INFO - Started process (PID=35317) to work on /opt/airflow/dags/test.py
[2025-04-08T07:36:19.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:36:19.546+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:19.545+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:36:19.563+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:19.563+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:36:19.567+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:36:19.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:19.587+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:36:19.603+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:19.603+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:36:19.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T07:36:49.782+0000] {processor.py:186} INFO - Started process (PID=35386) to work on /opt/airflow/dags/test.py
[2025-04-08T07:36:49.784+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:36:49.788+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:49.788+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:36:49.806+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:49.806+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:36:49.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:36:49.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:49.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:36:49.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:49.848+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:36:49.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T07:37:20.821+0000] {processor.py:186} INFO - Started process (PID=35455) to work on /opt/airflow/dags/test.py
[2025-04-08T07:37:20.822+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:37:20.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:20.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:37:20.849+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:20.849+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:37:20.853+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:37:20.875+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:20.875+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:37:20.893+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:20.893+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:37:20.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T07:37:51.140+0000] {processor.py:186} INFO - Started process (PID=35524) to work on /opt/airflow/dags/test.py
[2025-04-08T07:37:51.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:37:51.145+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:51.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:37:51.164+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:51.164+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:37:51.168+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:37:51.187+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:51.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:37:51.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:51.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:37:51.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:38:21.292+0000] {processor.py:186} INFO - Started process (PID=35593) to work on /opt/airflow/dags/test.py
[2025-04-08T07:38:21.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:38:21.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:21.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:38:21.311+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:21.311+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:38:21.315+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:38:21.336+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:21.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:38:21.354+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:21.353+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:38:21.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:38:51.466+0000] {processor.py:186} INFO - Started process (PID=35662) to work on /opt/airflow/dags/test.py
[2025-04-08T07:38:51.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:38:51.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:51.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:38:51.496+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:51.495+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:38:51.500+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:38:51.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:51.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:38:51.538+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:51.537+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:38:51.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T07:39:22.087+0000] {processor.py:186} INFO - Started process (PID=35731) to work on /opt/airflow/dags/test.py
[2025-04-08T07:39:22.088+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:39:22.091+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:22.091+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:39:22.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:22.109+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:39:22.113+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:39:22.133+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:22.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:39:22.150+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:22.149+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:39:22.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:39:53.203+0000] {processor.py:186} INFO - Started process (PID=35800) to work on /opt/airflow/dags/test.py
[2025-04-08T07:39:53.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:39:53.208+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:53.208+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:39:53.227+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:53.227+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:39:53.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:39:53.253+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:53.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:39:53.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:53.276+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:39:53.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-08T07:40:24.048+0000] {processor.py:186} INFO - Started process (PID=35869) to work on /opt/airflow/dags/test.py
[2025-04-08T07:40:24.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:40:24.054+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:24.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:40:24.071+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:24.070+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:40:24.074+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:40:24.098+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:24.097+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:40:24.115+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:24.115+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:40:24.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T07:40:55.168+0000] {processor.py:186} INFO - Started process (PID=35938) to work on /opt/airflow/dags/test.py
[2025-04-08T07:40:55.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:40:55.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:55.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:40:55.187+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:55.186+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:40:55.190+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:40:55.212+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:55.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:40:55.231+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:55.230+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:40:55.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:41:26.349+0000] {processor.py:186} INFO - Started process (PID=36007) to work on /opt/airflow/dags/test.py
[2025-04-08T07:41:26.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:41:26.354+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:26.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:41:26.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:26.374+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:41:26.378+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:41:26.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:26.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:41:26.414+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:26.414+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:41:26.450+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T07:41:56.558+0000] {processor.py:186} INFO - Started process (PID=36076) to work on /opt/airflow/dags/test.py
[2025-04-08T07:41:56.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:41:56.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:56.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:41:56.581+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:56.581+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:41:56.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:41:56.606+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:56.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:41:56.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:56.623+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:41:56.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:42:27.150+0000] {processor.py:186} INFO - Started process (PID=36145) to work on /opt/airflow/dags/test.py
[2025-04-08T07:42:27.151+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:42:27.155+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:27.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:42:27.171+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:27.171+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:42:27.177+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:42:27.199+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:27.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:42:27.217+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:27.217+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:42:27.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T07:42:57.491+0000] {processor.py:186} INFO - Started process (PID=36214) to work on /opt/airflow/dags/test.py
[2025-04-08T07:42:57.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:42:57.495+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:57.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:42:57.510+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:57.510+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:42:57.515+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:42:57.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:57.535+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:42:57.554+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:57.554+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:42:58.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 1.388 seconds
[2025-04-08T07:43:29.923+0000] {processor.py:186} INFO - Started process (PID=36283) to work on /opt/airflow/dags/test.py
[2025-04-08T07:43:29.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:43:29.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:29.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:43:29.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:29.952+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:43:29.956+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:43:29.974+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:29.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:43:29.990+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:29.990+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:43:30.021+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:44:00.862+0000] {processor.py:186} INFO - Started process (PID=36352) to work on /opt/airflow/dags/test.py
[2025-04-08T07:44:00.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:44:00.866+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:00.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:44:00.883+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:00.882+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:44:00.886+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:44:00.905+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:00.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:44:00.921+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:00.921+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:44:00.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:44:31.452+0000] {processor.py:186} INFO - Started process (PID=36421) to work on /opt/airflow/dags/test.py
[2025-04-08T07:44:31.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:44:31.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:31.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:44:31.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:31.471+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:44:31.475+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:44:31.494+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:31.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:44:31.511+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:31.511+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:44:31.541+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:45:02.160+0000] {processor.py:186} INFO - Started process (PID=36490) to work on /opt/airflow/dags/test.py
[2025-04-08T07:45:02.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:45:02.164+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:02.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:45:02.183+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:02.183+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:45:02.187+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:45:02.207+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:02.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:45:02.228+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:02.228+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:45:02.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:45:32.997+0000] {processor.py:186} INFO - Started process (PID=36559) to work on /opt/airflow/dags/test.py
[2025-04-08T07:45:32.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:45:33.001+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:33.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:45:33.019+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:33.019+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:45:33.023+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:45:33.043+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:33.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:45:33.059+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:33.059+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:45:33.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:46:03.177+0000] {processor.py:186} INFO - Started process (PID=36628) to work on /opt/airflow/dags/test.py
[2025-04-08T07:46:03.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:46:03.181+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:03.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:46:03.199+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:03.199+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:46:03.203+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:46:03.222+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:03.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:46:03.239+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:03.238+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:46:03.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:46:33.334+0000] {processor.py:186} INFO - Started process (PID=36697) to work on /opt/airflow/dags/test.py
[2025-04-08T07:46:33.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:46:33.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:33.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:46:33.357+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:33.357+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:46:33.361+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:46:33.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:33.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:46:33.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:33.398+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:46:33.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:47:03.700+0000] {processor.py:186} INFO - Started process (PID=36766) to work on /opt/airflow/dags/test.py
[2025-04-08T07:47:03.701+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:47:03.704+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:03.703+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:47:03.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:03.718+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:47:03.722+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:47:03.743+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:03.743+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:47:03.760+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:03.760+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:47:03.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T07:47:34.845+0000] {processor.py:186} INFO - Started process (PID=36835) to work on /opt/airflow/dags/test.py
[2025-04-08T07:47:34.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:47:34.851+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:34.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:47:34.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:34.867+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:47:34.871+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:47:34.891+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:34.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:47:34.908+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:34.908+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:47:34.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:48:05.111+0000] {processor.py:186} INFO - Started process (PID=36904) to work on /opt/airflow/dags/test.py
[2025-04-08T07:48:05.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:48:05.115+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:05.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:48:05.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:05.131+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:48:05.135+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:48:05.156+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:05.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:48:05.173+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:05.173+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:48:05.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:48:35.503+0000] {processor.py:186} INFO - Started process (PID=36973) to work on /opt/airflow/dags/test.py
[2025-04-08T07:48:35.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:48:35.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:35.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:48:35.526+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:35.526+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:48:35.530+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:48:35.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:35.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:48:35.572+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:35.572+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:48:35.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T07:49:05.911+0000] {processor.py:186} INFO - Started process (PID=37042) to work on /opt/airflow/dags/test.py
[2025-04-08T07:49:05.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:49:05.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:05.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:49:05.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:05.933+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:49:05.938+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:49:05.963+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:05.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:49:05.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:05.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:49:06.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T07:49:36.980+0000] {processor.py:186} INFO - Started process (PID=37111) to work on /opt/airflow/dags/test.py
[2025-04-08T07:49:36.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:49:36.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:36.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:49:37.001+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:37.000+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:49:37.004+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:49:37.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:37.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:49:37.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:37.041+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:49:37.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:50:07.842+0000] {processor.py:186} INFO - Started process (PID=37180) to work on /opt/airflow/dags/test.py
[2025-04-08T07:50:07.843+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:50:07.846+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:07.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:50:07.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:07.865+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:50:07.869+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:50:07.891+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:07.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:50:07.908+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:07.908+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:50:07.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T07:50:38.508+0000] {processor.py:186} INFO - Started process (PID=37249) to work on /opt/airflow/dags/test.py
[2025-04-08T07:50:38.510+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:50:38.514+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:38.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:50:38.530+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:38.530+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:50:38.534+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:50:38.555+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:38.555+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:50:38.572+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:38.572+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:50:38.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T07:51:09.507+0000] {processor.py:186} INFO - Started process (PID=37324) to work on /opt/airflow/dags/test.py
[2025-04-08T07:51:09.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:51:09.512+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:09.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:51:09.530+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:09.530+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:51:09.535+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:51:09.557+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:09.557+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:51:09.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:09.573+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:51:09.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T07:51:39.709+0000] {processor.py:186} INFO - Started process (PID=37393) to work on /opt/airflow/dags/test.py
[2025-04-08T07:51:39.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:51:39.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:39.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:51:39.737+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:39.736+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:51:39.741+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:51:39.760+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:39.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:51:39.778+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:39.778+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:51:39.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T07:52:09.999+0000] {processor.py:186} INFO - Started process (PID=37462) to work on /opt/airflow/dags/test.py
[2025-04-08T07:52:10.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:52:10.003+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:10.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:52:10.056+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:10.055+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:52:10.059+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:52:10.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:10.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:52:10.097+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:10.097+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:52:10.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.135 seconds
[2025-04-08T07:52:40.514+0000] {processor.py:186} INFO - Started process (PID=37531) to work on /opt/airflow/dags/test.py
[2025-04-08T07:52:40.515+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:52:40.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:40.518+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:52:40.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:40.535+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:52:40.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:52:40.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:40.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:52:40.582+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:40.582+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:52:40.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T07:53:10.742+0000] {processor.py:186} INFO - Started process (PID=37600) to work on /opt/airflow/dags/test.py
[2025-04-08T07:53:10.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:53:10.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:10.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:53:10.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:10.773+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:53:10.779+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:53:10.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:10.802+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:53:10.825+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:10.824+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:53:10.859+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-08T07:53:41.661+0000] {processor.py:186} INFO - Started process (PID=37669) to work on /opt/airflow/dags/test.py
[2025-04-08T07:53:41.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:53:41.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:41.665+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:53:41.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:41.679+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:53:41.683+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:53:41.703+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:41.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:53:41.720+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:41.720+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:53:41.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T07:54:12.509+0000] {processor.py:186} INFO - Started process (PID=37738) to work on /opt/airflow/dags/test.py
[2025-04-08T07:54:12.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:54:12.514+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:12.513+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:54:12.532+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:12.532+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:54:12.536+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:54:12.556+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:12.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:54:12.574+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:12.573+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:54:12.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:54:43.703+0000] {processor.py:186} INFO - Started process (PID=37807) to work on /opt/airflow/dags/test.py
[2025-04-08T07:54:43.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:54:43.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:43.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:54:43.725+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:43.724+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:54:43.728+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:54:43.748+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:43.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:54:43.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:43.764+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:54:43.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T07:55:14.019+0000] {processor.py:186} INFO - Started process (PID=37877) to work on /opt/airflow/dags/test.py
[2025-04-08T07:55:14.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:55:14.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:14.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:55:14.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:14.042+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:55:14.046+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:55:14.066+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:14.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:55:14.083+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:14.082+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:55:14.117+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T07:55:45.085+0000] {processor.py:186} INFO - Started process (PID=37946) to work on /opt/airflow/dags/test.py
[2025-04-08T07:55:45.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:55:45.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:45.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:55:45.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:45.107+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:55:45.111+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:55:45.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:45.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:55:45.148+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:45.148+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:55:45.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:56:16.201+0000] {processor.py:186} INFO - Started process (PID=38015) to work on /opt/airflow/dags/test.py
[2025-04-08T07:56:16.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:56:16.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:16.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:56:16.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:16.223+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:56:16.226+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:56:16.248+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:16.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:56:16.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:16.265+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:56:16.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T07:56:46.365+0000] {processor.py:186} INFO - Started process (PID=38084) to work on /opt/airflow/dags/test.py
[2025-04-08T07:56:46.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:56:46.369+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:46.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:56:46.387+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:46.387+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:56:46.391+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:56:46.410+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:46.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:56:46.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:46.426+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:56:46.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T07:57:16.580+0000] {processor.py:186} INFO - Started process (PID=38153) to work on /opt/airflow/dags/test.py
[2025-04-08T07:57:16.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:57:16.584+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:16.584+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:57:16.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:16.605+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:57:16.610+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:57:16.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:16.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:57:16.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:16.648+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:57:16.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T07:57:47.724+0000] {processor.py:186} INFO - Started process (PID=38222) to work on /opt/airflow/dags/test.py
[2025-04-08T07:57:47.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:57:47.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:47.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:57:47.747+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:47.747+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:57:47.751+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:57:47.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:47.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:57:47.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:47.787+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:57:47.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T07:58:18.042+0000] {processor.py:186} INFO - Started process (PID=38291) to work on /opt/airflow/dags/test.py
[2025-04-08T07:58:18.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:58:18.046+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:18.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:58:18.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:18.063+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:58:18.068+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:58:18.087+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:18.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:58:18.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:18.103+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:58:18.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T07:58:48.442+0000] {processor.py:186} INFO - Started process (PID=38360) to work on /opt/airflow/dags/test.py
[2025-04-08T07:58:48.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:58:48.447+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:48.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:58:48.465+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:48.465+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:58:48.469+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:58:48.490+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:48.490+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:58:48.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:48.506+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:58:48.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:59:19.114+0000] {processor.py:186} INFO - Started process (PID=38429) to work on /opt/airflow/dags/test.py
[2025-04-08T07:59:19.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:59:19.118+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:19.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:59:19.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:19.132+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:59:19.136+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:59:19.157+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:19.156+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:59:19.177+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:19.177+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:59:19.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T07:59:49.981+0000] {processor.py:186} INFO - Started process (PID=38496) to work on /opt/airflow/dags/test.py
[2025-04-08T07:59:49.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T07:59:49.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:49.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T07:59:49.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:49.999+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T07:59:50.003+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T07:59:50.024+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:50.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:59:50.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:50.042+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T07:59:50.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T08:00:20.649+0000] {processor.py:186} INFO - Started process (PID=38562) to work on /opt/airflow/dags/test.py
[2025-04-08T08:00:20.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:00:20.655+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:20.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:00:20.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:20.670+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:00:20.674+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:00:20.696+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:20.695+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:00:20.712+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:20.712+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:00:20.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:00:51.611+0000] {processor.py:186} INFO - Started process (PID=38631) to work on /opt/airflow/dags/test.py
[2025-04-08T08:00:51.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:00:51.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:51.615+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:00:51.632+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:51.631+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:00:51.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:00:51.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:51.657+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:00:51.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:51.673+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:00:51.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T08:01:22.407+0000] {processor.py:186} INFO - Started process (PID=38700) to work on /opt/airflow/dags/test.py
[2025-04-08T08:01:22.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:01:22.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:22.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:01:22.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:22.429+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:01:22.433+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:01:22.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:22.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:01:22.468+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:22.468+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:01:22.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T08:01:53.500+0000] {processor.py:186} INFO - Started process (PID=38769) to work on /opt/airflow/dags/test.py
[2025-04-08T08:01:53.501+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:01:53.504+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:53.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:01:53.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:53.523+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:01:53.527+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:01:53.548+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:53.547+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:01:53.564+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:53.564+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:01:53.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:02:23.799+0000] {processor.py:186} INFO - Started process (PID=38838) to work on /opt/airflow/dags/test.py
[2025-04-08T08:02:23.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:02:23.803+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:23.803+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:02:23.820+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:23.820+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:02:23.824+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:02:23.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:23.848+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:02:23.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:23.867+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:02:23.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:02:54.415+0000] {processor.py:186} INFO - Started process (PID=38907) to work on /opt/airflow/dags/test.py
[2025-04-08T08:02:54.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:02:54.420+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:54.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:02:54.435+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:54.435+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:02:54.439+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:02:54.460+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:54.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:02:54.478+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:54.478+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:02:54.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:03:24.989+0000] {processor.py:186} INFO - Started process (PID=38976) to work on /opt/airflow/dags/test.py
[2025-04-08T08:03:24.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:03:24.995+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:24.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:03:25.015+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:25.015+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:03:25.019+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:03:25.039+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:25.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:03:25.054+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:25.054+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:03:25.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T08:03:55.376+0000] {processor.py:186} INFO - Started process (PID=39045) to work on /opt/airflow/dags/test.py
[2025-04-08T08:03:55.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:03:55.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:55.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:03:55.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:55.398+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:03:55.402+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:03:55.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:55.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:03:55.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:55.438+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:03:55.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:04:26.358+0000] {processor.py:186} INFO - Started process (PID=39114) to work on /opt/airflow/dags/test.py
[2025-04-08T08:04:26.361+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:04:26.367+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:26.366+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:04:26.389+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:26.389+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:04:26.393+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:04:26.415+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:26.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:04:26.433+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:26.433+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:04:26.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-08T08:04:57.255+0000] {processor.py:186} INFO - Started process (PID=39183) to work on /opt/airflow/dags/test.py
[2025-04-08T08:04:57.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:04:57.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:57.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:04:57.278+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:57.278+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:04:57.282+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:04:57.301+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:57.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:04:57.318+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:57.318+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:04:57.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:05:28.076+0000] {processor.py:186} INFO - Started process (PID=39252) to work on /opt/airflow/dags/test.py
[2025-04-08T08:05:28.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:05:28.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:28.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:05:28.096+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:28.096+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:05:28.100+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:05:28.119+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:28.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:05:28.136+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:28.136+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:05:28.172+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T08:05:58.981+0000] {processor.py:186} INFO - Started process (PID=39321) to work on /opt/airflow/dags/test.py
[2025-04-08T08:05:58.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:05:58.987+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:58.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:05:59.005+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:59.004+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:05:59.008+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:05:59.028+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:59.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:05:59.046+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:59.045+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:05:59.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:06:29.715+0000] {processor.py:186} INFO - Started process (PID=39390) to work on /opt/airflow/dags/test.py
[2025-04-08T08:06:29.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:06:29.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:29.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:06:29.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:29.736+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:06:29.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:06:29.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:29.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:06:29.780+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:29.780+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:06:29.812+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:07:00.560+0000] {processor.py:186} INFO - Started process (PID=39459) to work on /opt/airflow/dags/test.py
[2025-04-08T08:07:00.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:07:00.564+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:00.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:07:00.581+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:00.581+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:07:00.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:07:00.606+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:00.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:07:00.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:00.623+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:07:00.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T08:07:30.753+0000] {processor.py:186} INFO - Started process (PID=39528) to work on /opt/airflow/dags/test.py
[2025-04-08T08:07:30.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:07:30.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:30.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:07:30.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:30.771+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:07:30.775+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:07:30.795+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:30.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:07:30.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:30.811+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:07:30.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:08:01.845+0000] {processor.py:186} INFO - Started process (PID=39597) to work on /opt/airflow/dags/test.py
[2025-04-08T08:08:01.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:08:01.851+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:01.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:08:01.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:01.867+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:08:01.871+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:08:01.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:01.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:08:01.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:01.914+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:08:01.945+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:08:32.267+0000] {processor.py:186} INFO - Started process (PID=39666) to work on /opt/airflow/dags/test.py
[2025-04-08T08:08:32.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:08:32.272+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:32.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:08:32.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:32.288+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:08:32.293+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:08:32.314+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:32.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:08:32.331+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:32.331+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:08:32.363+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:09:03.036+0000] {processor.py:186} INFO - Started process (PID=39735) to work on /opt/airflow/dags/test.py
[2025-04-08T08:09:03.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:09:03.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:03.042+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:09:03.064+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:03.064+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:09:03.070+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:09:03.101+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:03.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:09:03.129+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:03.128+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:09:03.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-08T08:09:34.208+0000] {processor.py:186} INFO - Started process (PID=39804) to work on /opt/airflow/dags/test.py
[2025-04-08T08:09:34.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:09:34.213+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:34.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:09:34.235+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:34.235+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:09:34.239+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:09:34.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:34.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:09:34.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:34.276+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:09:34.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-08T08:10:04.463+0000] {processor.py:186} INFO - Started process (PID=39873) to work on /opt/airflow/dags/test.py
[2025-04-08T08:10:04.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:10:04.468+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:04.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:10:04.483+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:04.483+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:10:04.487+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:10:04.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:04.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:10:04.525+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:04.525+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:10:04.558+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T08:10:35.353+0000] {processor.py:186} INFO - Started process (PID=39942) to work on /opt/airflow/dags/test.py
[2025-04-08T08:10:35.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:10:35.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:35.357+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:10:35.376+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:35.376+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:10:35.380+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:10:35.399+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:35.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:10:35.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:35.418+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:10:35.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:11:05.503+0000] {processor.py:186} INFO - Started process (PID=40011) to work on /opt/airflow/dags/test.py
[2025-04-08T08:11:05.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:11:05.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:05.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:11:05.525+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:05.525+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:11:05.529+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:11:05.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:05.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:11:05.568+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:05.568+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:11:05.598+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:11:35.911+0000] {processor.py:186} INFO - Started process (PID=40080) to work on /opt/airflow/dags/test.py
[2025-04-08T08:11:35.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:11:35.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:35.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:11:35.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:35.931+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:11:35.935+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:11:35.953+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:35.953+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:11:35.970+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:35.970+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:11:36.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T08:12:06.436+0000] {processor.py:186} INFO - Started process (PID=40149) to work on /opt/airflow/dags/test.py
[2025-04-08T08:12:06.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:12:06.440+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:06.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:12:06.459+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:06.459+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:12:06.463+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:12:06.484+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:06.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:12:06.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:06.502+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:12:06.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:12:36.937+0000] {processor.py:186} INFO - Started process (PID=40218) to work on /opt/airflow/dags/test.py
[2025-04-08T08:12:36.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:12:36.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:36.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:12:36.961+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:36.961+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:12:36.965+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:12:36.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:36.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:12:37.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:37.168+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:12:37.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.268 seconds
[2025-04-08T08:13:07.806+0000] {processor.py:186} INFO - Started process (PID=40288) to work on /opt/airflow/dags/test.py
[2025-04-08T08:13:07.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:13:07.810+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:07.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:13:07.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:07.826+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:13:07.830+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:13:07.849+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:07.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:13:07.866+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:07.866+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:13:07.900+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:13:38.700+0000] {processor.py:186} INFO - Started process (PID=40357) to work on /opt/airflow/dags/test.py
[2025-04-08T08:13:38.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:13:38.705+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:38.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:13:38.721+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:38.721+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:13:38.725+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:13:38.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:38.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:13:38.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:38.764+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:13:38.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:14:08.860+0000] {processor.py:186} INFO - Started process (PID=40427) to work on /opt/airflow/dags/test.py
[2025-04-08T08:14:08.861+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:14:08.865+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:08.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:14:08.886+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:08.886+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:14:08.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:14:08.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:08.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:14:08.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:08.931+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:14:08.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T08:14:39.283+0000] {processor.py:186} INFO - Started process (PID=40496) to work on /opt/airflow/dags/test.py
[2025-04-08T08:14:39.285+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:14:39.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:39.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:14:39.306+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:39.305+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:14:39.310+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:14:39.330+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:39.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:14:39.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:39.348+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:14:39.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:15:09.750+0000] {processor.py:186} INFO - Started process (PID=40565) to work on /opt/airflow/dags/test.py
[2025-04-08T08:15:09.752+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:15:09.755+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:09.755+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:15:09.774+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:09.774+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:15:09.779+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:15:09.799+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:09.799+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:15:09.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:09.816+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:15:09.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T08:15:39.943+0000] {processor.py:186} INFO - Started process (PID=40634) to work on /opt/airflow/dags/test.py
[2025-04-08T08:15:39.944+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:15:39.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:39.946+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:15:39.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:39.972+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:15:39.977+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:15:40.008+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:40.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:15:40.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:40.026+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:15:40.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-08T08:16:10.275+0000] {processor.py:186} INFO - Started process (PID=40703) to work on /opt/airflow/dags/test.py
[2025-04-08T08:16:10.277+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:16:10.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:10.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:16:10.300+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:10.299+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:16:10.303+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:16:10.324+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:10.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:16:10.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:10.340+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:16:10.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T08:16:40.549+0000] {processor.py:186} INFO - Started process (PID=40772) to work on /opt/airflow/dags/test.py
[2025-04-08T08:16:40.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:16:40.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:40.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:16:40.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:40.571+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:16:40.575+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:16:40.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:40.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:16:40.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:40.611+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:16:40.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T08:17:11.266+0000] {processor.py:186} INFO - Started process (PID=40841) to work on /opt/airflow/dags/test.py
[2025-04-08T08:17:11.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:17:11.270+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:11.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:17:11.285+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:11.284+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:17:11.289+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:17:11.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:11.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:17:11.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:11.326+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:17:11.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:17:42.093+0000] {processor.py:186} INFO - Started process (PID=40910) to work on /opt/airflow/dags/test.py
[2025-04-08T08:17:42.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:17:42.099+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:42.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:17:42.116+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:42.116+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:17:42.121+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:17:42.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:42.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:17:42.158+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:42.157+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:17:42.192+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T08:18:12.320+0000] {processor.py:186} INFO - Started process (PID=40979) to work on /opt/airflow/dags/test.py
[2025-04-08T08:18:12.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:18:12.324+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:12.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:18:12.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:12.340+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:18:12.345+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:18:12.367+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:12.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:18:12.386+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:12.386+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:18:12.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:18:43.215+0000] {processor.py:186} INFO - Started process (PID=41054) to work on /opt/airflow/dags/test.py
[2025-04-08T08:18:43.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:18:43.220+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:43.219+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:18:43.238+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:43.237+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:18:43.242+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:18:43.263+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:43.263+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:18:43.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:43.281+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:18:43.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:19:14.117+0000] {processor.py:186} INFO - Started process (PID=41123) to work on /opt/airflow/dags/test.py
[2025-04-08T08:19:14.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:19:14.121+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:14.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:19:14.140+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:14.139+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:19:14.143+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:19:14.164+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:14.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:19:14.181+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:14.181+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:19:14.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:19:44.450+0000] {processor.py:186} INFO - Started process (PID=41193) to work on /opt/airflow/dags/test.py
[2025-04-08T08:19:44.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:19:44.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:44.454+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:19:44.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:44.472+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:19:44.477+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:19:44.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:44.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:19:44.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:44.516+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:19:44.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T08:20:14.724+0000] {processor.py:186} INFO - Started process (PID=41262) to work on /opt/airflow/dags/test.py
[2025-04-08T08:20:14.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:20:14.728+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:14.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:20:14.743+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:14.743+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:20:14.747+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:20:14.772+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:14.772+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:20:14.793+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:14.793+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:20:14.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T08:20:45.364+0000] {processor.py:186} INFO - Started process (PID=41332) to work on /opt/airflow/dags/test.py
[2025-04-08T08:20:45.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:20:45.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:45.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:20:45.386+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:45.385+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:20:45.391+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:20:45.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:45.417+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:20:45.435+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:45.434+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:20:45.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T08:21:16.184+0000] {processor.py:186} INFO - Started process (PID=41401) to work on /opt/airflow/dags/test.py
[2025-04-08T08:21:16.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:21:16.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:16.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:21:16.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:16.205+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:21:16.210+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:21:16.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:16.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:21:16.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:16.246+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:21:16.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:21:46.982+0000] {processor.py:186} INFO - Started process (PID=41458) to work on /opt/airflow/dags/test.py
[2025-04-08T08:21:46.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:21:46.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:46.986+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:21:47.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:47.007+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:21:47.012+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:21:47.033+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:47.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:21:47.053+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:47.052+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:21:47.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T08:22:17.403+0000] {processor.py:186} INFO - Started process (PID=41524) to work on /opt/airflow/dags/test.py
[2025-04-08T08:22:17.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:22:17.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:17.407+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:22:17.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:17.424+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:22:17.429+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:22:17.449+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:17.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:22:17.466+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:17.465+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:22:17.496+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:22:55.910+0000] {processor.py:186} INFO - Started process (PID=41583) to work on /opt/airflow/dags/test.py
[2025-04-08T08:22:55.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:22:55.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:55.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:22:55.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:55.934+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:22:55.939+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:22:55.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:55.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:22:55.990+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:55.990+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:22:56.122+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.223 seconds
[2025-04-08T08:23:26.729+0000] {processor.py:186} INFO - Started process (PID=41649) to work on /opt/airflow/dags/test.py
[2025-04-08T08:23:26.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:23:26.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:26.732+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:23:26.751+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:26.750+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:23:26.755+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:23:26.774+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:26.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:23:26.791+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:26.790+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:23:26.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:23:56.979+0000] {processor.py:186} INFO - Started process (PID=41718) to work on /opt/airflow/dags/test.py
[2025-04-08T08:23:56.980+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:23:56.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:56.982+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:23:57.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:57.004+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:23:57.008+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:23:57.028+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:57.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:23:57.045+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:57.044+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:23:57.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:24:27.522+0000] {processor.py:186} INFO - Started process (PID=41787) to work on /opt/airflow/dags/test.py
[2025-04-08T08:24:27.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:24:27.525+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:27.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:24:27.546+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:27.546+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:24:27.550+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:24:27.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:27.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:24:27.589+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:27.588+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:24:27.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:24:58.038+0000] {processor.py:186} INFO - Started process (PID=41856) to work on /opt/airflow/dags/test.py
[2025-04-08T08:24:58.040+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:24:58.043+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:58.043+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:24:58.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:58.062+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:24:58.067+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:24:58.088+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:58.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:24:58.105+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:58.105+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:24:58.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:25:28.271+0000] {processor.py:186} INFO - Started process (PID=41925) to work on /opt/airflow/dags/test.py
[2025-04-08T08:25:28.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:25:28.275+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:28.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:25:28.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:28.296+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:25:28.300+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:25:28.321+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:28.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:25:28.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:28.338+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:25:28.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T08:25:59.127+0000] {processor.py:186} INFO - Started process (PID=41994) to work on /opt/airflow/dags/test.py
[2025-04-08T08:25:59.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:25:59.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:59.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:25:59.147+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:59.146+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:25:59.151+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:25:59.171+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:59.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:25:59.189+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:59.189+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:25:59.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:26:29.649+0000] {processor.py:186} INFO - Started process (PID=42062) to work on /opt/airflow/dags/test.py
[2025-04-08T08:26:29.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:26:29.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:29.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:26:29.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:29.673+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:26:29.682+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:26:29.703+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:29.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:26:29.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:29.719+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:26:29.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T08:27:00.396+0000] {processor.py:186} INFO - Started process (PID=42131) to work on /opt/airflow/dags/test.py
[2025-04-08T08:27:00.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:27:00.400+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:00.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:27:00.416+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:00.415+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:27:00.420+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:27:00.441+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:00.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:27:00.459+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:00.459+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:27:00.495+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:27:30.809+0000] {processor.py:186} INFO - Started process (PID=42200) to work on /opt/airflow/dags/test.py
[2025-04-08T08:27:30.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:27:30.814+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:30.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:27:30.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:30.830+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:27:30.835+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:27:30.857+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:30.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:27:30.874+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:30.873+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:27:30.903+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:28:01.381+0000] {processor.py:186} INFO - Started process (PID=42269) to work on /opt/airflow/dags/test.py
[2025-04-08T08:28:01.382+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:28:01.386+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:01.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:28:01.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:01.406+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:28:01.412+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:28:01.439+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:01.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:28:01.462+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:01.461+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:28:01.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T08:28:32.273+0000] {processor.py:186} INFO - Started process (PID=42338) to work on /opt/airflow/dags/test.py
[2025-04-08T08:28:32.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:28:32.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:32.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:28:32.299+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:32.298+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:28:32.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:28:32.323+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:32.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:28:32.341+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:32.341+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:28:32.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:29:02.762+0000] {processor.py:186} INFO - Started process (PID=42407) to work on /opt/airflow/dags/test.py
[2025-04-08T08:29:02.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:29:02.766+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:02.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:29:02.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:02.783+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:29:02.789+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:29:02.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:02.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:29:02.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:02.828+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:29:02.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:29:33.146+0000] {processor.py:186} INFO - Started process (PID=42476) to work on /opt/airflow/dags/test.py
[2025-04-08T08:29:33.147+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:29:33.150+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:33.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:29:33.166+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:33.166+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:29:33.170+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:29:33.192+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:33.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:29:33.209+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:33.209+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:29:33.240+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:30:03.417+0000] {processor.py:186} INFO - Started process (PID=42545) to work on /opt/airflow/dags/test.py
[2025-04-08T08:30:03.418+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:30:03.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:03.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:30:03.434+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:03.433+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:30:03.438+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:30:03.458+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:03.458+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:30:03.475+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:03.475+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:30:03.502+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T08:30:33.785+0000] {processor.py:186} INFO - Started process (PID=42607) to work on /opt/airflow/dags/test.py
[2025-04-08T08:30:33.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:30:33.790+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:33.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:30:33.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:33.807+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:30:33.812+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:30:33.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:33.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:30:33.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:33.847+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:30:33.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T08:31:04.684+0000] {processor.py:186} INFO - Started process (PID=42675) to work on /opt/airflow/dags/test.py
[2025-04-08T08:31:04.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:31:04.689+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:04.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:31:04.707+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:04.707+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:31:04.712+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:31:04.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:04.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:31:04.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:04.749+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:31:04.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:31:35.567+0000] {processor.py:186} INFO - Started process (PID=42744) to work on /opt/airflow/dags/test.py
[2025-04-08T08:31:35.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:31:35.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:35.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:31:35.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:35.586+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:31:35.591+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:31:35.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:35.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:31:35.636+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:35.635+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:31:35.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:32:06.242+0000] {processor.py:186} INFO - Started process (PID=42811) to work on /opt/airflow/dags/test.py
[2025-04-08T08:32:06.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:32:06.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:06.246+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:32:06.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:06.265+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:32:06.271+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:32:06.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:06.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:32:06.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:06.315+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:32:06.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.263 seconds
[2025-04-08T08:32:37.181+0000] {processor.py:186} INFO - Started process (PID=42880) to work on /opt/airflow/dags/test.py
[2025-04-08T08:32:37.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:32:37.185+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:37.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:32:37.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:37.202+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:32:37.206+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:32:37.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:37.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:32:37.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:37.256+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:32:37.293+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-08T08:33:07.715+0000] {processor.py:186} INFO - Started process (PID=42949) to work on /opt/airflow/dags/test.py
[2025-04-08T08:33:07.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:33:07.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:07.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:33:07.735+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:07.735+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:33:07.739+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:33:07.759+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:07.759+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:33:07.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:07.775+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:33:07.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T08:33:38.344+0000] {processor.py:186} INFO - Started process (PID=43018) to work on /opt/airflow/dags/test.py
[2025-04-08T08:33:38.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:33:38.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:38.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:33:38.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:38.367+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:33:38.372+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:33:38.392+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:38.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:33:38.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:38.408+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:33:38.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:34:08.843+0000] {processor.py:186} INFO - Started process (PID=43087) to work on /opt/airflow/dags/test.py
[2025-04-08T08:34:08.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:34:08.847+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:08.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:34:08.862+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:08.862+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:34:08.866+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:34:08.889+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:08.889+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:34:08.906+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:08.905+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:34:08.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:34:39.258+0000] {processor.py:186} INFO - Started process (PID=43156) to work on /opt/airflow/dags/test.py
[2025-04-08T08:34:39.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:34:39.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:39.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:34:39.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:39.279+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:34:39.284+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:34:39.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:39.304+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:34:39.322+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:39.322+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:34:39.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T08:35:09.852+0000] {processor.py:186} INFO - Started process (PID=43226) to work on /opt/airflow/dags/test.py
[2025-04-08T08:35:09.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:35:09.856+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:09.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:35:09.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:09.872+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:35:09.877+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:35:09.896+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:09.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:35:09.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:09.915+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:35:09.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:35:40.958+0000] {processor.py:186} INFO - Started process (PID=43295) to work on /opt/airflow/dags/test.py
[2025-04-08T08:35:40.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:35:40.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:40.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:35:40.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:40.982+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:35:40.987+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:35:41.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:41.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:35:41.024+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:41.024+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:35:41.059+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:36:11.318+0000] {processor.py:186} INFO - Started process (PID=43364) to work on /opt/airflow/dags/test.py
[2025-04-08T08:36:11.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:36:11.322+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:11.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:36:11.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:11.339+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:36:11.343+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:36:11.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:11.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:36:11.387+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:11.387+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:36:11.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:36:41.542+0000] {processor.py:186} INFO - Started process (PID=43433) to work on /opt/airflow/dags/test.py
[2025-04-08T08:36:41.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:36:41.547+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:41.546+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:36:41.566+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:41.566+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:36:41.570+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:36:41.591+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:41.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:36:41.607+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:41.607+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:36:41.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:37:11.804+0000] {processor.py:186} INFO - Started process (PID=43502) to work on /opt/airflow/dags/test.py
[2025-04-08T08:37:11.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:37:11.808+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:11.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:37:11.829+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:11.828+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:37:11.835+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:37:11.855+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:11.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:37:11.871+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:11.871+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:37:11.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-08T08:37:42.562+0000] {processor.py:186} INFO - Started process (PID=43571) to work on /opt/airflow/dags/test.py
[2025-04-08T08:37:42.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:37:42.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:42.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:37:42.584+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:42.583+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:37:42.588+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:37:42.607+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:42.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:37:42.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:42.624+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:37:42.656+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:38:13.364+0000] {processor.py:186} INFO - Started process (PID=43640) to work on /opt/airflow/dags/test.py
[2025-04-08T08:38:13.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:38:13.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:13.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:38:13.383+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:13.382+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:38:13.387+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:38:13.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:13.408+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:38:13.428+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:13.427+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:38:13.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:38:44.370+0000] {processor.py:186} INFO - Started process (PID=43709) to work on /opt/airflow/dags/test.py
[2025-04-08T08:38:44.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:38:44.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:44.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:38:44.391+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:44.391+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:38:44.395+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:38:44.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:44.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:38:44.442+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:44.441+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:38:44.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T08:39:14.798+0000] {processor.py:186} INFO - Started process (PID=43778) to work on /opt/airflow/dags/test.py
[2025-04-08T08:39:14.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:39:14.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:14.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:39:14.821+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:14.820+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:39:14.826+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:39:14.853+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:14.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:39:14.871+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:14.871+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:39:14.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T08:39:45.359+0000] {processor.py:186} INFO - Started process (PID=43847) to work on /opt/airflow/dags/test.py
[2025-04-08T08:39:45.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:39:45.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:45.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:39:45.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:45.381+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:39:45.385+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:39:45.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:45.406+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:39:45.423+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:45.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:39:45.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:40:15.600+0000] {processor.py:186} INFO - Started process (PID=43916) to work on /opt/airflow/dags/test.py
[2025-04-08T08:40:15.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:40:15.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:15.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:40:15.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:15.624+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:40:15.629+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:40:15.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:15.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:40:15.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:15.667+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:40:15.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T08:40:45.871+0000] {processor.py:186} INFO - Started process (PID=43991) to work on /opt/airflow/dags/test.py
[2025-04-08T08:40:45.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:40:45.876+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:45.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:40:45.895+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:45.895+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:40:45.899+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:40:45.919+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:45.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:40:45.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:45.939+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:40:45.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:41:16.041+0000] {processor.py:186} INFO - Started process (PID=44060) to work on /opt/airflow/dags/test.py
[2025-04-08T08:41:16.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:41:16.044+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:16.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:41:16.065+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:16.065+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:41:16.069+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:41:16.092+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:16.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:41:16.110+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:16.110+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:41:16.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:41:47.049+0000] {processor.py:186} INFO - Started process (PID=44127) to work on /opt/airflow/dags/test.py
[2025-04-08T08:41:47.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:41:47.053+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:47.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:41:47.071+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:47.071+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:41:47.075+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:41:47.094+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:47.094+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:41:47.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:47.111+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:41:47.143+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:42:17.347+0000] {processor.py:186} INFO - Started process (PID=44196) to work on /opt/airflow/dags/test.py
[2025-04-08T08:42:17.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:42:17.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:17.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:42:17.366+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:17.366+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:42:17.370+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:42:17.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:17.394+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:42:17.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:17.426+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:42:17.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-08T08:42:47.967+0000] {processor.py:186} INFO - Started process (PID=44264) to work on /opt/airflow/dags/test.py
[2025-04-08T08:42:47.969+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:42:47.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:47.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:42:47.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:47.991+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:42:47.995+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:42:48.020+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:48.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:42:48.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:48.038+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:42:48.076+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-08T08:43:18.375+0000] {processor.py:186} INFO - Started process (PID=44333) to work on /opt/airflow/dags/test.py
[2025-04-08T08:43:18.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:43:18.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:18.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:43:18.396+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:18.395+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:43:18.402+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:43:18.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:18.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:43:18.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:18.445+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:43:18.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T08:43:48.619+0000] {processor.py:186} INFO - Started process (PID=44390) to work on /opt/airflow/dags/test.py
[2025-04-08T08:43:48.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:43:48.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:48.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:43:48.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:48.640+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:43:48.644+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:43:48.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:48.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:43:48.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:48.679+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:43:48.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T08:44:18.947+0000] {processor.py:186} INFO - Started process (PID=44457) to work on /opt/airflow/dags/test.py
[2025-04-08T08:44:18.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:44:18.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:18.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:44:18.976+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:18.976+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:44:18.986+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:44:19.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:19.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:44:19.026+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:19.026+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:44:19.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-08T08:44:49.322+0000] {processor.py:186} INFO - Started process (PID=44525) to work on /opt/airflow/dags/test.py
[2025-04-08T08:44:49.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:44:49.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:49.326+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:44:49.344+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:49.344+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:44:49.348+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:44:49.367+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:49.367+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:44:49.383+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:49.383+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:44:49.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T08:45:19.797+0000] {processor.py:186} INFO - Started process (PID=44592) to work on /opt/airflow/dags/test.py
[2025-04-08T08:45:19.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:45:19.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:45:19.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.819+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:45:19.822+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:45:19.842+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:45:19.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.858+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:45:19.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T08:45:50.793+0000] {processor.py:186} INFO - Started process (PID=44659) to work on /opt/airflow/dags/test.py
[2025-04-08T08:45:50.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:45:50.797+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:45:50.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.818+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:45:50.822+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:45:50.842+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:45:50.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.858+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:45:50.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:46:21.342+0000] {processor.py:186} INFO - Started process (PID=44728) to work on /opt/airflow/dags/test.py
[2025-04-08T08:46:21.343+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:46:21.346+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:21.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:46:21.361+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:21.361+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:46:21.365+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:46:21.387+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:21.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:46:21.403+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:21.403+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:46:21.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T08:46:52.683+0000] {processor.py:186} INFO - Started process (PID=44797) to work on /opt/airflow/dags/test.py
[2025-04-08T08:46:52.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:46:52.687+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:52.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:46:52.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:52.706+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:46:52.710+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:46:52.730+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:52.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:46:52.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:52.746+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:46:52.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:47:24.109+0000] {processor.py:186} INFO - Started process (PID=44866) to work on /opt/airflow/dags/test.py
[2025-04-08T08:47:24.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:47:24.113+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:24.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:47:24.128+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:24.128+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:47:24.132+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:47:24.157+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:24.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:47:24.177+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:24.177+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:47:24.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-08T08:47:54.922+0000] {processor.py:186} INFO - Started process (PID=44935) to work on /opt/airflow/dags/test.py
[2025-04-08T08:47:54.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:47:54.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:47:54.943+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.942+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:47:54.947+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:47:54.969+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:47:54.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.986+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:47:55.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T08:48:26.353+0000] {processor.py:186} INFO - Started process (PID=45004) to work on /opt/airflow/dags/test.py
[2025-04-08T08:48:26.354+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:48:26.357+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:26.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:48:26.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:26.371+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:48:26.375+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:48:26.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:26.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:48:26.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:26.416+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:48:26.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T08:48:57.014+0000] {processor.py:186} INFO - Started process (PID=45073) to work on /opt/airflow/dags/test.py
[2025-04-08T08:48:57.015+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:48:57.018+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:57.018+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:48:57.033+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:57.033+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:48:57.037+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:48:57.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:57.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:48:57.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:57.075+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:48:57.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T08:49:27.581+0000] {processor.py:186} INFO - Started process (PID=45142) to work on /opt/airflow/dags/test.py
[2025-04-08T08:49:27.582+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:49:27.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:27.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:49:27.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:27.605+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:49:27.609+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:49:27.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:27.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:49:27.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:27.652+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:49:27.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T08:49:58.227+0000] {processor.py:186} INFO - Started process (PID=45211) to work on /opt/airflow/dags/test.py
[2025-04-08T08:49:58.228+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:49:58.231+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:58.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:49:58.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:58.246+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:49:58.250+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:49:58.272+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:58.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:49:58.289+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:58.289+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:49:58.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T08:50:28.814+0000] {processor.py:186} INFO - Started process (PID=45280) to work on /opt/airflow/dags/test.py
[2025-04-08T08:50:28.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:50:28.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:28.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:50:28.833+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:28.832+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:50:28.836+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:50:28.860+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:28.860+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:50:28.880+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:28.880+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:50:28.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:50:59.691+0000] {processor.py:186} INFO - Started process (PID=45349) to work on /opt/airflow/dags/test.py
[2025-04-08T08:50:59.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:50:59.695+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:59.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:50:59.711+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:59.711+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:50:59.714+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:50:59.734+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:59.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:50:59.752+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:59.752+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:50:59.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T08:51:30.810+0000] {processor.py:186} INFO - Started process (PID=45418) to work on /opt/airflow/dags/test.py
[2025-04-08T08:51:30.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:51:30.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:30.815+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:51:30.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:30.830+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:51:30.836+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:51:30.861+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:30.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:51:30.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:30.877+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:51:30.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:52:01.273+0000] {processor.py:186} INFO - Started process (PID=45487) to work on /opt/airflow/dags/test.py
[2025-04-08T08:52:01.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:52:01.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:01.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:52:01.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:01.294+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:52:01.298+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:52:01.318+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:01.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:52:01.335+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:01.335+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:52:01.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T08:52:32.226+0000] {processor.py:186} INFO - Started process (PID=45556) to work on /opt/airflow/dags/test.py
[2025-04-08T08:52:32.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:52:32.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:32.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:52:32.250+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:32.249+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:52:32.254+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:52:32.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:32.277+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:52:32.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:32.294+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:52:32.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T08:53:02.798+0000] {processor.py:186} INFO - Started process (PID=45625) to work on /opt/airflow/dags/test.py
[2025-04-08T08:53:02.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:53:02.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:53:02.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.819+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:53:02.823+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:53:02.843+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:53:02.859+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.858+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:53:02.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T08:53:33.856+0000] {processor.py:186} INFO - Started process (PID=45694) to work on /opt/airflow/dags/test.py
[2025-04-08T08:53:33.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:53:33.860+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:53:33.874+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.874+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:53:33.879+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:53:33.903+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:53:33.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.928+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:53:33.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T08:54:04.685+0000] {processor.py:186} INFO - Started process (PID=45762) to work on /opt/airflow/dags/test.py
[2025-04-08T08:54:04.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:54:04.691+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.690+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:54:04.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.707+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:54:04.712+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:54:04.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:54:04.752+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.752+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:54:04.784+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:54:35.419+0000] {processor.py:186} INFO - Started process (PID=45831) to work on /opt/airflow/dags/test.py
[2025-04-08T08:54:35.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:54:35.423+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:35.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:54:35.439+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:35.439+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:54:35.443+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:54:35.467+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:35.467+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:54:35.483+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:35.483+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:54:35.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T08:55:05.858+0000] {processor.py:186} INFO - Started process (PID=45900) to work on /opt/airflow/dags/test.py
[2025-04-08T08:55:05.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:55:05.862+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.861+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:55:05.879+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.879+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:55:05.883+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:55:05.901+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:55:05.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.917+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:55:05.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-08T08:55:36.620+0000] {processor.py:186} INFO - Started process (PID=45969) to work on /opt/airflow/dags/test.py
[2025-04-08T08:55:36.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:55:36.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:55:36.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.637+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:55:36.642+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:55:36.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:55:36.683+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:55:36.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:56:07.101+0000] {processor.py:186} INFO - Started process (PID=46038) to work on /opt/airflow/dags/test.py
[2025-04-08T08:56:07.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:56:07.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:07.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:56:07.122+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:07.122+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:56:07.126+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:56:07.145+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:07.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:56:07.162+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:07.161+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:56:07.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T08:56:37.830+0000] {processor.py:186} INFO - Started process (PID=46107) to work on /opt/airflow/dags/test.py
[2025-04-08T08:56:37.831+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:56:37.834+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:56:37.850+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.850+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:56:37.854+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:56:37.876+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:56:37.895+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.894+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:56:37.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-08T08:57:08.355+0000] {processor.py:186} INFO - Started process (PID=46176) to work on /opt/airflow/dags/test.py
[2025-04-08T08:57:08.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:57:08.359+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:08.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:57:08.375+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:08.375+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:57:08.379+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:57:08.400+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:08.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:57:08.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:08.417+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:57:08.447+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T08:57:39.795+0000] {processor.py:186} INFO - Started process (PID=46246) to work on /opt/airflow/dags/test.py
[2025-04-08T08:57:39.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:57:39.800+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:39.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:57:39.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:39.815+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:57:39.821+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:57:39.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:39.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:57:39.869+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:39.868+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:57:39.895+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T08:58:10.654+0000] {processor.py:186} INFO - Started process (PID=46315) to work on /opt/airflow/dags/test.py
[2025-04-08T08:58:10.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:58:10.659+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:10.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:58:10.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:10.675+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:58:10.679+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:58:10.700+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:10.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:58:10.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:10.718+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:58:10.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T08:58:41.527+0000] {processor.py:186} INFO - Started process (PID=46384) to work on /opt/airflow/dags/test.py
[2025-04-08T08:58:41.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:58:41.532+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:41.532+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:58:41.555+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:41.555+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:58:41.562+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:58:41.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:41.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:58:41.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:41.613+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:58:41.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-08T08:59:12.507+0000] {processor.py:186} INFO - Started process (PID=46453) to work on /opt/airflow/dags/test.py
[2025-04-08T08:59:12.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:59:12.512+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:12.512+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:59:12.533+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:12.533+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:59:12.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:59:12.563+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:12.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:59:12.583+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:12.583+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:59:12.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-08T08:59:43.452+0000] {processor.py:186} INFO - Started process (PID=46521) to work on /opt/airflow/dags/test.py
[2025-04-08T08:59:43.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T08:59:43.456+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:43.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T08:59:43.469+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:43.469+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T08:59:43.473+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T08:59:43.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:43.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:59:43.509+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:43.509+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T08:59:43.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T09:00:14.333+0000] {processor.py:186} INFO - Started process (PID=46589) to work on /opt/airflow/dags/test.py
[2025-04-08T09:00:14.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:00:14.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:14.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:00:14.353+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:14.352+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:00:14.356+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:00:14.377+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:14.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:00:14.393+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:14.393+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:00:14.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T09:00:45.109+0000] {processor.py:186} INFO - Started process (PID=46658) to work on /opt/airflow/dags/test.py
[2025-04-08T09:00:45.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:00:45.113+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:45.113+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:00:45.127+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:45.127+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:00:45.131+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:00:45.152+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:45.151+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:00:45.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:45.168+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:00:45.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T09:01:15.463+0000] {processor.py:186} INFO - Started process (PID=46726) to work on /opt/airflow/dags/test.py
[2025-04-08T09:01:15.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:01:15.467+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.467+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:01:15.489+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.488+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:01:15.493+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:01:15.515+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.514+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:01:15.532+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.532+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:01:15.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T09:01:45.995+0000] {processor.py:186} INFO - Started process (PID=46795) to work on /opt/airflow/dags/test.py
[2025-04-08T09:01:45.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:01:45.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:45.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:01:46.014+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:46.014+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:01:46.018+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:01:46.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:46.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:01:46.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:46.056+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:01:46.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T09:02:17.022+0000] {processor.py:186} INFO - Started process (PID=46864) to work on /opt/airflow/dags/test.py
[2025-04-08T09:02:17.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:02:17.028+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:17.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:02:17.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:17.050+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:02:17.054+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:02:17.076+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:17.075+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:02:17.093+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:17.092+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:02:17.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T09:02:47.261+0000] {processor.py:186} INFO - Started process (PID=46932) to work on /opt/airflow/dags/test.py
[2025-04-08T09:02:47.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:02:47.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:02:47.282+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.282+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:02:47.287+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:02:47.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:02:47.327+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.327+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:02:47.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T09:03:17.576+0000] {processor.py:186} INFO - Started process (PID=47000) to work on /opt/airflow/dags/test.py
[2025-04-08T09:03:17.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:03:17.582+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:17.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:03:17.603+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:17.603+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:03:17.607+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:03:17.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:17.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:03:17.659+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:17.659+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:03:17.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-08T09:03:47.796+0000] {processor.py:186} INFO - Started process (PID=47068) to work on /opt/airflow/dags/test.py
[2025-04-08T09:03:47.797+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:03:47.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:47.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:03:47.822+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:47.821+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:03:47.826+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:03:47.850+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:47.849+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:03:47.875+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:47.875+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:03:47.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-08T09:04:18.370+0000] {processor.py:186} INFO - Started process (PID=47137) to work on /opt/airflow/dags/test.py
[2025-04-08T09:04:18.372+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:04:18.375+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:18.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:04:18.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:18.393+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:04:18.397+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:04:18.419+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:18.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:04:18.435+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:18.435+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:04:18.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-08T09:04:49.328+0000] {processor.py:186} INFO - Started process (PID=47212) to work on /opt/airflow/dags/test.py
[2025-04-08T09:04:49.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:04:49.334+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:49.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:04:49.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:49.351+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:04:49.355+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:04:49.377+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:49.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:04:49.397+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:49.396+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:04:49.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T09:05:20.130+0000] {processor.py:186} INFO - Started process (PID=47280) to work on /opt/airflow/dags/test.py
[2025-04-08T09:05:20.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:05:20.135+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:20.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:05:20.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:20.153+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:05:20.157+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:05:20.182+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:20.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:05:20.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:20.205+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:05:20.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-08T09:05:50.923+0000] {processor.py:186} INFO - Started process (PID=47349) to work on /opt/airflow/dags/test.py
[2025-04-08T09:05:50.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:05:50.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:50.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:05:50.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:50.944+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:05:50.949+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:05:50.974+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:50.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:05:50.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:50.997+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:05:51.031+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-08T09:06:21.176+0000] {processor.py:186} INFO - Started process (PID=47418) to work on /opt/airflow/dags/test.py
[2025-04-08T09:06:21.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:06:21.180+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:21.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:06:21.198+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:21.198+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:06:21.202+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:06:21.220+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:21.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:06:21.236+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:21.235+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:06:21.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-08T09:06:51.320+0000] {processor.py:186} INFO - Started process (PID=47487) to work on /opt/airflow/dags/test.py
[2025-04-08T09:06:51.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:06:51.325+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:51.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:06:51.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:51.347+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:06:51.352+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:06:51.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:51.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:06:51.401+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:51.401+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:06:51.436+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-08T09:07:21.740+0000] {processor.py:186} INFO - Started process (PID=47556) to work on /opt/airflow/dags/test.py
[2025-04-08T09:07:21.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:07:21.745+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:21.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:07:21.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:21.763+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:07:21.767+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:07:21.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:21.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:07:21.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:21.804+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:07:21.829+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.095 seconds
[2025-04-08T09:07:52.593+0000] {processor.py:186} INFO - Started process (PID=47625) to work on /opt/airflow/dags/test.py
[2025-04-08T09:07:52.595+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:07:52.598+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:52.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:07:52.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:52.624+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:07:52.629+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:07:52.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:52.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:07:52.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:52.684+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:07:52.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.138 seconds
[2025-04-08T09:08:23.030+0000] {processor.py:186} INFO - Started process (PID=47694) to work on /opt/airflow/dags/test.py
[2025-04-08T09:08:23.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:08:23.035+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:23.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:08:23.056+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:23.055+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:08:23.060+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:08:23.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:23.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:08:23.099+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:23.099+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:08:23.134+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T09:08:53.934+0000] {processor.py:186} INFO - Started process (PID=47763) to work on /opt/airflow/dags/test.py
[2025-04-08T09:08:53.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:08:53.938+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:53.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:08:53.959+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:53.959+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:08:53.963+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:08:53.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:53.986+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:08:54.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:54.004+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:08:54.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T09:09:24.192+0000] {processor.py:186} INFO - Started process (PID=47832) to work on /opt/airflow/dags/test.py
[2025-04-08T09:09:24.193+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:09:24.196+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:24.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:09:24.215+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:24.215+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:09:24.218+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:09:24.238+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:24.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:09:24.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:24.255+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:09:24.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T09:09:54.456+0000] {processor.py:186} INFO - Started process (PID=47901) to work on /opt/airflow/dags/test.py
[2025-04-08T09:09:54.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:09:54.461+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:54.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:09:54.477+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:54.477+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:09:54.481+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:09:54.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:54.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:09:54.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:54.519+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:09:54.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.102 seconds
[2025-04-08T09:10:24.873+0000] {processor.py:186} INFO - Started process (PID=47970) to work on /opt/airflow/dags/test.py
[2025-04-08T09:10:24.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:10:24.877+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:24.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:10:24.897+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:24.896+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:10:24.900+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:10:24.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:24.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:10:24.937+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:24.936+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:10:24.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T09:10:55.863+0000] {processor.py:186} INFO - Started process (PID=48039) to work on /opt/airflow/dags/test.py
[2025-04-08T09:10:55.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:10:55.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:55.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:10:56.061+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:56.061+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:10:56.064+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:10:56.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:56.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:10:56.095+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:56.095+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:10:56.123+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.268 seconds
[2025-04-08T09:11:26.590+0000] {processor.py:186} INFO - Started process (PID=48106) to work on /opt/airflow/dags/test.py
[2025-04-08T09:11:26.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:11:26.595+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:26.594+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:11:26.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:26.611+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:11:26.615+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:11:26.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:26.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:11:26.658+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:26.658+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:11:26.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T09:11:57.185+0000] {processor.py:186} INFO - Started process (PID=48175) to work on /opt/airflow/dags/test.py
[2025-04-08T09:11:57.186+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:11:57.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:57.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:11:57.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:57.210+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:11:57.214+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:11:57.239+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:57.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:11:57.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:57.260+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:11:57.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-08T09:12:27.716+0000] {processor.py:186} INFO - Started process (PID=48244) to work on /opt/airflow/dags/test.py
[2025-04-08T09:12:27.717+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:12:27.720+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:27.720+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:12:27.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:27.741+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:12:27.745+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:12:27.765+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:27.765+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:12:27.784+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:27.784+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:12:27.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T09:12:58.340+0000] {processor.py:186} INFO - Started process (PID=48313) to work on /opt/airflow/dags/test.py
[2025-04-08T09:12:58.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:12:58.344+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:58.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:12:58.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:58.364+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:12:58.368+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:12:58.386+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:58.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:12:58.401+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:58.401+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:12:58.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T09:13:28.671+0000] {processor.py:186} INFO - Started process (PID=48383) to work on /opt/airflow/dags/test.py
[2025-04-08T09:13:28.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:13:28.683+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:28.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:13:28.707+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:28.707+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:13:28.712+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:13:28.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:28.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:13:28.752+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:28.751+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:13:28.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.131 seconds
[2025-04-08T09:13:59.317+0000] {processor.py:186} INFO - Started process (PID=48453) to work on /opt/airflow/dags/test.py
[2025-04-08T09:13:59.318+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:13:59.321+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:59.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:13:59.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:59.340+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:13:59.344+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:13:59.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:59.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:13:59.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:59.379+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:13:59.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T09:14:30.227+0000] {processor.py:186} INFO - Started process (PID=48522) to work on /opt/airflow/dags/test.py
[2025-04-08T09:14:30.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:14:30.232+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:30.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:14:30.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:30.255+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:14:30.260+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:14:30.285+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:30.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:14:30.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:30.305+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:14:30.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T09:15:01.084+0000] {processor.py:186} INFO - Started process (PID=48591) to work on /opt/airflow/dags/test.py
[2025-04-08T09:15:01.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:15:01.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:01.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:15:01.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:01.109+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:15:01.113+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:15:01.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:01.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:15:01.149+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:01.149+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:15:01.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T09:15:31.923+0000] {processor.py:186} INFO - Started process (PID=48660) to work on /opt/airflow/dags/test.py
[2025-04-08T09:15:31.925+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:15:31.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:31.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:15:31.948+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:31.948+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:15:31.952+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:15:31.970+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:31.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:15:31.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:31.986+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:15:32.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T09:16:02.207+0000] {processor.py:186} INFO - Started process (PID=48729) to work on /opt/airflow/dags/test.py
[2025-04-08T09:16:02.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:16:02.212+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:02.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:16:02.228+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:02.228+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:16:02.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:16:02.251+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:02.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:16:02.268+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:02.268+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:16:02.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-08T09:16:32.568+0000] {processor.py:186} INFO - Started process (PID=48798) to work on /opt/airflow/dags/test.py
[2025-04-08T09:16:32.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:16:32.572+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:32.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:16:32.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:32.592+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:16:32.596+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:16:32.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:32.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:16:32.634+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:32.634+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:16:32.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T09:17:03.293+0000] {processor.py:186} INFO - Started process (PID=48868) to work on /opt/airflow/dags/test.py
[2025-04-08T09:17:03.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:17:03.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:03.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:17:03.316+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:03.316+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:17:03.320+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:17:03.344+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:03.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:17:03.361+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:03.361+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:17:03.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T09:17:33.875+0000] {processor.py:186} INFO - Started process (PID=48937) to work on /opt/airflow/dags/test.py
[2025-04-08T09:17:33.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:17:33.880+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:33.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:17:33.901+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:33.901+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:17:33.905+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:17:33.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:33.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:17:33.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:33.944+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:17:33.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.107 seconds
[2025-04-08T09:18:04.739+0000] {processor.py:186} INFO - Started process (PID=49006) to work on /opt/airflow/dags/test.py
[2025-04-08T09:18:04.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:18:04.743+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:04.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:18:04.761+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:04.761+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:18:04.765+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:18:04.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:04.786+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:18:04.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:04.802+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:18:04.827+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-08T09:18:35.063+0000] {processor.py:186} INFO - Started process (PID=49074) to work on /opt/airflow/dags/test.py
[2025-04-08T09:18:35.064+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:18:35.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:35.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:18:35.088+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:35.088+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:18:35.092+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:18:35.114+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:35.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:18:35.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:35.131+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:18:35.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T09:19:05.519+0000] {processor.py:186} INFO - Started process (PID=49143) to work on /opt/airflow/dags/test.py
[2025-04-08T09:19:05.520+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:19:05.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:05.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:19:05.541+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:05.541+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:19:05.545+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:19:05.565+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:05.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:19:05.583+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:05.583+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:19:05.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T09:19:36.615+0000] {processor.py:186} INFO - Started process (PID=49212) to work on /opt/airflow/dags/test.py
[2025-04-08T09:19:36.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:19:36.620+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:36.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:19:36.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:36.639+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:19:36.643+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:19:36.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:36.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:19:36.683+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:36.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:19:36.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T09:20:07.673+0000] {processor.py:186} INFO - Started process (PID=49281) to work on /opt/airflow/dags/test.py
[2025-04-08T09:20:07.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:20:07.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:07.677+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:20:07.695+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:07.695+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:20:07.698+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:20:07.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:07.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:20:07.734+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:07.733+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:20:07.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-08T09:20:37.996+0000] {processor.py:186} INFO - Started process (PID=49351) to work on /opt/airflow/dags/test.py
[2025-04-08T09:20:37.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:20:38.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:38.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:20:38.033+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:38.033+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:20:38.039+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:20:38.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:38.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:20:38.073+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:38.073+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:20:38.104+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-08T09:21:08.781+0000] {processor.py:186} INFO - Started process (PID=49420) to work on /opt/airflow/dags/test.py
[2025-04-08T09:21:08.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:21:08.785+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:08.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:21:08.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:08.802+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:21:08.805+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:21:08.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:08.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:21:08.843+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:08.843+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:21:08.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T09:21:39.082+0000] {processor.py:186} INFO - Started process (PID=49489) to work on /opt/airflow/dags/test.py
[2025-04-08T09:21:39.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:21:39.088+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:39.088+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:21:39.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:39.110+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:21:39.115+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:21:39.135+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:39.134+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:21:39.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:39.151+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:21:39.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T09:22:09.366+0000] {processor.py:186} INFO - Started process (PID=49558) to work on /opt/airflow/dags/test.py
[2025-04-08T09:22:09.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:22:09.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:09.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:22:09.395+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:09.394+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:22:09.399+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:22:09.420+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:09.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:22:09.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:09.437+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:22:09.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-08T09:22:39.809+0000] {processor.py:186} INFO - Started process (PID=49627) to work on /opt/airflow/dags/test.py
[2025-04-08T09:22:39.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:22:39.814+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:39.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:22:39.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:39.831+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:22:39.835+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:22:39.855+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:39.854+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:22:39.871+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:39.871+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:22:39.902+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T09:23:10.444+0000] {processor.py:186} INFO - Started process (PID=49696) to work on /opt/airflow/dags/test.py
[2025-04-08T09:23:10.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:23:10.460+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:10.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:23:10.496+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:10.496+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:23:10.501+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:23:10.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:10.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:23:10.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:10.535+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:23:10.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.136 seconds
[2025-04-08T09:23:41.103+0000] {processor.py:186} INFO - Started process (PID=49765) to work on /opt/airflow/dags/test.py
[2025-04-08T09:23:41.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:23:41.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:41.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:23:41.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:41.131+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:23:41.135+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:23:41.157+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:41.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:23:41.176+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:41.176+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:23:41.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T09:24:11.902+0000] {processor.py:186} INFO - Started process (PID=49834) to work on /opt/airflow/dags/test.py
[2025-04-08T09:24:11.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:24:11.907+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:11.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:24:11.924+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:11.924+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:24:11.929+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:24:11.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:11.952+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:24:11.970+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:11.969+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:24:12.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-08T09:24:42.285+0000] {processor.py:186} INFO - Started process (PID=49903) to work on /opt/airflow/dags/test.py
[2025-04-08T09:24:42.286+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:24:42.289+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:42.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:24:42.307+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:42.307+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:24:42.311+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:24:42.331+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:42.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:24:42.347+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:42.347+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:24:42.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-08T09:25:12.502+0000] {processor.py:186} INFO - Started process (PID=49971) to work on /opt/airflow/dags/test.py
[2025-04-08T09:25:12.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:25:12.506+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:12.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:25:12.521+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:12.521+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:25:12.525+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:25:12.546+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:12.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:25:12.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:12.561+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:25:12.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.093 seconds
[2025-04-08T09:25:42.972+0000] {processor.py:186} INFO - Started process (PID=50039) to work on /opt/airflow/dags/test.py
[2025-04-08T09:25:42.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:25:42.978+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:42.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:25:42.996+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:42.996+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:25:43.000+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:25:43.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:43.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:25:43.044+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:43.044+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:25:43.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-08T09:26:14.043+0000] {processor.py:186} INFO - Started process (PID=50108) to work on /opt/airflow/dags/test.py
[2025-04-08T09:26:14.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:26:14.047+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:14.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:26:14.067+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:14.067+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:26:14.071+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:26:14.092+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:14.092+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:26:14.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:14.109+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:26:14.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-08T09:26:44.498+0000] {processor.py:186} INFO - Started process (PID=50177) to work on /opt/airflow/dags/test.py
[2025-04-08T09:26:44.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:26:44.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:44.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:26:44.518+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:44.517+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:26:44.521+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:26:44.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:44.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:26:44.563+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:44.562+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:26:44.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-08T09:27:14.967+0000] {processor.py:186} INFO - Started process (PID=50246) to work on /opt/airflow/dags/test.py
[2025-04-08T09:27:14.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:27:14.972+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:14.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:27:14.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:14.991+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:27:14.996+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:27:15.019+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:15.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:27:15.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:15.038+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:27:15.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-08T09:27:45.502+0000] {processor.py:186} INFO - Started process (PID=50315) to work on /opt/airflow/dags/test.py
[2025-04-08T09:27:45.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:27:45.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:45.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:27:45.525+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:45.525+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:27:45.529+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:27:45.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:45.553+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:27:45.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:45.571+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:27:45.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-08T09:28:15.868+0000] {processor.py:186} INFO - Started process (PID=50384) to work on /opt/airflow/dags/test.py
[2025-04-08T09:28:15.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:28:15.872+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:15.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:28:15.888+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:15.887+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:28:15.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:28:15.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:15.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:28:15.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:15.927+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:28:15.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T09:28:46.612+0000] {processor.py:186} INFO - Started process (PID=50453) to work on /opt/airflow/dags/test.py
[2025-04-08T09:28:46.613+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:28:46.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:46.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:28:46.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:46.633+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:28:46.638+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:28:46.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:46.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:28:46.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:46.677+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:28:46.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T09:29:17.041+0000] {processor.py:186} INFO - Started process (PID=50522) to work on /opt/airflow/dags/test.py
[2025-04-08T09:29:17.042+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:29:17.045+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:17.045+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:29:17.064+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:17.064+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:29:17.069+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:29:17.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:17.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:29:17.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:17.107+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:29:17.138+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-08T09:29:47.563+0000] {processor.py:186} INFO - Started process (PID=50590) to work on /opt/airflow/dags/test.py
[2025-04-08T09:29:47.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:29:47.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:47.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:29:47.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:47.588+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:29:47.594+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:29:47.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:47.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:29:47.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:47.641+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:29:47.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-08T09:30:17.872+0000] {processor.py:186} INFO - Started process (PID=50658) to work on /opt/airflow/dags/test.py
[2025-04-08T09:30:17.873+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:30:17.876+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:17.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:30:17.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:17.892+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:30:17.897+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:30:17.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:17.917+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:30:17.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:17.933+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:30:17.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-08T09:30:48.539+0000] {processor.py:186} INFO - Started process (PID=50726) to work on /opt/airflow/dags/test.py
[2025-04-08T09:30:48.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:30:48.543+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:48.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:30:48.563+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:48.562+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:30:48.568+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:30:48.591+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:48.591+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:30:48.608+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:48.608+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:30:48.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-08T09:31:19.522+0000] {processor.py:186} INFO - Started process (PID=50796) to work on /opt/airflow/dags/test.py
[2025-04-08T09:31:19.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:31:19.526+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:19.526+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:31:19.548+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:19.547+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:31:19.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:31:19.581+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:19.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:31:19.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:19.601+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:31:19.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-08T09:31:50.376+0000] {processor.py:186} INFO - Started process (PID=50865) to work on /opt/airflow/dags/test.py
[2025-04-08T09:31:50.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:31:50.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:50.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:31:50.400+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:50.400+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:31:50.404+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:31:50.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:50.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:31:50.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:50.455+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:31:50.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-08T09:32:26.817+0000] {processor.py:186} INFO - Started process (PID=50940) to work on /opt/airflow/dags/test.py
[2025-04-08T09:32:26.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:32:26.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:26.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:32:26.888+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:26.887+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:32:26.903+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:32:26.959+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:26.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:32:27.054+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:27.054+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:32:27.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.666 seconds
[2025-04-08T09:33:49.927+0000] {processor.py:186} INFO - Started process (PID=50995) to work on /opt/airflow/dags/test.py
[2025-04-08T09:33:49.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-08T09:33:49.977+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:49.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-08T09:33:50.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:50.124+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-08T09:33:50.129+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-08T09:33:50.160+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:50.160+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:33:50.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:50.194+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-08T09:33:50.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.314 seconds
