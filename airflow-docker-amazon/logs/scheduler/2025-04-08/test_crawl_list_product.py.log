[2025-04-08T03:13:31.731+0000] {processor.py:186} INFO - Started process (PID=87) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:13:31.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:13:31.740+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:31.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:13:33.147+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:13:33.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:33.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:13:33.531+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:13:33.531+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:13:33.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.876 seconds
[2025-04-08T03:14:03.882+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:14:03.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:14:03.886+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:03.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:14:05.163+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:14:05.369+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:05.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:14:05.392+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:05.391+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:14:05.427+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.554 seconds
[2025-04-08T03:14:35.714+0000] {processor.py:186} INFO - Started process (PID=232) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:14:35.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:14:35.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:35.719+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:14:36.902+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:14:37.086+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:37.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:14:37.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:14:37.104+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:14:37.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.437 seconds
[2025-04-08T03:15:07.394+0000] {processor.py:186} INFO - Started process (PID=307) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:15:07.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:15:07.401+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:07.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:15:08.783+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:15:08.960+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:08.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:15:08.981+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:08.980+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:15:09.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.636 seconds
[2025-04-08T03:15:39.137+0000] {processor.py:186} INFO - Started process (PID=384) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:15:39.138+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:15:39.142+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:39.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:15:40.073+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:15:40.235+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:40.234+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:15:40.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:15:40.255+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:15:40.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.159 seconds
[2025-04-08T03:16:10.365+0000] {processor.py:186} INFO - Started process (PID=454) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:16:10.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:16:10.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:10.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:16:11.297+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:16:11.462+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:11.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:16:11.482+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:11.482+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:16:11.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.161 seconds
[2025-04-08T03:16:41.928+0000] {processor.py:186} INFO - Started process (PID=523) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:16:41.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:16:41.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:41.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:16:42.994+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:16:43.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:43.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:16:43.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:16:43.184+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:16:43.216+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.298 seconds
[2025-04-08T03:17:13.834+0000] {processor.py:186} INFO - Started process (PID=594) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:17:13.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:17:13.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:13.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:17:14.882+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:17:15.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:15.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:17:15.066+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:15.066+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:17:15.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.281 seconds
[2025-04-08T03:17:45.542+0000] {processor.py:186} INFO - Started process (PID=670) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:17:45.569+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:17:45.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:45.576+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:17:56.703+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:17:56.922+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:56.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:17:56.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:17:56.947+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:17:57.081+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 11.572 seconds
[2025-04-08T03:18:30.031+0000] {processor.py:186} INFO - Started process (PID=745) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:18:30.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:18:30.037+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:30.036+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:18:31.622+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:18:31.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:31.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:18:31.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:18:31.839+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:18:31.872+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.850 seconds
[2025-04-08T03:19:02.655+0000] {processor.py:186} INFO - Started process (PID=815) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:19:02.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:19:02.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:02.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:19:04.473+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:19:04.739+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:04.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:19:04.774+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:04.774+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:19:04.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 2.194 seconds
[2025-04-08T03:19:35.047+0000] {processor.py:186} INFO - Started process (PID=889) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:19:35.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:19:35.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:35.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:19:36.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:19:37.242+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:37.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:19:37.263+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:19:37.262+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:19:37.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 2.254 seconds
[2025-04-08T03:20:08.127+0000] {processor.py:186} INFO - Started process (PID=964) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:20:08.129+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:20:08.133+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:08.132+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:20:09.390+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:20:09.568+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:09.568+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:20:09.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:09.588+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:20:09.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.517 seconds
[2025-04-08T03:20:40.248+0000] {processor.py:186} INFO - Started process (PID=1038) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:20:40.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:20:40.253+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:40.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:20:41.431+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:20:41.602+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:41.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:20:41.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:20:41.624+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:20:41.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.423 seconds
[2025-04-08T03:21:12.428+0000] {processor.py:186} INFO - Started process (PID=1109) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:12.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:21:12.434+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:12.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:13.788+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:14.065+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:14.064+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:21:14.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:14.103+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:21:14.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.740 seconds
[2025-04-08T03:21:44.448+0000] {processor.py:186} INFO - Started process (PID=1178) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:44.449+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:21:44.452+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:44.452+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:45.495+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:46.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:46.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:21:46.093+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:46.092+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:21:46.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.703 seconds
[2025-04-08T03:21:47.047+0000] {processor.py:186} INFO - Started process (PID=1182) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:47.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:21:47.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:47.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:48.319+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:21:48.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:48.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:21:48.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:21:48.358+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:21:48.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.366 seconds
[2025-04-08T03:22:02.881+0000] {processor.py:186} INFO - Started process (PID=1199) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:02.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:22:02.890+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:02.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:04.742+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:04.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:04.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:22:04.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:04.773+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:22:04.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.939 seconds
[2025-04-08T03:22:35.595+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:35.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:22:35.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:35.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:37.192+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:37.366+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:37.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:22:37.389+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:37.388+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:22:37.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.843 seconds
[2025-04-08T03:22:37.839+0000] {processor.py:186} INFO - Started process (PID=1278) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:37.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:22:37.845+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:37.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:39.270+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:22:39.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:39.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:22:39.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:22:39.543+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:22:40.060+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 2.231 seconds
[2025-04-08T03:23:10.393+0000] {processor.py:186} INFO - Started process (PID=1352) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:23:10.394+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:23:10.399+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:10.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:23:11.576+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:23:11.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:11.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:23:11.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:11.982+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:23:12.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.630 seconds
[2025-04-08T03:23:42.120+0000] {processor.py:186} INFO - Started process (PID=1421) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:23:42.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:23:42.127+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:42.126+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:23:43.498+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:23:44.152+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:44.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:23:44.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:23:44.179+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:23:44.218+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 2.109 seconds
[2025-04-08T03:24:14.690+0000] {processor.py:186} INFO - Started process (PID=1490) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:24:14.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:24:14.696+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:14.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:24:16.031+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:24:16.439+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:16.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:24:16.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:16.454+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:24:16.512+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.836 seconds
[2025-04-08T03:24:46.863+0000] {processor.py:186} INFO - Started process (PID=1565) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:24:46.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:24:46.870+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:46.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:24:48.258+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:24:48.459+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:48.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:24:48.487+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:24:48.487+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:24:48.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.682 seconds
[2025-04-08T03:25:18.749+0000] {processor.py:186} INFO - Started process (PID=1641) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:25:18.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:25:18.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:18.754+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:25:20.029+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:25:20.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:20.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:25:20.219+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:20.219+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:25:20.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.510 seconds
[2025-04-08T03:25:50.337+0000] {processor.py:186} INFO - Started process (PID=1717) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:25:50.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:25:50.341+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:50.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:25:51.682+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:25:51.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:51.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:25:51.940+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:25:51.940+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:25:51.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.641 seconds
[2025-04-08T03:26:22.875+0000] {processor.py:186} INFO - Started process (PID=1794) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:26:22.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:26:22.882+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:22.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:26:24.387+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:26:24.566+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:24.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:26:24.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:24.590+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:26:24.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.770 seconds
[2025-04-08T03:26:55.461+0000] {processor.py:186} INFO - Started process (PID=1864) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:26:55.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:26:55.468+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:55.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:26:57.145+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:26:57.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:57.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:26:57.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:26:57.339+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:26:57.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.933 seconds
[2025-04-08T03:27:28.293+0000] {processor.py:186} INFO - Started process (PID=1938) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:27:28.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:27:28.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:28.297+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:27:29.588+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:27:29.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:29.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:27:29.796+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:29.795+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:27:29.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.546 seconds
[2025-04-08T03:27:59.936+0000] {processor.py:186} INFO - Started process (PID=2010) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:27:59.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:27:59.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:27:59.940+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:28:01.155+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:28:01.274+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:01.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:28:01.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:01.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:28:01.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.390 seconds
[2025-04-08T03:28:31.502+0000] {processor.py:186} INFO - Started process (PID=2085) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:28:31.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:28:31.505+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:31.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:28:32.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:28:32.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:32.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:28:32.685+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:28:32.685+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:28:32.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.214 seconds
[2025-04-08T03:29:03.346+0000] {processor.py:186} INFO - Started process (PID=2154) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:29:03.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:29:03.349+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:03.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:29:04.663+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:29:04.820+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:04.819+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:29:04.833+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:04.833+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:29:04.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.532 seconds
[2025-04-08T03:29:35.222+0000] {processor.py:186} INFO - Started process (PID=2228) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:29:35.223+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:29:35.226+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:35.225+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:29:36.177+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:29:36.316+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:36.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:29:36.329+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:29:36.329+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:29:36.360+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.145 seconds
[2025-04-08T03:30:06.907+0000] {processor.py:186} INFO - Started process (PID=2297) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:30:06.908+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:30:06.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:06.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:30:07.952+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:30:08.081+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:08.080+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:30:08.095+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:08.094+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:30:08.121+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.221 seconds
[2025-04-08T03:30:38.766+0000] {processor.py:186} INFO - Started process (PID=2368) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:30:38.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:30:38.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:38.769+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:30:39.862+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:30:40.010+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:40.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:30:40.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:30:40.023+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:30:40.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.299 seconds
[2025-04-08T03:31:10.656+0000] {processor.py:186} INFO - Started process (PID=2438) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:10.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:31:10.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:10.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:11.714+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:11.852+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:11.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:31:11.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:11.867+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:31:11.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.250 seconds
[2025-04-08T03:31:42.125+0000] {processor.py:186} INFO - Started process (PID=2509) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:42.126+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:31:42.129+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:42.129+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:43.185+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:43.474+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:43.473+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:31:43.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:43.503+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:31:43.534+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.418 seconds
[2025-04-08T03:31:55.945+0000] {processor.py:186} INFO - Started process (PID=2534) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:55.946+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:31:55.948+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:55.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:56.235+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:56.251+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:56.250+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:31:56.268+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:56.268+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:31:56.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-08T03:31:56.693+0000] {processor.py:186} INFO - Started process (PID=2538) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:56.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:31:56.697+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:56.696+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:57.025+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:31:57.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:57.038+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:31:57.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:31:57.056+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:31:57.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.406 seconds
[2025-04-08T03:32:27.391+0000] {processor.py:186} INFO - Started process (PID=2607) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:32:27.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:32:27.397+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:27.397+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:32:27.724+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:32:27.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:27.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:32:27.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:27.971+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:32:28.005+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.622 seconds
[2025-04-08T03:32:32.204+0000] {processor.py:186} INFO - Started process (PID=2632) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:32:32.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:32:32.208+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:32.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:32:32.508+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:32:32.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:32.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:32:32.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:32:32.544+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:32:32.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.389 seconds
[2025-04-08T03:33:02.836+0000] {processor.py:186} INFO - Started process (PID=2701) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:33:02.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:33:02.840+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:02.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:33:03.134+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:33:03.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:03.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:33:03.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:03.179+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:33:03.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T03:33:33.681+0000] {processor.py:186} INFO - Started process (PID=2771) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:33:33.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:33:33.686+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:33.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:33:34.023+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:33:34.050+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:34.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:33:34.068+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:33:34.068+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:33:34.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.426 seconds
[2025-04-08T03:34:00.627+0000] {processor.py:186} INFO - Started process (PID=2815) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:34:00.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:34:00.632+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:00.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:34:01.003+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:34:01.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:01.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:34:01.059+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:01.059+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:34:01.089+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.469 seconds
[2025-04-08T03:34:31.377+0000] {processor.py:186} INFO - Started process (PID=2884) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:34:31.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:34:31.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:31.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:34:31.656+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:34:31.692+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:31.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:34:31.711+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:34:31.711+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:34:31.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-08T03:35:01.879+0000] {processor.py:186} INFO - Started process (PID=2954) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:35:01.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:35:01.883+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:01.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:35:02.212+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:35:02.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:02.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:35:02.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:02.276+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:35:02.307+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.437 seconds
[2025-04-08T03:35:32.707+0000] {processor.py:186} INFO - Started process (PID=3027) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:35:32.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:35:32.715+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:32.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:35:33.021+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:35:33.052+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:33.051+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:35:33.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:35:33.069+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:35:33.102+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-08T03:36:04.080+0000] {processor.py:186} INFO - Started process (PID=3097) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:36:04.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:36:04.086+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:04.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:36:04.479+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:36:04.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:04.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:36:04.568+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:04.567+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:36:04.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.554 seconds
[2025-04-08T03:36:35.541+0000] {processor.py:186} INFO - Started process (PID=3166) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:36:35.543+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:36:35.548+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:35.547+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:36:35.854+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:36:35.884+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:35.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:36:35.901+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:36:35.901+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:36:35.933+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.399 seconds
[2025-04-08T03:37:06.896+0000] {processor.py:186} INFO - Started process (PID=3235) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:06.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:37:06.902+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:06.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:07.246+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:07.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:07.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:37:07.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:07.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:37:07.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.459 seconds
[2025-04-08T03:37:38.221+0000] {processor.py:186} INFO - Started process (PID=3304) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:38.222+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:37:38.226+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:38.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:38.502+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:38.541+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:38.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:37:38.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:38.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:37:38.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.380 seconds
[2025-04-08T03:37:39.267+0000] {processor.py:186} INFO - Started process (PID=3311) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:39.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:37:39.271+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:39.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:39.624+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:37:39.666+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:39.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:37:39.686+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:37:39.685+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:37:39.727+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.471 seconds
[2025-04-08T03:38:10.588+0000] {processor.py:186} INFO - Started process (PID=3380) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:10.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:38:10.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:10.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:10.847+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:10.875+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:10.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:38:10.893+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:10.892+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:38:10.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T03:38:23.100+0000] {processor.py:186} INFO - Started process (PID=3407) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:23.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:38:23.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:23.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:23.597+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:23.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:23.672+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:38:23.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:23.714+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:38:23.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.723 seconds
[2025-04-08T03:38:53.933+0000] {processor.py:186} INFO - Started process (PID=3478) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:53.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:38:53.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:53.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:54.271+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:38:54.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:54.305+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:38:54.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:38:54.326+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:38:54.352+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.433 seconds
[2025-04-08T03:39:24.606+0000] {processor.py:186} INFO - Started process (PID=3565) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:39:24.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:39:24.622+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:24.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:39:25.719+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:39:25.810+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:25.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:39:25.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:25.866+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:39:25.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.384 seconds
[2025-04-08T03:39:56.346+0000] {processor.py:186} INFO - Started process (PID=3634) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:39:56.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:39:56.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:56.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:39:56.634+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:39:56.664+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:56.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:39:56.681+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:39:56.681+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:39:56.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.380 seconds
[2025-04-08T03:40:27.125+0000] {processor.py:186} INFO - Started process (PID=3703) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:40:27.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:40:27.130+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:27.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:40:27.416+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:40:27.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:27.451+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:40:27.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:27.471+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:40:29.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.944 seconds
[2025-04-08T03:40:59.167+0000] {processor.py:186} INFO - Started process (PID=3773) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:40:59.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:40:59.171+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:59.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:40:59.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:40:59.462+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:59.462+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:40:59.504+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:40:59.504+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:40:59.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.376 seconds
[2025-04-08T03:41:29.694+0000] {processor.py:186} INFO - Started process (PID=3842) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:41:29.696+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:41:29.699+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:29.699+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:41:30.024+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:41:30.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:30.058+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:41:30.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:41:30.074+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:41:30.100+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.416 seconds
[2025-04-08T03:42:00.870+0000] {processor.py:186} INFO - Started process (PID=3911) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:42:00.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:42:00.877+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:00.876+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:42:01.236+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:42:01.265+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:01.264+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:42:01.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:01.281+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:42:01.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.458 seconds
[2025-04-08T03:42:32.243+0000] {processor.py:186} INFO - Started process (PID=3981) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:42:32.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:42:32.247+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:32.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:42:32.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:42:32.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:32.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:42:32.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:42:32.621+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:42:32.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.430 seconds
[2025-04-08T03:43:02.802+0000] {processor.py:186} INFO - Started process (PID=4052) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:43:02.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:43:02.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:02.806+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:43:03.071+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:43:03.110+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:03.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:43:03.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:03.131+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:43:03.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-08T03:43:33.263+0000] {processor.py:186} INFO - Started process (PID=4125) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:43:33.265+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:43:33.267+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:33.267+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:43:33.538+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:43:33.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:33.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:43:33.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:43:33.587+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:43:33.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T03:44:03.783+0000] {processor.py:186} INFO - Started process (PID=4196) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:44:03.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:44:03.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:03.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:44:04.034+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:44:04.068+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:04.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:44:04.083+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:04.083+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:44:04.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T03:44:34.186+0000] {processor.py:186} INFO - Started process (PID=4263) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:44:34.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:44:34.190+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:34.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:44:34.602+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:44:34.636+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:34.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:44:34.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:44:34.657+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:44:34.693+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.519 seconds
[2025-04-08T03:45:04.869+0000] {processor.py:186} INFO - Started process (PID=4334) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:04.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:45:04.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:04.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:05.186+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:05.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:05.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:45:05.244+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:05.243+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:45:05.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.417 seconds
[2025-04-08T03:45:33.910+0000] {processor.py:186} INFO - Started process (PID=4399) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:33.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:45:33.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:33.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:34.203+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:34.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:34.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:45:34.250+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:34.250+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:45:34.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.559 seconds
[2025-04-08T03:45:35.186+0000] {processor.py:186} INFO - Started process (PID=4401) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:35.187+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:45:35.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:35.191+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:35.548+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:45:35.582+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:35.581+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:45:35.602+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:45:35.601+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:45:35.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.738 seconds
[2025-04-08T03:46:06.479+0000] {processor.py:186} INFO - Started process (PID=4470) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:46:06.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:46:06.485+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:06.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:46:06.936+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:46:06.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:06.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:46:07.014+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:07.013+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:46:07.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.581 seconds
[2025-04-08T03:46:37.198+0000] {processor.py:186} INFO - Started process (PID=4541) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:46:37.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:46:37.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:37.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:46:37.562+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:46:37.611+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:37.610+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:46:37.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:46:37.637+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:46:37.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.500 seconds
[2025-04-08T03:47:07.911+0000] {processor.py:186} INFO - Started process (PID=4612) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:47:07.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:47:07.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:07.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:47:08.294+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:47:08.336+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:08.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:47:08.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:08.363+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:47:08.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.494 seconds
[2025-04-08T03:47:38.964+0000] {processor.py:186} INFO - Started process (PID=4681) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:47:38.965+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:47:38.969+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:38.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:47:39.349+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:47:39.378+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:39.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:47:39.394+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:47:39.393+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:47:39.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.472 seconds
[2025-04-08T03:48:09.840+0000] {processor.py:186} INFO - Started process (PID=4750) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:48:09.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:48:09.844+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:09.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:48:10.124+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:48:10.159+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:10.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:48:10.190+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:10.189+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:48:10.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.397 seconds
[2025-04-08T03:48:40.314+0000] {processor.py:186} INFO - Started process (PID=4820) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:48:40.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:48:40.319+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:40.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:48:40.605+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:48:40.636+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:40.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:48:40.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:48:40.653+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:48:40.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.380 seconds
[2025-04-08T03:49:11.328+0000] {processor.py:186} INFO - Started process (PID=4888) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:49:11.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:49:11.333+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:11.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:49:11.669+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:49:11.709+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:11.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:49:11.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:11.727+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:49:11.765+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.447 seconds
[2025-04-08T03:49:42.307+0000] {processor.py:186} INFO - Started process (PID=4957) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:49:42.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:49:42.313+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:42.313+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:49:42.604+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:49:42.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:42.637+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:49:42.658+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:49:42.658+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:49:42.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T03:50:13.603+0000] {processor.py:186} INFO - Started process (PID=5026) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:50:13.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:50:13.607+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:13.606+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:50:13.889+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:50:13.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:13.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:50:13.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:13.951+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:50:13.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.393 seconds
[2025-04-08T03:50:44.172+0000] {processor.py:186} INFO - Started process (PID=5094) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:50:44.173+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:50:44.176+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:44.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:50:44.467+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:50:44.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:44.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:50:44.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:50:44.519+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:50:44.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.390 seconds
[2025-04-08T03:51:14.898+0000] {processor.py:186} INFO - Started process (PID=5163) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:51:14.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:51:14.902+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:14.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:51:15.181+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:51:15.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:15.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:51:15.226+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:15.225+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:51:15.257+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-08T03:51:46.055+0000] {processor.py:186} INFO - Started process (PID=5232) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:51:46.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:51:46.059+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:46.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:51:46.324+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:51:46.352+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:46.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:51:46.370+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:51:46.370+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:51:46.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-08T03:52:16.544+0000] {processor.py:186} INFO - Started process (PID=5301) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:52:16.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:52:16.548+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:16.548+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:52:16.790+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:52:16.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:16.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:52:16.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:16.832+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:52:17.039+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.504 seconds
[2025-04-08T03:52:47.828+0000] {processor.py:186} INFO - Started process (PID=5370) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:52:47.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:52:47.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:47.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:52:48.084+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:52:48.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:48.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:52:48.133+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:52:48.133+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:52:48.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-08T03:53:18.921+0000] {processor.py:186} INFO - Started process (PID=5439) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:53:18.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:53:18.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:18.926+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:53:19.225+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:53:19.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:19.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:53:19.312+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:19.312+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:53:19.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.448 seconds
[2025-04-08T03:53:50.162+0000] {processor.py:186} INFO - Started process (PID=5509) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:53:50.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:53:50.166+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:50.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:53:50.484+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:53:50.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:50.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:53:50.548+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:53:50.548+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:53:50.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.603 seconds
[2025-04-08T03:54:21.558+0000] {processor.py:186} INFO - Started process (PID=5580) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:54:21.561+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:54:21.565+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:21.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:54:21.847+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:54:21.880+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:21.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:54:22.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:22.089+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:54:22.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.585 seconds
[2025-04-08T03:54:52.369+0000] {processor.py:186} INFO - Started process (PID=5651) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:54:52.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:54:52.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:52.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:54:52.660+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:54:52.699+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:52.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:54:52.897+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:54:52.897+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:54:52.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.562 seconds
[2025-04-08T03:55:23.426+0000] {processor.py:186} INFO - Started process (PID=5722) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:55:23.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:55:23.431+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:23.431+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:55:23.744+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:55:23.782+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:23.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:55:23.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:23.970+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:55:23.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.582 seconds
[2025-04-08T03:55:54.174+0000] {processor.py:186} INFO - Started process (PID=5790) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:55:54.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:55:54.178+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:54.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:55:54.455+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:55:54.486+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:54.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:55:54.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:55:54.679+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:55:54.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.542 seconds
[2025-04-08T03:56:25.401+0000] {processor.py:186} INFO - Started process (PID=5858) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:56:25.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:56:25.407+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:25.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:56:25.696+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:56:25.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:25.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:56:25.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:25.927+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:56:25.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.570 seconds
[2025-04-08T03:56:56.737+0000] {processor.py:186} INFO - Started process (PID=5927) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:56:56.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:56:56.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:56.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:56:57.005+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:56:57.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:57.041+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:56:57.241+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:56:57.240+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:56:57.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.543 seconds
[2025-04-08T03:57:28.027+0000] {processor.py:186} INFO - Started process (PID=5996) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:57:28.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:57:28.031+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:28.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:57:28.311+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:57:28.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:28.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:57:28.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:28.535+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:57:28.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.548 seconds
[2025-04-08T03:57:59.344+0000] {processor.py:186} INFO - Started process (PID=6065) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:57:59.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:57:59.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:59.348+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:57:59.717+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:57:59.750+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:59.749+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:57:59.960+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:57:59.960+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:57:59.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.653 seconds
[2025-04-08T03:58:30.089+0000] {processor.py:186} INFO - Started process (PID=6135) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:58:30.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:58:30.094+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:30.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:58:30.340+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:58:30.372+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:30.371+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:58:30.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:58:30.544+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:58:30.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.491 seconds
[2025-04-08T03:59:01.049+0000] {processor.py:186} INFO - Started process (PID=6203) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:59:01.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:59:01.061+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:01.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:59:01.896+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:59:01.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:01.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:59:01.965+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:01.965+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:59:02.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.969 seconds
[2025-04-08T03:59:32.837+0000] {processor.py:186} INFO - Started process (PID=6273) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:59:32.838+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T03:59:32.841+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:32.840+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:59:33.286+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T03:59:33.318+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:33.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T03:59:33.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T03:59:33.338+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T03:59:33.368+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.538 seconds
[2025-04-08T04:00:03.745+0000] {processor.py:186} INFO - Started process (PID=6342) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:00:03.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:00:03.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:03.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:00:04.219+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:00:04.245+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:04.244+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:00:04.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:04.259+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:00:04.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.552 seconds
[2025-04-08T04:00:34.416+0000] {processor.py:186} INFO - Started process (PID=6411) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:00:34.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:00:34.420+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:34.420+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:00:34.909+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:00:34.988+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:34.987+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:00:35.013+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:00:35.013+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:00:35.037+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.629 seconds
[2025-04-08T04:01:05.718+0000] {processor.py:186} INFO - Started process (PID=6486) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:01:05.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:01:05.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:05.721+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:01:06.208+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:01:06.241+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:06.240+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:01:06.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:06.256+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:01:06.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.580 seconds
[2025-04-08T04:01:36.734+0000] {processor.py:186} INFO - Started process (PID=6555) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:01:36.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:01:36.739+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:36.738+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:01:37.176+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:01:37.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:37.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:01:37.220+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:01:37.220+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:01:37.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.529 seconds
[2025-04-08T04:02:07.355+0000] {processor.py:186} INFO - Started process (PID=6624) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:02:07.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:02:07.360+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:07.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:02:07.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:02:07.756+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:07.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:02:07.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:07.786+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:02:07.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.485 seconds
[2025-04-08T04:02:38.554+0000] {processor.py:186} INFO - Started process (PID=6702) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:02:38.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:02:38.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:38.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:02:39.353+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:02:39.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:39.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:02:39.506+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:02:39.506+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:02:39.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.079 seconds
[2025-04-08T04:03:52.477+0000] {processor.py:186} INFO - Started process (PID=6766) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:03:52.479+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:03:52.488+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:52.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:03:56.011+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:03:56.077+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:56.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:03:56.116+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:03:56.116+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:03:56.484+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 4.028 seconds
[2025-04-08T04:04:26.691+0000] {processor.py:186} INFO - Started process (PID=6835) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:04:26.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:04:26.697+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:26.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:04:27.352+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:04:27.433+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:27.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:04:27.473+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:27.473+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:04:27.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.859 seconds
[2025-04-08T04:04:57.755+0000] {processor.py:186} INFO - Started process (PID=6903) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:04:57.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:04:57.762+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:57.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:04:58.236+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:04:58.285+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:58.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:04:58.319+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:04:58.319+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:04:58.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.627 seconds
[2025-04-08T04:05:29.189+0000] {processor.py:186} INFO - Started process (PID=6972) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:05:29.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:05:29.195+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:29.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:05:29.633+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:05:29.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:29.763+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:05:29.803+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:05:29.803+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:05:31.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.955 seconds
[2025-04-08T04:06:01.336+0000] {processor.py:186} INFO - Started process (PID=7041) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:06:01.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:06:01.345+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:01.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:06:01.762+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:06:01.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:01.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:06:01.851+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:01.851+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:06:02.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.125 seconds
[2025-04-08T04:06:32.669+0000] {processor.py:186} INFO - Started process (PID=7110) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:06:32.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:06:32.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:32.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:06:32.898+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:06:32.924+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:32.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:06:32.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:06:32.939+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:06:32.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.307 seconds
[2025-04-08T04:07:03.392+0000] {processor.py:186} INFO - Started process (PID=7179) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:07:03.393+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:07:03.396+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:03.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:07:03.642+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:07:03.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:03.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:07:03.687+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:03.687+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:07:03.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T04:07:34.044+0000] {processor.py:186} INFO - Started process (PID=7247) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:07:34.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:07:34.048+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:34.048+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:07:34.306+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:07:34.335+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:34.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:07:34.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:07:34.351+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:07:34.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T04:08:04.759+0000] {processor.py:186} INFO - Started process (PID=7316) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:08:04.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:08:04.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:04.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:08:05.031+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:08:05.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:05.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:08:05.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:05.080+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:08:05.114+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T04:08:35.565+0000] {processor.py:186} INFO - Started process (PID=7385) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:08:35.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:08:35.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:35.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:08:35.805+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:08:35.835+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:35.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:08:35.850+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:08:35.849+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:08:35.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.317 seconds
[2025-04-08T04:09:06.289+0000] {processor.py:186} INFO - Started process (PID=7454) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:09:06.290+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:09:06.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:06.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:09:06.590+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:09:06.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:06.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:09:06.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:06.641+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:09:06.673+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.393 seconds
[2025-04-08T04:09:36.899+0000] {processor.py:186} INFO - Started process (PID=7523) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:09:36.900+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:09:36.903+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:36.903+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:09:37.152+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:09:37.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:37.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:09:37.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:09:37.194+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:09:37.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T04:10:07.332+0000] {processor.py:186} INFO - Started process (PID=7592) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:10:07.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:10:07.336+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:07.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:10:07.633+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:10:07.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:07.662+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:10:07.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:07.679+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:10:07.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-08T04:10:38.354+0000] {processor.py:186} INFO - Started process (PID=7661) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:10:38.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:10:38.359+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:38.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:10:38.579+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:10:38.604+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:38.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:10:38.619+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:10:38.619+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:10:38.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.302 seconds
[2025-04-08T04:11:09.099+0000] {processor.py:186} INFO - Started process (PID=7729) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:11:09.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:11:09.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:09.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:11:09.339+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:11:09.369+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:09.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:11:09.384+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:09.383+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:11:09.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-08T04:11:39.551+0000] {processor.py:186} INFO - Started process (PID=7799) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:11:39.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:11:39.555+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:39.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:11:39.777+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:11:39.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:39.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:11:39.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:11:39.818+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:11:39.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.303 seconds
[2025-04-08T04:12:10.241+0000] {processor.py:186} INFO - Started process (PID=7866) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:12:10.243+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:12:10.247+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:10.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:12:10.500+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:12:10.528+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:10.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:12:10.543+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:10.543+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:12:10.574+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T04:12:41.011+0000] {processor.py:186} INFO - Started process (PID=7935) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:12:41.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:12:41.015+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:12:41.279+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:12:41.306+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.306+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:12:41.322+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:12:41.321+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:12:41.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T04:13:12.350+0000] {processor.py:186} INFO - Started process (PID=8011) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:13:12.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:13:12.356+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:13:12.618+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:13:12.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:13:12.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:12.670+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:13:12.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-08T04:13:42.806+0000] {processor.py:186} INFO - Started process (PID=8081) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:13:42.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:13:42.810+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:42.810+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:13:43.034+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:13:43.060+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:43.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:13:43.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:13:43.074+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:13:43.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.305 seconds
[2025-04-08T04:14:14.086+0000] {processor.py:186} INFO - Started process (PID=8150) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:14:14.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:14:14.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:14.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:14:14.314+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:14:14.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:14.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:14:14.354+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:14.353+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:14:14.381+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.302 seconds
[2025-04-08T04:14:45.334+0000] {processor.py:186} INFO - Started process (PID=8219) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:14:45.336+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:14:45.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:45.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:14:45.566+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:14:45.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:45.592+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:14:45.608+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:14:45.607+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:14:45.636+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.309 seconds
[2025-04-08T04:15:15.733+0000] {processor.py:186} INFO - Started process (PID=8288) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:15:15.735+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:15:15.738+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:15.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:15:15.970+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:15:15.996+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:15.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:15:16.012+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:16.011+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:15:16.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.313 seconds
[2025-04-08T04:15:46.095+0000] {processor.py:186} INFO - Started process (PID=8357) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:15:46.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:15:46.100+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:46.099+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:15:46.336+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:15:46.365+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:46.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:15:46.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:15:46.380+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:15:46.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.322 seconds
[2025-04-08T04:16:17.317+0000] {processor.py:186} INFO - Started process (PID=8426) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:16:17.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:16:17.322+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:17.322+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:16:17.559+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:16:17.589+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:17.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:16:17.604+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:17.603+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:16:17.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.325 seconds
[2025-04-08T04:16:48.052+0000] {processor.py:186} INFO - Started process (PID=8495) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:16:48.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:16:48.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:48.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:16:48.305+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:16:48.338+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:48.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:16:48.355+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:16:48.355+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:16:48.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T04:17:18.869+0000] {processor.py:186} INFO - Started process (PID=8564) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:17:18.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:17:18.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:18.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:17:19.146+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:17:19.181+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:19.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:17:19.197+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:19.197+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:17:19.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-08T04:17:50.076+0000] {processor.py:186} INFO - Started process (PID=8633) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:17:50.077+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:17:50.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:50.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:17:50.317+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:17:50.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:50.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:17:50.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:17:50.362+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:17:50.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-08T04:18:20.632+0000] {processor.py:186} INFO - Started process (PID=8702) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:18:20.633+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:18:20.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:20.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:18:20.900+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:18:20.929+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:20.929+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:18:20.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:20.944+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:18:20.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T04:18:51.449+0000] {processor.py:186} INFO - Started process (PID=8771) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:18:51.451+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:18:51.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:51.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:18:51.699+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:18:51.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:51.727+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:18:51.743+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:18:51.743+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:18:51.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:19:22.289+0000] {processor.py:186} INFO - Started process (PID=8840) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:19:22.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:19:22.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:22.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:19:22.544+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:19:22.574+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:22.574+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:19:22.589+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:22.589+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:19:22.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T04:19:53.051+0000] {processor.py:186} INFO - Started process (PID=8909) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:19:53.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:19:53.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:53.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:19:53.296+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:19:53.325+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:53.324+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:19:53.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:19:53.339+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:19:53.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.325 seconds
[2025-04-08T04:20:23.453+0000] {processor.py:186} INFO - Started process (PID=8978) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:20:23.454+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:20:23.457+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:23.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:20:23.699+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:20:23.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:23.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:20:23.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:23.742+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:20:23.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T04:20:54.147+0000] {processor.py:186} INFO - Started process (PID=9046) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:20:54.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:20:54.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:54.151+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:20:54.394+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:20:54.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:54.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:20:54.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:20:54.438+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:20:54.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:21:24.828+0000] {processor.py:186} INFO - Started process (PID=9114) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:21:24.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:21:24.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:24.831+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:21:25.071+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:21:25.102+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:25.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:21:25.117+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:25.117+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:21:25.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T04:21:56.044+0000] {processor.py:186} INFO - Started process (PID=9184) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:21:56.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:21:56.050+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:56.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:21:56.313+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:21:56.342+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:56.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:21:56.359+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:21:56.359+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:21:56.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.549 seconds
[2025-04-08T04:22:27.228+0000] {processor.py:186} INFO - Started process (PID=9253) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:22:27.230+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:22:27.233+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:27.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:22:27.490+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:22:27.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:27.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:22:27.700+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:27.700+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:22:27.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.506 seconds
[2025-04-08T04:22:58.258+0000] {processor.py:186} INFO - Started process (PID=9323) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:22:58.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:22:58.262+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:58.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:22:58.512+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:22:58.678+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:58.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:22:58.694+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:22:58.693+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:22:58.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.474 seconds
[2025-04-08T04:23:28.905+0000] {processor.py:186} INFO - Started process (PID=9394) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:23:28.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:23:28.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:28.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:23:29.325+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:23:29.355+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:29.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:23:29.370+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:23:29.370+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:23:29.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.506 seconds
[2025-04-08T04:24:00.010+0000] {processor.py:186} INFO - Started process (PID=9462) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:24:00.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:24:00.016+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:00.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:24:00.410+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:24:00.437+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:00.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:24:00.452+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:00.451+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:24:00.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.472 seconds
[2025-04-08T04:24:31.330+0000] {processor.py:186} INFO - Started process (PID=9531) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:24:31.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:24:31.335+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:31.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:24:31.748+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:24:31.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:31.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:24:31.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:24:31.786+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:24:31.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.492 seconds
[2025-04-08T04:25:02.046+0000] {processor.py:186} INFO - Started process (PID=9600) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:25:02.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:25:02.050+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:02.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:25:02.505+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:25:02.538+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:02.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:25:02.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:02.553+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:25:02.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.547 seconds
[2025-04-08T04:25:32.913+0000] {processor.py:186} INFO - Started process (PID=9669) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:25:32.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:25:32.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:32.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:25:33.332+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:25:33.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:33.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:25:33.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:25:33.371+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:25:33.400+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.494 seconds
[2025-04-08T04:26:03.607+0000] {processor.py:186} INFO - Started process (PID=9738) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:26:03.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:26:03.613+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:03.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:26:04.052+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:26:04.084+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:04.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:26:04.098+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:04.097+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:26:04.126+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.527 seconds
[2025-04-08T04:26:34.653+0000] {processor.py:186} INFO - Started process (PID=9807) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:26:34.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:26:34.658+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:34.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:26:35.048+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:26:35.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:35.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:26:35.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:26:35.089+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:26:35.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.472 seconds
[2025-04-08T04:27:05.782+0000] {processor.py:186} INFO - Started process (PID=9876) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:27:05.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:27:05.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:05.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:27:06.192+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:27:06.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:06.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:27:06.235+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:06.234+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:27:06.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-08T04:27:36.584+0000] {processor.py:186} INFO - Started process (PID=9945) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:27:36.585+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:27:36.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:36.588+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:27:36.997+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:27:37.024+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:37.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:27:37.037+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:27:37.037+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:27:37.070+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.493 seconds
[2025-04-08T04:28:07.894+0000] {processor.py:186} INFO - Started process (PID=10014) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:28:07.895+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:28:07.899+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:07.899+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:28:08.316+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:28:08.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:08.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:28:08.357+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:08.357+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:28:08.397+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.509 seconds
[2025-04-08T04:28:38.737+0000] {processor.py:186} INFO - Started process (PID=10083) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:28:38.738+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:28:38.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:38.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:28:39.137+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:28:39.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:39.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:28:39.176+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:28:39.176+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:28:39.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.477 seconds
[2025-04-08T04:29:09.265+0000] {processor.py:186} INFO - Started process (PID=10152) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:29:09.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:29:09.269+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:09.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:29:09.696+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:29:09.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:09.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:29:09.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:09.736+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:29:09.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.508 seconds
[2025-04-08T04:29:40.070+0000] {processor.py:186} INFO - Started process (PID=10221) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:29:40.071+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:29:40.073+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:40.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:29:40.327+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:29:40.357+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:40.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:29:40.372+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:29:40.371+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:29:40.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T04:30:10.823+0000] {processor.py:186} INFO - Started process (PID=10289) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:30:10.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:30:10.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:10.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:30:11.088+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:30:11.118+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:11.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:30:11.135+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:11.135+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:30:11.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T04:30:41.452+0000] {processor.py:186} INFO - Started process (PID=10358) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:30:41.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:30:41.457+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:41.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:30:41.704+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:30:41.732+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:41.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:30:41.747+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:30:41.747+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:30:41.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-08T04:31:12.052+0000] {processor.py:186} INFO - Started process (PID=10427) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:31:12.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:31:12.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:12.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:31:12.307+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:31:12.337+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:12.336+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:31:12.353+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:12.352+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:31:12.383+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T04:31:42.447+0000] {processor.py:186} INFO - Started process (PID=10496) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:31:42.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:31:42.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:42.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:31:42.692+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:31:42.721+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:42.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:31:42.740+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:31:42.740+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:31:42.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T04:32:13.756+0000] {processor.py:186} INFO - Started process (PID=10565) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:32:13.758+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:32:13.762+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:13.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:32:14.031+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:32:14.077+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:14.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:32:14.101+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:14.101+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:32:14.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-08T04:32:44.900+0000] {processor.py:186} INFO - Started process (PID=10639) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:32:44.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:32:44.905+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:44.904+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:32:45.150+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:32:45.180+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:45.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:32:45.195+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:32:45.195+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:32:45.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T04:33:15.667+0000] {processor.py:186} INFO - Started process (PID=10708) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:33:15.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:33:15.671+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:15.670+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:33:15.945+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:33:15.976+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:15.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:33:15.993+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:15.993+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:33:16.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-08T04:33:46.823+0000] {processor.py:186} INFO - Started process (PID=10777) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:33:46.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:33:46.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:46.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:33:47.072+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:33:47.101+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:47.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:33:47.116+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:33:47.116+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:33:47.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:34:17.275+0000] {processor.py:186} INFO - Started process (PID=10846) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:34:17.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:34:17.281+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:17.280+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:34:17.533+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:34:17.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:17.562+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:34:17.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:17.578+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:34:17.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T04:34:48.554+0000] {processor.py:186} INFO - Started process (PID=10915) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:34:48.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:34:48.558+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:48.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:34:48.792+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:34:48.822+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:48.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:34:48.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:34:48.838+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:34:48.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.321 seconds
[2025-04-08T04:35:19.287+0000] {processor.py:186} INFO - Started process (PID=10984) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:35:19.288+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:35:19.292+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:19.292+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:35:19.544+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:35:19.579+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:19.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:35:19.599+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:19.598+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:35:19.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T04:35:49.946+0000] {processor.py:186} INFO - Started process (PID=11053) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:35:49.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:35:49.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:49.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:35:50.210+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:35:50.239+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:50.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:35:50.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:35:50.255+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:35:50.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T04:36:20.641+0000] {processor.py:186} INFO - Started process (PID=11122) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:36:20.642+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:36:20.646+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:20.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:36:20.883+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:36:20.913+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:20.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:36:20.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:20.928+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:36:20.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T04:36:51.789+0000] {processor.py:186} INFO - Started process (PID=11191) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:36:51.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:36:51.795+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:51.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:36:52.056+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:36:52.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:52.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:36:52.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:36:52.107+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:36:52.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T04:37:22.225+0000] {processor.py:186} INFO - Started process (PID=11260) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:37:22.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:37:22.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:22.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:37:22.483+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:37:22.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:22.516+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:37:22.537+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:22.537+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:37:22.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T04:37:53.412+0000] {processor.py:186} INFO - Started process (PID=11329) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:37:53.413+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:37:53.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:53.417+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:37:53.660+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:37:53.689+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:53.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:37:53.705+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:37:53.705+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:37:53.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:38:23.902+0000] {processor.py:186} INFO - Started process (PID=11398) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:38:23.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:38:23.907+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:23.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:38:24.156+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:38:24.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:24.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:38:24.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:24.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:38:24.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T04:38:54.527+0000] {processor.py:186} INFO - Started process (PID=11467) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:38:54.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:38:54.531+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:54.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:38:54.777+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:38:54.808+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:54.808+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:38:54.824+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:38:54.824+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:38:54.854+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T04:39:25.808+0000] {processor.py:186} INFO - Started process (PID=11536) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:39:25.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:39:25.814+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:25.813+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:39:26.079+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:39:26.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:26.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:39:26.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:26.124+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:39:26.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T04:39:57.115+0000] {processor.py:186} INFO - Started process (PID=11605) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:39:57.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:39:57.121+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:57.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:39:57.377+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:39:57.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:57.407+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:39:57.423+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:39:57.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:39:57.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T04:40:28.102+0000] {processor.py:186} INFO - Started process (PID=11674) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:40:28.104+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:40:28.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:28.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:40:28.363+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:40:28.399+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:28.399+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:40:28.416+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:28.415+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:40:28.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-08T04:40:59.181+0000] {processor.py:186} INFO - Started process (PID=11743) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:40:59.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:40:59.186+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:59.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:40:59.439+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:40:59.470+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:59.469+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:40:59.487+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:40:59.487+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:40:59.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-08T04:41:30.144+0000] {processor.py:186} INFO - Started process (PID=11812) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:41:30.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:41:30.150+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:30.149+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:41:30.395+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:41:30.424+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:30.423+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:41:30.440+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:41:30.440+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:41:30.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-08T04:42:01.036+0000] {processor.py:186} INFO - Started process (PID=11881) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:42:01.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:42:01.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:01.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:42:01.345+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:42:01.393+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:01.392+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:42:01.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:01.421+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:42:01.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.431 seconds
[2025-04-08T04:42:32.338+0000] {processor.py:186} INFO - Started process (PID=11950) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:42:32.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:42:32.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:32.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:42:32.596+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:42:32.627+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:32.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:42:32.644+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:42:32.644+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:42:32.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T04:43:03.603+0000] {processor.py:186} INFO - Started process (PID=12019) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:43:03.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:43:03.610+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:03.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:43:03.859+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:43:03.887+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:03.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:43:03.906+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:03.906+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:43:03.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T04:43:34.564+0000] {processor.py:186} INFO - Started process (PID=12088) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:43:34.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:43:34.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:34.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:43:34.806+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:43:34.837+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:34.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:43:34.852+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:43:34.852+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:43:34.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T04:44:05.523+0000] {processor.py:186} INFO - Started process (PID=12158) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:44:05.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:44:05.527+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:05.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:44:05.775+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:44:05.806+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:05.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:44:05.824+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:05.823+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:44:05.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T04:44:35.930+0000] {processor.py:186} INFO - Started process (PID=12227) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:44:35.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:44:35.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:35.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:44:36.164+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:44:36.190+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:36.189+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:44:36.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:44:36.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:44:36.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.309 seconds
[2025-04-08T04:45:06.741+0000] {processor.py:186} INFO - Started process (PID=12296) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:45:06.742+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:45:06.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:06.745+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:45:06.983+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:45:07.012+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:07.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:45:07.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:07.027+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:45:07.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.325 seconds
[2025-04-08T04:45:37.268+0000] {processor.py:186} INFO - Started process (PID=12365) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:45:37.269+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:45:37.274+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:37.273+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:45:37.512+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:45:37.543+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:37.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:45:37.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:45:37.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:45:37.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T04:46:08.120+0000] {processor.py:186} INFO - Started process (PID=12434) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:46:08.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:46:08.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:08.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:46:08.363+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:46:08.393+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:08.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:46:08.408+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:08.408+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:46:08.437+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T04:46:39.431+0000] {processor.py:186} INFO - Started process (PID=12503) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:46:39.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:46:39.437+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:39.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:46:39.681+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:46:39.709+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:39.709+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:46:39.725+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:46:39.724+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:46:39.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:47:10.383+0000] {processor.py:186} INFO - Started process (PID=12572) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:47:10.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:47:10.388+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:10.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:47:10.664+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:47:10.694+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:10.693+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:47:10.711+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:10.710+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:47:10.740+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-08T04:47:41.452+0000] {processor.py:186} INFO - Started process (PID=12641) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:47:41.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:47:41.456+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:41.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:47:41.705+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:47:41.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:41.736+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:47:41.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:47:41.753+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:47:41.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T04:48:12.766+0000] {processor.py:186} INFO - Started process (PID=12710) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:48:12.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:48:12.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:12.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:48:13.025+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:48:13.054+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:13.054+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:48:13.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:13.069+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:48:13.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T04:48:43.796+0000] {processor.py:186} INFO - Started process (PID=12779) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:48:43.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:48:43.802+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:43.801+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:48:44.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:48:44.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:44.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:48:44.097+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:48:44.097+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:48:44.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T04:49:14.916+0000] {processor.py:186} INFO - Started process (PID=12848) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:49:14.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:49:14.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:14.920+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:49:15.170+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:49:15.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:15.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:49:15.219+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:15.219+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:49:15.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T04:49:45.763+0000] {processor.py:186} INFO - Started process (PID=12917) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:49:45.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:49:45.768+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:45.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:49:46.018+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:49:46.046+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:46.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:49:46.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:49:46.063+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:49:46.096+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T04:50:16.417+0000] {processor.py:186} INFO - Started process (PID=12987) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:50:16.419+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:50:16.424+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:16.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:50:16.711+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:50:16.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:16.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:50:16.768+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:16.768+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:50:16.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.400 seconds
[2025-04-08T04:50:47.239+0000] {processor.py:186} INFO - Started process (PID=13061) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:50:47.241+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:50:47.245+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:47.245+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:50:47.493+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:50:47.524+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:47.523+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:50:47.539+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:50:47.538+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:50:47.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T04:51:18.493+0000] {processor.py:186} INFO - Started process (PID=13130) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:51:18.494+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:51:18.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:18.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:51:18.739+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:51:18.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:18.769+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:51:18.785+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:18.785+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:51:18.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:51:49.374+0000] {processor.py:186} INFO - Started process (PID=13199) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:51:49.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:51:49.379+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:49.379+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:51:49.622+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:51:49.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:49.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:51:49.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:51:49.667+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:51:49.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T04:52:20.135+0000] {processor.py:186} INFO - Started process (PID=13268) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:52:20.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:52:20.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:20.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:52:20.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:52:20.579+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:20.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:52:20.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:20.593+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:52:20.621+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.493 seconds
[2025-04-08T04:52:51.561+0000] {processor.py:186} INFO - Started process (PID=13337) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:52:51.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:52:51.566+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:51.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:52:51.814+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:52:51.843+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:51.842+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:52:52.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:52:52.004+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:52:52.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.478 seconds
[2025-04-08T04:53:22.836+0000] {processor.py:186} INFO - Started process (PID=13406) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:53:22.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:53:22.841+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:22.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:53:23.075+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:53:23.105+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:23.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:53:23.273+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:23.273+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:53:23.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.474 seconds
[2025-04-08T04:53:54.369+0000] {processor.py:186} INFO - Started process (PID=13476) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:53:54.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:53:54.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:54.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:53:54.788+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:53:54.813+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:54.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:53:54.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:53:54.827+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:53:54.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T04:54:25.832+0000] {processor.py:186} INFO - Started process (PID=13545) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:54:25.834+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:54:25.837+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:25.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:54:26.309+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:54:26.333+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:26.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:54:26.346+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:26.346+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:54:26.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.555 seconds
[2025-04-08T04:54:57.208+0000] {processor.py:186} INFO - Started process (PID=13614) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:54:57.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:54:57.213+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:57.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:54:57.626+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:54:57.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:57.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:54:57.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:54:57.664+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:54:57.694+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.493 seconds
[2025-04-08T04:55:28.482+0000] {processor.py:186} INFO - Started process (PID=13683) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:55:28.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:55:28.487+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:28.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:55:28.779+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:55:28.813+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:28.813+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:55:28.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:28.830+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:55:28.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.387 seconds
[2025-04-08T04:55:59.427+0000] {processor.py:186} INFO - Started process (PID=13752) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:55:59.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:55:59.432+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:59.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:55:59.699+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:55:59.726+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:59.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:55:59.742+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:55:59.742+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:55:59.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T04:56:31.174+0000] {processor.py:186} INFO - Started process (PID=13821) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:56:31.175+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:56:31.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:31.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:56:31.438+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:56:31.465+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:31.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:56:31.480+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:56:31.480+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:56:31.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T04:57:01.636+0000] {processor.py:186} INFO - Started process (PID=13890) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:57:01.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:57:01.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:01.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:57:01.943+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:57:01.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:01.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:57:01.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:01.998+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:57:02.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.400 seconds
[2025-04-08T04:57:32.912+0000] {processor.py:186} INFO - Started process (PID=13959) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:57:32.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:57:32.918+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:32.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:57:33.156+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:57:33.185+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:33.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:57:33.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:57:33.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:57:33.235+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T04:58:03.940+0000] {processor.py:186} INFO - Started process (PID=14028) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:58:03.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:58:03.945+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:03.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:58:04.198+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:58:04.227+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:04.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:58:04.244+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:04.244+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:58:04.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-08T04:58:34.842+0000] {processor.py:186} INFO - Started process (PID=14097) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:58:34.844+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:58:34.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:34.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:58:35.085+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:58:35.115+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:35.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:58:35.130+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:58:35.129+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:58:35.161+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.325 seconds
[2025-04-08T04:59:05.522+0000] {processor.py:186} INFO - Started process (PID=14166) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:59:05.523+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:59:05.527+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:05.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:59:05.804+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:59:05.834+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:05.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:59:05.850+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:05.850+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:59:05.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T04:59:36.619+0000] {processor.py:186} INFO - Started process (PID=14235) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:59:36.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T04:59:36.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:36.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:59:36.874+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T04:59:36.902+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:36.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T04:59:36.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T04:59:36.917+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T04:59:36.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T05:00:07.258+0000] {processor.py:186} INFO - Started process (PID=14304) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:00:07.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:00:07.262+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:07.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:00:07.515+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:00:07.543+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:07.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:00:07.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:07.560+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:00:07.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T05:00:38.231+0000] {processor.py:186} INFO - Started process (PID=14373) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:00:38.232+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:00:38.237+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:38.236+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:00:38.480+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:00:38.509+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:38.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:00:38.524+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:00:38.523+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:00:38.553+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T05:01:08.954+0000] {processor.py:186} INFO - Started process (PID=14442) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:01:08.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:01:08.960+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:08.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:01:09.211+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:01:09.243+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:09.243+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:01:09.262+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:09.261+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:01:09.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T05:01:39.493+0000] {processor.py:186} INFO - Started process (PID=14511) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:01:39.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:01:39.498+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:39.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:01:39.758+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:01:39.790+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:39.789+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:01:39.805+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:01:39.805+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:01:39.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T05:02:10.793+0000] {processor.py:186} INFO - Started process (PID=14580) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:02:10.794+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:02:10.798+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:10.797+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:02:11.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:02:11.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:11.081+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:02:11.097+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:11.096+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:02:11.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T05:02:41.648+0000] {processor.py:186} INFO - Started process (PID=14649) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:02:41.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:02:41.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:41.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:02:41.910+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:02:41.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:41.939+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:02:41.959+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:02:41.958+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:02:41.989+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T05:03:12.218+0000] {processor.py:186} INFO - Started process (PID=14718) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:03:12.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:03:12.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:12.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:03:12.481+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:03:12.510+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:12.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:03:12.525+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:12.525+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:03:12.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T05:03:43.257+0000] {processor.py:186} INFO - Started process (PID=14787) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:03:43.258+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:03:43.263+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:43.262+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:03:43.547+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:03:43.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:43.576+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:03:43.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:03:43.601+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:03:43.632+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-08T05:04:14.334+0000] {processor.py:186} INFO - Started process (PID=14856) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:04:14.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:04:14.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:14.339+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:04:14.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:04:14.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:14.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:04:14.629+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:14.629+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:04:14.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T05:04:45.379+0000] {processor.py:186} INFO - Started process (PID=14925) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:04:45.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:04:45.384+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:45.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:04:45.640+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:04:45.669+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:45.668+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:04:45.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:04:45.684+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:04:45.715+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T05:05:16.312+0000] {processor.py:186} INFO - Started process (PID=14994) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:05:16.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:05:16.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:16.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:05:16.597+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:05:16.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:16.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:05:16.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:16.641+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:05:16.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.384 seconds
[2025-04-08T05:05:46.829+0000] {processor.py:186} INFO - Started process (PID=15063) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:05:46.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:05:46.834+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:46.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:05:47.079+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:05:47.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:47.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:05:47.123+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:05:47.123+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:05:47.153+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T05:06:17.434+0000] {processor.py:186} INFO - Started process (PID=15132) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:06:17.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:06:17.439+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:17.438+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:06:17.686+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:06:17.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:17.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:06:17.734+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:17.734+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:06:17.767+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T05:06:48.031+0000] {processor.py:186} INFO - Started process (PID=15201) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:06:48.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:06:48.036+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:06:48.282+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:06:48.312+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:06:48.329+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:06:48.329+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:06:48.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-08T05:07:18.491+0000] {processor.py:186} INFO - Started process (PID=15270) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:07:18.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:07:18.496+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:18.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:07:18.772+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:07:18.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:18.803+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:07:18.823+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:18.822+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:07:18.850+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-08T05:07:49.775+0000] {processor.py:186} INFO - Started process (PID=15345) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:07:49.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:07:49.780+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:49.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:07:50.036+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:07:50.066+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:50.065+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:07:50.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:07:50.082+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:07:50.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T05:08:20.499+0000] {processor.py:186} INFO - Started process (PID=15414) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:08:20.500+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:08:20.504+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:20.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:08:20.764+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:08:20.794+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:20.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:08:20.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:20.814+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:08:20.846+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T05:08:51.650+0000] {processor.py:186} INFO - Started process (PID=15483) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:08:51.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:08:51.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:51.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:08:51.896+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:08:51.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:51.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:08:51.943+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:08:51.943+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:08:51.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T05:09:22.730+0000] {processor.py:186} INFO - Started process (PID=15552) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:09:22.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:09:22.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:22.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:09:22.995+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:09:23.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:23.025+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:09:23.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:23.040+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:09:23.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T05:09:53.729+0000] {processor.py:186} INFO - Started process (PID=15621) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:09:53.730+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:09:53.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:53.733+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:09:54.062+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:09:54.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:54.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:09:54.105+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:09:54.105+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:09:54.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.408 seconds
[2025-04-08T05:10:24.530+0000] {processor.py:186} INFO - Started process (PID=15690) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:10:24.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:10:24.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:24.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:10:24.789+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:10:24.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:24.817+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:10:24.835+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:24.835+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:10:24.865+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T05:10:55.451+0000] {processor.py:186} INFO - Started process (PID=15759) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:10:55.452+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:10:55.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:55.455+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:10:55.692+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:10:55.723+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:55.723+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:10:55.740+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:10:55.740+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:10:55.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T05:11:25.950+0000] {processor.py:186} INFO - Started process (PID=15828) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:11:25.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:11:25.955+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:25.955+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:11:26.193+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:11:26.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:26.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:11:26.236+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:26.236+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:11:26.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-08T05:11:56.931+0000] {processor.py:186} INFO - Started process (PID=15897) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:11:56.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:11:56.936+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:56.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:11:57.177+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:11:57.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:57.206+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:11:57.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:11:57.221+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:11:57.251+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T05:12:27.822+0000] {processor.py:186} INFO - Started process (PID=15966) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:12:27.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:12:27.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:27.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:12:28.081+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:12:28.110+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:28.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:12:28.128+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:28.127+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:12:28.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T05:12:58.394+0000] {processor.py:186} INFO - Started process (PID=16035) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:12:58.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:12:58.400+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:58.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:12:58.637+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:12:58.666+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:58.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:12:58.682+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:12:58.681+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:12:58.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.328 seconds
[2025-04-08T05:13:28.849+0000] {processor.py:186} INFO - Started process (PID=16104) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:13:28.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:13:28.854+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:28.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:13:29.090+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:13:29.117+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:29.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:13:29.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:29.132+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:13:29.162+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.320 seconds
[2025-04-08T05:13:59.829+0000] {processor.py:186} INFO - Started process (PID=16173) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:13:59.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:13:59.835+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:13:59.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:14:00.084+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:14:00.119+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:00.118+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:14:00.140+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:00.140+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:14:00.169+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T05:14:30.899+0000] {processor.py:186} INFO - Started process (PID=16242) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:14:30.901+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:14:30.905+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:30.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:14:31.154+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:14:31.186+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:31.186+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:14:31.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:14:31.202+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:14:31.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T05:15:01.921+0000] {processor.py:186} INFO - Started process (PID=16311) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:15:01.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:15:01.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:01.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:15:02.191+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:15:02.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:02.221+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:15:02.237+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:02.237+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:15:02.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T05:15:32.984+0000] {processor.py:186} INFO - Started process (PID=16380) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:15:32.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:15:32.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:32.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:15:33.238+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:15:33.444+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:33.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:15:33.458+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:15:33.458+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:15:33.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.505 seconds
[2025-04-08T05:16:03.974+0000] {processor.py:186} INFO - Started process (PID=16449) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:16:03.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:16:03.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:03.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:16:04.403+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:16:04.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:04.429+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:16:04.443+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:04.443+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:16:04.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.504 seconds
[2025-04-08T05:16:35.080+0000] {processor.py:186} INFO - Started process (PID=16518) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:16:35.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:16:35.087+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:16:35.544+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:16:35.569+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:16:35.583+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:16:35.583+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:16:35.614+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.540 seconds
[2025-04-08T05:17:06.115+0000] {processor.py:186} INFO - Started process (PID=16587) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:17:06.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:17:06.120+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.119+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:17:06.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:17:06.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:17:06.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:06.590+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:17:06.617+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.509 seconds
[2025-04-08T05:17:36.752+0000] {processor.py:186} INFO - Started process (PID=16656) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:17:36.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:17:36.757+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:36.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:17:36.999+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:17:37.028+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:37.028+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:17:37.044+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:17:37.044+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:17:37.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T05:18:07.628+0000] {processor.py:186} INFO - Started process (PID=16725) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:18:07.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:18:07.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:07.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:18:07.874+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:18:07.904+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:07.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:18:07.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:07.920+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:18:07.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T05:18:38.023+0000] {processor.py:186} INFO - Started process (PID=16794) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:18:38.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:18:38.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:18:38.251+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:18:38.277+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:18:38.291+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:18:38.291+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:18:38.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.301 seconds
[2025-04-08T05:19:08.433+0000] {processor.py:186} INFO - Started process (PID=16861) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:19:08.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:19:08.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:08.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:19:08.844+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:19:08.870+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:08.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:19:08.883+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:08.883+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:19:08.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.485 seconds
[2025-04-08T05:19:39.355+0000] {processor.py:186} INFO - Started process (PID=16930) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:19:39.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:19:39.359+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:39.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:19:39.770+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:19:39.796+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:39.795+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:19:39.809+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:19:39.808+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:19:39.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.490 seconds
[2025-04-08T05:20:10.365+0000] {processor.py:186} INFO - Started process (PID=16999) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:20:10.367+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:20:10.370+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:10.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:20:10.614+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:20:10.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:10.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:20:10.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:10.656+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:20:10.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T05:20:41.657+0000] {processor.py:186} INFO - Started process (PID=17069) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:20:41.658+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:20:41.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:41.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:20:42.075+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:20:42.100+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:42.099+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:20:42.114+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:20:42.114+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:20:42.145+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T05:21:12.627+0000] {processor.py:186} INFO - Started process (PID=17139) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:21:12.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:21:12.632+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:12.632+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:21:13.060+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:21:13.091+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:13.090+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:21:13.105+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:13.104+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:21:13.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.517 seconds
[2025-04-08T05:21:43.667+0000] {processor.py:186} INFO - Started process (PID=17208) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:21:43.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:21:43.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:43.672+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:21:44.092+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:21:44.120+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:44.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:21:44.138+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:21:44.138+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:21:44.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.507 seconds
[2025-04-08T05:22:14.253+0000] {processor.py:186} INFO - Started process (PID=17277) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:22:14.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:22:14.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:14.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:22:14.668+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:22:14.701+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:14.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:22:14.715+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:14.714+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:22:14.739+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.492 seconds
[2025-04-08T05:22:44.937+0000] {processor.py:186} INFO - Started process (PID=17345) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:22:44.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:22:44.943+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:44.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:22:45.356+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:22:45.383+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:45.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:22:45.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:22:45.397+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:22:45.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.499 seconds
[2025-04-08T05:23:15.888+0000] {processor.py:186} INFO - Started process (PID=17414) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:23:15.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:23:15.893+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:15.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:23:16.377+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:23:16.409+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:16.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:23:16.424+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:16.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:23:16.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.575 seconds
[2025-04-08T05:23:46.657+0000] {processor.py:186} INFO - Started process (PID=17483) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:23:46.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:23:46.662+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:46.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:23:46.954+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:23:46.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:46.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:23:47.009+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:23:47.008+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:23:47.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T05:24:17.108+0000] {processor.py:186} INFO - Started process (PID=17552) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:24:17.109+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:24:17.112+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:17.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:24:17.421+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:24:17.456+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:17.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:24:17.480+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:17.479+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:24:17.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-08T05:24:47.580+0000] {processor.py:186} INFO - Started process (PID=17620) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:24:47.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:24:47.584+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:47.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:24:47.899+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:24:47.932+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:47.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:24:47.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:24:47.951+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:24:47.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.416 seconds
[2025-04-08T05:25:18.770+0000] {processor.py:186} INFO - Started process (PID=17689) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:25:18.772+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:25:18.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:18.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:25:19.087+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:25:19.117+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:19.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:25:19.136+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:19.136+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:25:19.170+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.407 seconds
[2025-04-08T05:25:50.057+0000] {processor.py:186} INFO - Started process (PID=17758) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:25:50.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:25:50.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:50.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:25:50.382+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:25:50.422+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:50.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:25:50.442+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:25:50.442+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:25:50.472+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.424 seconds
[2025-04-08T05:26:20.622+0000] {processor.py:186} INFO - Started process (PID=17827) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:26:20.624+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:26:20.627+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:20.627+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:26:20.921+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:26:20.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:20.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:26:20.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:20.984+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:26:21.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.415 seconds
[2025-04-08T05:26:51.853+0000] {processor.py:186} INFO - Started process (PID=17902) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:26:51.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:26:51.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:51.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:26:52.166+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:26:52.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:52.203+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:26:52.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:26:52.229+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:26:52.264+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.420 seconds
[2025-04-08T05:27:23.144+0000] {processor.py:186} INFO - Started process (PID=17971) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:27:23.146+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:27:23.155+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:23.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:27:23.460+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:27:23.494+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:23.494+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:27:23.522+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:23.522+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:27:23.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.425 seconds
[2025-04-08T05:27:53.722+0000] {processor.py:186} INFO - Started process (PID=18041) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:27:53.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:27:53.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:53.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:27:54.039+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:27:54.072+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:54.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:27:54.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:27:54.089+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:27:54.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.410 seconds
[2025-04-08T05:28:24.368+0000] {processor.py:186} INFO - Started process (PID=18110) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:28:24.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:28:24.373+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:24.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:28:24.673+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:28:24.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:24.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:28:24.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:24.733+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:28:24.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-08T05:28:55.222+0000] {processor.py:186} INFO - Started process (PID=18179) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:28:55.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:28:55.227+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:28:55.579+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:28:55.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:28:55.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:28:55.633+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:28:55.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.453 seconds
[2025-04-08T05:29:25.840+0000] {processor.py:186} INFO - Started process (PID=18248) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:29:25.841+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:29:25.847+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:25.846+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:29:26.154+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:29:26.186+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:26.185+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:29:26.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:26.203+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:29:26.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-08T05:29:56.603+0000] {processor.py:186} INFO - Started process (PID=18317) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:29:56.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:29:56.609+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:56.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:29:56.911+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:29:56.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:56.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:29:56.966+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:29:56.965+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:29:57.001+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.407 seconds
[2025-04-08T05:30:27.289+0000] {processor.py:186} INFO - Started process (PID=18386) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:30:27.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:30:27.294+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.293+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:30:27.576+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:30:27.608+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:30:27.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:27.625+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:30:27.658+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-08T05:30:58.035+0000] {processor.py:186} INFO - Started process (PID=18455) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:30:58.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:30:58.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:30:58.306+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:30:58.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.338+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:30:58.356+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:30:58.355+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:30:58.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-08T05:31:28.666+0000] {processor.py:186} INFO - Started process (PID=18524) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:31:28.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:31:28.672+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:28.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:31:28.950+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:31:28.988+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:28.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:31:29.012+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:29.012+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:31:29.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.388 seconds
[2025-04-08T05:31:59.223+0000] {processor.py:186} INFO - Started process (PID=18593) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:31:59.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:31:59.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:31:59.530+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:31:59.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:31:59.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:31:59.593+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:31:59.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.416 seconds
[2025-04-08T05:32:30.677+0000] {processor.py:186} INFO - Started process (PID=18662) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:32:30.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:32:30.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:30.683+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:32:30.965+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:32:30.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:30.997+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:32:31.017+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:32:31.017+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:32:31.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.380 seconds
[2025-04-08T05:33:01.992+0000] {processor.py:186} INFO - Started process (PID=18731) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:33:01.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:33:01.996+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:01.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:33:02.270+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:33:02.303+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:02.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:33:02.319+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:02.319+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:33:02.347+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-08T05:33:32.910+0000] {processor.py:186} INFO - Started process (PID=18800) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:33:32.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:33:32.916+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:32.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:33:33.245+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:33:33.286+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:33.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:33:33.308+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:33:33.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:33:33.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.470 seconds
[2025-04-08T05:34:03.825+0000] {processor.py:186} INFO - Started process (PID=18869) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:34:03.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:34:03.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:03.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:34:04.126+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:34:04.162+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:04.161+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:34:04.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:04.183+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:34:04.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.405 seconds
[2025-04-08T05:34:35.087+0000] {processor.py:186} INFO - Started process (PID=18938) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:34:35.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:34:35.093+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:34:35.394+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:34:35.427+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:34:35.444+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:34:35.444+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:34:35.477+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.397 seconds
[2025-04-08T05:35:05.802+0000] {processor.py:186} INFO - Started process (PID=19008) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:35:05.803+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:35:05.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:05.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:35:06.101+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:35:06.135+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:06.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:35:06.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:06.152+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:35:06.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T05:35:37.100+0000] {processor.py:186} INFO - Started process (PID=19077) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:35:37.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:35:37.106+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:37.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:35:37.393+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:35:37.428+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:37.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:35:37.448+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:35:37.448+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:35:37.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.390 seconds
[2025-04-08T05:36:08.219+0000] {processor.py:186} INFO - Started process (PID=19146) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:36:08.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:36:08.226+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:08.226+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:36:08.514+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:36:08.545+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:08.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:36:08.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:08.561+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:36:08.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.564 seconds
[2025-04-08T05:36:39.022+0000] {processor.py:186} INFO - Started process (PID=19215) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:36:39.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:36:39.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:36:39.284+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:36:39.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:36:39.333+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:36:39.333+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:36:39.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T05:37:10.093+0000] {processor.py:186} INFO - Started process (PID=19284) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:37:10.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:37:10.098+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:37:10.365+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:37:10.396+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:37:10.413+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:10.413+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:37:10.443+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-08T05:37:40.975+0000] {processor.py:186} INFO - Started process (PID=19353) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:37:40.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:37:40.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:40.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:37:41.240+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:37:41.272+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:41.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:37:41.290+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:37:41.289+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:37:41.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T05:38:11.848+0000] {processor.py:186} INFO - Started process (PID=19422) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:38:11.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:38:11.852+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:11.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:38:12.106+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:38:12.136+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:12.135+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:38:12.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:12.153+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:38:12.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T05:38:42.346+0000] {processor.py:186} INFO - Started process (PID=19491) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:38:42.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:38:42.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:42.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:38:42.603+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:38:42.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:42.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:38:42.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:38:42.651+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:38:42.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T05:39:13.250+0000] {processor.py:186} INFO - Started process (PID=19560) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:39:13.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:39:13.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:13.254+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:39:13.503+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:39:13.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:13.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:39:13.552+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:13.551+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:39:13.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T05:39:43.953+0000] {processor.py:186} INFO - Started process (PID=19629) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:39:43.954+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:39:43.957+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:43.957+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:39:44.211+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:39:44.242+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:44.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:39:44.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:39:44.259+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:39:44.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T05:40:14.923+0000] {processor.py:186} INFO - Started process (PID=19698) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:40:14.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:40:14.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:14.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:40:15.184+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:40:15.216+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:15.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:40:15.232+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:15.232+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:40:15.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T05:40:45.975+0000] {processor.py:186} INFO - Started process (PID=19767) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:40:45.977+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:40:45.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:45.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:40:46.234+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:40:46.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:46.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:40:46.435+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:40:46.435+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:40:46.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.499 seconds
[2025-04-08T05:41:16.908+0000] {processor.py:186} INFO - Started process (PID=19836) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:41:16.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:41:16.912+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:16.911+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:41:17.178+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:41:17.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:17.209+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:41:17.226+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:17.226+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:41:17.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-08T05:41:47.590+0000] {processor.py:186} INFO - Started process (PID=19905) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:41:47.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:41:47.596+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:47.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:41:47.851+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:41:47.881+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:47.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:41:47.896+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:41:47.896+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:41:47.928+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T05:42:18.082+0000] {processor.py:186} INFO - Started process (PID=19974) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:42:18.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:42:18.087+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:42:18.336+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:42:18.366+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.365+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:42:18.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:18.381+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:42:18.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T05:42:48.905+0000] {processor.py:186} INFO - Started process (PID=20043) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:42:48.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:42:48.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:48.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:42:49.161+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:42:49.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:49.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:42:49.214+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:42:49.213+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:42:49.244+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T05:43:19.376+0000] {processor.py:186} INFO - Started process (PID=20112) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:43:19.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:43:19.380+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:19.380+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:43:19.630+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:43:19.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:19.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:43:19.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:19.679+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:43:19.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-08T05:43:50.097+0000] {processor.py:186} INFO - Started process (PID=20181) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:43:50.098+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:43:50.102+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.101+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:43:50.372+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:43:50.401+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:43:50.417+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:43:50.417+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:43:50.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-08T05:44:20.639+0000] {processor.py:186} INFO - Started process (PID=20250) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:44:20.640+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:44:20.644+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:20.643+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:44:20.901+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:44:20.928+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:20.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:44:20.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:20.944+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:44:20.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T05:44:51.199+0000] {processor.py:186} INFO - Started process (PID=20319) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:44:51.200+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:44:51.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.203+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:44:51.588+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:44:51.613+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:44:51.630+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:44:51.629+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:44:51.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.473 seconds
[2025-04-08T05:45:22.398+0000] {processor.py:186} INFO - Started process (PID=20388) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:45:22.399+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:45:22.403+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:22.403+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:45:22.645+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:45:22.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:22.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:45:22.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:22.878+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:45:22.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.517 seconds
[2025-04-08T05:45:53.168+0000] {processor.py:186} INFO - Started process (PID=20457) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:45:53.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:45:53.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:45:53.465+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:45:53.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.506+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:45:53.723+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:45:53.722+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:45:53.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.589 seconds
[2025-04-08T05:46:24.538+0000] {processor.py:186} INFO - Started process (PID=20533) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:46:24.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:46:24.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:24.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:46:24.807+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:46:25.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:25.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:46:25.018+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:25.018+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:46:25.045+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.514 seconds
[2025-04-08T05:46:55.193+0000] {processor.py:186} INFO - Started process (PID=20602) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:46:55.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:46:55.198+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:55.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:46:55.617+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:46:55.645+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:55.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:46:55.658+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:46:55.658+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:46:55.688+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.504 seconds
[2025-04-08T05:47:26.028+0000] {processor.py:186} INFO - Started process (PID=20671) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:47:26.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:47:26.032+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:26.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:47:26.444+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:47:26.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:26.471+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:47:26.485+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:26.485+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:47:26.513+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.491 seconds
[2025-04-08T05:47:56.985+0000] {processor.py:186} INFO - Started process (PID=20740) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:47:56.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:47:56.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:56.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:47:57.411+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:47:57.438+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:57.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:47:57.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:47:57.451+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:47:57.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.502 seconds
[2025-04-08T05:48:28.044+0000] {processor.py:186} INFO - Started process (PID=20809) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:48:28.045+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:48:28.050+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:28.049+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:48:28.475+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:48:28.502+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:28.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:48:28.515+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:28.515+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:48:28.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.510 seconds
[2025-04-08T05:48:58.692+0000] {processor.py:186} INFO - Started process (PID=20878) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:48:58.693+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:48:58.697+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:58.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:48:59.101+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:48:59.129+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:59.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:48:59.143+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:48:59.143+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:48:59.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.490 seconds
[2025-04-08T05:49:29.992+0000] {processor.py:186} INFO - Started process (PID=20947) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:49:29.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:49:29.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:29.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:49:30.261+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:49:30.290+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:30.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:49:30.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:49:30.305+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:49:30.338+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T05:50:00.863+0000] {processor.py:186} INFO - Started process (PID=21017) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:50:00.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:50:00.869+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:00.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:50:01.159+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:50:01.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:01.190+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:50:01.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:01.210+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:50:01.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T05:50:31.663+0000] {processor.py:186} INFO - Started process (PID=21086) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:50:31.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:50:31.669+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:31.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:50:31.932+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:50:31.963+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:31.962+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:50:31.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:50:31.981+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:50:32.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-08T05:51:02.178+0000] {processor.py:186} INFO - Started process (PID=21155) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:51:02.179+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:51:02.182+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.182+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:51:02.446+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:51:02.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:51:02.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:02.493+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:51:02.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T05:51:33.046+0000] {processor.py:186} INFO - Started process (PID=21224) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:51:33.047+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:51:33.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:51:33.295+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:51:33.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:51:33.341+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:51:33.341+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:51:33.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-08T05:52:03.654+0000] {processor.py:186} INFO - Started process (PID=21293) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:52:03.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:52:03.659+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:03.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:52:03.984+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:52:04.021+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:04.020+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:52:04.037+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:04.037+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:52:04.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.421 seconds
[2025-04-08T05:52:34.483+0000] {processor.py:186} INFO - Started process (PID=21362) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:52:34.484+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:52:34.488+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:52:34.754+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:52:34.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:52:34.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:52:34.800+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:52:34.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T05:53:05.201+0000] {processor.py:186} INFO - Started process (PID=21431) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:53:05.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:53:05.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:53:05.468+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:53:05.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.500+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:53:05.517+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:05.517+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:53:05.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T05:53:35.916+0000] {processor.py:186} INFO - Started process (PID=21500) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:53:35.917+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:53:35.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:35.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:53:36.179+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:53:36.212+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:36.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:53:36.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:53:36.229+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:53:36.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T05:54:06.552+0000] {processor.py:186} INFO - Started process (PID=21569) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:54:06.553+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:54:06.557+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:54:06.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:54:06.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:54:06.856+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:06.856+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:54:06.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T05:54:37.171+0000] {processor.py:186} INFO - Started process (PID=21638) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:54:37.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:54:37.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:54:37.442+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:54:37.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:54:37.488+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:54:37.488+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:54:37.517+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T05:55:08.048+0000] {processor.py:186} INFO - Started process (PID=21707) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:55:08.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:55:08.054+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:55:08.300+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:55:08.331+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:55:08.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:08.347+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:55:08.382+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T05:55:39.133+0000] {processor.py:186} INFO - Started process (PID=21776) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:55:39.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:55:39.139+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:55:39.400+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:55:39.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:55:39.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:55:39.446+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:55:39.479+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T05:56:09.995+0000] {processor.py:186} INFO - Started process (PID=21845) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:56:09.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:56:09.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:09.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:56:10.264+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:56:10.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:10.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:56:10.311+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:10.310+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:56:10.343+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-08T05:56:40.675+0000] {processor.py:186} INFO - Started process (PID=21914) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:56:40.677+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:56:40.680+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:40.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:56:40.945+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:56:40.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:40.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:56:41.000+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:56:41.000+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:56:41.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-08T05:57:11.100+0000] {processor.py:186} INFO - Started process (PID=21983) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:57:11.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:57:11.104+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.103+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:57:11.334+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:57:11.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:57:11.378+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:11.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:57:11.407+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.314 seconds
[2025-04-08T05:57:41.772+0000] {processor.py:186} INFO - Started process (PID=22051) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:57:41.773+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:57:41.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:41.775+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:57:42.029+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:57:42.060+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:42.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:57:42.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:57:42.075+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:57:42.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T05:58:12.619+0000] {processor.py:186} INFO - Started process (PID=22120) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:58:12.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:58:12.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:12.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:58:12.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:58:12.922+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:12.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:58:12.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:12.941+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:58:12.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-08T05:58:43.224+0000] {processor.py:186} INFO - Started process (PID=22189) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:58:43.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:58:43.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:43.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:58:43.476+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:58:43.505+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:43.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:58:43.521+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:58:43.520+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:58:43.552+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T05:59:14.130+0000] {processor.py:186} INFO - Started process (PID=22258) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:59:14.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:59:14.135+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:14.135+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:59:14.374+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:59:14.403+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:14.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:59:14.419+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:14.419+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:59:14.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.326 seconds
[2025-04-08T05:59:44.986+0000] {processor.py:186} INFO - Started process (PID=22327) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:59:44.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T05:59:44.992+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:44.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:59:45.253+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T05:59:45.283+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:45.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T05:59:45.299+0000] {logging_mixin.py:190} INFO - [2025-04-08T05:59:45.299+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T05:59:45.330+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T06:00:15.931+0000] {processor.py:186} INFO - Started process (PID=22396) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:00:15.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:00:15.937+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:15.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:00:16.204+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:00:16.235+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:16.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:00:16.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:16.256+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:00:16.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-08T06:00:46.827+0000] {processor.py:186} INFO - Started process (PID=22465) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:00:46.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:00:46.833+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:46.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:00:47.079+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:00:47.110+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:47.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:00:47.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:00:47.130+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:00:47.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-08T06:01:17.275+0000] {processor.py:186} INFO - Started process (PID=22534) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:01:17.276+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:01:17.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:17.279+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:01:17.534+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:01:17.570+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:17.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:01:17.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:17.588+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:01:17.612+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T06:01:47.866+0000] {processor.py:186} INFO - Started process (PID=22602) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:01:47.868+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:01:47.871+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:47.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:01:48.109+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:01:48.138+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:48.138+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:01:48.156+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:01:48.155+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:01:48.190+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T06:02:18.498+0000] {processor.py:186} INFO - Started process (PID=22671) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:02:18.499+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:02:18.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:18.503+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:02:18.762+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:02:18.791+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:18.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:02:18.808+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:18.808+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:02:18.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T06:02:49.086+0000] {processor.py:186} INFO - Started process (PID=22740) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:02:49.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:02:49.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:49.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:02:49.321+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:02:49.348+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:49.347+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:02:49.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:02:49.363+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:02:49.394+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-08T06:03:19.670+0000] {processor.py:186} INFO - Started process (PID=22809) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:03:19.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:03:19.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:19.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:03:19.927+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:03:19.956+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:19.956+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:03:19.973+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:19.973+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:03:20.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T06:03:50.248+0000] {processor.py:186} INFO - Started process (PID=22878) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:03:50.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:03:50.253+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:50.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:03:50.495+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:03:50.528+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:50.527+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:03:50.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:03:50.551+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:03:50.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T06:04:20.914+0000] {processor.py:186} INFO - Started process (PID=22947) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:04:20.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:04:20.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:20.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:04:21.196+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:04:21.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:21.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:04:21.247+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:21.246+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:04:21.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-08T06:04:51.974+0000] {processor.py:186} INFO - Started process (PID=23016) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:04:51.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:04:51.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:51.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:04:52.223+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:04:52.255+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:52.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:04:52.273+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:04:52.272+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:04:52.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T06:05:22.675+0000] {processor.py:186} INFO - Started process (PID=23085) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:05:22.676+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:05:22.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:22.679+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:05:22.938+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:05:22.965+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:22.965+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:05:22.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:22.981+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:05:23.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T06:05:53.737+0000] {processor.py:186} INFO - Started process (PID=23154) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:05:53.739+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:05:53.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:53.741+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:05:53.998+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:05:54.027+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:54.027+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:05:54.045+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:05:54.044+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:05:54.071+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T06:06:24.791+0000] {processor.py:186} INFO - Started process (PID=23222) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:06:24.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:06:24.795+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:24.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:06:25.028+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:06:25.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:25.055+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:06:25.071+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:25.070+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:06:25.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.317 seconds
[2025-04-08T06:06:55.659+0000] {processor.py:186} INFO - Started process (PID=23291) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:06:55.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:06:55.663+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:55.663+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:06:55.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:06:55.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:55.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:06:55.932+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:06:55.932+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:06:55.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.310 seconds
[2025-04-08T06:07:26.670+0000] {processor.py:186} INFO - Started process (PID=23366) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:07:26.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:07:26.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:26.673+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:07:26.910+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:07:26.938+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:26.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:07:26.956+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:26.956+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:07:27.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.484 seconds
[2025-04-08T06:07:57.768+0000] {processor.py:186} INFO - Started process (PID=23435) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:07:57.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:07:57.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:57.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:07:58.027+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:07:58.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:58.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:07:58.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:07:58.075+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:07:58.105+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T06:08:28.609+0000] {processor.py:186} INFO - Started process (PID=23504) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:08:28.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:08:28.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:28.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:08:29.045+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:08:29.072+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:29.071+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:08:29.086+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:29.086+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:08:29.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.517 seconds
[2025-04-08T06:08:59.700+0000] {processor.py:186} INFO - Started process (PID=23573) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:08:59.702+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:08:59.704+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:08:59.704+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:09:00.124+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:09:00.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:00.152+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:09:00.167+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:00.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:09:00.196+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.503 seconds
[2025-04-08T06:09:31.048+0000] {processor.py:186} INFO - Started process (PID=23642) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:09:31.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:09:31.053+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:09:31.426+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:09:31.450+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.450+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:09:31.463+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:09:31.463+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:09:31.490+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.449 seconds
[2025-04-08T06:10:01.588+0000] {processor.py:186} INFO - Started process (PID=23709) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:10:01.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:10:01.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:01.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:10:02.013+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:10:02.042+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:02.042+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:10:02.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:02.068+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:10:02.106+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.526 seconds
[2025-04-08T06:10:32.274+0000] {processor.py:186} INFO - Started process (PID=23778) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:10:32.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:10:32.278+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:32.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:10:32.714+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:10:32.739+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:32.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:10:32.755+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:10:32.755+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:10:32.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.518 seconds
[2025-04-08T06:11:03.186+0000] {processor.py:186} INFO - Started process (PID=23847) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:11:03.188+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:11:03.191+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:03.190+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:11:03.663+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:11:03.695+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:03.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:11:03.718+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:03.718+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:11:03.752+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.573 seconds
[2025-04-08T06:11:34.162+0000] {processor.py:186} INFO - Started process (PID=23916) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:11:34.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:11:34.166+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:34.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:11:34.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:11:34.564+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:34.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:11:34.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:11:34.577+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:11:34.606+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.451 seconds
[2025-04-08T06:12:04.898+0000] {processor.py:186} INFO - Started process (PID=23985) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:12:04.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:12:04.902+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:04.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:12:05.301+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:12:05.329+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:05.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:12:05.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:05.343+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:12:05.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.481 seconds
[2025-04-08T06:12:35.599+0000] {processor.py:186} INFO - Started process (PID=24054) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:12:35.600+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:12:35.604+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:35.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:12:35.980+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:12:36.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:36.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:12:36.022+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:12:36.022+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:12:36.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.460 seconds
[2025-04-08T06:13:06.376+0000] {processor.py:186} INFO - Started process (PID=24123) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:13:06.378+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:13:06.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:13:06.767+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:13:06.795+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.794+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:13:06.809+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:06.808+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:13:06.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.466 seconds
[2025-04-08T06:13:36.946+0000] {processor.py:186} INFO - Started process (PID=24193) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:13:36.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:13:36.950+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:36.950+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:13:37.339+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:13:37.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:37.363+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:13:37.377+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:13:37.377+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:13:37.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.465 seconds
[2025-04-08T06:14:07.545+0000] {processor.py:186} INFO - Started process (PID=24261) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:14:07.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:14:07.550+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:14:07.793+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:14:07.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:14:07.833+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:07.833+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:14:07.862+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T06:14:38.327+0000] {processor.py:186} INFO - Started process (PID=24330) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:14:38.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:14:38.331+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:14:38.578+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:14:38.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.604+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:14:38.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:14:38.621+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:14:38.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T06:15:08.896+0000] {processor.py:186} INFO - Started process (PID=24399) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:15:08.897+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:15:08.900+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:08.900+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:15:09.142+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:15:09.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:09.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:15:09.183+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:09.183+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:15:09.212+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.325 seconds
[2025-04-08T06:15:39.380+0000] {processor.py:186} INFO - Started process (PID=24469) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:15:39.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:15:39.384+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:15:39.622+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:15:39.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.652+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:15:39.669+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:15:39.669+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:15:39.700+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T06:16:10.646+0000] {processor.py:186} INFO - Started process (PID=24538) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:16:10.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:16:10.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:10.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:16:10.883+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:16:10.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:10.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:16:10.925+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:10.925+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:16:10.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T06:16:41.305+0000] {processor.py:186} INFO - Started process (PID=24607) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:16:41.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:16:41.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:41.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:16:41.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:16:41.617+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:41.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:16:41.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:16:41.637+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:16:41.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-08T06:17:11.950+0000] {processor.py:186} INFO - Started process (PID=24676) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:17:11.951+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:17:11.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:11.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:17:12.233+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:17:12.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:12.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:17:12.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:12.276+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:17:12.306+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T06:17:43.202+0000] {processor.py:186} INFO - Started process (PID=24745) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:17:43.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:17:43.207+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:43.206+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:17:43.478+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:17:43.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:43.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:17:43.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:17:43.522+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:17:43.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-08T06:18:13.650+0000] {processor.py:186} INFO - Started process (PID=24814) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:18:13.651+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:18:13.654+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:13.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:18:13.903+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:18:13.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:13.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:18:13.946+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:13.946+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:18:13.974+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T06:18:44.080+0000] {processor.py:186} INFO - Started process (PID=24883) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:18:44.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:18:44.084+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:44.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:18:44.336+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:18:44.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:44.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:18:44.377+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:18:44.377+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:18:44.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T06:19:15.201+0000] {processor.py:186} INFO - Started process (PID=24952) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:19:15.202+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:19:15.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:15.205+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:19:15.452+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:19:15.480+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:15.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:19:15.495+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:15.494+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:19:15.523+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T06:19:45.600+0000] {processor.py:186} INFO - Started process (PID=25021) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:19:45.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:19:45.604+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:45.604+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:19:45.838+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:19:45.864+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:45.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:19:45.879+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:19:45.879+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:19:45.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.315 seconds
[2025-04-08T06:20:16.052+0000] {processor.py:186} INFO - Started process (PID=25090) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:20:16.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:20:16.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:16.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:20:16.299+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:20:16.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:16.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:20:16.340+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:16.340+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:20:16.369+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.328 seconds
[2025-04-08T06:20:46.670+0000] {processor.py:186} INFO - Started process (PID=25159) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:20:46.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:20:46.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:46.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:20:46.912+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:20:46.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:46.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:20:46.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:20:46.954+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:20:46.984+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-08T06:21:17.485+0000] {processor.py:186} INFO - Started process (PID=25228) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:21:17.486+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:21:17.489+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:17.489+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:21:17.730+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:21:17.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:17.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:21:17.773+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:17.772+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:21:17.801+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-08T06:21:47.914+0000] {processor.py:186} INFO - Started process (PID=25297) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:21:47.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:21:47.919+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:47.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:21:48.153+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:21:48.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:48.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:21:48.193+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:21:48.193+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:21:48.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.321 seconds
[2025-04-08T06:22:19.093+0000] {processor.py:186} INFO - Started process (PID=25366) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:22:19.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:22:19.100+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:19.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:22:19.349+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:22:19.375+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:19.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:22:19.389+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:19.389+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:22:19.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T06:22:49.538+0000] {processor.py:186} INFO - Started process (PID=25435) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:22:49.539+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:22:49.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:49.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:22:49.817+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:22:49.847+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:49.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:22:49.864+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:22:49.864+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:22:49.894+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T06:23:20.661+0000] {processor.py:186} INFO - Started process (PID=25504) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:23:20.662+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:23:20.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:20.664+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:23:20.936+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:23:20.965+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:20.964+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:23:20.982+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:20.982+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:23:21.011+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-08T06:23:51.935+0000] {processor.py:186} INFO - Started process (PID=25573) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:23:51.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:23:51.939+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:51.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:23:52.185+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:23:52.211+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:52.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:23:52.228+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:23:52.228+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:23:52.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.328 seconds
[2025-04-08T06:24:22.606+0000] {processor.py:186} INFO - Started process (PID=25642) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:24:22.607+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:24:22.611+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:22.610+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:24:22.894+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:24:22.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:22.925+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:24:22.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:22.946+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:24:22.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.384 seconds
[2025-04-08T06:24:53.143+0000] {processor.py:186} INFO - Started process (PID=25711) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:24:53.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:24:53.148+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:53.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:24:53.382+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:24:53.410+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:53.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:24:53.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:24:53.426+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:24:53.455+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.321 seconds
[2025-04-08T06:25:23.652+0000] {processor.py:186} INFO - Started process (PID=25780) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:25:23.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:25:23.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:23.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:25:23.906+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:25:23.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:23.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:25:23.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:23.962+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:25:23.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T06:25:54.662+0000] {processor.py:186} INFO - Started process (PID=25849) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:25:54.663+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:25:54.667+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:54.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:25:54.927+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:25:54.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:54.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:25:54.975+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:25:54.975+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:25:55.007+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-08T06:26:25.229+0000] {processor.py:186} INFO - Started process (PID=25918) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:26:25.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:26:25.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:25.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:26:25.552+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:26:25.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:25.584+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:26:25.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:25.604+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:26:25.634+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.412 seconds
[2025-04-08T06:26:55.901+0000] {processor.py:186} INFO - Started process (PID=25987) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:26:55.903+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:26:55.906+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:55.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:26:56.173+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:26:56.205+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:56.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:26:56.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:26:56.223+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:26:56.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-08T06:27:26.510+0000] {processor.py:186} INFO - Started process (PID=26056) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:27:26.511+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:27:26.515+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:26.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:27:26.787+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:27:26.827+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:26.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:27:26.845+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:26.844+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:27:26.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-08T06:27:57.270+0000] {processor.py:186} INFO - Started process (PID=26125) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:27:57.272+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:27:57.276+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:57.275+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:27:57.553+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:27:57.586+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:57.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:27:57.602+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:27:57.602+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:27:57.627+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-08T06:28:28.114+0000] {processor.py:186} INFO - Started process (PID=26194) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:28:28.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:28:28.118+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:28.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:28:28.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:28:28.458+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:28.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:28:28.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:28.476+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:28:28.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.397 seconds
[2025-04-08T06:28:58.804+0000] {processor.py:186} INFO - Started process (PID=26263) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:28:58.805+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:28:58.809+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:58.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:28:59.105+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:28:59.133+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:59.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:28:59.149+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:28:59.148+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:28:59.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-08T06:29:29.827+0000] {processor.py:186} INFO - Started process (PID=26338) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:29:29.828+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:29:29.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:29.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:29:30.110+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:29:30.148+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:30.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:29:30.166+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:29:30.165+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:29:30.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-08T06:30:00.702+0000] {processor.py:186} INFO - Started process (PID=26407) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:30:00.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:30:00.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:00.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:30:00.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:30:00.993+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:00.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:30:01.011+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:01.010+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:30:01.042+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T06:30:31.592+0000] {processor.py:186} INFO - Started process (PID=26476) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:30:31.594+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:30:31.599+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:31.598+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:30:31.902+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:30:31.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:31.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:30:31.950+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:30:31.950+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:30:31.981+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.396 seconds
[2025-04-08T06:31:02.544+0000] {processor.py:186} INFO - Started process (PID=26545) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:31:02.546+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:31:02.550+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:02.549+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:31:02.817+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:31:02.847+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:02.846+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:31:02.863+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:02.862+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:31:02.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T06:31:33.441+0000] {processor.py:186} INFO - Started process (PID=26614) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:31:33.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:31:33.446+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:33.446+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:31:33.704+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:31:33.735+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:33.734+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:31:33.750+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:31:33.750+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:31:33.780+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T06:32:04.251+0000] {processor.py:186} INFO - Started process (PID=26683) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:32:04.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:32:04.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:04.256+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:32:04.510+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:32:04.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:04.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:32:04.558+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:04.558+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:32:04.590+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T06:32:35.265+0000] {processor.py:186} INFO - Started process (PID=26752) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:32:35.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:32:35.270+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:35.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:32:35.529+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:32:35.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:35.560+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:32:35.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:32:35.577+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:32:35.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-08T06:33:06.196+0000] {processor.py:186} INFO - Started process (PID=26821) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:33:06.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:33:06.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:06.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:33:06.481+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:33:06.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:06.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:33:06.539+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:06.539+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:33:06.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-08T06:33:36.714+0000] {processor.py:186} INFO - Started process (PID=26890) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:33:36.715+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:33:36.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:36.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:33:36.973+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:33:37.008+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:37.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:33:37.024+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:33:37.024+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:33:37.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T06:34:07.575+0000] {processor.py:186} INFO - Started process (PID=26959) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:34:07.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:34:07.580+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:07.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:34:07.829+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:34:08.018+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:08.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:34:08.035+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:08.034+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:34:08.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T06:34:38.643+0000] {processor.py:186} INFO - Started process (PID=27028) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:34:38.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:34:38.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:38.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:34:39.098+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:34:39.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:39.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:34:39.138+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:34:39.138+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:34:39.168+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.536 seconds
[2025-04-08T06:35:09.531+0000] {processor.py:186} INFO - Started process (PID=27097) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:35:09.533+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:35:09.536+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:09.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:35:09.811+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:35:09.840+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:09.840+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:35:09.857+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:09.857+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:35:09.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T06:35:40.459+0000] {processor.py:186} INFO - Started process (PID=27166) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:35:40.460+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:35:40.464+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:40.464+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:35:40.727+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:35:40.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:40.758+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:35:40.778+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:35:40.778+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:35:40.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-08T06:36:11.613+0000] {processor.py:186} INFO - Started process (PID=27235) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:36:11.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:36:11.618+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:11.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:36:11.867+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:36:11.898+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:11.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:36:11.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:11.914+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:36:11.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-08T06:36:42.244+0000] {processor.py:186} INFO - Started process (PID=27304) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:36:42.245+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:36:42.249+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:42.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:36:42.505+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:36:42.538+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:42.538+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:36:42.554+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:36:42.554+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:36:42.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T06:37:13.258+0000] {processor.py:186} INFO - Started process (PID=27373) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:37:13.259+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:37:13.262+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:13.261+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:37:13.521+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:37:13.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:13.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:37:13.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:13.567+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:37:13.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T06:37:44.047+0000] {processor.py:186} INFO - Started process (PID=27442) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:37:44.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:37:44.052+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:44.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:37:44.334+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:37:44.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:44.364+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:37:44.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:37:44.381+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:37:44.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-08T06:38:15.193+0000] {processor.py:186} INFO - Started process (PID=27511) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:38:15.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:38:15.197+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:15.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:38:15.596+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:38:15.624+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:15.624+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:38:15.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:15.640+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:38:15.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.483 seconds
[2025-04-08T06:38:45.825+0000] {processor.py:186} INFO - Started process (PID=27580) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:38:45.826+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:38:45.830+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:45.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:38:46.084+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:38:46.117+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:46.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:38:46.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:38:46.304+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:38:46.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.511 seconds
[2025-04-08T06:39:16.467+0000] {processor.py:186} INFO - Started process (PID=27649) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:39:16.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:39:16.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:16.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:39:16.880+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:39:16.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:16.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:39:16.925+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:16.924+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:39:16.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T06:39:47.224+0000] {processor.py:186} INFO - Started process (PID=27717) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:39:47.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:39:47.229+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:47.229+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:39:47.630+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:39:47.659+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:47.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:39:47.673+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:39:47.673+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:39:47.701+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.486 seconds
[2025-04-08T06:40:18.072+0000] {processor.py:186} INFO - Started process (PID=27786) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:40:18.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:40:18.076+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:18.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:40:18.452+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:40:18.478+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:18.478+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:40:18.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:18.493+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:40:18.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.455 seconds
[2025-04-08T06:40:49.209+0000] {processor.py:186} INFO - Started process (PID=27855) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:40:49.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:40:49.214+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:49.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:40:49.455+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:40:49.487+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:49.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:40:49.503+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:40:49.503+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:40:49.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T06:41:20.025+0000] {processor.py:186} INFO - Started process (PID=27924) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:41:20.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:41:20.031+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:20.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:41:20.272+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:41:20.302+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:20.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:41:20.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:20.317+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:41:20.348+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T06:41:50.839+0000] {processor.py:186} INFO - Started process (PID=27993) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:41:50.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:41:50.843+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:50.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:41:51.087+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:41:51.115+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:51.115+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:41:51.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:41:51.131+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:41:51.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T06:42:21.844+0000] {processor.py:186} INFO - Started process (PID=28062) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:42:21.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:42:21.848+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:21.847+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:42:22.112+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:42:22.145+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:22.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:42:22.161+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:22.161+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:42:22.191+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T06:42:52.708+0000] {processor.py:186} INFO - Started process (PID=28131) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:42:52.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:42:52.713+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:52.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:42:52.991+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:42:53.022+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:53.021+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:42:53.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:42:53.040+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:42:53.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.374 seconds
[2025-04-08T06:43:23.517+0000] {processor.py:186} INFO - Started process (PID=28200) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:43:23.518+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:43:23.521+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:23.521+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:43:23.791+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:43:23.818+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:23.818+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:43:23.835+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:23.834+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:43:23.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-08T06:43:54.050+0000] {processor.py:186} INFO - Started process (PID=28267) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:43:54.051+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:43:54.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:54.054+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:43:54.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:43:54.332+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:54.331+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:43:54.349+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:43:54.349+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:43:54.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T06:44:25.354+0000] {processor.py:186} INFO - Started process (PID=28336) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:44:25.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:44:25.359+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:25.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:44:25.604+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:44:25.636+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:25.636+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:44:25.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:25.653+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:44:25.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T06:44:56.259+0000] {processor.py:186} INFO - Started process (PID=28405) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:44:56.260+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:44:56.264+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:56.264+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:44:56.512+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:44:56.545+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:56.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:44:56.564+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:44:56.564+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:44:56.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-08T06:45:27.607+0000] {processor.py:186} INFO - Started process (PID=28473) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:45:27.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:45:27.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:27.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:45:27.871+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:45:27.904+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:27.903+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:45:27.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:27.920+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:45:27.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-08T06:45:58.537+0000] {processor.py:186} INFO - Started process (PID=28542) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:45:58.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:45:58.542+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:58.542+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:45:58.793+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:45:58.822+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:58.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:45:58.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:45:58.838+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:45:58.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T06:46:29.118+0000] {processor.py:186} INFO - Started process (PID=28611) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:46:29.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:46:29.123+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:29.122+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:46:29.373+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:46:29.403+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:29.402+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:46:29.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:46:29.418+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:46:29.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T06:47:00.467+0000] {processor.py:186} INFO - Started process (PID=28680) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:47:00.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:47:00.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:00.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:47:00.721+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:47:00.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:00.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:47:00.778+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:00.778+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:47:00.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-08T06:47:31.646+0000] {processor.py:186} INFO - Started process (PID=28755) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:47:31.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:47:31.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:31.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:47:31.907+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:47:31.935+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:31.935+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:47:31.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:47:31.951+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:47:31.988+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T06:48:02.289+0000] {processor.py:186} INFO - Started process (PID=28824) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:48:02.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:48:02.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:02.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:48:02.617+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:48:02.644+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:02.644+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:48:02.660+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:02.660+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:48:02.683+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.401 seconds
[2025-04-08T06:48:33.697+0000] {processor.py:186} INFO - Started process (PID=28893) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:48:33.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:48:33.701+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:33.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:48:33.959+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:48:33.989+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:33.989+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:48:34.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:48:34.007+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:48:34.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T06:49:04.239+0000] {processor.py:186} INFO - Started process (PID=28962) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:49:04.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:49:04.244+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:04.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:49:04.531+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:49:04.568+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:04.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:49:04.585+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:04.584+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:49:04.613+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.384 seconds
[2025-04-08T06:49:35.430+0000] {processor.py:186} INFO - Started process (PID=29031) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:49:35.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:49:35.436+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:35.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:49:35.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:49:35.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:35.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:49:35.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:49:35.729+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:49:35.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-08T06:50:06.048+0000] {processor.py:186} INFO - Started process (PID=29100) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:50:06.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:50:06.053+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:06.052+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:50:06.297+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:50:06.328+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:06.327+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:50:06.345+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:06.345+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:50:06.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T06:50:36.654+0000] {processor.py:186} INFO - Started process (PID=29169) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:50:36.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:50:36.660+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:36.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:50:36.910+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:50:36.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:36.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:50:36.957+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:50:36.956+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:50:36.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T06:51:07.972+0000] {processor.py:186} INFO - Started process (PID=29238) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:51:07.973+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:51:07.978+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:07.977+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:51:08.243+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:51:08.272+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:08.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:51:08.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:08.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:51:08.317+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T06:51:38.692+0000] {processor.py:186} INFO - Started process (PID=29307) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:51:38.694+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:51:38.697+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:38.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:51:38.952+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:51:38.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:38.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:51:38.997+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:51:38.997+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:51:39.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T06:52:09.655+0000] {processor.py:186} INFO - Started process (PID=29376) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:52:09.656+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:52:09.659+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:09.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:52:09.907+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:52:09.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:09.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:52:09.949+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:09.949+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:52:10.027+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.380 seconds
[2025-04-08T06:52:40.098+0000] {processor.py:186} INFO - Started process (PID=29443) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:52:40.099+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:52:40.102+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:40.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:52:40.360+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:52:40.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:40.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:52:40.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:52:40.421+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:52:40.453+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T06:53:11.359+0000] {processor.py:186} INFO - Started process (PID=29512) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:53:11.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:53:11.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:11.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:53:11.618+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:53:11.649+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:11.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:53:11.666+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:11.666+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:53:11.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T06:53:42.104+0000] {processor.py:186} INFO - Started process (PID=29581) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:53:42.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:53:42.108+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:42.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:53:42.386+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:53:42.414+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:42.413+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:53:42.428+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:53:42.428+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:53:42.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-08T06:54:12.558+0000] {processor.py:186} INFO - Started process (PID=29650) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:54:12.559+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:54:12.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:12.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:54:12.795+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:54:12.823+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:12.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:54:12.838+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:12.838+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:54:12.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-08T06:54:43.230+0000] {processor.py:186} INFO - Started process (PID=29719) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:54:43.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:54:43.234+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:43.234+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:54:43.463+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:54:43.490+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:43.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:54:43.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:54:43.506+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:54:43.533+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.310 seconds
[2025-04-08T06:55:13.993+0000] {processor.py:186} INFO - Started process (PID=29788) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:55:13.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:55:13.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:13.997+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:55:14.262+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:55:14.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:14.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:55:14.311+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:14.311+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:55:14.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-08T06:55:44.527+0000] {processor.py:186} INFO - Started process (PID=29857) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:55:44.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:55:44.531+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:44.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:55:44.763+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:55:44.792+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:44.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:55:44.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:55:44.807+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:55:44.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.318 seconds
[2025-04-08T06:56:15.249+0000] {processor.py:186} INFO - Started process (PID=29926) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:56:15.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:56:15.253+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:15.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:56:15.484+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:56:15.512+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:15.512+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:56:15.527+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:15.527+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:56:15.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.312 seconds
[2025-04-08T06:56:46.207+0000] {processor.py:186} INFO - Started process (PID=29995) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:56:46.209+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:56:46.212+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:46.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:56:46.479+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:56:46.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:46.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:56:46.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:56:46.522+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:56:46.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T06:57:16.673+0000] {processor.py:186} INFO - Started process (PID=30064) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:57:16.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:57:16.677+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:16.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:57:16.908+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:57:16.938+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:16.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:57:16.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:16.954+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:57:16.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-08T06:57:47.703+0000] {processor.py:186} INFO - Started process (PID=30133) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:57:47.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:57:47.709+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:47.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:57:47.947+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:57:47.975+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:47.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:57:47.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:57:47.991+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:57:48.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T06:58:18.420+0000] {processor.py:186} INFO - Started process (PID=30202) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:58:18.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:58:18.425+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:18.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:58:18.810+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:58:18.854+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:18.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:58:18.876+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:18.876+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:58:18.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.498 seconds
[2025-04-08T06:58:49.101+0000] {processor.py:186} INFO - Started process (PID=30271) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:58:49.103+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:58:49.106+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:49.106+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:58:49.525+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:58:49.549+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:49.548+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:58:49.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:58:49.562+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:58:49.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.499 seconds
[2025-04-08T06:59:20.143+0000] {processor.py:186} INFO - Started process (PID=30340) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:59:20.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:59:20.149+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:20.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:59:20.583+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:59:20.609+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:20.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:59:20.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:20.623+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:59:20.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.518 seconds
[2025-04-08T06:59:51.615+0000] {processor.py:186} INFO - Started process (PID=30410) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:59:51.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T06:59:51.621+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:51.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:59:52.083+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T06:59:52.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:52.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T06:59:52.126+0000] {logging_mixin.py:190} INFO - [2025-04-08T06:59:52.126+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T06:59:52.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.549 seconds
[2025-04-08T07:00:22.313+0000] {processor.py:186} INFO - Started process (PID=30479) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:00:22.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:00:22.318+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:22.318+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:00:22.726+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:00:22.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:22.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:00:22.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:22.769+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:00:22.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.496 seconds
[2025-04-08T07:00:53.628+0000] {processor.py:186} INFO - Started process (PID=30548) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:00:53.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:00:53.634+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:53.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:00:54.031+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:00:54.060+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:54.059+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:00:54.075+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:00:54.075+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:00:54.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-08T07:01:25.074+0000] {processor.py:186} INFO - Started process (PID=30617) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:01:25.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:01:25.079+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:25.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:01:25.476+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:01:25.504+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:25.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:01:25.519+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:25.518+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:01:25.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.484 seconds
[2025-04-08T07:01:56.447+0000] {processor.py:186} INFO - Started process (PID=30686) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:01:56.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:01:56.452+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:56.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:01:56.887+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:01:56.913+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:56.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:01:56.927+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:01:56.927+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:01:56.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.520 seconds
[2025-04-08T07:02:27.228+0000] {processor.py:186} INFO - Started process (PID=30755) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:02:27.229+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:02:27.233+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.232+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:02:27.645+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:02:27.672+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.671+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:02:27.685+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:27.685+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:02:27.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.497 seconds
[2025-04-08T07:02:58.530+0000] {processor.py:186} INFO - Started process (PID=30825) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:02:58.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:02:58.534+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:58.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:02:58.950+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:02:58.977+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:58.976+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:02:58.992+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:02:58.991+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:02:59.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.497 seconds
[2025-04-08T07:03:29.235+0000] {processor.py:186} INFO - Started process (PID=30893) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:03:29.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:03:29.240+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.240+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:03:29.644+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:03:29.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:03:29.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:03:29.687+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:03:29.717+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-08T07:04:00.416+0000] {processor.py:186} INFO - Started process (PID=30962) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:04:00.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:04:00.421+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:00.421+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:04:00.830+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:04:00.858+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:00.857+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:04:00.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:00.877+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:04:00.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.499 seconds
[2025-04-08T07:04:31.756+0000] {processor.py:186} INFO - Started process (PID=31031) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:04:31.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:04:31.761+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:31.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:04:32.186+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:04:32.213+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:32.213+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:04:32.227+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:04:32.227+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:04:32.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.510 seconds
[2025-04-08T07:05:02.848+0000] {processor.py:186} INFO - Started process (PID=31100) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:05:02.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:05:02.854+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:02.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:05:03.114+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:05:03.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:03.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:05:03.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:03.162+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:05:03.187+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T07:05:34.083+0000] {processor.py:186} INFO - Started process (PID=31175) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:05:34.085+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:05:34.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:05:34.344+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:05:34.375+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:05:34.391+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:05:34.391+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:05:34.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T07:06:04.503+0000] {processor.py:186} INFO - Started process (PID=31244) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:06:04.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:06:04.509+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:06:04.755+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:06:04.789+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:06:04.805+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:04.805+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:06:04.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T07:06:35.769+0000] {processor.py:186} INFO - Started process (PID=31313) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:06:35.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:06:35.775+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:35.774+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:06:36.017+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:06:36.046+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:36.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:06:36.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:06:36.061+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:06:36.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T07:07:06.640+0000] {processor.py:186} INFO - Started process (PID=31382) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:07:06.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:07:06.645+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:06.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:07:06.932+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:07:06.961+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:06.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:07:06.978+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:06.977+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:07:07.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-08T07:07:37.217+0000] {processor.py:186} INFO - Started process (PID=31451) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:07:37.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:07:37.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:07:37.479+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:07:37.511+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:07:37.527+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:07:37.527+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:07:37.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T07:08:08.172+0000] {processor.py:186} INFO - Started process (PID=31520) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:08:08.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:08:08.177+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.177+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:08:08.433+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:08:08.464+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:08:08.480+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:08.480+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:08:08.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T07:08:38.819+0000] {processor.py:186} INFO - Started process (PID=31589) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:08:38.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:08:38.825+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:38.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:08:39.094+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:08:39.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:39.123+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:08:39.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:08:39.141+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:08:39.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T07:09:09.867+0000] {processor.py:186} INFO - Started process (PID=31658) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:09:09.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:09:09.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:09.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:09:10.130+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:09:10.158+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:10.157+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:09:10.173+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:10.173+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:09:10.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T07:09:41.154+0000] {processor.py:186} INFO - Started process (PID=31727) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:09:41.155+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:09:41.159+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.159+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:09:41.408+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:09:41.440+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.440+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:09:41.457+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:09:41.457+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:09:41.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T07:10:12.178+0000] {processor.py:186} INFO - Started process (PID=31796) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:10:12.180+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:10:12.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.184+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:10:12.436+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:10:12.467+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.466+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:10:12.483+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:12.483+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:10:12.515+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T07:10:43.400+0000] {processor.py:186} INFO - Started process (PID=31865) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:10:43.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:10:43.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:10:43.683+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:10:43.713+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:10:43.731+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:10:43.731+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:10:43.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-08T07:11:14.538+0000] {processor.py:186} INFO - Started process (PID=31934) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:11:14.540+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:11:14.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.543+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:11:14.803+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:11:14.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.830+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:11:14.846+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:14.846+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:11:14.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T07:11:44.998+0000] {processor.py:186} INFO - Started process (PID=32003) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:11:45.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:11:45.004+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.003+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:11:45.258+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:11:45.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.287+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:11:45.304+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:11:45.304+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:11:45.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T07:12:16.032+0000] {processor.py:186} INFO - Started process (PID=32072) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:12:16.034+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:12:16.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:12:16.279+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:12:16.311+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:12:16.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:16.326+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:12:16.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T07:12:46.784+0000] {processor.py:186} INFO - Started process (PID=32141) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:12:46.786+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:12:46.790+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:46.790+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:12:47.042+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:12:47.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:47.074+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:12:47.090+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:12:47.090+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:12:47.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T07:13:17.929+0000] {processor.py:186} INFO - Started process (PID=32210) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:13:17.930+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:13:17.934+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:17.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:13:18.183+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:13:18.214+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:18.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:13:18.231+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:18.231+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:13:18.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-08T07:13:48.830+0000] {processor.py:186} INFO - Started process (PID=32279) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:13:48.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:13:48.836+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:48.835+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:13:49.081+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:13:49.112+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:49.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:13:49.129+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:13:49.129+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:13:49.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T07:14:19.435+0000] {processor.py:186} INFO - Started process (PID=32348) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:14:19.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:14:19.440+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:19.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:14:19.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:14:19.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:19.753+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:14:19.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:19.769+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:14:19.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-08T07:14:50.112+0000] {processor.py:186} INFO - Started process (PID=32417) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:14:50.113+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:14:50.116+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.116+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:14:50.394+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:14:50.426+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:14:50.443+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:14:50.443+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:14:50.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-08T07:15:20.633+0000] {processor.py:186} INFO - Started process (PID=32486) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:15:20.635+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:15:20.639+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:20.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:15:20.892+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:15:20.921+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:20.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:15:20.941+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:20.940+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:15:20.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T07:15:51.171+0000] {processor.py:186} INFO - Started process (PID=32555) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:15:51.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:15:51.174+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:15:51.450+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:15:51.481+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:15:51.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:15:51.499+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:15:51.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-08T07:16:22.173+0000] {processor.py:186} INFO - Started process (PID=32624) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:16:22.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:16:22.179+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.178+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:16:22.447+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:16:22.475+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.475+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:16:22.491+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:22.491+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:16:22.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T07:16:52.732+0000] {processor.py:186} INFO - Started process (PID=32693) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:16:52.733+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:16:52.737+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:52.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:16:52.981+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:16:53.013+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:53.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:16:53.030+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:16:53.029+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:16:53.061+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T07:17:23.480+0000] {processor.py:186} INFO - Started process (PID=32762) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:17:23.481+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:17:23.485+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:23.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:17:23.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:17:23.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:23.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:17:23.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:23.786+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:17:23.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T07:17:54.075+0000] {processor.py:186} INFO - Started process (PID=32831) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:17:54.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:17:54.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.080+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:17:54.323+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:17:54.354+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.353+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:17:54.370+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:17:54.369+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:17:54.399+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T07:18:24.947+0000] {processor.py:186} INFO - Started process (PID=32900) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:18:24.948+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:18:24.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:24.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:18:25.199+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:18:25.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:25.230+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:18:25.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:25.246+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:18:25.277+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T07:18:55.912+0000] {processor.py:186} INFO - Started process (PID=32969) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:18:55.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:18:55.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:55.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:18:56.162+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:18:56.194+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:56.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:18:56.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:18:56.209+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:18:56.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T07:19:26.372+0000] {processor.py:186} INFO - Started process (PID=33038) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:19:26.374+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:19:26.378+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:26.377+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:19:26.638+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:19:26.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:26.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:19:26.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:26.688+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:19:26.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T07:19:57.490+0000] {processor.py:186} INFO - Started process (PID=33107) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:19:57.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:19:57.496+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:19:57.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:19:57.769+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.768+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:19:57.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:19:57.786+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:19:57.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T07:20:28.395+0000] {processor.py:186} INFO - Started process (PID=33176) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:20:28.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:20:28.400+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:28.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:20:28.654+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:20:28.684+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:28.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:20:28.702+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:28.702+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:20:28.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T07:20:58.834+0000] {processor.py:186} INFO - Started process (PID=33245) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:20:58.836+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:20:58.840+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:58.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:20:59.130+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:20:59.159+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:59.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:20:59.178+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:20:59.177+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:20:59.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.387 seconds
[2025-04-08T07:21:29.547+0000] {processor.py:186} INFO - Started process (PID=33314) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:21:29.548+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:21:29.552+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:29.552+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:21:29.801+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:21:29.836+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:29.835+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:21:29.852+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:21:29.852+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:21:29.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-08T07:22:00.194+0000] {processor.py:186} INFO - Started process (PID=33383) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:22:00.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:22:00.200+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:22:00.454+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:22:00.489+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:22:00.514+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:00.513+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:22:00.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-08T07:22:31.072+0000] {processor.py:186} INFO - Started process (PID=33452) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:22:31.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:22:31.078+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:22:31.381+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:22:31.580+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:22:31.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:22:31.594+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:22:31.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.557 seconds
[2025-04-08T07:23:01.949+0000] {processor.py:186} INFO - Started process (PID=33521) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:23:01.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:23:01.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:01.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:23:02.370+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:23:02.396+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:02.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:23:02.410+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:02.409+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:23:02.438+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.497 seconds
[2025-04-08T07:23:32.808+0000] {processor.py:186} INFO - Started process (PID=33591) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:23:32.810+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:23:32.814+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:32.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:23:33.267+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:23:33.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:33.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:23:33.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:23:33.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:23:33.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.535 seconds
[2025-04-08T07:24:03.680+0000] {processor.py:186} INFO - Started process (PID=33660) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:24:03.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:24:03.685+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:03.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:24:04.142+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:24:04.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:04.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:24:04.184+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:04.184+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:24:04.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.538 seconds
[2025-04-08T07:24:34.562+0000] {processor.py:186} INFO - Started process (PID=33729) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:24:34.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:24:34.568+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:24:34.815+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:24:34.846+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:24:34.861+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:24:34.861+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:24:34.892+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T07:25:05.487+0000] {processor.py:186} INFO - Started process (PID=33798) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:25:05.489+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:25:05.492+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:05.492+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:25:05.967+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:25:05.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:05.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:25:06.007+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:06.006+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:25:06.036+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.555 seconds
[2025-04-08T07:25:36.212+0000] {processor.py:186} INFO - Started process (PID=33873) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:25:36.213+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:25:36.218+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:25:36.628+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:25:36.656+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.656+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:25:36.670+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:25:36.670+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:25:36.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.494 seconds
[2025-04-08T07:26:07.069+0000] {processor.py:186} INFO - Started process (PID=33942) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:26:07.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:26:07.074+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.074+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:26:07.512+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:26:07.539+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.539+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:26:07.553+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:07.553+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:26:07.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.523 seconds
[2025-04-08T07:26:37.705+0000] {processor.py:186} INFO - Started process (PID=34011) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:26:37.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:26:37.713+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:37.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:26:38.214+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:26:38.249+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:38.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:26:38.267+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:26:38.267+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:26:38.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.599 seconds
[2025-04-08T07:27:08.481+0000] {processor.py:186} INFO - Started process (PID=34081) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:27:08.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:27:08.485+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:08.484+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:27:08.956+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:27:08.988+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:08.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:27:09.003+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:09.002+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:27:09.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.560 seconds
[2025-04-08T07:27:39.290+0000] {processor.py:186} INFO - Started process (PID=34149) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:27:39.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:27:39.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:27:39.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:27:39.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.748+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:27:39.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:27:39.764+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:27:39.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.510 seconds
[2025-04-08T07:28:10.382+0000] {processor.py:186} INFO - Started process (PID=34218) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:28:10.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:28:10.387+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:28:10.798+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:28:10.824+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:28:10.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:10.838+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:28:10.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T07:28:41.307+0000] {processor.py:186} INFO - Started process (PID=34287) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:28:41.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:28:41.311+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.310+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:28:41.712+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:28:41.739+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.738+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:28:41.754+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:28:41.754+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:28:41.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.483 seconds
[2025-04-08T07:29:12.616+0000] {processor.py:186} INFO - Started process (PID=34356) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:29:12.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:29:12.622+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:12.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:29:12.876+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:29:12.906+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:12.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:29:12.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:12.926+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:29:12.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T07:29:43.469+0000] {processor.py:186} INFO - Started process (PID=34425) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:29:43.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:29:43.474+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:29:43.731+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:29:43.761+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:29:43.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:29:43.777+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:29:43.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T07:30:13.988+0000] {processor.py:186} INFO - Started process (PID=34494) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:30:13.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:30:13.992+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:13.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:30:14.237+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:30:14.269+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:14.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:30:14.285+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:14.285+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:30:14.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T07:30:44.476+0000] {processor.py:186} INFO - Started process (PID=34563) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:30:44.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:30:44.481+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:30:44.746+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:30:44.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:30:44.793+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:30:44.793+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:30:44.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-08T07:31:14.927+0000] {processor.py:186} INFO - Started process (PID=34632) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:31:14.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:31:14.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:14.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:31:15.175+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:31:15.202+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:15.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:31:15.217+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:15.217+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:31:15.245+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.325 seconds
[2025-04-08T07:31:45.671+0000] {processor.py:186} INFO - Started process (PID=34701) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:31:45.672+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:31:45.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:45.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:31:45.958+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:31:45.990+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:45.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:31:46.005+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:31:46.005+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:31:46.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-08T07:32:16.265+0000] {processor.py:186} INFO - Started process (PID=34770) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:32:16.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:32:16.270+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:32:16.534+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:32:16.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:32:16.579+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:16.579+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:32:16.609+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T07:32:46.709+0000] {processor.py:186} INFO - Started process (PID=34841) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:32:46.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:32:46.713+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:46.713+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:32:46.979+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:32:47.008+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:47.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:32:47.025+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:32:47.025+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:32:47.052+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-08T07:33:17.782+0000] {processor.py:186} INFO - Started process (PID=34909) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:33:17.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:33:17.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:17.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:33:18.057+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:33:18.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:18.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:33:18.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:18.108+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:33:18.142+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-08T07:33:48.998+0000] {processor.py:186} INFO - Started process (PID=34978) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:33:49.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:33:49.003+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:49.002+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:33:49.254+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:33:49.286+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:49.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:33:49.301+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:33:49.301+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:33:49.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T07:34:19.873+0000] {processor.py:186} INFO - Started process (PID=35047) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:34:19.874+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:34:19.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:19.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:34:20.134+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:34:20.166+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:20.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:34:20.183+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:20.182+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:34:20.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T07:34:50.708+0000] {processor.py:186} INFO - Started process (PID=35116) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:34:50.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:34:50.715+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:50.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:34:50.995+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:34:51.024+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:51.023+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:34:51.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:34:51.040+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:34:51.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-08T07:35:21.413+0000] {processor.py:186} INFO - Started process (PID=35185) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:35:21.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:35:21.418+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:21.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:35:21.665+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:35:21.696+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:21.696+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:35:21.712+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:21.712+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:35:21.742+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T07:35:52.291+0000] {processor.py:186} INFO - Started process (PID=35254) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:35:52.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:35:52.297+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:52.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:35:52.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:35:52.573+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:52.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:35:52.592+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:35:52.592+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:35:52.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T07:36:23.005+0000] {processor.py:186} INFO - Started process (PID=35323) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:36:23.006+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:36:23.010+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:23.010+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:36:23.271+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:36:23.301+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:23.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:36:23.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:23.316+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:36:23.346+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T07:36:53.407+0000] {processor.py:186} INFO - Started process (PID=35392) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:36:53.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:36:53.411+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:53.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:36:53.714+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:36:53.746+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:53.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:36:53.763+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:36:53.763+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:36:53.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T07:37:24.329+0000] {processor.py:186} INFO - Started process (PID=35461) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:37:24.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:37:24.333+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:24.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:37:24.584+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:37:24.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:24.613+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:37:24.629+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:24.629+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:37:24.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-08T07:37:54.796+0000] {processor.py:186} INFO - Started process (PID=35530) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:37:54.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:37:54.800+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:54.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:37:55.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:37:55.083+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:55.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:37:55.103+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:37:55.103+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:37:55.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T07:38:25.283+0000] {processor.py:186} INFO - Started process (PID=35596) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:38:25.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:38:25.286+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:25.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:38:25.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:38:25.596+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:25.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:38:25.614+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:25.614+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:38:25.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-08T07:38:56.497+0000] {processor.py:186} INFO - Started process (PID=35665) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:38:56.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:38:56.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:56.500+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:38:56.762+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:38:56.799+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:56.798+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:38:56.817+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:38:56.816+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:38:56.844+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-08T07:39:27.224+0000] {processor.py:186} INFO - Started process (PID=35733) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:39:27.225+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:39:27.228+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:27.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:39:27.484+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:39:27.517+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:27.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:39:27.533+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:27.533+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:39:27.564+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T07:39:58.344+0000] {processor.py:186} INFO - Started process (PID=35802) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:39:58.345+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:39:58.349+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:58.349+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:39:58.641+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:39:58.674+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:58.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:39:58.694+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:39:58.694+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:39:58.726+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.391 seconds
[2025-04-08T07:40:29.195+0000] {processor.py:186} INFO - Started process (PID=35871) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:40:29.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:40:29.201+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:29.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:40:29.466+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:40:29.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:29.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:40:29.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:40:29.516+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:40:29.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-08T07:41:00.291+0000] {processor.py:186} INFO - Started process (PID=35940) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:41:00.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:41:00.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:00.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:41:00.606+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:41:00.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:00.635+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:41:00.651+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:00.651+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:41:00.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.403 seconds
[2025-04-08T07:41:31.488+0000] {processor.py:186} INFO - Started process (PID=36009) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:41:31.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:41:31.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:31.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:41:31.753+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:41:31.784+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:31.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:41:31.800+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:41:31.800+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:41:31.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T07:42:02.715+0000] {processor.py:186} INFO - Started process (PID=36078) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:42:02.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:42:02.719+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:02.718+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:42:03.078+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:42:03.111+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:03.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:42:03.130+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:03.130+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:42:03.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.456 seconds
[2025-04-08T07:42:33.367+0000] {processor.py:186} INFO - Started process (PID=36147) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:42:33.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:42:33.371+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:33.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:42:33.654+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:42:33.686+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:33.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:42:33.705+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:42:33.704+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:42:33.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-08T07:43:04.008+0000] {processor.py:186} INFO - Started process (PID=36216) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:43:04.009+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:43:04.013+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:04.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:43:04.282+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:43:04.310+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:04.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:43:04.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:04.326+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:43:04.492+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.491 seconds
[2025-04-08T07:43:35.314+0000] {processor.py:186} INFO - Started process (PID=36285) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:43:35.316+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:43:35.320+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:35.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:43:35.592+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:43:35.622+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:35.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:43:35.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:43:35.638+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:43:35.668+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-08T07:44:06.077+0000] {processor.py:186} INFO - Started process (PID=36354) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:44:06.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:44:06.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:06.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:44:06.354+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:44:06.385+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:06.385+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:44:06.402+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:06.401+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:44:06.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T07:44:36.751+0000] {processor.py:186} INFO - Started process (PID=36423) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:44:36.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:44:36.757+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:36.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:44:37.007+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:44:37.034+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:37.033+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:44:37.054+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:44:37.053+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:44:37.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T07:45:07.308+0000] {processor.py:186} INFO - Started process (PID=36492) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:45:07.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:45:07.314+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:07.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:45:07.575+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:45:07.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:07.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:45:07.622+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:07.622+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:45:07.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.502 seconds
[2025-04-08T07:45:38.260+0000] {processor.py:186} INFO - Started process (PID=36561) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:45:38.262+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:45:38.266+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:38.265+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:45:38.538+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:45:38.570+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:38.569+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:45:38.588+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:45:38.587+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:45:38.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-08T07:46:09.481+0000] {processor.py:186} INFO - Started process (PID=36636) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:46:09.482+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:46:09.487+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:09.486+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:46:09.739+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:46:09.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:09.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:46:09.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:09.804+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:46:09.837+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T07:46:40.703+0000] {processor.py:186} INFO - Started process (PID=36705) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:46:40.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:46:40.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:40.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:46:41.135+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:46:41.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:41.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:46:41.176+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:46:41.176+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:46:41.206+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.512 seconds
[2025-04-08T07:47:11.888+0000] {processor.py:186} INFO - Started process (PID=36774) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:47:11.890+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:47:11.894+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:11.893+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:47:12.304+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:47:12.330+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:12.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:47:12.344+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:12.343+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:47:12.370+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-08T07:47:43.204+0000] {processor.py:186} INFO - Started process (PID=36843) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:47:43.205+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:47:43.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:43.209+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:47:43.460+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:47:43.491+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:43.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:47:43.507+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:47:43.506+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:47:43.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T07:48:14.503+0000] {processor.py:186} INFO - Started process (PID=36912) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:48:14.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:48:14.509+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:14.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:48:14.753+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:48:14.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:14.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:48:14.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:14.801+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:48:14.828+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-08T07:48:45.748+0000] {processor.py:186} INFO - Started process (PID=36981) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:48:45.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:48:45.753+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:45.753+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:48:46.180+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:48:46.206+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:46.205+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:48:46.222+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:48:46.221+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:48:46.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.509 seconds
[2025-04-08T07:49:17.194+0000] {processor.py:186} INFO - Started process (PID=37050) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:49:17.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:49:17.200+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:17.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:49:17.485+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:49:17.516+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:17.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:49:17.689+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:17.689+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:49:17.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.531 seconds
[2025-04-08T07:49:48.357+0000] {processor.py:186} INFO - Started process (PID=37119) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:49:48.359+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:49:48.363+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:48.362+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:49:48.799+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:49:48.828+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:48.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:49:48.842+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:49:48.842+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:49:48.866+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.516 seconds
[2025-04-08T07:50:19.155+0000] {processor.py:186} INFO - Started process (PID=37188) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:50:19.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:50:19.161+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:19.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:50:19.562+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:50:19.591+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:19.590+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:50:19.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:19.605+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:50:19.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.480 seconds
[2025-04-08T07:50:49.851+0000] {processor.py:186} INFO - Started process (PID=37257) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:50:49.852+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:50:49.857+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:49.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:50:50.264+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:50:50.291+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:50.291+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:50:50.305+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:50:50.305+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:50:50.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.490 seconds
[2025-04-08T07:51:20.817+0000] {processor.py:186} INFO - Started process (PID=37326) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:51:20.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:51:20.823+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:20.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:51:21.248+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:51:21.275+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:21.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:51:21.288+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:21.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:51:21.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.511 seconds
[2025-04-08T07:51:52.050+0000] {processor.py:186} INFO - Started process (PID=37395) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:51:52.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:51:52.056+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:52.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:51:52.497+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:51:52.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:52.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:51:52.537+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:51:52.537+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:51:52.563+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.519 seconds
[2025-04-08T07:52:23.467+0000] {processor.py:186} INFO - Started process (PID=37464) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:52:23.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:52:23.472+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:23.472+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:52:23.875+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:52:23.904+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:23.904+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:52:23.918+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:23.918+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:52:23.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-08T07:52:54.848+0000] {processor.py:186} INFO - Started process (PID=37533) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:52:54.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:52:54.855+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:54.854+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:52:55.129+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:52:55.159+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:55.159+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:52:55.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:52:55.175+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:52:55.208+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-08T07:53:26.054+0000] {processor.py:186} INFO - Started process (PID=37602) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:53:26.056+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:53:26.060+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:26.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:53:26.327+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:53:26.357+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:26.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:53:26.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:26.374+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:53:26.406+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-08T07:53:57.205+0000] {processor.py:186} INFO - Started process (PID=37671) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:53:57.206+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:53:57.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:57.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:53:57.466+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:53:57.496+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:57.496+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:53:57.515+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:53:57.515+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:53:57.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T07:54:27.866+0000] {processor.py:186} INFO - Started process (PID=37740) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:54:27.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:54:27.871+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:27.871+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:54:28.140+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:54:28.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:28.171+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:54:28.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:28.188+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:54:28.219+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-08T07:54:59.106+0000] {processor.py:186} INFO - Started process (PID=37809) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:54:59.108+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:54:59.112+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:59.111+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:54:59.382+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:54:59.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:59.412+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:54:59.428+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:54:59.428+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:54:59.459+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-08T07:55:30.431+0000] {processor.py:186} INFO - Started process (PID=37879) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:55:30.433+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:55:30.437+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:30.436+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:55:30.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:55:30.714+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:30.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:55:30.730+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:55:30.729+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:55:30.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-08T07:56:01.471+0000] {processor.py:186} INFO - Started process (PID=37948) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:56:01.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:56:01.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:01.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:56:01.752+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:56:01.784+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:01.783+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:56:01.800+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:01.800+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:56:01.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T07:56:32.704+0000] {processor.py:186} INFO - Started process (PID=38017) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:56:32.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:56:32.710+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:32.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:56:32.976+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:56:33.005+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:33.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:56:33.023+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:56:33.023+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:56:33.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-08T07:57:03.854+0000] {processor.py:186} INFO - Started process (PID=38086) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:57:03.856+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:57:03.859+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:03.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:57:04.177+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:57:04.213+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:04.212+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:57:04.230+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:04.229+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:57:04.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.418 seconds
[2025-04-08T07:57:35.134+0000] {processor.py:186} INFO - Started process (PID=38155) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:57:35.135+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:57:35.139+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:35.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:57:35.382+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:57:35.411+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:35.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:57:35.430+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:57:35.430+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:57:35.460+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-08T07:58:06.123+0000] {processor.py:186} INFO - Started process (PID=38224) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:58:06.124+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:58:06.127+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:06.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:58:06.376+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:58:06.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:06.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:58:06.422+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:06.422+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:58:06.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T07:58:36.585+0000] {processor.py:186} INFO - Started process (PID=38293) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:58:36.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:58:36.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:36.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:58:36.833+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:58:36.863+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:36.862+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:58:36.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:58:36.878+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:58:36.908+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T07:59:06.979+0000] {processor.py:186} INFO - Started process (PID=38362) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:59:06.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:59:06.983+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:06.983+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:59:07.219+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:59:07.246+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:07.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:59:07.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:07.261+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:59:07.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.317 seconds
[2025-04-08T07:59:37.816+0000] {processor.py:186} INFO - Started process (PID=38431) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:59:37.818+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T07:59:37.821+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:37.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:59:38.070+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T07:59:38.100+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:38.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T07:59:38.116+0000] {logging_mixin.py:190} INFO - [2025-04-08T07:59:38.116+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T07:59:38.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T08:00:08.473+0000] {processor.py:186} INFO - Started process (PID=38500) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:00:08.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:00:08.478+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:08.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:00:08.730+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:00:08.765+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:08.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:00:08.782+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:08.782+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:00:08.816+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T08:00:39.556+0000] {processor.py:186} INFO - Started process (PID=38569) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:00:39.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:00:39.562+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:39.562+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:00:39.821+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:00:39.851+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:39.850+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:00:39.869+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:00:39.869+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:00:39.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-08T08:01:10.346+0000] {processor.py:186} INFO - Started process (PID=38638) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:01:10.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:01:10.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:10.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:01:10.630+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:01:10.660+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:10.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:01:10.683+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:10.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:01:10.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-08T08:01:40.876+0000] {processor.py:186} INFO - Started process (PID=38713) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:01:40.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:01:40.882+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:40.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:01:41.132+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:01:41.164+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:41.164+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:01:41.180+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:01:41.180+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:01:41.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T08:02:11.724+0000] {processor.py:186} INFO - Started process (PID=38782) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:02:11.725+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:02:11.728+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:11.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:02:11.973+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:02:12.005+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:12.005+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:02:12.021+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:12.021+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:02:12.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T08:02:42.158+0000] {processor.py:186} INFO - Started process (PID=38851) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:02:42.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:02:42.162+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:42.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:02:42.414+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:02:42.444+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:42.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:02:42.459+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:02:42.459+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:02:42.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T08:03:12.671+0000] {processor.py:186} INFO - Started process (PID=38920) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:03:12.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:03:12.675+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:12.675+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:03:12.938+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:03:12.973+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:12.973+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:03:12.992+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:12.991+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:03:13.034+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-08T08:03:43.251+0000] {processor.py:186} INFO - Started process (PID=38989) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:03:43.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:03:43.257+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:43.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:03:43.514+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:03:43.544+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:43.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:03:43.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:03:43.561+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:03:43.594+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T08:04:14.177+0000] {processor.py:186} INFO - Started process (PID=39058) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:04:14.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:04:14.182+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:14.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:04:14.447+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:04:14.477+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:14.477+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:04:14.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:14.493+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:04:14.518+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T08:04:45.136+0000] {processor.py:186} INFO - Started process (PID=39127) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:04:45.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:04:45.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:45.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:04:45.409+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:04:45.437+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:45.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:04:45.455+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:04:45.455+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:04:45.483+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T08:05:16.059+0000] {processor.py:186} INFO - Started process (PID=39196) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:05:16.060+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:05:16.063+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:16.063+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:05:16.314+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:05:16.346+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:16.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:05:16.362+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:16.362+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:05:16.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T08:05:46.778+0000] {processor.py:186} INFO - Started process (PID=39265) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:05:46.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:05:46.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:46.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:05:47.042+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:05:47.073+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:47.073+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:05:47.089+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:05:47.089+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:05:47.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-08T08:06:17.291+0000] {processor.py:186} INFO - Started process (PID=39334) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:06:17.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:06:17.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:17.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:06:17.583+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:06:17.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:17.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:06:17.789+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:17.789+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:06:17.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.530 seconds
[2025-04-08T08:06:48.155+0000] {processor.py:186} INFO - Started process (PID=39403) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:06:48.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:06:48.161+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:48.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:06:48.572+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:06:48.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:48.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:06:48.613+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:06:48.613+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:06:48.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.494 seconds
[2025-04-08T08:07:18.777+0000] {processor.py:186} INFO - Started process (PID=39472) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:07:18.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:07:18.783+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:18.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:07:19.033+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:07:19.064+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:19.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:07:19.084+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:19.084+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:07:19.116+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-08T08:07:49.633+0000] {processor.py:186} INFO - Started process (PID=39541) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:07:49.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:07:49.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:49.638+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:07:49.886+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:07:49.917+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:49.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:07:49.933+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:07:49.932+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:07:49.964+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-08T08:08:20.355+0000] {processor.py:186} INFO - Started process (PID=39610) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:08:20.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:08:20.360+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:20.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:08:20.599+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:08:20.629+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:20.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:08:20.645+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:20.644+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:08:20.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T08:08:51.021+0000] {processor.py:186} INFO - Started process (PID=39679) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:08:51.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:08:51.026+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:51.025+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:08:51.281+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:08:51.312+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:51.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:08:51.328+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:08:51.327+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:08:51.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T08:09:21.849+0000] {processor.py:186} INFO - Started process (PID=39748) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:09:21.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:09:21.854+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:21.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:09:22.107+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:09:22.136+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:22.136+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:09:22.151+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:22.151+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:09:22.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T08:09:52.573+0000] {processor.py:186} INFO - Started process (PID=39817) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:09:52.574+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:09:52.578+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:52.577+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:09:52.996+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:09:53.022+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:53.022+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:09:53.038+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:09:53.038+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:09:53.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.499 seconds
[2025-04-08T08:10:23.167+0000] {processor.py:186} INFO - Started process (PID=39886) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:10:23.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:10:23.172+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:23.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:10:23.428+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:10:23.457+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:23.457+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:10:23.637+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:23.637+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:10:23.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.508 seconds
[2025-04-08T08:10:54.311+0000] {processor.py:186} INFO - Started process (PID=39955) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:10:54.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:10:54.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:54.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:10:54.569+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:10:54.599+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:54.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:10:54.768+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:10:54.768+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:10:54.798+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.493 seconds
[2025-04-08T08:11:25.088+0000] {processor.py:186} INFO - Started process (PID=40024) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:11:25.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:11:25.093+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:25.092+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:11:25.362+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:11:25.546+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:25.546+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:11:25.560+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:25.560+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:11:25.589+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.509 seconds
[2025-04-08T08:11:56.192+0000] {processor.py:186} INFO - Started process (PID=40093) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:11:56.194+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:11:56.197+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:56.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:11:56.612+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:11:56.639+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:56.639+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:11:56.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:11:56.653+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:11:56.682+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.496 seconds
[2025-04-08T08:12:27.188+0000] {processor.py:186} INFO - Started process (PID=40162) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:12:27.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:12:27.193+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:27.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:12:27.601+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:12:27.630+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:27.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:12:27.645+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:27.645+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:12:27.677+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T08:12:57.950+0000] {processor.py:186} INFO - Started process (PID=40232) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:12:57.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:12:57.956+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:57.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:12:58.374+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:12:58.401+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:58.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:12:58.416+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:12:58.415+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:12:58.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.510 seconds
[2025-04-08T08:13:28.640+0000] {processor.py:186} INFO - Started process (PID=40301) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:13:28.641+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:13:28.644+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:28.644+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:13:28.938+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:13:28.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:28.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:13:28.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:28.983+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:13:29.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-08T08:13:59.175+0000] {processor.py:186} INFO - Started process (PID=40371) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:13:59.177+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:13:59.181+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:59.181+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:13:59.429+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:13:59.460+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:59.460+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:13:59.476+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:13:59.476+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:13:59.506+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-08T08:14:29.900+0000] {processor.py:186} INFO - Started process (PID=40440) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:14:29.902+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:14:29.906+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:29.906+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:14:30.158+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:14:30.188+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:30.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:14:30.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:14:30.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:14:30.234+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T08:15:00.530+0000] {processor.py:186} INFO - Started process (PID=40509) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:15:00.531+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:15:00.535+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:00.534+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:15:00.802+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:15:00.832+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:00.831+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:15:00.849+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:00.849+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:15:00.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-08T08:15:31.052+0000] {processor.py:186} INFO - Started process (PID=40578) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:15:31.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:15:31.057+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:31.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:15:31.301+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:15:31.330+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:31.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:15:31.346+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:15:31.346+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:15:31.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T08:16:02.113+0000] {processor.py:186} INFO - Started process (PID=40647) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:16:02.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:16:02.119+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:02.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:16:02.374+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:16:02.404+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:02.403+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:16:02.420+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:02.419+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:16:02.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T08:16:32.695+0000] {processor.py:186} INFO - Started process (PID=40716) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:16:32.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:16:32.701+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:32.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:16:32.949+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:16:32.979+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:32.979+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:16:32.998+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:16:32.998+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:16:33.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-08T08:17:03.400+0000] {processor.py:186} INFO - Started process (PID=40785) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:17:03.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:17:03.405+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:03.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:17:03.689+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:17:03.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:03.726+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:17:03.745+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:03.744+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:17:03.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.385 seconds
[2025-04-08T08:17:34.216+0000] {processor.py:186} INFO - Started process (PID=40854) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:17:34.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:17:34.221+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:34.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:17:34.486+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:17:34.520+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:34.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:17:34.539+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:17:34.539+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:17:34.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T08:18:04.636+0000] {processor.py:186} INFO - Started process (PID=40923) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:18:04.637+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:18:04.640+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:04.640+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:18:04.885+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:18:04.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:04.913+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:18:04.931+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:04.931+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:18:04.960+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T08:18:35.285+0000] {processor.py:186} INFO - Started process (PID=40992) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:18:35.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:18:35.290+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:35.289+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:18:35.561+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:18:35.596+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:35.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:18:35.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:18:35.612+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:18:35.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-08T08:19:05.829+0000] {processor.py:186} INFO - Started process (PID=41062) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:19:05.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:19:05.833+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:05.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:19:06.095+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:19:06.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:06.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:19:06.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:06.141+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:19:06.171+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T08:19:36.331+0000] {processor.py:186} INFO - Started process (PID=41130) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:19:36.332+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:19:36.335+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:36.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:19:36.591+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:19:36.619+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:36.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:19:36.635+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:19:36.634+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:19:36.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-08T08:20:06.753+0000] {processor.py:186} INFO - Started process (PID=41197) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:20:06.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:20:06.757+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:06.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:20:07.012+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:20:07.040+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:07.039+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:20:07.056+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:07.056+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:20:07.087+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-08T08:20:37.339+0000] {processor.py:186} INFO - Started process (PID=41264) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:20:37.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:20:37.343+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:37.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:20:37.595+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:20:37.626+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:37.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:20:37.643+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:20:37.643+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:20:37.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-08T08:21:07.766+0000] {processor.py:186} INFO - Started process (PID=41334) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:21:07.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:21:07.770+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:07.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:21:08.005+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:21:08.032+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:08.031+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:21:08.047+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:08.046+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:21:08.075+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-08T08:21:38.773+0000] {processor.py:186} INFO - Started process (PID=41403) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:21:38.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:21:38.778+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:38.778+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:21:39.010+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:21:39.037+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:39.037+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:21:39.052+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:21:39.052+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:21:39.082+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.318 seconds
[2025-04-08T08:22:09.297+0000] {processor.py:186} INFO - Started process (PID=41472) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:22:09.298+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:22:09.301+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:09.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:22:09.568+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:22:09.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:09.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:22:09.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:09.611+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:22:09.642+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T08:22:39.848+0000] {processor.py:186} INFO - Started process (PID=41543) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:22:39.849+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:22:39.852+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:39.852+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:22:40.113+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:22:40.143+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:40.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:22:40.168+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:22:40.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:22:40.278+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.437 seconds
[2025-04-08T08:23:10.466+0000] {processor.py:186} INFO - Started process (PID=41610) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:23:10.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:23:10.470+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:10.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:23:10.734+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:23:10.760+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:10.760+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:23:10.775+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:10.775+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:23:10.803+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T08:23:41.074+0000] {processor.py:186} INFO - Started process (PID=41679) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:23:41.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:23:41.079+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:41.079+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:23:41.352+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:23:41.381+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:41.381+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:23:41.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:23:41.397+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:23:41.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-08T08:24:12.120+0000] {processor.py:186} INFO - Started process (PID=41748) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:24:12.122+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:24:12.125+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:12.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:24:12.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:24:12.454+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:12.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:24:12.471+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:12.471+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:24:12.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.391 seconds
[2025-04-08T08:24:42.748+0000] {processor.py:186} INFO - Started process (PID=41817) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:24:42.749+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:24:42.752+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:42.752+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:24:43.041+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:24:43.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:43.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:24:43.086+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:24:43.086+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:24:43.113+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.374 seconds
[2025-04-08T08:25:13.351+0000] {processor.py:186} INFO - Started process (PID=41886) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:25:13.353+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:25:13.356+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:13.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:25:13.642+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:25:13.683+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:13.683+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:25:13.706+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:13.706+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:25:13.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.392 seconds
[2025-04-08T08:25:43.880+0000] {processor.py:186} INFO - Started process (PID=41963) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:25:43.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:25:43.884+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:43.884+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:25:44.119+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:25:44.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:44.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:25:44.162+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:25:44.161+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:25:44.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-08T08:26:14.356+0000] {processor.py:186} INFO - Started process (PID=42032) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:26:14.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:26:14.359+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:14.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:26:14.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:26:14.612+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:14.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:26:14.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:14.631+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:26:14.662+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.313 seconds
[2025-04-08T08:26:45.615+0000] {processor.py:186} INFO - Started process (PID=42101) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:26:45.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:26:45.619+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:45.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:26:45.857+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:26:45.884+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:45.884+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:26:45.900+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:26:45.900+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:26:45.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-08T08:27:16.862+0000] {processor.py:186} INFO - Started process (PID=42171) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:27:16.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:27:16.867+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:16.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:27:17.101+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:27:17.129+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:17.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:27:17.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:17.145+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:27:17.173+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.320 seconds
[2025-04-08T08:27:47.936+0000] {processor.py:186} INFO - Started process (PID=42240) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:27:47.937+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:27:47.940+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:47.939+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:27:48.176+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:27:48.203+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:48.202+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:27:48.219+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:27:48.219+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:27:48.246+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.317 seconds
[2025-04-08T08:28:18.906+0000] {processor.py:186} INFO - Started process (PID=42309) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:28:18.907+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:28:18.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:18.910+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:28:19.143+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:28:19.176+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:19.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:28:19.196+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:19.196+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:28:19.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T08:28:50.030+0000] {processor.py:186} INFO - Started process (PID=42378) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:28:50.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:28:50.034+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:50.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:28:50.283+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:28:50.310+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:50.310+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:28:50.325+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:28:50.325+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:28:50.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T08:29:20.492+0000] {processor.py:186} INFO - Started process (PID=42447) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:29:20.493+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:29:20.495+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:20.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:29:20.738+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:29:20.765+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:20.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:29:20.780+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:20.780+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:29:20.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T08:29:51.752+0000] {processor.py:186} INFO - Started process (PID=42516) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:29:51.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:29:51.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:51.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:29:52.015+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:29:52.045+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:52.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:29:52.061+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:29:52.061+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:29:52.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T08:30:22.904+0000] {processor.py:186} INFO - Started process (PID=42585) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:30:22.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:30:22.910+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:22.909+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:30:23.178+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:30:23.209+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:23.208+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:30:23.228+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:23.228+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:30:23.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-08T08:30:53.363+0000] {processor.py:186} INFO - Started process (PID=42654) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:30:53.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:30:53.368+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:53.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:30:53.703+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:30:53.733+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:53.732+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:30:53.749+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:30:53.748+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:30:53.835+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.479 seconds
[2025-04-08T08:31:24.496+0000] {processor.py:186} INFO - Started process (PID=42723) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:31:24.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:31:24.501+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:24.501+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:31:24.754+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:31:24.784+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:24.784+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:31:24.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:24.801+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:31:24.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T08:31:54.994+0000] {processor.py:186} INFO - Started process (PID=42792) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:31:54.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:31:54.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:54.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:31:55.250+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:31:55.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:55.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:31:55.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:31:55.295+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:31:55.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T08:32:25.923+0000] {processor.py:186} INFO - Started process (PID=42861) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:32:25.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:32:25.932+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:25.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:32:26.191+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:32:26.220+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:26.220+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:32:26.241+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:26.241+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:32:26.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-08T08:32:56.384+0000] {processor.py:186} INFO - Started process (PID=42930) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:32:56.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:32:56.389+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:56.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:32:56.631+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:32:56.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:56.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:32:56.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:32:56.678+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:32:56.709+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T08:33:26.782+0000] {processor.py:186} INFO - Started process (PID=42999) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:33:26.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:33:26.786+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:26.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:33:27.015+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:33:27.044+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:27.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:33:27.058+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:27.058+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:33:27.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.310 seconds
[2025-04-08T08:33:57.405+0000] {processor.py:186} INFO - Started process (PID=43068) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:33:57.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:33:57.409+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:57.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:33:57.646+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:33:57.676+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:57.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:33:57.693+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:33:57.693+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:33:57.722+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-08T08:34:28.653+0000] {processor.py:186} INFO - Started process (PID=43137) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:34:28.654+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:34:28.657+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:28.656+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:34:28.932+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:34:29.109+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:29.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:34:29.123+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:34:29.123+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:34:29.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.504 seconds
[2025-04-08T08:35:00.206+0000] {processor.py:186} INFO - Started process (PID=43207) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:35:00.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:35:00.210+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:00.210+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:35:00.599+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:35:00.633+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:00.632+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:35:00.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:00.649+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:35:00.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.482 seconds
[2025-04-08T08:35:31.527+0000] {processor.py:186} INFO - Started process (PID=43276) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:35:31.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:35:31.532+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:31.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:35:31.953+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:35:31.981+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:31.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:35:31.994+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:35:31.994+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:35:32.024+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.505 seconds
[2025-04-08T08:36:02.833+0000] {processor.py:186} INFO - Started process (PID=43345) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:36:02.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:36:02.839+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:02.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:36:03.337+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:36:03.374+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:03.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:36:03.388+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:03.388+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:36:03.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.588 seconds
[2025-04-08T08:36:34.037+0000] {processor.py:186} INFO - Started process (PID=43413) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:36:34.038+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:36:34.041+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:34.041+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:36:34.459+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:36:34.484+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:34.483+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:36:34.497+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:36:34.497+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:36:34.526+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.496 seconds
[2025-04-08T08:37:05.550+0000] {processor.py:186} INFO - Started process (PID=43482) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:37:05.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:37:05.555+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:05.555+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:37:05.829+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:37:05.856+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:05.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:37:05.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:05.872+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:37:05.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-08T08:37:36.056+0000] {processor.py:186} INFO - Started process (PID=43543) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:37:36.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:37:36.060+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:36.059+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:37:36.344+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:37:36.373+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:36.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:37:36.389+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:37:36.389+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:37:36.420+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.374 seconds
[2025-04-08T08:38:07.333+0000] {processor.py:186} INFO - Started process (PID=43612) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:38:07.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:38:07.337+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:07.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:38:07.745+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:38:07.771+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:07.770+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:38:07.787+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:07.787+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:38:07.815+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.491 seconds
[2025-04-08T08:38:38.155+0000] {processor.py:186} INFO - Started process (PID=43681) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:38:38.156+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:38:38.159+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:38.158+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:38:38.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:38:38.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:38.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:38:38.608+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:38:38.608+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:38:38.635+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.488 seconds
[2025-04-08T08:39:08.969+0000] {processor.py:186} INFO - Started process (PID=43750) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:39:08.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:39:08.973+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:08.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:39:09.371+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:39:09.398+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:09.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:39:09.413+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:09.412+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:39:09.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.482 seconds
[2025-04-08T08:39:39.656+0000] {processor.py:186} INFO - Started process (PID=43819) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:39:39.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:39:39.660+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:39.659+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:39:40.085+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:39:40.112+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:40.111+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:39:40.126+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:39:40.126+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:39:40.157+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.508 seconds
[2025-04-08T08:40:10.389+0000] {processor.py:186} INFO - Started process (PID=43888) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:40:10.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:40:10.393+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:10.393+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:40:10.654+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:40:10.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:10.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:40:10.709+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:10.708+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:40:10.741+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-08T08:40:40.888+0000] {processor.py:186} INFO - Started process (PID=43958) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:40:40.889+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:40:40.892+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:40.891+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:40:41.156+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:40:41.182+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:41.182+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:40:41.198+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:40:41.197+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:40:41.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-08T08:41:11.280+0000] {processor.py:186} INFO - Started process (PID=44029) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:41:11.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:41:11.284+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:11.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:41:11.519+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:41:11.546+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:11.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:41:11.561+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:11.561+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:41:11.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.319 seconds
[2025-04-08T08:41:41.869+0000] {processor.py:186} INFO - Started process (PID=44098) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:41:41.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:41:41.873+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:41.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:41:42.116+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:41:42.142+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:42.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:41:42.155+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:41:42.155+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:41:42.279+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.417 seconds
[2025-04-08T08:42:13.215+0000] {processor.py:186} INFO - Started process (PID=44167) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:42:13.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:42:13.220+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:13.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:42:13.719+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:42:13.777+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:13.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:42:13.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:13.810+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:42:13.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.757 seconds
[2025-04-08T08:42:44.554+0000] {processor.py:186} INFO - Started process (PID=44236) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:42:44.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:42:44.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:44.559+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:42:44.849+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:42:44.879+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:44.878+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:42:44.898+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:42:44.898+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:42:44.927+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-08T08:43:15.949+0000] {processor.py:186} INFO - Started process (PID=44305) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:43:15.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:43:15.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:15.953+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:43:16.270+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:43:16.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:16.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:43:16.315+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:16.315+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:43:16.345+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.405 seconds
[2025-04-08T08:43:47.344+0000] {processor.py:186} INFO - Started process (PID=44380) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:43:47.346+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:43:47.351+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:47.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:43:47.592+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:43:47.623+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:47.622+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:43:47.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:43:47.638+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:43:47.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T08:44:17.752+0000] {processor.py:186} INFO - Started process (PID=44449) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:44:17.754+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:44:17.758+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:17.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:44:18.040+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:44:18.069+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:18.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:44:18.087+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:18.087+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:44:18.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-08T08:44:48.539+0000] {processor.py:186} INFO - Started process (PID=44519) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:44:48.541+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:44:48.545+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:48.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:44:48.795+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:44:48.826+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:48.825+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:44:48.841+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:44:48.841+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:44:48.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T08:45:19.136+0000] {processor.py:186} INFO - Started process (PID=44588) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:45:19.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:45:19.141+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:45:19.389+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:45:19.419+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.418+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:45:19.434+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:19.434+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:45:19.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T08:45:50.088+0000] {processor.py:186} INFO - Started process (PID=44656) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:45:50.089+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:45:50.093+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.093+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:45:50.338+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:45:50.367+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:45:50.382+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:45:50.382+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:45:50.412+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-08T08:46:20.645+0000] {processor.py:186} INFO - Started process (PID=44725) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:46:20.647+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:46:20.652+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:20.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:46:20.892+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:46:20.920+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:20.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:46:20.936+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:20.935+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:46:20.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-08T08:46:51.982+0000] {processor.py:186} INFO - Started process (PID=44794) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:46:51.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:46:51.987+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:51.987+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:46:52.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:46:52.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:52.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:46:52.278+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:46:52.278+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:46:52.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-08T08:47:23.318+0000] {processor.py:186} INFO - Started process (PID=44863) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:47:23.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:47:23.323+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:23.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:47:23.567+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:47:23.598+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:23.598+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:47:23.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:23.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:47:23.645+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-08T08:47:54.217+0000] {processor.py:186} INFO - Started process (PID=44932) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:47:54.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:47:54.222+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.222+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:47:54.465+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:47:54.493+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:47:54.508+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:47:54.507+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:47:54.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T08:48:25.464+0000] {processor.py:186} INFO - Started process (PID=45001) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:48:25.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:48:25.469+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:25.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:48:25.765+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:48:25.801+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:25.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:48:25.819+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:25.819+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:48:25.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.397 seconds
[2025-04-08T08:48:56.306+0000] {processor.py:186} INFO - Started process (PID=45070) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:48:56.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:48:56.312+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:56.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:48:56.552+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:48:56.583+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:56.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:48:56.598+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:48:56.598+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:48:56.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T08:49:26.704+0000] {processor.py:186} INFO - Started process (PID=45139) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:49:26.705+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:49:26.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:26.708+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:49:27.043+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:49:27.079+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:27.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:49:27.102+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:27.102+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:49:27.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.444 seconds
[2025-04-08T08:49:57.496+0000] {processor.py:186} INFO - Started process (PID=45208) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:49:57.498+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:49:57.502+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:57.502+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:49:57.758+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:49:57.793+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:57.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:49:57.811+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:49:57.810+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:49:57.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T08:50:27.980+0000] {processor.py:186} INFO - Started process (PID=45277) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:50:27.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:50:27.984+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:27.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:50:28.263+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:50:28.299+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:28.299+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:50:28.323+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:28.323+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:50:28.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-08T08:50:58.980+0000] {processor.py:186} INFO - Started process (PID=45346) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:50:58.981+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:50:58.985+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:58.984+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:50:59.229+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:50:59.261+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:59.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:50:59.278+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:50:59.278+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:50:59.309+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-08T08:51:29.960+0000] {processor.py:186} INFO - Started process (PID=45415) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:51:29.962+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:51:29.966+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:29.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:51:30.272+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:51:30.313+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:30.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:51:30.332+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:51:30.332+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:51:30.367+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-08T08:52:00.517+0000] {processor.py:186} INFO - Started process (PID=45484) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:52:00.519+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:52:00.523+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:00.522+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:52:00.781+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:52:00.817+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:00.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:52:00.836+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:00.836+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:52:00.870+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-08T08:52:31.381+0000] {processor.py:186} INFO - Started process (PID=45553) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:52:31.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:52:31.387+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:31.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:52:31.671+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:52:31.704+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:31.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:52:31.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:52:31.722+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:52:31.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-08T08:53:02.058+0000] {processor.py:186} INFO - Started process (PID=45622) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:53:02.059+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:53:02.062+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:53:02.328+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:53:02.358+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:53:02.373+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:02.372+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:53:02.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-08T08:53:33.358+0000] {processor.py:186} INFO - Started process (PID=45691) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:53:33.360+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:53:33.364+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.363+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:53:33.686+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:53:33.722+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:53:33.741+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:53:33.740+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:53:33.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.425 seconds
[2025-04-08T08:54:04.218+0000] {processor.py:186} INFO - Started process (PID=45760) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:54:04.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:54:04.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:54:04.547+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:54:04.582+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.582+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:54:04.600+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:04.600+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:54:04.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.422 seconds
[2025-04-08T08:54:34.946+0000] {processor.py:186} INFO - Started process (PID=45829) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:54:34.947+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:54:34.952+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:34.951+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:54:35.286+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:54:35.320+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:35.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:54:35.339+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:54:35.338+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:54:35.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.434 seconds
[2025-04-08T08:55:05.470+0000] {processor.py:186} INFO - Started process (PID=45898) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:55:05.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:55:05.475+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.475+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:55:05.735+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:55:05.765+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.764+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:55:05.781+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:05.780+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:55:05.813+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-08T08:55:36.169+0000] {processor.py:186} INFO - Started process (PID=45967) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:55:36.171+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:55:36.174+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.174+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:55:36.504+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:55:36.538+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:55:36.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:55:36.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:55:36.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.434 seconds
[2025-04-08T08:56:06.702+0000] {processor.py:186} INFO - Started process (PID=46036) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:56:06.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:56:06.708+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:06.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:56:06.971+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:56:07.001+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:07.001+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:56:07.017+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:07.017+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:56:07.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-08T08:56:37.396+0000] {processor.py:186} INFO - Started process (PID=46105) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:56:37.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:56:37.401+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:56:37.690+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:56:37.726+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:56:37.750+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:56:37.750+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:56:37.779+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.390 seconds
[2025-04-08T08:57:07.954+0000] {processor.py:186} INFO - Started process (PID=46174) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:57:07.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:57:07.960+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:07.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:57:08.221+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:57:08.254+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:08.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:57:08.270+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:08.269+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:57:08.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-08T08:57:38.406+0000] {processor.py:186} INFO - Started process (PID=46242) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:57:38.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:57:38.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:38.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:57:38.733+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:57:38.776+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:38.775+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:57:38.796+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:57:38.796+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:57:38.830+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.433 seconds
[2025-04-08T08:58:09.384+0000] {processor.py:186} INFO - Started process (PID=46311) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:58:09.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:58:09.390+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:09.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:58:09.678+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:58:09.712+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:09.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:58:09.729+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:09.728+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:58:09.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.388 seconds
[2025-04-08T08:58:40.242+0000] {processor.py:186} INFO - Started process (PID=46380) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:58:40.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:58:40.247+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:40.247+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:58:40.539+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:58:40.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:40.571+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:58:40.589+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:58:40.589+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:58:40.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.385 seconds
[2025-04-08T08:59:11.273+0000] {processor.py:186} INFO - Started process (PID=46449) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:59:11.275+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:59:11.279+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:11.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:59:11.563+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:59:11.594+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:11.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:59:11.610+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:11.610+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:59:11.643+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-08T08:59:42.254+0000] {processor.py:186} INFO - Started process (PID=46517) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:59:42.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T08:59:42.260+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:42.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:59:42.561+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T08:59:42.596+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:42.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T08:59:42.616+0000] {logging_mixin.py:190} INFO - [2025-04-08T08:59:42.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T08:59:42.650+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.405 seconds
[2025-04-08T09:00:12.993+0000] {processor.py:186} INFO - Started process (PID=46586) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:00:12.995+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:00:12.999+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:12.998+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:00:13.263+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:00:13.293+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:13.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:00:13.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:13.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:00:13.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T09:00:43.913+0000] {processor.py:186} INFO - Started process (PID=46655) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:00:43.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:00:43.919+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:43.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:00:44.213+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:00:44.243+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:44.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:00:44.259+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:00:44.259+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:00:44.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.387 seconds
[2025-04-08T09:01:15.026+0000] {processor.py:186} INFO - Started process (PID=46724) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:01:15.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:01:15.030+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.030+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:01:15.331+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:01:15.361+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:01:15.379+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:15.379+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:01:15.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T09:01:45.553+0000] {processor.py:186} INFO - Started process (PID=46793) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:01:45.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:01:45.559+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:45.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:01:45.826+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:01:45.862+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:45.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:01:45.915+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:01:45.914+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:01:45.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.400 seconds
[2025-04-08T09:02:16.636+0000] {processor.py:186} INFO - Started process (PID=46862) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:02:16.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:02:16.641+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:16.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:02:16.889+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:02:16.919+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:16.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:02:16.936+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:16.936+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:02:17.128+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.500 seconds
[2025-04-08T09:02:47.425+0000] {processor.py:186} INFO - Started process (PID=46933) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:02:47.426+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:02:47.429+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.428+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:02:47.727+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:02:47.762+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:02:47.781+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:02:47.781+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:02:47.810+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-08T09:03:18.191+0000] {processor.py:186} INFO - Started process (PID=47002) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:03:18.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:03:18.197+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:18.196+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:03:18.505+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:03:18.551+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:18.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:03:18.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:18.570+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:03:18.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-08T09:03:48.848+0000] {processor.py:186} INFO - Started process (PID=47076) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:03:48.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:03:48.853+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:48.853+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:03:49.130+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:03:49.163+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:49.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:03:49.395+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:03:49.395+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:03:49.424+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.583 seconds
[2025-04-08T09:04:19.989+0000] {processor.py:186} INFO - Started process (PID=47146) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:04:19.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:04:19.993+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:19.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:04:20.277+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:04:20.310+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:20.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:04:20.327+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:20.326+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:04:20.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-08T09:04:50.496+0000] {processor.py:186} INFO - Started process (PID=47214) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:04:50.497+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:04:50.500+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:50.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:04:50.757+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:04:50.943+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:50.943+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:04:50.958+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:04:50.957+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:04:50.986+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.497 seconds
[2025-04-08T09:05:21.305+0000] {processor.py:186} INFO - Started process (PID=47283) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:05:21.306+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:05:21.309+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:21.308+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:05:21.734+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:05:21.762+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:21.761+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:05:21.785+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:21.784+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:05:21.814+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.516 seconds
[2025-04-08T09:05:51.949+0000] {processor.py:186} INFO - Started process (PID=47351) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:05:51.950+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:05:51.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:51.954+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:05:52.453+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:05:52.482+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:52.481+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:05:52.497+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:05:52.497+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:05:52.531+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.590 seconds
[2025-04-08T09:06:23.022+0000] {processor.py:186} INFO - Started process (PID=47420) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:06:23.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:06:23.028+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:23.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:06:23.542+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:06:23.567+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:23.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:06:23.581+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:23.581+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:06:23.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.591 seconds
[2025-04-08T09:06:54.142+0000] {processor.py:186} INFO - Started process (PID=47489) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:06:54.143+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:06:54.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:54.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:06:54.552+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:06:54.577+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:54.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:06:54.591+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:06:54.591+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:06:54.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.484 seconds
[2025-04-08T09:07:24.799+0000] {processor.py:186} INFO - Started process (PID=47557) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:07:24.800+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:07:24.804+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:24.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:07:25.272+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:07:25.299+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:25.298+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:07:25.313+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:25.313+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:07:25.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.549 seconds
[2025-04-08T09:07:55.731+0000] {processor.py:186} INFO - Started process (PID=47626) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:07:55.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:07:55.736+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:55.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:07:56.210+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:07:56.242+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:56.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:07:56.256+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:07:56.255+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:07:56.522+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.798 seconds
[2025-04-08T09:08:27.169+0000] {processor.py:186} INFO - Started process (PID=47695) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:08:27.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:08:27.173+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:27.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:08:27.623+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:08:27.650+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:27.649+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:08:27.665+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:27.665+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:08:27.691+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.530 seconds
[2025-04-08T09:08:58.051+0000] {processor.py:186} INFO - Started process (PID=47764) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:08:58.052+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:08:58.055+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:58.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:08:58.535+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:08:58.565+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:58.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:08:58.579+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:08:58.579+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:08:58.611+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.568 seconds
[2025-04-08T09:09:29.340+0000] {processor.py:186} INFO - Started process (PID=47833) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:09:29.341+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:09:29.345+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:29.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:09:29.787+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:09:29.815+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:29.815+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:09:29.831+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:09:29.831+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:09:29.861+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.527 seconds
[2025-04-08T09:10:00.590+0000] {processor.py:186} INFO - Started process (PID=47902) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:10:00.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:10:00.595+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:00.595+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:10:01.086+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:10:01.115+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:01.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:10:01.131+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:01.131+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:10:01.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.606 seconds
[2025-04-08T09:10:31.987+0000] {processor.py:186} INFO - Started process (PID=47971) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:10:31.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:10:31.991+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:31.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:10:32.407+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:10:32.435+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:32.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:10:32.450+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:10:32.450+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:10:32.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.495 seconds
[2025-04-08T09:11:03.063+0000] {processor.py:186} INFO - Started process (PID=48040) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:11:03.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:11:03.068+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:03.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:11:03.366+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:11:03.397+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:03.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:11:03.412+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:03.412+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:11:03.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.385 seconds
[2025-04-08T09:11:33.501+0000] {processor.py:186} INFO - Started process (PID=48109) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:11:33.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:11:33.505+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:33.505+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:11:33.778+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:11:33.807+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:33.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:11:33.822+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:11:33.822+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:11:33.851+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T09:12:04.035+0000] {processor.py:186} INFO - Started process (PID=48178) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:12:04.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:12:04.039+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:04.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:12:04.280+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:12:04.310+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:04.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:12:04.326+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:04.325+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:12:04.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-08T09:12:34.965+0000] {processor.py:186} INFO - Started process (PID=48247) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:12:34.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:12:34.971+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:34.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:12:35.261+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:12:35.296+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:35.296+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:12:35.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:12:35.316+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:12:35.349+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.390 seconds
[2025-04-08T09:13:05.609+0000] {processor.py:186} INFO - Started process (PID=48316) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:13:05.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:13:05.615+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:05.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:13:05.925+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:13:05.962+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:05.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:13:05.986+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:05.985+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:13:06.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.416 seconds
[2025-04-08T09:13:36.314+0000] {processor.py:186} INFO - Started process (PID=48386) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:13:36.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:13:36.322+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:36.321+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:13:36.597+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:13:36.630+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:36.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:13:36.648+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:13:36.648+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:13:36.680+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-08T09:14:07.316+0000] {processor.py:186} INFO - Started process (PID=48456) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:14:07.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:14:07.320+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:07.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:14:07.628+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:14:07.661+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:07.659+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:14:07.690+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:07.690+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:14:07.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.412 seconds
[2025-04-08T09:14:38.120+0000] {processor.py:186} INFO - Started process (PID=48525) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:14:38.121+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:14:38.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:38.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:14:38.415+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:14:38.448+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:38.447+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:14:38.465+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:14:38.465+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:14:38.493+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.380 seconds
[2025-04-08T09:15:08.910+0000] {processor.py:186} INFO - Started process (PID=48594) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:15:08.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:15:08.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:08.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:15:09.175+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:15:09.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:09.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:15:09.225+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:09.225+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:15:09.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-08T09:15:39.815+0000] {processor.py:186} INFO - Started process (PID=48663) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:15:39.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:15:39.821+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:39.820+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:15:40.071+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:15:40.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:40.107+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:15:40.124+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:15:40.124+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:15:40.150+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-08T09:16:11.030+0000] {processor.py:186} INFO - Started process (PID=48732) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:16:11.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:16:11.035+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:11.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:16:11.285+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:16:11.317+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:11.316+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:16:11.334+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:11.334+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:16:11.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-08T09:16:41.673+0000] {processor.py:186} INFO - Started process (PID=48801) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:16:41.674+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:16:41.679+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:41.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:16:41.984+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:16:42.014+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:42.013+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:16:42.030+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:16:42.030+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:16:42.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.399 seconds
[2025-04-08T09:17:12.667+0000] {processor.py:186} INFO - Started process (PID=48871) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:17:12.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:17:12.671+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:12.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:17:13.043+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:17:13.080+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:13.079+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:17:13.101+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:13.101+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:17:13.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.483 seconds
[2025-04-08T09:17:44.073+0000] {processor.py:186} INFO - Started process (PID=48940) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:17:44.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:17:44.082+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:44.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:17:44.378+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:17:44.411+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:44.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:17:44.431+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:17:44.431+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:17:44.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.413 seconds
[2025-04-08T09:18:14.811+0000] {processor.py:186} INFO - Started process (PID=49009) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:18:14.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:18:14.816+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:14.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:18:15.107+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:18:15.145+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:15.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:18:15.167+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:15.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:18:15.203+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.401 seconds
[2025-04-08T09:18:45.298+0000] {processor.py:186} INFO - Started process (PID=49075) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:18:45.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:18:45.302+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:45.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:18:45.567+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:18:45.601+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:45.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:18:45.619+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:18:45.618+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:18:45.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-08T09:19:15.726+0000] {processor.py:186} INFO - Started process (PID=49144) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:19:15.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:19:15.730+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:15.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:19:16.022+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:19:16.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:16.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:19:16.067+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:16.067+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:19:16.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-08T09:19:46.910+0000] {processor.py:186} INFO - Started process (PID=49213) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:19:46.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:19:46.914+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:46.914+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:19:47.191+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:19:47.223+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:47.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:19:47.241+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:19:47.240+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:19:47.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-08T09:20:17.871+0000] {processor.py:186} INFO - Started process (PID=49282) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:20:17.872+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:20:17.878+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:17.877+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:20:18.156+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:20:18.185+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:18.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:20:18.204+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:18.203+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:20:18.228+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-08T09:20:48.329+0000] {processor.py:186} INFO - Started process (PID=49352) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:20:48.331+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:20:48.333+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:48.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:20:48.577+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:20:48.605+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:48.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:20:48.620+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:20:48.620+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:20:48.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-08T09:21:19.020+0000] {processor.py:186} INFO - Started process (PID=49421) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:21:19.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:21:19.026+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:19.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:21:19.326+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:21:19.361+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:19.360+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:21:19.377+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:19.377+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:21:19.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.393 seconds
[2025-04-08T09:21:49.583+0000] {processor.py:186} INFO - Started process (PID=49492) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:21:49.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:21:49.587+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:49.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:21:49.840+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:21:49.868+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:49.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:21:49.885+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:21:49.885+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:21:49.916+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-08T09:22:20.816+0000] {processor.py:186} INFO - Started process (PID=49561) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:22:20.817+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:22:20.821+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:20.821+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:22:21.103+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:22:21.132+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:21.132+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:22:21.150+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:21.150+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:22:21.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-08T09:22:52.181+0000] {processor.py:186} INFO - Started process (PID=49636) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:22:52.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:22:52.187+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:52.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:22:52.457+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:22:52.489+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:52.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:22:52.505+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:22:52.505+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:22:52.539+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-08T09:23:22.646+0000] {processor.py:186} INFO - Started process (PID=49705) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:23:22.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:23:22.653+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:22.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:23:22.918+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:23:22.951+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:22.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:23:22.968+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:22.968+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:23:23.000+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-08T09:23:53.591+0000] {processor.py:186} INFO - Started process (PID=49774) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:23:53.592+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:23:53.597+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:53.596+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:23:53.885+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:23:53.926+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:53.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:23:53.944+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:23:53.944+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:23:53.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.388 seconds
[2025-04-08T09:24:24.290+0000] {processor.py:186} INFO - Started process (PID=49843) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:24:24.292+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:24:24.295+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:24.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:24:24.542+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:24:24.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:24.570+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:24:24.590+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:24.590+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:24:24.625+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-08T09:24:54.683+0000] {processor.py:186} INFO - Started process (PID=49912) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:24:54.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:24:54.687+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:54.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:24:54.934+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:24:54.964+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:54.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:24:54.980+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:24:54.980+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:24:55.010+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-08T09:25:25.136+0000] {processor.py:186} INFO - Started process (PID=49981) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:25:25.137+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:25:25.140+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:25.140+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:25:25.377+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:25:25.406+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:25.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:25:25.424+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:25.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:25:25.452+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.326 seconds
[2025-04-08T09:25:55.626+0000] {processor.py:186} INFO - Started process (PID=50050) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:25:55.627+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:25:55.631+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:55.630+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:25:55.873+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:25:55.902+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:55.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:25:55.918+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:25:55.918+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:25:55.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.322 seconds
[2025-04-08T09:26:26.011+0000] {processor.py:186} INFO - Started process (PID=50119) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:26:26.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:26:26.017+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:26.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:26:26.246+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:26:26.274+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:26.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:26:26.289+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:26.289+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:26:26.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.320 seconds
[2025-04-08T09:26:56.760+0000] {processor.py:186} INFO - Started process (PID=50188) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:26:56.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:26:56.764+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:56.764+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:26:57.009+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:26:57.036+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:57.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:26:57.051+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:26:57.051+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:26:57.080+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-08T09:27:27.293+0000] {processor.py:186} INFO - Started process (PID=50257) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:27:27.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:27:27.298+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:27.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:27:27.583+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:27:27.617+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:27.617+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:27:27.638+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:27.637+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:27:27.667+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-08T09:27:58.684+0000] {processor.py:186} INFO - Started process (PID=50326) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:27:58.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:27:58.688+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:58.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:27:58.913+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:27:58.940+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:58.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:27:58.954+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:27:58.954+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:27:58.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.308 seconds
[2025-04-08T09:28:29.988+0000] {processor.py:186} INFO - Started process (PID=50395) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:28:29.990+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:28:29.993+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:29.993+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:28:30.259+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:28:30.289+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:30.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:28:30.308+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:28:30.308+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:28:30.497+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.516 seconds
[2025-04-08T09:29:00.989+0000] {processor.py:186} INFO - Started process (PID=50464) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:29:00.991+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:29:00.995+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:00.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:29:01.324+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:29:01.354+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:01.354+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:29:01.383+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:01.382+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:29:01.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.439 seconds
[2025-04-08T09:29:32.169+0000] {processor.py:186} INFO - Started process (PID=50533) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:29:32.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:29:32.175+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:32.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:29:32.471+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:29:32.514+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:32.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:29:32.537+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:29:32.536+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:29:32.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.409 seconds
[2025-04-08T09:30:02.628+0000] {processor.py:186} INFO - Started process (PID=50602) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:30:02.629+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:30:02.634+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:02.633+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:30:03.080+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:30:03.107+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:03.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:30:03.122+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:03.122+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:30:03.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.532 seconds
[2025-04-08T09:30:33.445+0000] {processor.py:186} INFO - Started process (PID=50671) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:30:33.447+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:30:33.451+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:33.450+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:30:33.902+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:30:33.932+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:33.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:30:33.947+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:30:33.947+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:30:33.975+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.539 seconds
[2025-04-08T09:31:04.845+0000] {processor.py:186} INFO - Started process (PID=50743) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:31:04.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:31:04.851+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:04.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:31:05.122+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:31:05.153+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:05.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:31:05.169+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:05.169+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:31:05.200+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-08T09:31:35.292+0000] {processor.py:186} INFO - Started process (PID=50812) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:31:35.293+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:31:35.297+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:35.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:31:35.529+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:31:35.556+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:35.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:31:35.571+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:31:35.571+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:31:35.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.322 seconds
[2025-04-08T09:32:05.721+0000] {processor.py:186} INFO - Started process (PID=50881) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:32:05.723+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:32:05.727+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:05.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:32:06.092+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:32:06.146+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:06.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:32:06.219+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:06.219+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:32:06.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.623 seconds
[2025-04-08T09:32:47.152+0000] {processor.py:186} INFO - Started process (PID=50951) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:32:47.252+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:32:47.308+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:47.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:32:55.822+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:32:55.887+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:55.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:32:55.911+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:32:55.911+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:32:55.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 8.837 seconds
[2025-04-08T09:33:42.684+0000] {processor.py:186} INFO - Started process (PID=50991) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:33:42.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-08T09:33:42.809+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:42.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:33:45.519+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-08T09:33:45.676+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:45.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-08T09:33:45.695+0000] {logging_mixin.py:190} INFO - [2025-04-08T09:33:45.694+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-08T09:33:46.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 4.028 seconds
