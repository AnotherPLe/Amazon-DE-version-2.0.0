[2025-04-05T13:48:42.600+0000] {processor.py:186} INFO - Started process (PID=93) to work on /opt/airflow/dags/test.py
[2025-04-05T13:48:42.603+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:48:42.609+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:48:42.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:48:42.656+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:48:42.655+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:48:42.674+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:48:42.747+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:48:42.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:48:42.804+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:48:42.804+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:48:42.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.287 seconds
[2025-04-05T13:49:13.686+0000] {processor.py:186} INFO - Started process (PID=160) to work on /opt/airflow/dags/test.py
[2025-04-05T13:49:13.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:49:13.691+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:13.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:49:13.718+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:13.718+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:49:13.724+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:49:13.752+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:13.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:49:13.769+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:13.769+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:49:13.805+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-05T13:49:44.757+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/test.py
[2025-04-05T13:49:44.759+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:49:44.762+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:44.762+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:49:44.780+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:44.779+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:49:44.784+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:49:44.810+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:44.810+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:49:44.834+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:49:44.833+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:49:44.867+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-05T13:50:15.279+0000] {processor.py:186} INFO - Started process (PID=294) to work on /opt/airflow/dags/test.py
[2025-04-05T13:50:15.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:50:15.283+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:15.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:50:15.299+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:15.299+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:50:15.303+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:50:15.326+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:15.325+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:50:15.351+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:15.351+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:50:15.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-05T13:50:45.877+0000] {processor.py:186} INFO - Started process (PID=361) to work on /opt/airflow/dags/test.py
[2025-04-05T13:50:45.879+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:50:45.883+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:45.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:50:45.908+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:45.908+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:50:45.915+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:50:45.946+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:45.946+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:50:45.976+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:50:45.975+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:50:46.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.150 seconds
[2025-04-05T13:51:16.810+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/test.py
[2025-04-05T13:51:16.812+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:51:16.818+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:16.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:51:16.845+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:16.844+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:51:16.851+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:51:16.880+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:16.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:51:16.909+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:16.909+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:51:16.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.152 seconds
[2025-04-05T13:51:47.522+0000] {processor.py:186} INFO - Started process (PID=496) to work on /opt/airflow/dags/test.py
[2025-04-05T13:51:47.524+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:51:47.528+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:47.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:51:47.566+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:47.566+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:51:47.574+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:51:47.616+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:47.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:51:47.646+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:51:47.646+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:51:47.684+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.173 seconds
[2025-04-05T13:52:18.552+0000] {processor.py:186} INFO - Started process (PID=564) to work on /opt/airflow/dags/test.py
[2025-04-05T13:52:18.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:52:18.557+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:18.556+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:52:18.587+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:18.587+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:52:18.592+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:52:18.615+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:18.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:52:18.635+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:18.635+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:52:18.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-05T13:52:49.083+0000] {processor.py:186} INFO - Started process (PID=631) to work on /opt/airflow/dags/test.py
[2025-04-05T13:52:49.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:52:49.087+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:49.087+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:52:49.115+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:49.115+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:52:49.119+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:52:49.141+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:49.141+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:52:49.175+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:52:49.174+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:52:49.211+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.135 seconds
[2025-04-05T13:53:20.110+0000] {processor.py:186} INFO - Started process (PID=698) to work on /opt/airflow/dags/test.py
[2025-04-05T13:53:20.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:53:20.115+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:20.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:53:20.136+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:20.135+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:53:20.144+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:53:20.179+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:20.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:53:20.216+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:20.216+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:53:20.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.155 seconds
[2025-04-05T13:53:50.633+0000] {processor.py:186} INFO - Started process (PID=765) to work on /opt/airflow/dags/test.py
[2025-04-05T13:53:50.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:53:50.637+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:50.636+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:53:50.656+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:50.655+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:53:50.660+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:53:50.683+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:50.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:53:50.704+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:53:50.704+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:53:50.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-05T13:54:21.312+0000] {processor.py:186} INFO - Started process (PID=833) to work on /opt/airflow/dags/test.py
[2025-04-05T13:54:21.314+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:54:21.318+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:21.317+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:54:21.340+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:21.339+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:54:21.345+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:54:21.373+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:21.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:54:21.403+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:21.402+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:54:21.439+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.139 seconds
[2025-04-05T13:54:52.326+0000] {processor.py:186} INFO - Started process (PID=900) to work on /opt/airflow/dags/test.py
[2025-04-05T13:54:52.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:54:52.330+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:52.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:54:52.349+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:52.348+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:54:52.354+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:54:52.383+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:52.383+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:54:52.408+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:54:52.407+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:54:52.448+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-05T13:55:23.431+0000] {processor.py:186} INFO - Started process (PID=968) to work on /opt/airflow/dags/test.py
[2025-04-05T13:55:23.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:55:23.434+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:23.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:55:23.448+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:23.448+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:55:23.453+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:55:23.476+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:23.476+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:55:23.495+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:23.495+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:55:23.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-05T13:55:54.161+0000] {processor.py:186} INFO - Started process (PID=1035) to work on /opt/airflow/dags/test.py
[2025-04-05T13:55:54.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:55:54.166+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:54.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:55:54.192+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:54.192+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:55:54.196+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:55:54.220+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:54.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:55:54.244+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:55:54.244+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:55:54.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.136 seconds
[2025-04-05T13:56:25.772+0000] {processor.py:186} INFO - Started process (PID=1102) to work on /opt/airflow/dags/test.py
[2025-04-05T13:56:25.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:56:25.777+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:25.776+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:56:25.798+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:25.797+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:56:25.802+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:56:25.825+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:25.824+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:56:25.843+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:25.842+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:56:26.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.451 seconds
[2025-04-05T13:56:56.848+0000] {processor.py:186} INFO - Started process (PID=1169) to work on /opt/airflow/dags/test.py
[2025-04-05T13:56:56.850+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:56:56.857+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:56.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:56:56.897+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:56.896+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:56:56.925+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:56:56.963+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:56.963+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:56:56.987+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:56:56.987+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:56:57.030+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.193 seconds
[2025-04-05T13:57:27.745+0000] {processor.py:186} INFO - Started process (PID=1236) to work on /opt/airflow/dags/test.py
[2025-04-05T13:57:27.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:57:27.750+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:27.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:57:27.773+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:27.773+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:57:27.778+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:57:27.802+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:27.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:57:27.824+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:27.823+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:57:27.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-05T13:57:58.823+0000] {processor.py:186} INFO - Started process (PID=1303) to work on /opt/airflow/dags/test.py
[2025-04-05T13:57:58.824+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:57:58.827+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:58.827+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:57:58.846+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:58.845+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:57:58.850+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:57:58.872+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:58.871+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:57:58.890+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:57:58.890+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:57:58.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-05T13:58:30.169+0000] {processor.py:186} INFO - Started process (PID=1370) to work on /opt/airflow/dags/test.py
[2025-04-05T13:58:30.170+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:58:30.173+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:58:30.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:58:30.189+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:58:30.188+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:58:30.193+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:58:30.214+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:58:30.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:58:30.233+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:58:30.233+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:58:30.261+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-05T13:59:01.055+0000] {processor.py:186} INFO - Started process (PID=1443) to work on /opt/airflow/dags/test.py
[2025-04-05T13:59:01.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:59:01.066+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:01.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:59:01.080+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:01.080+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:59:01.084+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:59:01.105+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:01.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:59:01.124+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:01.123+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:59:01.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.106 seconds
[2025-04-05T13:59:32.151+0000] {processor.py:186} INFO - Started process (PID=1510) to work on /opt/airflow/dags/test.py
[2025-04-05T13:59:32.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T13:59:32.156+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:32.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T13:59:32.176+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:32.176+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T13:59:32.181+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T13:59:32.229+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:32.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T13:59:32.258+0000] {logging_mixin.py:190} INFO - [2025-04-05T13:59:32.258+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T13:59:32.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.163 seconds
[2025-04-05T14:00:04.112+0000] {processor.py:186} INFO - Started process (PID=1577) to work on /opt/airflow/dags/test.py
[2025-04-05T14:00:04.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:00:04.117+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:04.117+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:00:04.139+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:04.138+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:00:04.144+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:00:04.180+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:04.179+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:00:04.211+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:04.210+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:00:04.473+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.374 seconds
[2025-04-05T14:00:35.139+0000] {processor.py:186} INFO - Started process (PID=1644) to work on /opt/airflow/dags/test.py
[2025-04-05T14:00:35.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:00:35.143+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:35.143+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:00:35.159+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:35.159+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:00:35.163+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:00:35.183+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:35.183+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:00:35.201+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:00:35.200+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:00:35.230+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-05T14:01:06.673+0000] {processor.py:186} INFO - Started process (PID=1712) to work on /opt/airflow/dags/test.py
[2025-04-05T14:01:06.675+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:01:06.678+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:06.678+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:01:06.694+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:06.693+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:01:06.698+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:01:06.721+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:06.720+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:01:06.747+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:06.746+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:01:06.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-05T14:01:37.426+0000] {processor.py:186} INFO - Started process (PID=1779) to work on /opt/airflow/dags/test.py
[2025-04-05T14:01:37.428+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:01:37.433+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:37.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:01:37.453+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:37.452+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:01:37.457+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:01:37.488+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:37.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:01:37.514+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:01:37.513+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:01:37.559+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.146 seconds
[2025-04-05T14:02:08.607+0000] {processor.py:186} INFO - Started process (PID=1846) to work on /opt/airflow/dags/test.py
[2025-04-05T14:02:08.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:02:08.611+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:08.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:02:08.631+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:08.631+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:02:08.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:02:08.658+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:08.658+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:02:08.679+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:08.678+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:02:08.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.112 seconds
[2025-04-05T14:02:39.959+0000] {processor.py:186} INFO - Started process (PID=1913) to work on /opt/airflow/dags/test.py
[2025-04-05T14:02:39.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:02:39.964+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:39.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:02:39.985+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:39.984+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:02:39.990+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:02:40.015+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:40.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:02:40.035+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:02:40.034+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:02:40.064+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-05T14:03:10.904+0000] {processor.py:186} INFO - Started process (PID=1980) to work on /opt/airflow/dags/test.py
[2025-04-05T14:03:10.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:03:10.908+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:10.908+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:03:10.927+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:10.927+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:03:10.931+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:03:10.958+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:10.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:03:10.977+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:10.976+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:03:11.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.108 seconds
[2025-04-05T14:03:41.955+0000] {processor.py:186} INFO - Started process (PID=2047) to work on /opt/airflow/dags/test.py
[2025-04-05T14:03:41.957+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:03:41.960+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:41.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:03:41.983+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:41.983+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:03:41.988+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:03:42.015+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:42.015+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:03:42.037+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:03:42.037+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:03:42.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.131 seconds
[2025-04-05T14:04:12.688+0000] {processor.py:186} INFO - Started process (PID=2114) to work on /opt/airflow/dags/test.py
[2025-04-05T14:04:12.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:04:12.692+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:12.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:04:12.712+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:12.712+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:04:12.716+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:04:12.739+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:12.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:04:12.759+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:12.759+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:04:12.792+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-05T14:04:43.466+0000] {processor.py:186} INFO - Started process (PID=2181) to work on /opt/airflow/dags/test.py
[2025-04-05T14:04:43.467+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:04:43.470+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:43.470+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:04:43.489+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:43.489+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:04:43.493+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:04:43.514+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:43.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:04:43.531+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:04:43.531+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:04:43.560+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-05T14:05:14.117+0000] {processor.py:186} INFO - Started process (PID=2248) to work on /opt/airflow/dags/test.py
[2025-04-05T14:05:14.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:05:14.121+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:14.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:05:14.138+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:14.137+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:05:14.144+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:05:14.168+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:14.168+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:05:14.190+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:14.190+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:05:14.226+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-05T14:05:45.064+0000] {processor.py:186} INFO - Started process (PID=2315) to work on /opt/airflow/dags/test.py
[2025-04-05T14:05:45.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T14:05:45.068+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:45.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T14:05:45.085+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:45.084+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T14:05:45.088+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T14:05:45.108+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:45.108+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T14:05:45.125+0000] {logging_mixin.py:190} INFO - [2025-04-05T14:05:45.124+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T14:05:45.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-05T17:39:31.711+0000] {processor.py:186} INFO - Started process (PID=2382) to work on /opt/airflow/dags/test.py
[2025-04-05T17:39:31.719+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:39:31.728+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:39:31.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:39:31.803+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:39:31.803+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:39:31.810+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:39:31.865+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:39:31.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:39:31.936+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:39:31.935+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:39:32.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.355 seconds
[2025-04-05T17:40:02.790+0000] {processor.py:186} INFO - Started process (PID=2450) to work on /opt/airflow/dags/test.py
[2025-04-05T17:40:02.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:40:02.797+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:02.796+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:40:02.830+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:02.828+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:40:02.837+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:40:02.863+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:02.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:40:02.882+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:02.882+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:40:02.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.137 seconds
[2025-04-05T17:40:33.681+0000] {processor.py:186} INFO - Started process (PID=2517) to work on /opt/airflow/dags/test.py
[2025-04-05T17:40:33.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:40:33.686+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:33.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:40:33.705+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:33.705+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:40:33.711+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:40:33.739+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:33.739+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:40:33.770+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:40:33.770+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:40:33.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.139 seconds
[2025-04-05T17:41:04.491+0000] {processor.py:186} INFO - Started process (PID=2583) to work on /opt/airflow/dags/test.py
[2025-04-05T17:41:04.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:41:04.494+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:04.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:41:04.510+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:04.510+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:41:04.515+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:41:04.537+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:04.537+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:41:04.559+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:04.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:41:04.597+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.113 seconds
[2025-04-05T17:41:35.030+0000] {processor.py:186} INFO - Started process (PID=2650) to work on /opt/airflow/dags/test.py
[2025-04-05T17:41:35.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:41:35.033+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:35.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:41:35.049+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:35.049+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:41:35.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:41:35.076+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:35.076+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:41:35.101+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:41:35.101+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:41:35.133+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-05T17:42:05.962+0000] {processor.py:186} INFO - Started process (PID=2717) to work on /opt/airflow/dags/test.py
[2025-04-05T17:42:05.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:42:05.966+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:05.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:42:05.982+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:05.981+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:42:05.987+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:42:06.008+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:06.008+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:42:06.030+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:06.029+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:42:06.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-05T17:42:37.095+0000] {processor.py:186} INFO - Started process (PID=2784) to work on /opt/airflow/dags/test.py
[2025-04-05T17:42:37.096+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:42:37.099+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:37.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:42:37.123+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:37.123+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:42:37.127+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:42:37.153+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:37.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:42:37.177+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:42:37.176+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:42:37.207+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-05T17:43:07.785+0000] {processor.py:186} INFO - Started process (PID=2851) to work on /opt/airflow/dags/test.py
[2025-04-05T17:43:07.787+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:43:07.790+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:07.789+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:43:07.808+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:07.807+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:43:07.811+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:43:07.832+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:07.832+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:43:07.850+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:07.850+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:43:07.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-05T17:43:38.282+0000] {processor.py:186} INFO - Started process (PID=2918) to work on /opt/airflow/dags/test.py
[2025-04-05T17:43:38.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:43:38.287+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:38.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:43:38.304+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:38.304+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:43:38.308+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:43:38.330+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:38.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:43:38.347+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:43:38.347+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:43:38.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.104 seconds
[2025-04-05T17:44:08.866+0000] {processor.py:186} INFO - Started process (PID=2985) to work on /opt/airflow/dags/test.py
[2025-04-05T17:44:08.867+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:44:08.870+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:08.869+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:44:08.885+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:08.884+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:44:08.890+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:44:08.912+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:08.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:44:08.931+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:08.931+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:44:08.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-05T17:44:39.617+0000] {processor.py:186} INFO - Started process (PID=3052) to work on /opt/airflow/dags/test.py
[2025-04-05T17:44:39.618+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:44:39.621+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:39.621+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:44:39.640+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:39.639+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:44:39.645+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:44:39.664+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:39.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:44:39.680+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:44:39.680+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:44:39.706+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-05T17:45:10.339+0000] {processor.py:186} INFO - Started process (PID=3119) to work on /opt/airflow/dags/test.py
[2025-04-05T17:45:10.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:45:10.342+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:10.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:45:10.355+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:10.355+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:45:10.359+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:45:10.378+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:10.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:45:10.394+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:10.394+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:45:10.421+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-05T17:45:41.176+0000] {processor.py:186} INFO - Started process (PID=3186) to work on /opt/airflow/dags/test.py
[2025-04-05T17:45:41.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:45:41.180+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:41.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:45:41.195+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:41.195+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:45:41.198+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:45:41.217+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:41.216+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:45:41.232+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:45:41.231+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:45:41.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-05T17:46:12.029+0000] {processor.py:186} INFO - Started process (PID=3254) to work on /opt/airflow/dags/test.py
[2025-04-05T17:46:12.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:46:12.033+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:12.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:46:12.056+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:12.056+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:46:12.060+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:46:12.082+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:12.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:46:12.097+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:12.097+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:46:12.125+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-05T17:46:42.973+0000] {processor.py:186} INFO - Started process (PID=3320) to work on /opt/airflow/dags/test.py
[2025-04-05T17:46:42.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:46:42.977+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:42.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:46:42.992+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:42.992+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:46:42.996+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:46:43.016+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:43.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:46:43.057+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:46:43.056+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:46:43.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-05T17:47:13.790+0000] {processor.py:186} INFO - Started process (PID=3393) to work on /opt/airflow/dags/test.py
[2025-04-05T17:47:13.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:47:13.799+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:13.798+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:47:13.814+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:13.814+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:47:13.818+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:47:13.838+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:13.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:47:13.854+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:13.854+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:47:13.877+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-05T17:47:44.216+0000] {processor.py:186} INFO - Started process (PID=3460) to work on /opt/airflow/dags/test.py
[2025-04-05T17:47:44.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:47:44.220+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:44.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:47:44.235+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:44.235+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:47:44.239+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:47:44.258+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:44.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:47:44.275+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:47:44.274+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:47:44.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.089 seconds
[2025-04-05T17:48:14.916+0000] {processor.py:186} INFO - Started process (PID=3527) to work on /opt/airflow/dags/test.py
[2025-04-05T17:48:14.918+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:48:14.922+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:14.921+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:48:14.937+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:14.937+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:48:14.941+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:48:14.961+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:14.960+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:48:14.979+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:14.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:48:15.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-05T17:48:45.426+0000] {processor.py:186} INFO - Started process (PID=3594) to work on /opt/airflow/dags/test.py
[2025-04-05T17:48:45.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:48:45.430+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:45.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:48:45.444+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:45.443+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:48:45.447+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:48:45.469+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:45.468+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:48:45.491+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:48:45.491+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:48:45.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-05T17:49:16.066+0000] {processor.py:186} INFO - Started process (PID=3661) to work on /opt/airflow/dags/test.py
[2025-04-05T17:49:16.067+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:49:16.071+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:16.070+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:49:16.088+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:16.088+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:49:16.092+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:49:16.113+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:16.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:49:16.130+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:16.130+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:49:16.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-05T17:49:46.852+0000] {processor.py:186} INFO - Started process (PID=3728) to work on /opt/airflow/dags/test.py
[2025-04-05T17:49:46.853+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:49:46.856+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:46.856+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:49:46.886+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:46.885+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:49:46.889+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:49:46.912+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:46.912+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:49:46.934+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:49:46.934+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:49:46.966+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-05T17:50:17.665+0000] {processor.py:186} INFO - Started process (PID=3795) to work on /opt/airflow/dags/test.py
[2025-04-05T17:50:17.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:50:17.669+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:17.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:50:17.682+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:17.682+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:50:17.686+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:50:17.706+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:17.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:50:17.727+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:17.726+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:50:17.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-05T17:50:48.049+0000] {processor.py:186} INFO - Started process (PID=3862) to work on /opt/airflow/dags/test.py
[2025-04-05T17:50:48.050+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:50:48.054+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:48.053+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:50:48.069+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:48.069+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:50:48.073+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:50:48.093+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:48.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:50:48.111+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:50:48.111+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:50:48.137+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.096 seconds
[2025-04-05T17:51:18.921+0000] {processor.py:186} INFO - Started process (PID=3929) to work on /opt/airflow/dags/test.py
[2025-04-05T17:51:18.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:51:18.925+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:18.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:51:18.943+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:18.943+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:51:18.947+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:51:18.967+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:18.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:51:18.986+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:18.986+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:51:19.014+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-05T17:51:49.687+0000] {processor.py:186} INFO - Started process (PID=3996) to work on /opt/airflow/dags/test.py
[2025-04-05T17:51:49.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:51:49.691+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:49.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:51:49.705+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:49.705+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:51:49.709+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:51:49.728+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:49.728+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:51:49.747+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:51:49.747+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:51:49.771+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.090 seconds
[2025-04-05T17:52:20.229+0000] {processor.py:186} INFO - Started process (PID=4063) to work on /opt/airflow/dags/test.py
[2025-04-05T17:52:20.231+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:52:20.234+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:20.233+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:52:20.250+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:20.250+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:52:20.254+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:52:20.274+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:20.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:52:20.291+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:20.291+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:52:20.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-05T17:52:50.435+0000] {processor.py:186} INFO - Started process (PID=4129) to work on /opt/airflow/dags/test.py
[2025-04-05T17:52:50.436+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:52:50.439+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:50.439+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:52:50.455+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:50.455+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:52:50.459+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:52:50.480+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:50.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:52:50.496+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:52:50.496+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:52:50.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.097 seconds
[2025-04-05T17:53:20.814+0000] {processor.py:186} INFO - Started process (PID=4196) to work on /opt/airflow/dags/test.py
[2025-04-05T17:53:20.815+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:53:20.818+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:20.818+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:53:20.835+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:20.835+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:53:20.839+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:53:20.861+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:20.861+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:53:20.879+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:20.879+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:53:20.911+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-05T17:53:51.506+0000] {processor.py:186} INFO - Started process (PID=4263) to work on /opt/airflow/dags/test.py
[2025-04-05T17:53:51.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:53:51.510+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:51.510+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:53:51.533+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:51.532+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:53:51.538+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:53:51.564+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:51.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:53:51.586+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:53:51.586+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:53:51.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-05T17:54:22.118+0000] {processor.py:186} INFO - Started process (PID=4329) to work on /opt/airflow/dags/test.py
[2025-04-05T17:54:22.119+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:54:22.124+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:22.123+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:54:22.145+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:22.144+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:54:22.148+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:54:22.174+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:22.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:54:22.193+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:22.193+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:54:22.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-05T17:54:53.495+0000] {processor.py:186} INFO - Started process (PID=4397) to work on /opt/airflow/dags/test.py
[2025-04-05T17:54:53.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:54:53.499+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:53.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:54:53.519+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:53.518+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:54:53.524+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:54:53.552+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:53.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:54:53.578+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:54:53.576+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:54:53.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.131 seconds
[2025-04-05T17:55:24.575+0000] {processor.py:186} INFO - Started process (PID=4463) to work on /opt/airflow/dags/test.py
[2025-04-05T17:55:24.576+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:55:24.580+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:24.579+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:55:24.599+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:24.598+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:55:24.604+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:55:24.627+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:24.627+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:55:24.652+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:24.651+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:55:24.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-05T17:55:55.515+0000] {processor.py:186} INFO - Started process (PID=4530) to work on /opt/airflow/dags/test.py
[2025-04-05T17:55:55.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:55:55.521+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:55.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:55:55.541+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:55.540+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:55:55.544+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:55:55.565+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:55.565+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:55:55.584+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:55:55.584+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:55:55.618+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-05T17:56:26.387+0000] {processor.py:186} INFO - Started process (PID=4596) to work on /opt/airflow/dags/test.py
[2025-04-05T17:56:26.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:56:26.392+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:26.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:56:26.415+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:26.415+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:56:26.420+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:56:26.446+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:26.446+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:56:26.467+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:26.466+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:56:26.494+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.124 seconds
[2025-04-05T17:56:56.608+0000] {processor.py:186} INFO - Started process (PID=4660) to work on /opt/airflow/dags/test.py
[2025-04-05T17:56:56.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:56:56.612+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:56.612+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:56:56.629+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:56.628+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:56:56.632+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:56:56.654+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:56.654+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:56:56.674+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:56:56.673+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:56:56.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.105 seconds
[2025-04-05T17:57:26.875+0000] {processor.py:186} INFO - Started process (PID=4727) to work on /opt/airflow/dags/test.py
[2025-04-05T17:57:26.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:57:26.879+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:26.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:57:26.900+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:26.900+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:57:26.904+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:57:26.923+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:26.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:57:26.938+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:26.938+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:57:26.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-05T17:57:57.390+0000] {processor.py:186} INFO - Started process (PID=4793) to work on /opt/airflow/dags/test.py
[2025-04-05T17:57:57.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:57:57.395+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:57.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:57:57.410+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:57.409+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:57:57.414+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:57:57.435+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:57.434+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:57:57.450+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:57:57.450+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:57:57.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.098 seconds
[2025-04-05T17:58:27.861+0000] {processor.py:186} INFO - Started process (PID=4860) to work on /opt/airflow/dags/test.py
[2025-04-05T17:58:27.862+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:58:27.864+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:27.864+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:58:27.883+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:27.882+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:58:27.886+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:58:27.907+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:27.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:58:27.925+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:27.924+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:58:27.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-05T17:58:58.177+0000] {processor.py:186} INFO - Started process (PID=4927) to work on /opt/airflow/dags/test.py
[2025-04-05T17:58:58.178+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:58:58.181+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:58.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:58:58.195+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:58.195+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:58:58.199+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:58:58.217+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:58.217+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:58:58.235+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:58:58.234+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:58:58.263+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.094 seconds
[2025-04-05T17:59:28.557+0000] {processor.py:186} INFO - Started process (PID=4994) to work on /opt/airflow/dags/test.py
[2025-04-05T17:59:28.558+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:59:28.562+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:28.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:59:28.579+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:28.579+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:59:28.582+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:59:28.602+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:28.602+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:59:28.619+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:28.619+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:59:28.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.100 seconds
[2025-04-05T17:59:58.957+0000] {processor.py:186} INFO - Started process (PID=5061) to work on /opt/airflow/dags/test.py
[2025-04-05T17:59:58.958+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T17:59:58.961+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:58.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T17:59:58.980+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:58.980+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T17:59:58.984+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T17:59:59.004+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:59.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T17:59:59.020+0000] {logging_mixin.py:190} INFO - [2025-04-05T17:59:59.019+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T17:59:59.233+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.282 seconds
[2025-04-05T18:00:29.311+0000] {processor.py:186} INFO - Started process (PID=5128) to work on /opt/airflow/dags/test.py
[2025-04-05T18:00:29.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:00:29.316+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:29.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:00:29.335+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:29.335+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:00:29.341+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:00:29.366+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:29.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:00:29.389+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:29.389+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:00:29.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-05T18:00:59.769+0000] {processor.py:186} INFO - Started process (PID=5195) to work on /opt/airflow/dags/test.py
[2025-04-05T18:00:59.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:00:59.773+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:59.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:00:59.790+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:59.790+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:00:59.794+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:00:59.816+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:59.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:00:59.835+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:00:59.834+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:00:59.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.101 seconds
[2025-04-05T18:01:30.712+0000] {processor.py:186} INFO - Started process (PID=5262) to work on /opt/airflow/dags/test.py
[2025-04-05T18:01:30.716+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:01:30.725+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:01:30.724+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:01:30.755+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:01:30.754+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:01:30.758+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:01:30.778+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:01:30.778+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:01:30.794+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:01:30.793+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:01:30.821+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.130 seconds
[2025-04-05T18:02:01.441+0000] {processor.py:186} INFO - Started process (PID=5329) to work on /opt/airflow/dags/test.py
[2025-04-05T18:02:01.443+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:02:01.445+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:01.445+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:02:01.462+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:01.462+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:02:01.466+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:02:01.486+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:01.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:02:01.651+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:01.651+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:02:01.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.245 seconds
[2025-04-05T18:02:31.895+0000] {processor.py:186} INFO - Started process (PID=5396) to work on /opt/airflow/dags/test.py
[2025-04-05T18:02:31.896+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:02:31.899+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:31.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:02:31.919+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:31.919+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:02:31.922+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:02:31.941+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:31.941+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:02:32.115+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:02:32.114+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:02:32.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.258 seconds
[2025-04-05T18:03:02.548+0000] {processor.py:186} INFO - Started process (PID=5463) to work on /opt/airflow/dags/test.py
[2025-04-05T18:03:02.549+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:03:02.552+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:02.551+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:03:02.569+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:02.569+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:03:02.574+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:03:02.593+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:02.593+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:03:02.832+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:02.832+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:03:02.864+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.327 seconds
[2025-04-05T18:03:33.513+0000] {processor.py:186} INFO - Started process (PID=5530) to work on /opt/airflow/dags/test.py
[2025-04-05T18:03:33.516+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:03:33.521+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:33.520+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:03:33.552+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:33.551+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:03:33.556+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:03:33.580+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:33.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:03:33.816+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:03:33.816+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:03:33.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.337 seconds
[2025-04-05T18:04:04.389+0000] {processor.py:186} INFO - Started process (PID=5597) to work on /opt/airflow/dags/test.py
[2025-04-05T18:04:04.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:04:04.396+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:04.396+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:04:04.417+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:04.417+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:04:04.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:04:04.449+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:04.449+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:04:04.474+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:04.474+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:04:04.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:04:35.266+0000] {processor.py:186} INFO - Started process (PID=5664) to work on /opt/airflow/dags/test.py
[2025-04-05T18:04:35.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:04:35.270+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:35.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:04:35.291+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:35.290+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:04:35.299+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:04:35.321+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:35.321+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:04:35.342+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:04:35.341+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:04:35.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-05T18:05:05.897+0000] {processor.py:186} INFO - Started process (PID=5731) to work on /opt/airflow/dags/test.py
[2025-04-05T18:05:05.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:05:05.906+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:05.905+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:05:05.926+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:05.926+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:05:05.930+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:05:05.958+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:05.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:05:05.980+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:05.979+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:05:06.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-05T18:05:36.767+0000] {processor.py:186} INFO - Started process (PID=5798) to work on /opt/airflow/dags/test.py
[2025-04-05T18:05:36.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:05:36.772+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:36.771+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:05:36.800+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:36.799+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:05:36.803+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:05:36.829+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:36.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:05:36.850+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:05:36.850+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:05:36.883+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.130 seconds
[2025-04-05T18:06:07.760+0000] {processor.py:186} INFO - Started process (PID=5865) to work on /opt/airflow/dags/test.py
[2025-04-05T18:06:07.761+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:06:07.767+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:07.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:06:07.791+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:07.791+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:06:07.796+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:06:07.841+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:07.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:06:07.887+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:07.886+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:06:07.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.169 seconds
[2025-04-05T18:06:38.011+0000] {processor.py:186} INFO - Started process (PID=5933) to work on /opt/airflow/dags/test.py
[2025-04-05T18:06:38.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:06:38.015+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:38.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:06:38.037+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:38.036+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:06:38.044+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:06:38.067+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:38.067+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:06:38.091+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:06:38.091+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:06:38.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-05T18:07:08.788+0000] {processor.py:186} INFO - Started process (PID=6000) to work on /opt/airflow/dags/test.py
[2025-04-05T18:07:08.790+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:07:08.801+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:08.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:07:08.830+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:08.830+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:07:08.836+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:07:08.869+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:08.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:07:08.889+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:08.889+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:07:08.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.184 seconds
[2025-04-05T18:07:39.079+0000] {processor.py:186} INFO - Started process (PID=6067) to work on /opt/airflow/dags/test.py
[2025-04-05T18:07:39.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:07:39.095+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:39.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:07:39.142+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:39.141+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:07:39.149+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:07:39.181+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:39.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:07:39.204+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:07:39.204+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:07:39.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.162 seconds
[2025-04-05T18:08:09.387+0000] {processor.py:186} INFO - Started process (PID=6134) to work on /opt/airflow/dags/test.py
[2025-04-05T18:08:09.388+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:08:09.394+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:09.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:08:09.408+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:09.407+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:08:09.414+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:08:09.438+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:09.437+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:08:09.466+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:09.466+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:08:09.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-05T18:08:40.266+0000] {processor.py:186} INFO - Started process (PID=6201) to work on /opt/airflow/dags/test.py
[2025-04-05T18:08:40.267+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:08:40.271+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:40.270+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:08:40.295+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:40.294+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:08:40.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:08:40.329+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:40.329+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:08:40.358+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:08:40.358+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:08:40.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.138 seconds
[2025-04-05T18:09:10.934+0000] {processor.py:186} INFO - Started process (PID=6268) to work on /opt/airflow/dags/test.py
[2025-04-05T18:09:10.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:09:10.942+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:10.942+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:09:10.964+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:10.963+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:09:10.967+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:09:10.996+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:10.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:09:11.018+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:11.018+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:09:11.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:09:41.564+0000] {processor.py:186} INFO - Started process (PID=6335) to work on /opt/airflow/dags/test.py
[2025-04-05T18:09:41.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:09:41.570+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:41.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:09:41.592+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:41.591+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:09:41.600+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:09:41.633+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:41.633+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:09:41.659+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:09:41.658+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:09:41.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.144 seconds
[2025-04-05T18:10:12.648+0000] {processor.py:186} INFO - Started process (PID=6402) to work on /opt/airflow/dags/test.py
[2025-04-05T18:10:12.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:10:12.655+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:12.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:10:12.677+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:12.676+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:10:12.681+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:10:12.707+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:12.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:10:12.728+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:12.728+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:10:12.760+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-05T18:10:43.663+0000] {processor.py:186} INFO - Started process (PID=6469) to work on /opt/airflow/dags/test.py
[2025-04-05T18:10:43.665+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:10:43.669+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:43.668+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:10:43.694+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:43.693+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:10:43.700+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:10:43.732+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:43.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:10:43.764+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:10:43.764+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:10:43.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.150 seconds
[2025-04-05T18:11:13.910+0000] {processor.py:186} INFO - Started process (PID=6536) to work on /opt/airflow/dags/test.py
[2025-04-05T18:11:13.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:11:13.920+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:13.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:11:13.943+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:13.943+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:11:13.951+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:11:13.974+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:13.974+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:11:13.998+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:13.997+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:11:14.025+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-05T18:11:44.789+0000] {processor.py:186} INFO - Started process (PID=6603) to work on /opt/airflow/dags/test.py
[2025-04-05T18:11:44.791+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:11:44.796+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:44.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:11:44.817+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:44.816+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:11:44.823+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:11:44.847+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:44.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:11:44.867+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:11:44.867+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:11:44.898+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-05T18:12:15.170+0000] {processor.py:186} INFO - Started process (PID=6670) to work on /opt/airflow/dags/test.py
[2025-04-05T18:12:15.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:12:15.177+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:15.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:12:15.203+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:15.202+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:12:15.208+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:12:15.235+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:15.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:12:15.255+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:15.255+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:12:15.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:12:45.926+0000] {processor.py:186} INFO - Started process (PID=6743) to work on /opt/airflow/dags/test.py
[2025-04-05T18:12:45.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:12:45.932+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:45.931+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:12:45.958+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:45.957+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:12:45.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:12:45.988+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:45.988+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:12:46.008+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:12:46.008+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:12:46.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.126 seconds
[2025-04-05T18:13:16.198+0000] {processor.py:186} INFO - Started process (PID=6811) to work on /opt/airflow/dags/test.py
[2025-04-05T18:13:16.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:13:16.203+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:16.202+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:13:16.228+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:16.228+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:13:16.233+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:13:16.256+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:16.256+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:13:16.280+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:16.280+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:13:16.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-05T18:13:46.652+0000] {processor.py:186} INFO - Started process (PID=6878) to work on /opt/airflow/dags/test.py
[2025-04-05T18:13:46.653+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:13:46.655+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:46.655+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:13:46.672+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:46.671+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:13:46.676+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:13:46.700+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:46.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:13:46.719+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:13:46.719+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:13:46.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-05T18:14:17.134+0000] {processor.py:186} INFO - Started process (PID=6945) to work on /opt/airflow/dags/test.py
[2025-04-05T18:14:17.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:14:17.141+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:17.141+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:14:17.166+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:17.165+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:14:17.173+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:14:17.198+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:17.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:14:17.226+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:17.226+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:14:17.259+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-05T18:14:47.642+0000] {processor.py:186} INFO - Started process (PID=7012) to work on /opt/airflow/dags/test.py
[2025-04-05T18:14:47.645+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:14:47.651+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:47.650+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:14:47.677+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:47.676+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:14:47.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:14:47.707+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:47.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:14:47.735+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:14:47.735+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:14:47.768+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-05T18:15:18.309+0000] {processor.py:186} INFO - Started process (PID=7079) to work on /opt/airflow/dags/test.py
[2025-04-05T18:15:18.311+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:15:18.317+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:18.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:15:18.331+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:18.331+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:15:18.338+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:15:18.359+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:18.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:15:18.378+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:18.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:15:18.410+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-05T18:15:49.379+0000] {processor.py:186} INFO - Started process (PID=7146) to work on /opt/airflow/dags/test.py
[2025-04-05T18:15:49.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:15:49.384+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:49.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:15:49.411+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:49.411+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:15:49.416+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:15:49.443+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:49.443+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:15:49.465+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:15:49.465+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:15:49.499+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-05T18:16:19.987+0000] {processor.py:186} INFO - Started process (PID=7212) to work on /opt/airflow/dags/test.py
[2025-04-05T18:16:19.989+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:16:19.993+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:19.992+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:16:20.027+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:20.027+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:16:20.034+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:16:20.057+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:20.057+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:16:20.083+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:20.083+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:16:20.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.135 seconds
[2025-04-05T18:16:50.321+0000] {processor.py:186} INFO - Started process (PID=7279) to work on /opt/airflow/dags/test.py
[2025-04-05T18:16:50.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:16:50.326+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:50.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:16:50.350+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:50.350+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:16:50.356+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:16:50.397+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:50.396+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:16:50.429+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:16:50.429+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:16:50.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.158 seconds
[2025-04-05T18:17:20.685+0000] {processor.py:186} INFO - Started process (PID=7345) to work on /opt/airflow/dags/test.py
[2025-04-05T18:17:20.688+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:17:20.693+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:20.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:17:20.720+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:20.720+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:17:20.724+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:17:20.751+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:20.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:17:20.771+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:20.770+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:17:20.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.133 seconds
[2025-04-05T18:17:50.910+0000] {processor.py:186} INFO - Started process (PID=7412) to work on /opt/airflow/dags/test.py
[2025-04-05T18:17:50.911+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:17:50.917+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:50.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:17:50.940+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:50.940+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:17:50.944+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:17:50.969+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:50.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:17:50.989+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:17:50.989+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:17:51.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-05T18:18:21.277+0000] {processor.py:186} INFO - Started process (PID=7478) to work on /opt/airflow/dags/test.py
[2025-04-05T18:18:21.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:18:21.281+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:21.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:18:21.303+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:21.302+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:18:21.307+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:18:21.332+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:21.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:18:21.352+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:21.352+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:18:21.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.119 seconds
[2025-04-05T18:18:51.819+0000] {processor.py:186} INFO - Started process (PID=7545) to work on /opt/airflow/dags/test.py
[2025-04-05T18:18:51.820+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:18:51.824+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:51.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:18:51.847+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:51.847+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:18:51.853+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:18:51.874+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:51.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:18:51.896+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:18:51.896+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:18:51.934+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:19:22.244+0000] {processor.py:186} INFO - Started process (PID=7611) to work on /opt/airflow/dags/test.py
[2025-04-05T18:19:22.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:19:22.248+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:22.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:19:22.271+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:22.271+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:19:22.277+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:19:22.300+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:22.300+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:19:22.323+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:22.321+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:19:22.350+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-05T18:19:52.873+0000] {processor.py:186} INFO - Started process (PID=7677) to work on /opt/airflow/dags/test.py
[2025-04-05T18:19:52.875+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:19:52.880+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:52.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:19:52.900+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:52.899+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:19:52.903+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:19:52.926+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:52.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:19:52.949+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:19:52.949+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:19:52.983+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-05T18:20:23.793+0000] {processor.py:186} INFO - Started process (PID=7744) to work on /opt/airflow/dags/test.py
[2025-04-05T18:20:23.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:20:23.807+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:23.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:20:23.840+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:23.840+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:20:23.848+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:20:23.876+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:23.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:20:23.896+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:23.896+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:20:23.923+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.149 seconds
[2025-04-05T18:20:54.868+0000] {processor.py:186} INFO - Started process (PID=7811) to work on /opt/airflow/dags/test.py
[2025-04-05T18:20:54.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:20:54.875+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:54.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:20:54.897+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:54.897+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:20:54.901+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:20:54.924+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:54.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:20:54.945+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:20:54.945+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:20:54.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-05T18:21:25.211+0000] {processor.py:186} INFO - Started process (PID=7878) to work on /opt/airflow/dags/test.py
[2025-04-05T18:21:25.212+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:21:25.218+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:25.218+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:21:25.240+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:25.239+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:21:25.244+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:21:25.269+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:25.269+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:21:25.288+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:25.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:21:25.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.120 seconds
[2025-04-05T18:21:55.733+0000] {processor.py:186} INFO - Started process (PID=7945) to work on /opt/airflow/dags/test.py
[2025-04-05T18:21:55.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:21:55.740+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:55.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:21:55.764+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:55.764+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:21:55.768+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:21:55.792+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:55.792+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:21:55.811+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:21:55.810+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:21:55.849+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:22:26.642+0000] {processor.py:186} INFO - Started process (PID=8012) to work on /opt/airflow/dags/test.py
[2025-04-05T18:22:26.643+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:22:26.649+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:26.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:22:26.671+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:26.670+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:22:26.674+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:22:26.701+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:26.701+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:22:26.720+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:26.720+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:22:26.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.118 seconds
[2025-04-05T18:22:57.277+0000] {processor.py:186} INFO - Started process (PID=8079) to work on /opt/airflow/dags/test.py
[2025-04-05T18:22:57.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:22:57.281+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:57.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:22:57.304+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:57.303+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:22:57.308+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:22:57.330+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:57.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:22:57.351+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:22:57.350+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:22:57.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-05T18:23:28.274+0000] {processor.py:186} INFO - Started process (PID=8146) to work on /opt/airflow/dags/test.py
[2025-04-05T18:23:28.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:23:28.287+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:28.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:23:28.310+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:28.309+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:23:28.314+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:23:28.337+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:28.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:23:28.360+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:28.360+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:23:28.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-05T18:23:58.619+0000] {processor.py:186} INFO - Started process (PID=8213) to work on /opt/airflow/dags/test.py
[2025-04-05T18:23:58.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:23:58.625+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:58.624+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:23:58.654+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:58.654+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:23:58.658+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:23:58.685+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:58.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:23:58.704+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:23:58.704+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:23:58.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-05T18:24:29.074+0000] {processor.py:186} INFO - Started process (PID=8280) to work on /opt/airflow/dags/test.py
[2025-04-05T18:24:29.075+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:24:29.078+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:29.077+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:24:29.097+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:29.096+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:24:29.100+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:24:29.124+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:29.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:24:29.143+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:29.142+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:24:29.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.114 seconds
[2025-04-05T18:24:59.438+0000] {processor.py:186} INFO - Started process (PID=8347) to work on /opt/airflow/dags/test.py
[2025-04-05T18:24:59.439+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:24:59.443+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:59.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:24:59.466+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:59.466+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:24:59.470+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:24:59.492+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:59.492+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:24:59.510+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:24:59.510+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:24:59.543+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-05T18:25:29.610+0000] {processor.py:186} INFO - Started process (PID=8414) to work on /opt/airflow/dags/test.py
[2025-04-05T18:25:29.612+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:25:29.615+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:25:29.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:25:29.639+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:25:29.639+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:25:29.643+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:25:29.665+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:25:29.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:25:29.683+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:25:29.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:25:29.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.111 seconds
[2025-04-05T18:25:59.986+0000] {processor.py:186} INFO - Started process (PID=8481) to work on /opt/airflow/dags/test.py
[2025-04-05T18:25:59.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:25:59.993+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:25:59.991+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:26:00.014+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:00.014+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:26:00.021+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:26:00.048+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:00.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:26:00.068+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:00.067+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:26:00.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.122 seconds
[2025-04-05T18:26:30.245+0000] {processor.py:186} INFO - Started process (PID=8549) to work on /opt/airflow/dags/test.py
[2025-04-05T18:26:30.246+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:26:30.252+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:30.251+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:26:30.275+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:30.274+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:26:30.278+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:26:30.304+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:30.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:26:30.325+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:26:30.324+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:26:30.354+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-05T18:27:00.683+0000] {processor.py:186} INFO - Started process (PID=8617) to work on /opt/airflow/dags/test.py
[2025-04-05T18:27:00.684+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:27:00.691+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:00.691+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:27:00.717+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:00.716+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:27:00.724+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:27:00.747+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:00.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:27:00.768+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:00.768+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:27:00.799+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:27:31.086+0000] {processor.py:186} INFO - Started process (PID=8684) to work on /opt/airflow/dags/test.py
[2025-04-05T18:27:31.087+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:27:31.090+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:31.090+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:27:31.112+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:31.111+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:27:31.118+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:27:31.139+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:31.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:27:31.159+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:27:31.158+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:27:31.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-05T18:28:01.877+0000] {processor.py:186} INFO - Started process (PID=8751) to work on /opt/airflow/dags/test.py
[2025-04-05T18:28:01.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:28:01.883+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:01.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:28:01.908+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:01.907+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:28:01.914+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:28:01.942+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:01.942+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:28:01.969+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:01.968+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:28:01.998+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.128 seconds
[2025-04-05T18:28:32.937+0000] {processor.py:186} INFO - Started process (PID=8818) to work on /opt/airflow/dags/test.py
[2025-04-05T18:28:32.939+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:28:32.945+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:32.944+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:28:32.973+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:32.972+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:28:32.980+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:28:33.002+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:33.002+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:28:33.021+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:28:33.021+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:28:33.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:29:03.723+0000] {processor.py:186} INFO - Started process (PID=8885) to work on /opt/airflow/dags/test.py
[2025-04-05T18:29:03.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:29:03.727+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:03.726+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:29:03.751+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:03.751+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:29:03.755+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:29:03.783+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:03.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:29:03.802+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:03.802+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:29:03.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-05T18:29:34.226+0000] {processor.py:186} INFO - Started process (PID=8952) to work on /opt/airflow/dags/test.py
[2025-04-05T18:29:34.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:29:34.230+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:34.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:29:34.252+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:34.251+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:29:34.259+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:29:34.281+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:34.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:29:34.300+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:29:34.300+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:29:34.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-05T18:30:04.720+0000] {processor.py:186} INFO - Started process (PID=9019) to work on /opt/airflow/dags/test.py
[2025-04-05T18:30:04.722+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:30:04.729+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:04.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:30:04.752+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:04.752+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:30:04.757+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:30:04.781+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:04.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:30:04.802+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:04.802+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:30:04.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-05T18:30:35.476+0000] {processor.py:186} INFO - Started process (PID=9086) to work on /opt/airflow/dags/test.py
[2025-04-05T18:30:35.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:30:35.482+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:35.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:30:35.510+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:35.510+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:30:35.517+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:30:35.541+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:35.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:30:35.561+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:30:35.560+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:30:35.593+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.125 seconds
[2025-04-05T18:31:06.334+0000] {processor.py:186} INFO - Started process (PID=9153) to work on /opt/airflow/dags/test.py
[2025-04-05T18:31:06.335+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:31:06.339+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:06.338+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:31:06.361+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:06.360+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:31:06.365+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:31:06.389+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:06.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:31:06.412+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:06.411+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:31:06.446+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.121 seconds
[2025-04-05T18:31:37.182+0000] {processor.py:186} INFO - Started process (PID=9220) to work on /opt/airflow/dags/test.py
[2025-04-05T18:31:37.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:31:37.189+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:37.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:31:37.216+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:37.214+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:31:37.220+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:31:37.247+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:37.246+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:31:37.269+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:31:37.269+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:31:37.303+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.140 seconds
[2025-04-05T18:32:08.109+0000] {processor.py:186} INFO - Started process (PID=9287) to work on /opt/airflow/dags/test.py
[2025-04-05T18:32:08.110+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:32:08.112+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:08.112+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:32:08.137+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:08.137+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:32:08.142+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:32:08.171+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:08.170+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:32:08.207+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:08.207+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:32:08.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.166 seconds
[2025-04-05T18:32:39.321+0000] {processor.py:186} INFO - Started process (PID=9354) to work on /opt/airflow/dags/test.py
[2025-04-05T18:32:39.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:32:39.329+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:39.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:32:39.346+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:39.346+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:32:39.350+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:32:39.372+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:39.372+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:32:39.399+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:32:39.399+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:32:39.441+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.132 seconds
[2025-04-05T18:33:09.542+0000] {processor.py:186} INFO - Started process (PID=9421) to work on /opt/airflow/dags/test.py
[2025-04-05T18:33:09.545+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:33:09.555+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:09.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:33:09.572+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:09.572+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:33:09.576+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:33:09.597+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:09.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:33:09.616+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:09.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:33:09.652+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-05T18:33:39.996+0000] {processor.py:186} INFO - Started process (PID=9488) to work on /opt/airflow/dags/test.py
[2025-04-05T18:33:39.997+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:33:40.000+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:39.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:33:40.016+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:40.016+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:33:40.020+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:33:40.043+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:40.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:33:40.060+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:33:40.060+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:33:40.085+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.099 seconds
[2025-04-05T18:34:10.933+0000] {processor.py:186} INFO - Started process (PID=9553) to work on /opt/airflow/dags/test.py
[2025-04-05T18:34:10.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:34:10.938+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:10.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:34:10.960+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:10.960+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:34:10.968+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:34:11.000+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:11.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:34:11.025+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:11.025+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:34:11.058+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.136 seconds
[2025-04-05T18:34:41.694+0000] {processor.py:186} INFO - Started process (PID=9618) to work on /opt/airflow/dags/test.py
[2025-04-05T18:34:41.695+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:34:41.698+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:41.697+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:34:41.714+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:41.714+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:34:41.721+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:34:41.744+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:41.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:34:41.771+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:34:41.771+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:34:41.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.117 seconds
[2025-04-05T18:35:12.132+0000] {processor.py:186} INFO - Started process (PID=9682) to work on /opt/airflow/dags/test.py
[2025-04-05T18:35:12.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:35:12.136+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:12.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:35:12.157+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:12.157+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:35:12.163+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:35:12.184+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:12.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:35:12.203+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:12.203+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:35:12.237+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-05T18:35:42.769+0000] {processor.py:186} INFO - Started process (PID=9748) to work on /opt/airflow/dags/test.py
[2025-04-05T18:35:42.770+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:35:42.773+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:42.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:35:42.792+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:42.792+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:35:42.796+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:35:42.821+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:42.821+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:35:42.842+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:35:42.842+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:35:42.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.116 seconds
[2025-04-05T18:36:13.464+0000] {processor.py:186} INFO - Started process (PID=9812) to work on /opt/airflow/dags/test.py
[2025-04-05T18:36:13.465+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:36:13.468+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:13.468+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:36:13.492+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:13.492+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:36:13.496+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:36:13.520+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:13.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:36:13.542+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:13.542+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:36:13.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.123 seconds
[2025-04-05T18:36:43.744+0000] {processor.py:186} INFO - Started process (PID=9873) to work on /opt/airflow/dags/test.py
[2025-04-05T18:36:43.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:36:43.751+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:43.751+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:36:43.770+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:43.770+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:36:43.774+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:36:43.800+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:43.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:36:43.819+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:36:43.819+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:36:43.852+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.115 seconds
[2025-04-05T18:37:14.393+0000] {processor.py:186} INFO - Started process (PID=9939) to work on /opt/airflow/dags/test.py
[2025-04-05T18:37:14.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:37:14.410+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:14.401+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:37:14.432+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:14.432+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:37:14.441+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:37:14.465+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:14.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:37:14.488+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:14.487+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:37:14.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.134 seconds
[2025-04-05T18:37:44.930+0000] {processor.py:186} INFO - Started process (PID=10006) to work on /opt/airflow/dags/test.py
[2025-04-05T18:37:44.931+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:37:44.934+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:44.933+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:37:44.952+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:44.951+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:37:44.956+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:37:44.983+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:44.982+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:37:45.003+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:37:45.003+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:37:45.049+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.129 seconds
[2025-04-05T18:38:15.479+0000] {processor.py:186} INFO - Started process (PID=10071) to work on /opt/airflow/dags/test.py
[2025-04-05T18:38:15.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:38:15.488+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:15.487+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:38:15.513+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:15.512+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:38:15.520+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:38:15.543+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:15.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:38:15.562+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:15.562+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:38:15.596+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.127 seconds
[2025-04-05T18:38:46.311+0000] {processor.py:186} INFO - Started process (PID=10138) to work on /opt/airflow/dags/test.py
[2025-04-05T18:38:46.312+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:38:46.314+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:46.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:38:46.331+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:46.331+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:38:46.335+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:38:46.359+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:46.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:38:46.378+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:38:46.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:38:46.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.109 seconds
[2025-04-05T18:39:18.681+0000] {processor.py:186} INFO - Started process (PID=10203) to work on /opt/airflow/dags/test.py
[2025-04-05T18:39:18.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:39:18.684+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:18.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:39:18.701+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:18.701+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:39:18.705+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:39:18.725+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:18.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:39:18.745+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:18.744+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:39:18.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.103 seconds
[2025-04-05T18:39:49.096+0000] {processor.py:186} INFO - Started process (PID=10267) to work on /opt/airflow/dags/test.py
[2025-04-05T18:39:49.097+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:39:49.101+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:49.100+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:39:49.123+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:49.123+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:39:49.126+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:39:49.148+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:49.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:39:49.168+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:39:49.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:39:49.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.110 seconds
[2025-04-05T18:40:20.469+0000] {processor.py:186} INFO - Started process (PID=10333) to work on /opt/airflow/dags/test.py
[2025-04-05T18:40:20.471+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test.py for tasks to queue
[2025-04-05T18:40:20.474+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:40:20.473+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test.py
[2025-04-05T18:40:20.498+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:40:20.498+0000] {test.py:24} ERROR - Error reading CSV file: [Errno 2] No such file or directory: '/opt/airflow/csv/src_input/amazon_categories_full copy.csv.csv'
[2025-04-05T18:40:20.502+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag_test' retrieved from /opt/airflow/dags/test.py
[2025-04-05T18:40:20.529+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:40:20.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-05T18:40:20.752+0000] {logging_mixin.py:190} INFO - [2025-04-05T18:40:20.752+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag_test to None, run_after=None
[2025-04-05T18:40:20.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test.py took 0.320 seconds
