[2025-04-07T14:08:01.654+0000] {processor.py:186} INFO - Started process (PID=91) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:08:01.655+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:08:01.659+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:08:01.658+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:08:02.841+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:08:02.894+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:08:02.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:08:02.913+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:08:02.912+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:08:02.993+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.353 seconds
[2025-04-07T14:08:34.046+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:08:34.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:08:34.052+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:08:34.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:08:34.308+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:08:34.340+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:08:34.340+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:08:34.357+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:08:34.357+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:08:34.389+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T14:09:05.052+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:09:05.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:09:05.056+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:09:05.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:09:05.365+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:09:05.400+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:09:05.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:09:05.428+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:09:05.428+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:09:05.474+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.431 seconds
[2025-04-07T14:09:35.889+0000] {processor.py:186} INFO - Started process (PID=293) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:09:35.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:09:35.895+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:09:35.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:09:36.212+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:09:36.248+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:09:36.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:09:36.274+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:09:36.274+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:09:36.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.438 seconds
[2025-04-07T14:10:07.234+0000] {processor.py:186} INFO - Started process (PID=360) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:10:07.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:10:07.254+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:10:07.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:10:07.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:10:07.962+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:10:07.961+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:10:08.024+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:10:08.024+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:10:08.193+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.975 seconds
[2025-04-07T14:10:39.026+0000] {processor.py:186} INFO - Started process (PID=428) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:10:39.041+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:10:39.044+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:10:39.044+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:10:39.367+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:10:39.399+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:10:39.398+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:10:39.417+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:10:39.417+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:10:39.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.431 seconds
[2025-04-07T14:11:09.881+0000] {processor.py:186} INFO - Started process (PID=495) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:11:09.882+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:11:09.885+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:11:09.885+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:11:10.117+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:11:10.147+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:11:10.146+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:11:10.164+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:11:10.164+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:11:10.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-07T14:11:40.457+0000] {processor.py:186} INFO - Started process (PID=562) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:11:40.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:11:40.461+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:11:40.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:11:40.686+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:11:40.716+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:11:40.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:11:40.733+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:11:40.733+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:11:40.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.312 seconds
[2025-04-07T14:12:10.914+0000] {processor.py:186} INFO - Started process (PID=629) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:12:10.915+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:12:10.918+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:12:10.918+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:12:11.151+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:12:11.181+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:12:11.180+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:12:11.198+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:12:11.197+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:12:11.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-07T14:12:41.616+0000] {processor.py:186} INFO - Started process (PID=697) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:12:41.617+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:12:41.620+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:12:41.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:12:41.865+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:12:41.898+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:12:41.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:12:41.917+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:12:41.916+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:12:41.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-07T14:13:12.583+0000] {processor.py:186} INFO - Started process (PID=764) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:13:12.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:13:12.587+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:13:12.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:13:12.845+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:13:12.881+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:13:12.880+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:13:12.905+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:13:12.905+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:13:12.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-07T14:13:43.308+0000] {processor.py:186} INFO - Started process (PID=831) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:13:43.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:13:43.314+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:13:43.314+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:13:43.566+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:13:43.600+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:13:43.600+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:13:43.619+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:13:43.618+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:13:43.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-07T14:14:14.294+0000] {processor.py:186} INFO - Started process (PID=898) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:14:14.295+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:14:14.299+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:14:14.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:14:14.571+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:14:14.607+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:14:14.606+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:14:14.629+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:14:14.629+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:14:14.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-07T14:14:45.031+0000] {processor.py:186} INFO - Started process (PID=965) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:14:45.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:14:45.038+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:14:45.037+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:14:45.336+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:14:45.371+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:14:45.370+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:14:45.390+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:14:45.390+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:14:45.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.401 seconds
[2025-04-07T14:15:15.577+0000] {processor.py:186} INFO - Started process (PID=1032) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:15:15.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:15:15.582+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:15:15.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:15:15.874+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:15:15.902+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:15:15.902+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:15:15.919+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:15:15.919+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:15:16.063+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.496 seconds
[2025-04-07T14:15:46.209+0000] {processor.py:186} INFO - Started process (PID=1099) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:15:46.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:15:46.216+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:15:46.215+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:15:46.497+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:15:46.530+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:15:46.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:15:46.548+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:15:46.547+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:15:46.586+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.387 seconds
[2025-04-07T14:16:16.967+0000] {processor.py:186} INFO - Started process (PID=1167) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:16:16.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:16:16.972+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:16:16.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:16:17.226+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:16:17.254+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:16:17.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:16:17.271+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:16:17.271+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:16:17.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-07T14:16:47.868+0000] {processor.py:186} INFO - Started process (PID=1234) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:16:47.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:16:47.872+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:16:47.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:16:48.222+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:16:48.269+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:16:48.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:16:48.290+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:16:48.289+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:16:48.319+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.459 seconds
[2025-04-07T14:17:18.490+0000] {processor.py:186} INFO - Started process (PID=1303) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:17:18.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:17:18.494+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:17:18.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:17:18.708+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:17:18.738+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:17:18.737+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:17:18.753+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:17:18.752+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:17:18.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.298 seconds
[2025-04-07T14:17:49.189+0000] {processor.py:186} INFO - Started process (PID=1368) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:17:49.190+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:17:49.193+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:17:49.193+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:17:49.478+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:17:49.514+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:17:49.513+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:17:49.536+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:17:49.536+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:17:49.582+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.402 seconds
[2025-04-07T14:18:19.818+0000] {processor.py:186} INFO - Started process (PID=1437) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:18:19.819+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:18:19.822+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:18:19.822+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:18:20.033+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:18:20.063+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:18:20.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:18:20.080+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:18:20.080+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:18:20.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.298 seconds
[2025-04-07T14:18:50.797+0000] {processor.py:186} INFO - Started process (PID=1502) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:18:50.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:18:50.801+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:18:50.800+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:18:51.045+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:18:51.084+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:18:51.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:18:51.105+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:18:51.105+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:18:51.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-07T14:19:21.311+0000] {processor.py:186} INFO - Started process (PID=1572) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:19:21.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:19:21.320+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:19:21.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:19:21.757+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:19:21.789+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:19:21.788+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:19:21.807+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:19:21.806+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:19:21.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.538 seconds
[2025-04-07T14:19:52.782+0000] {processor.py:186} INFO - Started process (PID=1639) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:19:52.783+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:19:52.787+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:19:52.786+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:19:53.063+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:19:53.260+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:19:53.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:19:53.277+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:19:53.276+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:19:53.305+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.534 seconds
[2025-04-07T14:20:23.430+0000] {processor.py:186} INFO - Started process (PID=1707) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:20:23.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:20:23.434+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:20:23.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:20:23.696+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:20:23.907+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:20:23.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:20:23.922+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:20:23.921+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:20:23.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.526 seconds
[2025-04-07T14:20:54.182+0000] {processor.py:186} INFO - Started process (PID=1773) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:20:54.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:20:54.186+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:20:54.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:20:54.444+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:20:54.665+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:20:54.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:20:54.681+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:20:54.681+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:20:54.707+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.537 seconds
[2025-04-07T14:21:24.892+0000] {processor.py:186} INFO - Started process (PID=1843) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:21:24.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:21:24.897+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:21:24.896+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:21:25.185+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:21:25.389+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:21:25.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:21:25.403+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:21:25.403+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:21:25.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.548 seconds
[2025-04-07T14:21:55.618+0000] {processor.py:186} INFO - Started process (PID=1910) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:21:55.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:21:55.624+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:21:55.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:21:56.062+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:21:56.086+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:21:56.085+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:21:56.100+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:21:56.100+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:21:56.131+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.520 seconds
[2025-04-07T14:22:26.766+0000] {processor.py:186} INFO - Started process (PID=1978) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:22:26.767+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:22:26.770+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:22:26.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:22:27.240+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:22:27.277+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:22:27.276+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:22:27.297+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:22:27.296+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:22:27.334+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.580 seconds
[2025-04-07T14:22:57.446+0000] {processor.py:186} INFO - Started process (PID=2050) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:22:57.448+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:22:57.451+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:22:57.451+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:22:57.926+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:22:57.955+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:22:57.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:22:57.975+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:22:57.975+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:22:58.003+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.565 seconds
[2025-04-07T14:23:28.419+0000] {processor.py:186} INFO - Started process (PID=2117) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:23:28.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:23:28.423+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:23:28.422+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:23:28.823+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:23:28.856+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:23:28.855+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:23:28.872+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:23:28.871+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:23:28.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.485 seconds
[2025-04-07T14:23:59.278+0000] {processor.py:186} INFO - Started process (PID=2184) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:23:59.280+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:23:59.283+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:23:59.283+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:23:59.728+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:23:59.754+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:23:59.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:23:59.770+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:23:59.769+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:23:59.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.587 seconds
[2025-04-07T14:24:30.678+0000] {processor.py:186} INFO - Started process (PID=2252) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:24:30.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:24:30.682+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:24:30.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:24:31.110+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:24:31.151+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:24:31.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:24:31.173+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:24:31.173+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:24:31.205+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.536 seconds
[2025-04-07T14:25:01.387+0000] {processor.py:186} INFO - Started process (PID=2322) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:25:01.389+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:25:01.392+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:25:01.391+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:25:01.881+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:25:01.919+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:25:01.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:25:01.947+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:25:01.946+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:25:01.991+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.611 seconds
[2025-04-07T14:25:32.098+0000] {processor.py:186} INFO - Started process (PID=2391) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:25:32.100+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:25:32.103+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:25:32.102+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:25:32.494+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:25:32.520+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:25:32.519+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:25:32.533+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:25:32.533+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:25:32.562+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.471 seconds
[2025-04-07T14:26:03.368+0000] {processor.py:186} INFO - Started process (PID=2458) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:26:03.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:26:03.373+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:26:03.373+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:26:03.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:26:03.919+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:26:03.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:26:03.948+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:26:03.948+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:26:03.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.619 seconds
[2025-04-07T14:26:35.001+0000] {processor.py:186} INFO - Started process (PID=2528) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:26:35.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:26:35.006+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:26:35.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:26:35.457+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:26:35.496+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:26:35.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:26:35.518+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:26:35.518+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:26:35.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.571 seconds
[2025-04-07T14:27:05.875+0000] {processor.py:186} INFO - Started process (PID=2599) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:27:05.876+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:27:05.879+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:27:05.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:27:06.187+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:27:06.227+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:27:06.227+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:27:06.248+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:27:06.248+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:27:06.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.418 seconds
[2025-04-07T14:27:36.658+0000] {processor.py:186} INFO - Started process (PID=2665) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:27:36.659+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:27:36.662+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:27:36.661+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:27:36.887+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:27:36.924+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:27:36.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:27:36.948+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:27:36.948+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:27:36.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-07T14:28:07.135+0000] {processor.py:186} INFO - Started process (PID=2734) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:28:07.136+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:28:07.138+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:28:07.138+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:28:07.362+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:28:07.402+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:28:07.401+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:28:07.432+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:28:07.431+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:28:07.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-07T14:28:38.079+0000] {processor.py:186} INFO - Started process (PID=2799) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:28:38.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:28:38.084+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:28:38.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:28:38.362+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:28:38.398+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:28:38.397+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:28:38.433+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:28:38.433+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:28:38.467+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.399 seconds
[2025-04-07T14:29:08.921+0000] {processor.py:186} INFO - Started process (PID=2865) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:29:08.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:29:08.925+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:29:08.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:29:09.188+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:29:09.262+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:29:09.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:29:09.280+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:29:09.280+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:29:09.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.403 seconds
[2025-04-07T14:29:39.756+0000] {processor.py:186} INFO - Started process (PID=2932) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:29:39.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:29:39.761+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:29:39.760+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:29:40.015+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:29:40.048+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:29:40.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:29:40.066+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:29:40.065+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:29:40.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T14:30:10.293+0000] {processor.py:186} INFO - Started process (PID=2999) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:30:10.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:30:10.298+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:30:10.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:30:10.582+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:30:10.626+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:30:10.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:30:10.652+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:30:10.652+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:30:10.685+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.403 seconds
[2025-04-07T14:30:40.903+0000] {processor.py:186} INFO - Started process (PID=3068) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:30:40.904+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:30:40.907+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:30:40.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:30:41.127+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:30:41.154+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:30:41.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:30:41.169+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:30:41.169+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:30:41.199+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.303 seconds
[2025-04-07T14:31:11.354+0000] {processor.py:186} INFO - Started process (PID=3135) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:31:11.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:31:11.359+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:31:11.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:31:11.617+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:31:11.650+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:31:11.650+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:31:11.670+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:31:11.670+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:31:11.704+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-07T14:31:41.940+0000] {processor.py:186} INFO - Started process (PID=3199) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:31:41.953+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:31:41.957+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:31:41.956+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:31:42.311+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:31:42.357+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:31:42.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:31:42.378+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:31:42.378+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:31:42.411+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-07T14:32:12.622+0000] {processor.py:186} INFO - Started process (PID=3265) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:32:12.623+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:32:12.626+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:32:12.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:32:12.912+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:32:12.945+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:32:12.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:32:12.964+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:32:12.964+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:32:12.997+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.384 seconds
[2025-04-07T14:32:43.540+0000] {processor.py:186} INFO - Started process (PID=3335) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:32:43.542+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:32:43.545+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:32:43.544+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:32:43.904+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:32:44.019+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:32:44.018+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:32:44.047+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:32:44.047+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:32:44.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.560 seconds
[2025-04-07T14:33:14.190+0000] {processor.py:186} INFO - Started process (PID=3403) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:33:14.191+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:33:14.194+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:33:14.194+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:33:14.416+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:33:14.457+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:33:14.456+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:33:14.476+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:33:14.476+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:33:14.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.321 seconds
[2025-04-07T14:33:44.568+0000] {processor.py:186} INFO - Started process (PID=3469) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:33:44.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:33:44.575+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:33:44.574+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:33:44.841+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:33:44.892+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:33:44.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:33:44.908+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:33:44.908+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:33:44.939+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-07T14:34:15.380+0000] {processor.py:186} INFO - Started process (PID=3536) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:34:15.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:34:15.384+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:34:15.383+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:34:15.627+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:34:15.661+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:34:15.660+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:34:15.682+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:34:15.682+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:34:15.721+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-07T14:34:46.079+0000] {processor.py:186} INFO - Started process (PID=3605) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:34:46.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:34:46.083+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:34:46.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:34:46.329+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:34:46.363+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:34:46.362+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:34:46.384+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:34:46.383+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:34:46.417+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-07T14:35:16.493+0000] {processor.py:186} INFO - Started process (PID=3670) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:35:16.495+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:35:16.498+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:35:16.498+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:35:16.780+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:35:16.821+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:35:16.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:35:16.843+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:35:16.842+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:35:16.885+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.401 seconds
[2025-04-07T14:35:47.057+0000] {processor.py:186} INFO - Started process (PID=3737) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:35:47.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:35:47.061+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:35:47.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:35:47.336+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:35:47.369+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:35:47.368+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:35:47.389+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:35:47.389+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:35:47.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.376 seconds
[2025-04-07T14:36:17.561+0000] {processor.py:186} INFO - Started process (PID=3805) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:36:17.562+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:36:17.565+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:36:17.565+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:36:17.804+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:36:17.844+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:36:17.843+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:36:17.870+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:36:17.870+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:36:17.912+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-07T14:36:48.182+0000] {processor.py:186} INFO - Started process (PID=3874) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:36:48.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:36:48.187+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:36:48.187+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:36:48.470+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:36:48.503+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:36:48.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:36:48.520+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:36:48.520+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:36:48.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-07T14:37:19.161+0000] {processor.py:186} INFO - Started process (PID=3940) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:37:19.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:37:19.165+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:37:19.165+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:37:19.400+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:37:19.428+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:37:19.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:37:19.445+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:37:19.445+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:37:19.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-07T14:37:49.570+0000] {processor.py:186} INFO - Started process (PID=4008) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:37:49.571+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:37:49.575+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:37:49.575+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:37:49.830+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:37:49.869+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:37:49.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:37:49.887+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:37:49.887+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:37:49.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-07T14:38:20.157+0000] {processor.py:186} INFO - Started process (PID=4076) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:38:20.158+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:38:20.163+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:38:20.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:38:20.405+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:38:20.439+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:38:20.439+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:38:20.456+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:38:20.456+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:38:20.489+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-07T14:38:51.277+0000] {processor.py:186} INFO - Started process (PID=4143) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:38:51.278+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:38:51.281+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:38:51.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:38:51.496+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:38:51.525+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:38:51.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:38:51.539+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:38:51.539+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:38:51.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.301 seconds
[2025-04-07T14:39:21.844+0000] {processor.py:186} INFO - Started process (PID=4210) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:39:21.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:39:21.850+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:39:21.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:39:22.143+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:39:22.173+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:39:22.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:39:22.192+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:39:22.192+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:39:22.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-07T14:39:52.829+0000] {processor.py:186} INFO - Started process (PID=4277) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:39:52.830+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:39:52.834+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:39:52.834+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:39:53.079+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:39:53.110+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:39:53.109+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:39:53.133+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:39:53.132+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:39:53.167+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-07T14:40:23.839+0000] {processor.py:186} INFO - Started process (PID=4344) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:40:23.840+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:40:23.843+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:40:23.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:40:24.083+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:40:24.113+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:40:24.112+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:40:24.135+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:40:24.135+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:40:24.165+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-07T14:40:54.280+0000] {processor.py:186} INFO - Started process (PID=4413) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:40:54.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:40:54.286+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:40:54.286+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:40:54.537+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:40:54.564+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:40:54.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:40:54.581+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:40:54.581+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:40:54.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-07T14:41:24.912+0000] {processor.py:186} INFO - Started process (PID=4478) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:41:24.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:41:24.917+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:41:24.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:41:25.212+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:41:25.238+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:41:25.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:41:25.259+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:41:25.258+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:41:25.289+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.388 seconds
[2025-04-07T14:41:55.431+0000] {processor.py:186} INFO - Started process (PID=4547) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:41:55.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:41:55.435+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:41:55.435+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:41:55.663+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:41:55.691+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:41:55.690+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:41:55.706+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:41:55.705+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:41:55.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.311 seconds
[2025-04-07T14:42:25.897+0000] {processor.py:186} INFO - Started process (PID=4612) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:42:25.898+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:42:25.902+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:42:25.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:42:26.204+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:42:26.241+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:42:26.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:42:26.265+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:42:26.264+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:42:26.294+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.407 seconds
[2025-04-07T14:42:56.752+0000] {processor.py:186} INFO - Started process (PID=4679) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:42:56.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:42:56.757+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:42:56.757+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:42:56.993+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:42:57.025+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:42:57.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:42:57.048+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:42:57.048+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:42:57.078+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-07T14:43:27.431+0000] {processor.py:186} INFO - Started process (PID=4746) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:43:27.432+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:43:27.434+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:43:27.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:43:27.668+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:43:27.700+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:43:27.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:43:27.716+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:43:27.716+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:43:27.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-07T14:43:58.052+0000] {processor.py:186} INFO - Started process (PID=4813) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:43:58.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:43:58.056+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:43:58.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:43:58.350+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:43:58.383+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:43:58.382+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:43:58.398+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:43:58.398+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:43:58.419+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.376 seconds
[2025-04-07T14:44:28.646+0000] {processor.py:186} INFO - Started process (PID=4880) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:44:28.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:44:28.653+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:44:28.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:44:28.964+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:44:28.997+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:44:28.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:44:29.013+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:44:29.013+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:44:29.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-07T14:44:59.191+0000] {processor.py:186} INFO - Started process (PID=4947) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:44:59.192+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:44:59.195+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:44:59.195+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:44:59.502+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:44:59.531+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:44:59.531+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:44:59.556+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:44:59.556+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:44:59.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-07T14:45:29.731+0000] {processor.py:186} INFO - Started process (PID=5021) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:45:29.732+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:45:29.735+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:45:29.735+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:45:29.976+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:45:30.005+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:45:30.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:45:30.030+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:45:30.030+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:45:30.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-07T14:46:00.306+0000] {processor.py:186} INFO - Started process (PID=5090) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:46:00.308+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:46:00.311+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:46:00.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:46:00.580+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:46:00.609+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:46:00.608+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:46:00.629+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:46:00.628+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:46:00.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-07T14:46:30.885+0000] {processor.py:186} INFO - Started process (PID=5157) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:46:30.887+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:46:30.891+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:46:30.890+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:46:31.133+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:46:31.163+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:46:31.163+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:46:31.183+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:46:31.183+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:46:31.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-07T14:47:01.477+0000] {processor.py:186} INFO - Started process (PID=5221) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:47:01.478+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:47:01.481+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:47:01.481+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:47:01.754+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:47:01.791+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:47:01.790+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:47:01.809+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:47:01.809+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:47:01.839+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-07T14:47:31.972+0000] {processor.py:186} INFO - Started process (PID=5288) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:47:31.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:47:31.977+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:47:31.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:47:32.285+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:47:32.324+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:47:32.323+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:47:32.345+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:47:32.344+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:47:32.379+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.415 seconds
[2025-04-07T14:48:02.546+0000] {processor.py:186} INFO - Started process (PID=5356) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:48:02.547+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:48:02.550+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:48:02.550+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:48:02.772+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:48:02.801+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:48:02.800+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:48:02.817+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:48:02.817+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:48:02.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-07T14:48:33.196+0000] {processor.py:186} INFO - Started process (PID=5422) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:48:33.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:48:33.200+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:48:33.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:48:33.454+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:48:33.483+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:48:33.482+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:48:33.498+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:48:33.498+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:48:33.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-07T14:49:03.878+0000] {processor.py:186} INFO - Started process (PID=5489) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:49:03.880+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:49:03.883+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:49:03.882+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:49:04.195+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:49:04.242+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:49:04.241+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:49:04.272+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:49:04.272+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:49:04.315+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.449 seconds
[2025-04-07T14:49:34.880+0000] {processor.py:186} INFO - Started process (PID=5556) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:49:34.881+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:49:34.884+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:49:34.883+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:49:35.113+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:49:35.149+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:49:35.148+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:49:35.175+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:49:35.175+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:49:35.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T14:50:06.009+0000] {processor.py:186} INFO - Started process (PID=5621) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:50:06.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:50:06.014+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:50:06.013+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:50:06.277+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:50:06.313+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:50:06.313+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:50:06.337+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:50:06.337+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:50:06.373+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-07T14:50:37.246+0000] {processor.py:186} INFO - Started process (PID=5689) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:50:37.248+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:50:37.251+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:50:37.250+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:50:37.520+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:50:37.557+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:50:37.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:50:37.580+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:50:37.580+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:50:37.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-07T14:51:07.923+0000] {processor.py:186} INFO - Started process (PID=5756) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:51:07.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:51:07.929+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:51:07.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:51:08.193+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:51:08.227+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:51:08.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:51:08.243+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:51:08.242+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:51:08.271+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-07T14:51:38.385+0000] {processor.py:186} INFO - Started process (PID=5823) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:51:38.387+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:51:38.389+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:51:38.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:51:38.676+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:51:38.714+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:51:38.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:51:38.731+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:51:38.731+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:51:38.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-07T14:56:54.326+0000] {processor.py:186} INFO - Started process (PID=109) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:56:54.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:56:54.332+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:56:54.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:56:54.749+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:56:54.865+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:56:54.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:56:54.883+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:56:54.882+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:56:55.013+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.697 seconds
[2025-04-07T14:57:26.003+0000] {processor.py:186} INFO - Started process (PID=176) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:57:26.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:57:26.006+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:57:26.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:57:26.235+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:57:26.264+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:57:26.264+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:57:26.282+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:57:26.281+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:57:26.311+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.315 seconds
[2025-04-07T14:58:02.765+0000] {processor.py:186} INFO - Started process (PID=243) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:58:02.766+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:58:02.769+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:58:02.768+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:58:02.985+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:58:03.017+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:58:03.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:58:03.034+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:58:03.034+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:58:03.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.614 seconds
[2025-04-07T14:58:33.635+0000] {processor.py:186} INFO - Started process (PID=310) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:58:33.636+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:58:33.639+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:58:33.639+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:58:33.971+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:58:34.013+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:58:34.012+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:58:34.030+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:58:34.030+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:58:34.057+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.429 seconds
[2025-04-07T14:59:04.333+0000] {processor.py:186} INFO - Started process (PID=377) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:59:04.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:59:04.338+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:59:04.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:59:04.619+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:59:04.668+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:59:04.667+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:59:04.689+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:59:04.689+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:59:04.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.393 seconds
[2025-04-07T14:59:35.365+0000] {processor.py:186} INFO - Started process (PID=444) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:59:35.366+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T14:59:35.369+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:59:35.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:59:35.640+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T14:59:35.669+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:59:35.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T14:59:35.693+0000] {logging_mixin.py:190} INFO - [2025-04-07T14:59:35.692+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T14:59:35.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-07T15:00:06.473+0000] {processor.py:186} INFO - Started process (PID=511) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:00:06.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:00:06.477+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:00:06.477+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:00:06.756+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:00:06.786+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:00:06.785+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:00:06.808+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:00:06.807+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:00:06.836+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-07T15:00:38.061+0000] {processor.py:186} INFO - Started process (PID=579) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:00:38.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:00:38.066+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:00:38.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:00:38.383+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:00:38.464+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:00:38.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:00:38.490+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:00:38.489+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:00:38.525+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.475 seconds
[2025-04-07T15:01:09.578+0000] {processor.py:186} INFO - Started process (PID=647) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:01:09.579+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:01:09.582+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:01:09.581+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:01:09.874+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:01:09.908+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:01:09.907+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:01:09.929+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:01:09.929+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:01:09.955+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-07T15:01:40.304+0000] {processor.py:186} INFO - Started process (PID=712) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:01:40.305+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:01:40.308+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:01:40.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:01:40.566+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:01:40.596+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:01:40.595+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:01:40.612+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:01:40.612+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:01:40.640+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-07T15:02:12.064+0000] {processor.py:186} INFO - Started process (PID=778) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:02:12.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:02:12.068+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:02:12.068+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:02:12.295+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:02:12.335+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:02:12.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:02:12.354+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:02:12.354+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:02:12.385+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-07T15:02:42.846+0000] {processor.py:186} INFO - Started process (PID=840) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:02:42.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:02:42.850+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:02:42.850+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:02:43.104+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:02:43.134+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:02:43.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:02:43.152+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:02:43.152+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:02:43.183+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-07T15:03:14.511+0000] {processor.py:186} INFO - Started process (PID=909) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:03:14.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:03:14.515+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:03:14.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:03:14.835+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:03:14.865+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:03:14.864+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:03:14.881+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:03:14.880+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:03:14.913+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.409 seconds
[2025-04-07T15:03:45.903+0000] {processor.py:186} INFO - Started process (PID=982) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:03:45.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:03:45.908+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:03:45.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:03:46.171+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:03:46.211+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:03:46.210+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:03:46.236+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:03:46.236+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:03:46.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-07T15:04:17.449+0000] {processor.py:186} INFO - Started process (PID=1051) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:04:17.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:04:17.453+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:04:17.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:04:17.687+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:04:17.715+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:04:17.714+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:04:17.733+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:04:17.732+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:04:17.778+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-07T15:04:47.864+0000] {processor.py:186} INFO - Started process (PID=1115) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:04:47.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:04:47.868+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:04:47.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:04:48.111+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:04:48.143+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:04:48.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:04:48.164+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:04:48.163+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:04:48.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-07T15:05:18.472+0000] {processor.py:186} INFO - Started process (PID=1183) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:05:18.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:05:18.476+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:05:18.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:05:18.930+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:05:18.957+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:05:18.957+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:05:18.972+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:05:18.972+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:05:19.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.615 seconds
[2025-04-07T15:05:49.495+0000] {processor.py:186} INFO - Started process (PID=1250) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:05:49.496+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:05:49.499+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:05:49.499+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:05:49.955+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:05:49.985+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:05:49.985+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:05:50.002+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:05:50.002+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:05:50.033+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.549 seconds
[2025-04-07T15:06:20.132+0000] {processor.py:186} INFO - Started process (PID=1318) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:06:20.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:06:20.137+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:06:20.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:06:20.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:06:20.612+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:06:20.611+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:06:20.627+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:06:20.626+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:06:20.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.533 seconds
[2025-04-07T15:06:50.779+0000] {processor.py:186} INFO - Started process (PID=1386) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:06:50.781+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:06:50.784+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:06:50.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:06:51.267+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:06:51.294+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:06:51.293+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:06:51.309+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:06:51.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:06:51.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.568 seconds
[2025-04-07T15:07:21.854+0000] {processor.py:186} INFO - Started process (PID=1453) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:07:21.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:07:21.858+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:07:21.858+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:07:22.348+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:07:22.376+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:07:22.375+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:07:22.393+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:07:22.393+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:07:22.423+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.576 seconds
[2025-04-07T15:07:52.627+0000] {processor.py:186} INFO - Started process (PID=1519) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:07:52.628+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:07:52.631+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:07:52.631+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:07:53.088+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:07:53.114+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:07:53.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:07:53.129+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:07:53.129+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:07:53.159+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.543 seconds
[2025-04-07T15:08:23.555+0000] {processor.py:186} INFO - Started process (PID=1589) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:08:23.556+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:08:23.561+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:08:23.561+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:08:24.114+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:08:24.144+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:08:24.144+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:08:24.165+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:08:24.164+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:08:24.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.653 seconds
[2025-04-07T15:08:54.827+0000] {processor.py:186} INFO - Started process (PID=1656) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:08:54.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:08:54.833+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:08:54.833+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:08:55.064+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:08:55.258+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:08:55.258+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:08:55.274+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:08:55.273+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:08:55.298+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.480 seconds
[2025-04-07T15:09:25.445+0000] {processor.py:186} INFO - Started process (PID=1723) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:09:25.446+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:09:25.449+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:09:25.449+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:09:25.661+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:09:25.688+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:09:25.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:09:25.865+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:09:25.865+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:09:25.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.457 seconds
[2025-04-07T15:09:56.043+0000] {processor.py:186} INFO - Started process (PID=1790) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:09:56.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:09:56.047+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:09:56.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:09:56.418+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:09:56.443+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:09:56.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:09:56.456+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:09:56.456+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:09:56.485+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.453 seconds
[2025-04-07T15:10:27.437+0000] {processor.py:186} INFO - Started process (PID=1857) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:10:27.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:10:27.442+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:10:27.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:10:27.895+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:10:27.918+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:10:27.918+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:10:27.932+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:10:27.932+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:10:27.961+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.531 seconds
[2025-04-07T15:10:58.072+0000] {processor.py:186} INFO - Started process (PID=1927) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:10:58.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:10:58.076+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:10:58.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:10:58.511+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:10:58.534+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:10:58.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:10:58.548+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:10:58.548+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:10:58.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.515 seconds
[2025-04-07T15:11:28.883+0000] {processor.py:186} INFO - Started process (PID=1996) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:11:28.884+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:11:28.887+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:11:28.887+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:11:29.314+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:11:29.338+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:11:29.337+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:11:29.351+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:11:29.351+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:11:29.378+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.502 seconds
[2025-04-07T15:11:59.658+0000] {processor.py:186} INFO - Started process (PID=2063) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:11:59.660+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:11:59.662+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:11:59.662+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:12:00.073+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:12:00.098+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:12:00.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:12:00.112+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:12:00.112+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:12:00.140+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.489 seconds
[2025-04-07T15:12:31.117+0000] {processor.py:186} INFO - Started process (PID=2130) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:12:31.118+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:12:31.120+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:12:31.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:12:31.534+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:12:31.560+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:12:31.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:12:31.574+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:12:31.574+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:12:31.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.496 seconds
[2025-04-07T15:13:02.018+0000] {processor.py:186} INFO - Started process (PID=2198) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:13:02.019+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:13:02.022+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:13:02.022+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:13:02.275+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:13:02.312+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:13:02.311+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:13:02.334+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:13:02.334+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:13:02.366+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-07T15:13:32.422+0000] {processor.py:186} INFO - Started process (PID=2266) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:13:32.423+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:13:32.426+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:13:32.425+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:13:32.652+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:13:32.683+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:13:32.682+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:13:32.705+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:13:32.705+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:13:32.737+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.322 seconds
[2025-04-07T15:14:02.991+0000] {processor.py:186} INFO - Started process (PID=2333) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:14:02.992+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:14:02.994+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:14:02.994+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:14:03.282+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:14:03.315+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:14:03.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:14:03.332+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:14:03.332+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:14:03.364+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-07T15:14:34.166+0000] {processor.py:186} INFO - Started process (PID=2400) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:14:34.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:14:34.171+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:14:34.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:14:34.430+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:14:34.471+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:14:34.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:14:34.490+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:14:34.489+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:14:34.519+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-07T15:15:04.678+0000] {processor.py:186} INFO - Started process (PID=2469) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:15:04.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:15:04.683+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:15:04.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:15:04.986+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:15:05.017+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:15:05.017+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:15:05.039+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:15:05.039+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:15:05.074+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.406 seconds
[2025-04-07T15:15:35.991+0000] {processor.py:186} INFO - Started process (PID=2535) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:15:35.993+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:15:35.995+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:15:35.995+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:15:36.262+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:15:36.303+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:15:36.302+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:15:36.321+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:15:36.321+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:15:36.353+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-07T15:16:06.419+0000] {processor.py:186} INFO - Started process (PID=2602) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:16:06.420+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:16:06.423+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:16:06.423+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:16:06.708+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:16:06.747+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:16:06.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:16:06.763+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:16:06.763+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:16:06.795+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-07T15:16:36.882+0000] {processor.py:186} INFO - Started process (PID=2670) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:16:36.883+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:16:36.887+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:16:36.886+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:16:37.139+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:16:37.170+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:16:37.169+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:16:37.189+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:16:37.189+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:16:37.225+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-07T15:17:07.369+0000] {processor.py:186} INFO - Started process (PID=2736) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:17:07.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:17:07.375+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:17:07.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:17:07.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:17:07.730+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:17:07.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:17:07.755+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:17:07.755+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:17:07.797+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.439 seconds
[2025-04-07T15:17:38.021+0000] {processor.py:186} INFO - Started process (PID=2805) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:17:38.023+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:17:38.027+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:17:38.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:17:38.251+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:17:38.280+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:17:38.279+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:17:38.296+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:17:38.296+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:17:38.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.310 seconds
[2025-04-07T15:18:09.320+0000] {processor.py:186} INFO - Started process (PID=2872) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:18:09.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:18:09.324+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:18:09.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:18:09.586+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:18:09.619+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:18:09.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:18:09.638+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:18:09.638+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:18:09.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-07T15:18:40.209+0000] {processor.py:186} INFO - Started process (PID=2939) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:18:40.210+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:18:40.214+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:18:40.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:18:40.477+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:18:40.506+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:18:40.505+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:18:40.522+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:18:40.521+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:18:40.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.498 seconds
[2025-04-07T15:19:10.869+0000] {processor.py:186} INFO - Started process (PID=3006) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:19:10.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:19:10.873+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:19:10.873+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:19:11.118+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:19:11.148+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:19:11.147+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:19:11.175+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:19:11.174+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:19:11.209+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-07T15:19:41.265+0000] {processor.py:186} INFO - Started process (PID=3075) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:19:41.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:19:41.268+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:19:41.268+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:19:41.512+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:19:41.541+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:19:41.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:19:41.557+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:19:41.556+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:19:41.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-07T15:20:11.739+0000] {processor.py:186} INFO - Started process (PID=3139) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:20:11.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:20:11.744+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:20:11.743+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:20:11.978+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:20:12.008+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:20:12.007+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:20:12.027+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:20:12.026+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:20:12.056+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-07T15:20:42.565+0000] {processor.py:186} INFO - Started process (PID=3206) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:20:42.566+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:20:42.569+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:20:42.568+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:20:42.806+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:20:42.838+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:20:42.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:20:42.857+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:20:42.856+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:20:42.887+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.329 seconds
[2025-04-07T15:21:13.020+0000] {processor.py:186} INFO - Started process (PID=3273) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:21:13.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:21:13.025+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:21:13.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:21:13.253+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:21:13.284+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:21:13.283+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:21:13.303+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:21:13.302+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:21:13.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-07T15:21:43.396+0000] {processor.py:186} INFO - Started process (PID=3340) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:21:43.398+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:21:43.401+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:21:43.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:21:43.636+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:21:43.671+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:21:43.670+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:21:43.702+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:21:43.702+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:21:43.738+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-07T15:22:14.269+0000] {processor.py:186} INFO - Started process (PID=3407) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:22:14.271+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:22:14.275+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:22:14.274+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:22:14.526+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:22:14.561+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:22:14.561+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:22:14.577+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:22:14.577+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:22:14.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-07T15:22:44.739+0000] {processor.py:186} INFO - Started process (PID=3473) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:22:44.740+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:22:44.743+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:22:44.742+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:22:45.010+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:22:45.047+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:22:45.046+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:22:45.068+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:22:45.068+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:22:45.101+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-07T15:23:16.072+0000] {processor.py:186} INFO - Started process (PID=3540) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:23:16.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:23:16.075+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:23:16.075+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:23:16.289+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:23:16.319+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:23:16.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:23:16.338+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:23:16.337+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:23:16.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.298 seconds
[2025-04-07T15:23:46.444+0000] {processor.py:186} INFO - Started process (PID=3607) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:23:46.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:23:46.449+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:23:46.448+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:23:46.672+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:23:46.700+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:23:46.700+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:23:46.715+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:23:46.715+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:23:46.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.318 seconds
[2025-04-07T15:24:17.822+0000] {processor.py:186} INFO - Started process (PID=3680) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:24:17.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:24:17.826+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:24:17.825+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:24:18.112+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:24:18.182+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:24:18.181+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:24:18.222+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:24:18.222+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:24:18.262+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.453 seconds
[2025-04-07T15:24:48.511+0000] {processor.py:186} INFO - Started process (PID=3747) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:24:48.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:24:48.515+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:24:48.514+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:24:48.786+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:24:48.817+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:24:48.816+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:24:48.837+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:24:48.837+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:24:48.868+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-07T15:25:19.403+0000] {processor.py:186} INFO - Started process (PID=3814) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:25:19.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:25:19.410+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:25:19.409+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:25:19.685+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:25:19.716+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:25:19.715+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:25:19.735+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:25:19.735+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:25:19.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.420 seconds
[2025-04-07T15:25:50.720+0000] {processor.py:186} INFO - Started process (PID=3882) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:25:50.721+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:25:50.724+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:25:50.723+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:25:51.005+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:25:51.035+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:25:51.034+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:25:51.051+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:25:51.050+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:25:51.079+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-07T15:26:21.260+0000] {processor.py:186} INFO - Started process (PID=3950) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:26:21.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:26:21.264+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:26:21.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:26:21.544+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:26:21.580+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:26:21.580+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:26:21.600+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:26:21.599+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:26:21.633+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-07T15:26:51.824+0000] {processor.py:186} INFO - Started process (PID=4016) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:26:51.825+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:26:51.828+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:26:51.828+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:26:52.057+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:26:52.099+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:26:52.098+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:26:52.118+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:26:52.118+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:26:52.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-07T15:27:22.354+0000] {processor.py:186} INFO - Started process (PID=4084) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:27:22.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:27:22.360+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:27:22.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:27:22.611+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:27:22.641+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:27:22.641+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:27:22.662+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:27:22.661+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:27:22.692+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-07T15:27:52.986+0000] {processor.py:186} INFO - Started process (PID=4153) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:27:52.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:27:52.991+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:27:52.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:27:53.222+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:27:53.286+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:27:53.285+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:27:53.309+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:27:53.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:27:53.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-07T15:28:23.426+0000] {processor.py:186} INFO - Started process (PID=4220) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:28:23.430+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:28:23.434+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:28:23.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:28:23.764+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:28:23.791+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:28:23.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:28:23.809+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:28:23.809+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:28:23.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.432 seconds
[2025-04-07T15:28:54.132+0000] {processor.py:186} INFO - Started process (PID=4286) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:28:54.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:28:54.137+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:28:54.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:28:54.395+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:28:54.426+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:28:54.426+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:28:54.446+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:28:54.445+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:28:54.476+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T15:29:24.930+0000] {processor.py:186} INFO - Started process (PID=4351) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:29:24.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:29:24.937+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:29:24.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:29:25.255+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:29:25.291+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:29:25.290+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:29:25.311+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:29:25.311+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:29:25.339+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.421 seconds
[2025-04-07T15:29:55.401+0000] {processor.py:186} INFO - Started process (PID=4417) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:29:55.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:29:55.404+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:29:55.404+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:29:55.617+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:29:55.648+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:29:55.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:29:55.668+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:29:55.668+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:29:55.695+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.301 seconds
[2025-04-07T15:30:26.919+0000] {processor.py:186} INFO - Started process (PID=4484) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:30:26.920+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:30:26.924+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:30:26.923+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:30:27.248+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:30:27.289+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:30:27.289+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:30:27.309+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:30:27.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:30:27.341+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.431 seconds
[2025-04-07T15:30:58.104+0000] {processor.py:186} INFO - Started process (PID=4551) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:30:58.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:30:58.107+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:30:58.107+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:30:58.356+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:30:58.390+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:30:58.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:30:58.410+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:30:58.410+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:30:58.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.443 seconds
[2025-04-07T15:31:28.831+0000] {processor.py:186} INFO - Started process (PID=4617) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:31:28.832+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:31:28.836+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:31:28.836+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:31:29.135+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:31:29.188+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:31:29.187+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:31:29.221+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:31:29.220+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:31:29.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.436 seconds
[2025-04-07T15:31:59.396+0000] {processor.py:186} INFO - Started process (PID=4684) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:31:59.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:31:59.400+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:31:59.400+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:31:59.600+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:31:59.628+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:31:59.628+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:31:59.642+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:31:59.642+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:31:59.671+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.282 seconds
[2025-04-07T15:32:30.311+0000] {processor.py:186} INFO - Started process (PID=4751) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:32:30.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:32:30.316+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:32:30.315+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:32:30.585+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:32:30.612+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:32:30.612+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:32:30.628+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:32:30.628+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:32:30.657+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T15:33:00.960+0000] {processor.py:186} INFO - Started process (PID=4818) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:33:00.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:33:00.965+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:33:00.965+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:33:01.211+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:33:01.242+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:33:01.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:33:01.263+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:33:01.263+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:33:01.291+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-07T15:33:31.695+0000] {processor.py:186} INFO - Started process (PID=4885) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:33:31.697+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:33:31.700+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:33:31.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:33:31.984+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:33:32.011+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:33:32.010+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:33:32.025+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:33:32.025+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:33:32.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-07T15:34:02.404+0000] {processor.py:186} INFO - Started process (PID=4953) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:34:02.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:34:02.409+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:34:02.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:34:02.700+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:34:02.732+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:34:02.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:34:02.751+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:34:02.751+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:34:02.787+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.393 seconds
[2025-04-07T15:34:32.925+0000] {processor.py:186} INFO - Started process (PID=5021) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:34:32.926+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:34:32.928+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:34:32.928+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:34:33.150+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:34:33.178+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:34:33.178+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:34:33.193+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:34:33.193+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:34:33.223+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.306 seconds
[2025-04-07T15:35:03.294+0000] {processor.py:186} INFO - Started process (PID=5088) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:35:03.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:35:03.298+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:35:03.298+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:35:03.521+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:35:03.551+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:35:03.550+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:35:03.566+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:35:03.566+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:35:03.595+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.308 seconds
[2025-04-07T15:35:33.762+0000] {processor.py:186} INFO - Started process (PID=5155) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:35:33.763+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:35:33.766+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:35:33.766+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:35:34.066+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:35:34.094+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:35:34.093+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:35:34.108+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:35:34.108+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:35:34.139+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-07T15:36:04.198+0000] {processor.py:186} INFO - Started process (PID=5223) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:36:04.199+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:36:04.202+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:36:04.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:36:04.431+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:36:04.459+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:36:04.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:36:04.475+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:36:04.474+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:36:04.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.313 seconds
[2025-04-07T15:36:34.587+0000] {processor.py:186} INFO - Started process (PID=5290) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:36:34.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:36:34.591+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:36:34.591+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:36:34.807+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:36:34.839+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:36:34.838+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:36:34.854+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:36:34.853+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:36:34.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.301 seconds
[2025-04-07T15:37:05.056+0000] {processor.py:186} INFO - Started process (PID=5356) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:37:05.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:37:05.060+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:37:05.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:37:05.505+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:37:05.545+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:37:05.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:37:05.568+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:37:05.568+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:37:05.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.555 seconds
[2025-04-07T15:37:35.787+0000] {processor.py:186} INFO - Started process (PID=5424) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:37:35.789+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:37:35.792+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:37:35.791+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:37:36.296+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:37:36.332+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:37:36.332+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:37:36.347+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:37:36.347+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:37:36.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.597 seconds
[2025-04-07T15:38:07.028+0000] {processor.py:186} INFO - Started process (PID=5491) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:38:07.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:38:07.033+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:38:07.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:38:07.614+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:38:07.648+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:38:07.647+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:38:07.665+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:38:07.665+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:38:07.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.681 seconds
[2025-04-07T15:38:37.922+0000] {processor.py:186} INFO - Started process (PID=5561) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:38:37.924+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:38:37.928+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:38:37.927+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:38:38.223+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:38:38.474+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:38:38.474+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:38:38.493+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:38:38.492+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:38:38.628+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.714 seconds
[2025-04-07T15:39:09.420+0000] {processor.py:186} INFO - Started process (PID=5627) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:39:09.421+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:39:09.424+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:39:09.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:39:09.853+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:39:09.884+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:39:09.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:39:09.899+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:39:09.899+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:39:09.929+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.522 seconds
[2025-04-07T15:39:40.885+0000] {processor.py:186} INFO - Started process (PID=5695) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:39:40.886+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:39:40.889+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:39:40.888+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:39:41.127+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:39:41.319+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:39:41.319+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:39:41.335+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:39:41.334+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:39:41.362+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.486 seconds
[2025-04-07T15:40:11.436+0000] {processor.py:186} INFO - Started process (PID=5764) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:40:11.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:40:11.440+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:40:11.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:40:11.688+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:40:11.722+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:40:11.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:40:11.943+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:40:11.943+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:40:11.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.545 seconds
[2025-04-07T15:40:42.152+0000] {processor.py:186} INFO - Started process (PID=5831) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:40:42.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:40:42.156+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:40:42.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:40:42.517+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:40:42.540+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:40:42.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:40:42.553+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:40:42.553+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:40:42.581+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.436 seconds
[2025-04-07T15:41:13.409+0000] {processor.py:186} INFO - Started process (PID=5898) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:41:13.411+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:41:13.414+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:41:13.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:41:13.857+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:41:13.894+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:41:13.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:41:13.917+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:41:13.916+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:41:13.953+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.557 seconds
[2025-04-07T15:41:44.356+0000] {processor.py:186} INFO - Started process (PID=5968) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:41:44.358+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:41:44.362+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:41:44.361+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:41:44.813+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:41:44.869+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:41:44.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:41:44.888+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:41:44.888+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:41:44.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.575 seconds
[2025-04-07T15:42:15.677+0000] {processor.py:186} INFO - Started process (PID=6036) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:42:15.682+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:42:15.687+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:42:15.686+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:42:16.259+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:42:16.284+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:42:16.284+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:42:16.299+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:42:16.298+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:42:16.328+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.661 seconds
[2025-04-07T15:42:46.484+0000] {processor.py:186} INFO - Started process (PID=6103) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:42:46.485+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:42:46.488+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:42:46.488+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:42:46.906+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:42:46.931+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:42:46.931+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:42:46.945+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:42:46.945+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:42:46.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.497 seconds
[2025-04-07T15:43:17.146+0000] {processor.py:186} INFO - Started process (PID=6171) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:43:17.148+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:43:17.151+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:43:17.150+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:43:17.646+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:43:17.674+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:43:17.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:43:17.689+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:43:17.689+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:43:17.719+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.582 seconds
[2025-04-07T15:43:47.861+0000] {processor.py:186} INFO - Started process (PID=6239) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:43:47.863+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:43:47.866+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:43:47.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:43:48.128+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:43:48.166+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:43:48.166+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:43:48.185+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:43:48.184+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:43:48.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-07T15:44:18.608+0000] {processor.py:186} INFO - Started process (PID=6306) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:44:18.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:44:18.613+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:44:18.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:44:18.899+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:44:18.956+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:44:18.955+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:44:18.975+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:44:18.974+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:44:19.009+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.408 seconds
[2025-04-07T15:44:49.479+0000] {processor.py:186} INFO - Started process (PID=6373) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:44:49.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:44:49.483+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:44:49.483+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:44:49.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:44:49.756+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:44:49.755+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:44:49.772+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:44:49.772+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:44:49.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-07T15:45:20.363+0000] {processor.py:186} INFO - Started process (PID=6447) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:45:20.364+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:45:20.368+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:45:20.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:45:20.625+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:45:20.662+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:45:20.661+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:45:20.685+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:45:20.685+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:45:20.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-07T15:45:51.080+0000] {processor.py:186} INFO - Started process (PID=6514) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:45:51.081+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:45:51.084+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:45:51.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:45:51.303+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:45:51.331+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:45:51.330+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:45:51.346+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:45:51.346+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:45:51.375+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.302 seconds
[2025-04-07T15:46:21.845+0000] {processor.py:186} INFO - Started process (PID=6581) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:46:21.846+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:46:21.849+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:46:21.848+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:46:22.060+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:46:22.087+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:46:22.087+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:46:22.103+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:46:22.102+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:46:22.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.294 seconds
[2025-04-07T15:46:53.165+0000] {processor.py:186} INFO - Started process (PID=6648) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:46:53.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:46:53.169+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:46:53.168+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:46:53.441+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:46:53.471+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:46:53.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:46:53.490+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:46:53.490+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:46:53.524+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-07T15:47:24.265+0000] {processor.py:186} INFO - Started process (PID=6715) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:47:24.266+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:47:24.269+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:47:24.269+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:47:24.589+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:47:24.630+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:47:24.629+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:47:24.657+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:47:24.656+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:47:24.696+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.440 seconds
[2025-04-07T15:47:55.064+0000] {processor.py:186} INFO - Started process (PID=6782) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:47:55.065+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:47:55.068+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:47:55.067+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:47:55.287+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:47:55.314+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:47:55.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:47:55.330+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:47:55.330+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:47:55.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.302 seconds
[2025-04-07T15:48:26.286+0000] {processor.py:186} INFO - Started process (PID=6849) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:48:26.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:48:26.291+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:48:26.290+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:48:26.556+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:48:26.588+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:48:26.588+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:48:26.606+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:48:26.606+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:48:26.639+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-07T15:48:56.820+0000] {processor.py:186} INFO - Started process (PID=6915) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:48:56.821+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:48:56.824+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:48:56.824+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:48:57.054+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:48:57.087+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:48:57.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:48:57.108+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:48:57.108+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:48:57.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.320 seconds
[2025-04-07T15:49:27.339+0000] {processor.py:186} INFO - Started process (PID=6982) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:49:27.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:49:27.344+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:49:27.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:49:27.632+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:49:27.663+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:49:27.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:49:27.679+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:49:27.679+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:49:27.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-07T15:49:57.797+0000] {processor.py:186} INFO - Started process (PID=7049) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:49:57.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:49:57.802+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:49:57.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:49:58.039+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:49:58.070+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:49:58.069+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:49:58.088+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:49:58.087+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:49:58.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.320 seconds
[2025-04-07T15:50:28.710+0000] {processor.py:186} INFO - Started process (PID=7117) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:50:28.711+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:50:28.715+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:50:28.714+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:50:28.999+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:50:29.032+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:50:29.032+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:50:29.061+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:50:29.061+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:50:29.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-07T15:50:59.937+0000] {processor.py:186} INFO - Started process (PID=7184) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:50:59.938+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:50:59.941+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:50:59.941+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:51:00.207+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:51:00.234+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:51:00.233+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:51:00.251+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:51:00.251+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:51:00.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-07T15:51:30.383+0000] {processor.py:186} INFO - Started process (PID=7251) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:51:30.384+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:51:30.386+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:51:30.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:51:30.591+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:51:30.616+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:51:30.616+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:51:30.630+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:51:30.630+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:51:30.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.287 seconds
[2025-04-07T15:52:00.864+0000] {processor.py:186} INFO - Started process (PID=7319) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:52:00.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:52:00.869+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:52:00.868+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:52:01.111+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:52:01.143+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:52:01.142+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:52:01.158+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:52:01.158+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:52:01.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-07T15:52:31.633+0000] {processor.py:186} INFO - Started process (PID=7389) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:52:31.634+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:52:31.637+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:52:31.637+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:52:31.876+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:52:31.911+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:52:31.911+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:52:31.936+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:52:31.936+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:52:31.977+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-07T15:53:02.254+0000] {processor.py:186} INFO - Started process (PID=7457) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:53:02.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:53:02.258+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:53:02.257+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:53:02.514+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:53:02.543+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:53:02.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:53:02.559+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:53:02.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:53:02.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-07T15:53:32.723+0000] {processor.py:186} INFO - Started process (PID=7526) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:53:32.724+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:53:32.728+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:53:32.727+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:53:32.976+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:53:33.004+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:53:33.004+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:53:33.021+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:53:33.021+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:53:33.053+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-07T15:54:03.567+0000] {processor.py:186} INFO - Started process (PID=7594) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:54:03.568+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:54:03.571+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:54:03.571+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:54:03.841+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:54:03.871+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:54:03.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:54:03.889+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:54:03.888+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:54:03.918+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-07T15:54:34.590+0000] {processor.py:186} INFO - Started process (PID=7662) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:54:34.591+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:54:34.594+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:54:34.593+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:54:34.906+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:54:34.933+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:54:34.932+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:54:34.949+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:54:34.948+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:54:34.976+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-07T15:55:05.051+0000] {processor.py:186} INFO - Started process (PID=7730) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:55:05.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:55:05.057+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:55:05.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:55:05.303+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:55:05.335+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:55:05.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:55:05.351+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:55:05.351+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:55:05.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-07T15:55:45.089+0000] {processor.py:186} INFO - Started process (PID=7791) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:55:45.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:55:45.094+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:55:45.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:55:45.435+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:55:45.470+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:55:45.470+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:55:45.488+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:55:45.488+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:55:45.530+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.453 seconds
[2025-04-07T15:56:23.603+0000] {processor.py:186} INFO - Started process (PID=7854) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:56:23.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:56:23.646+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:56:23.645+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:56:24.402+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:56:24.445+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:56:24.444+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:56:24.475+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:56:24.474+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:56:24.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.909 seconds
[2025-04-07T15:56:54.582+0000] {processor.py:186} INFO - Started process (PID=7922) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:56:54.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:56:54.587+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:56:54.587+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:56:54.863+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:56:54.898+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:56:54.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:56:54.913+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:56:54.913+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:56:54.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-07T15:57:25.141+0000] {processor.py:186} INFO - Started process (PID=7989) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:57:25.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:57:25.146+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:57:25.145+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:57:25.447+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:57:25.479+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:57:25.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:57:25.502+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:57:25.501+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:57:25.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.402 seconds
[2025-04-07T15:57:55.746+0000] {processor.py:186} INFO - Started process (PID=8057) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:57:55.748+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:57:55.750+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:57:55.750+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:57:56.021+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:57:56.048+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:57:56.048+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:57:56.064+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:57:56.064+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:57:56.090+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-07T15:58:26.471+0000] {processor.py:186} INFO - Started process (PID=8125) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:58:26.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:58:26.475+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:58:26.474+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:58:26.745+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:58:26.773+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:58:26.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:58:26.792+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:58:26.791+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:58:26.824+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-07T15:58:57.667+0000] {processor.py:186} INFO - Started process (PID=8193) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:58:57.668+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:58:57.672+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:58:57.671+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:58:57.909+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:58:57.937+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:58:57.937+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:58:57.954+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:58:57.953+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:58:57.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.322 seconds
[2025-04-07T15:59:28.822+0000] {processor.py:186} INFO - Started process (PID=8261) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:59:28.823+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T15:59:28.827+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:59:28.826+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:59:29.097+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T15:59:29.133+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:59:29.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T15:59:29.152+0000] {logging_mixin.py:190} INFO - [2025-04-07T15:59:29.152+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T15:59:29.180+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-07T16:00:00.062+0000] {processor.py:186} INFO - Started process (PID=8330) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:00:00.063+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:00:00.066+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:00:00.066+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:00:00.326+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:00:00.357+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:00:00.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:00:00.375+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:00:00.374+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:00:00.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-07T16:00:31.130+0000] {processor.py:186} INFO - Started process (PID=8398) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:00:31.132+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:00:31.136+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:00:31.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:00:31.443+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:00:31.485+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:00:31.484+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:00:31.506+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:00:31.505+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:00:31.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.417 seconds
[2025-04-07T16:01:01.619+0000] {processor.py:186} INFO - Started process (PID=8468) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:01:01.621+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:01:01.624+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:01:01.623+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:01:01.890+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:01:01.928+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:01:01.927+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:01:01.950+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:01:01.950+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:01:01.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-07T16:01:32.356+0000] {processor.py:186} INFO - Started process (PID=8536) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:01:32.357+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:01:32.360+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:01:32.359+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:01:32.685+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:01:32.722+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:01:32.721+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:01:32.745+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:01:32.744+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:01:32.775+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.426 seconds
[2025-04-07T16:02:02.921+0000] {processor.py:186} INFO - Started process (PID=8606) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:02:02.922+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:02:02.925+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:02:02.924+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:02:03.193+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:02:03.233+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:02:03.232+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:02:03.250+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:02:03.250+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:02:03.283+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-07T16:02:34.194+0000] {processor.py:186} INFO - Started process (PID=8675) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:02:34.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:02:34.197+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:02:34.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:02:34.478+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:02:34.509+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:02:34.508+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:02:34.527+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:02:34.527+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:02:34.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-07T16:03:04.726+0000] {processor.py:186} INFO - Started process (PID=8743) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:03:04.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:03:04.730+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:03:04.730+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:03:05.023+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:03:05.061+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:03:05.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:03:05.080+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:03:05.079+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:03:05.111+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.396 seconds
[2025-04-07T16:03:35.315+0000] {processor.py:186} INFO - Started process (PID=8812) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:03:35.317+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:03:35.320+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:03:35.320+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:03:35.579+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:03:35.618+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:03:35.618+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:03:35.641+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:03:35.640+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:03:35.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-07T16:04:05.776+0000] {processor.py:186} INFO - Started process (PID=8881) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:04:05.777+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:04:05.780+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:04:05.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:04:06.069+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:04:06.104+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:04:06.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:04:06.125+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:04:06.125+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:04:06.152+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-07T16:04:37.056+0000] {processor.py:186} INFO - Started process (PID=8950) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:04:37.057+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:04:37.060+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:04:37.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:04:37.334+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:04:37.380+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:04:37.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:04:37.399+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:04:37.398+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:04:37.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.385 seconds
[2025-04-07T16:05:07.676+0000] {processor.py:186} INFO - Started process (PID=9020) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:05:07.678+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:05:07.681+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:05:07.680+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:05:08.083+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:05:08.129+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:05:08.128+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:05:08.149+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:05:08.149+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:05:08.186+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.521 seconds
[2025-04-07T16:05:38.337+0000] {processor.py:186} INFO - Started process (PID=9091) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:05:38.338+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:05:38.342+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:05:38.341+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:05:38.622+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:05:38.656+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:05:38.655+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:05:38.672+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:05:38.672+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:05:38.705+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-07T16:06:08.959+0000] {processor.py:186} INFO - Started process (PID=9160) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:06:08.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:06:08.963+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:06:08.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:06:09.240+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:06:09.272+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:06:09.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:06:09.289+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:06:09.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:06:09.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-07T16:13:07.193+0000] {processor.py:186} INFO - Started process (PID=79) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:13:07.255+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:13:07.258+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:13:07.258+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:13:07.620+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:13:07.615+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:13:07.622+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:13:07.711+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.531 seconds
[2025-04-07T16:13:48.737+0000] {processor.py:186} INFO - Started process (PID=147) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:13:48.750+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:13:48.794+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:13:48.794+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:13:49.136+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:13:49.127+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:13:49.138+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:13:49.184+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.461 seconds
[2025-04-07T16:14:19.347+0000] {processor.py:186} INFO - Started process (PID=215) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:14:19.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:14:19.351+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:14:19.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:14:19.506+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:14:19.498+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:14:19.508+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:14:19.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.197 seconds
[2025-04-07T16:14:49.863+0000] {processor.py:186} INFO - Started process (PID=283) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:14:49.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:14:49.866+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:14:49.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:14:50.054+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:14:50.048+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:14:50.056+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:14:50.086+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.230 seconds
[2025-04-07T16:15:20.791+0000] {processor.py:186} INFO - Started process (PID=345) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:15:20.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:15:20.794+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:15:20.793+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:15:20.986+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:15:20.979+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:15:20.989+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:15:21.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.236 seconds
[2025-04-07T16:15:52.905+0000] {processor.py:186} INFO - Started process (PID=413) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:15:52.906+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:15:52.907+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:15:52.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:15:53.063+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:15:53.056+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:15:53.065+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:15:53.093+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.195 seconds
[2025-04-07T16:16:24.118+0000] {processor.py:186} INFO - Started process (PID=478) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:16:24.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:16:24.121+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:16:24.121+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:16:24.321+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:16:24.314+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:16:24.322+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:16:24.356+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.245 seconds
[2025-04-07T16:16:55.746+0000] {processor.py:186} INFO - Started process (PID=547) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:16:55.747+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:16:55.748+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:16:55.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:16:55.938+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:16:55.931+0000] {dagbag.py:387} ERROR - Failed to import: /opt/airflow/dags/test_crawl_list_product.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 383, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 999, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/test_crawl_list_product.py", line 11, in <module>
    from selenium import webdriver
ModuleNotFoundError: No module named 'selenium'
[2025-04-07T16:16:55.940+0000] {processor.py:927} WARNING - No viable dags retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:16:55.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.231 seconds
[2025-04-07T16:20:05.735+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:20:05.736+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:20:05.740+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:20:05.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:20:06.106+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:20:06.276+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:20:06.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:20:06.290+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:20:06.290+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:20:07.204+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.480 seconds
[2025-04-07T16:20:37.308+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:20:37.310+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:20:37.312+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:20:37.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:20:37.574+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:20:37.602+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:20:37.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:20:37.619+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:20:37.619+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:20:37.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-07T16:21:07.856+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:21:07.857+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:21:07.860+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:21:07.859+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:21:08.142+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:21:08.174+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:21:08.173+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:21:08.196+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:21:08.196+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:21:08.221+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-07T16:21:38.396+0000] {processor.py:186} INFO - Started process (PID=298) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:21:38.397+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:21:38.400+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:21:38.399+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:21:38.651+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:21:38.688+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:21:38.687+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:21:38.703+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:21:38.703+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:21:38.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-07T16:22:09.104+0000] {processor.py:186} INFO - Started process (PID=365) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:22:09.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:22:09.109+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:22:09.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:22:09.413+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:22:09.452+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:22:09.452+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:22:09.472+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:22:09.472+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:22:09.501+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.406 seconds
[2025-04-07T16:22:40.110+0000] {processor.py:186} INFO - Started process (PID=434) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:22:40.112+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:22:40.115+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:22:40.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:22:40.400+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:22:40.429+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:22:40.428+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:22:40.444+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:22:40.444+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:22:40.468+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-07T16:23:11.051+0000] {processor.py:186} INFO - Started process (PID=503) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:23:11.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:23:11.056+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:23:11.055+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:23:11.356+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:23:11.388+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:23:11.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:23:11.405+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:23:11.405+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:23:11.434+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.392 seconds
[2025-04-07T16:23:41.580+0000] {processor.py:186} INFO - Started process (PID=574) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:23:41.581+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:23:41.584+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:23:41.583+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:23:41.863+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:23:41.892+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:23:41.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:23:41.911+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:23:41.911+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:23:41.941+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-07T16:24:12.402+0000] {processor.py:186} INFO - Started process (PID=645) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:24:12.403+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:24:12.407+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:24:12.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:24:12.822+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:24:12.887+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:24:12.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:24:12.930+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:24:12.930+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:24:12.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.587 seconds
[2025-04-07T16:24:43.085+0000] {processor.py:186} INFO - Started process (PID=716) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:24:43.086+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:24:43.089+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:24:43.089+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:24:43.362+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:24:43.390+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:24:43.389+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:24:43.408+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:24:43.408+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:24:43.435+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-07T16:25:14.110+0000] {processor.py:186} INFO - Started process (PID=784) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:25:14.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:25:14.114+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:25:14.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:25:14.447+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:25:14.480+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:25:14.480+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:25:14.498+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:25:14.498+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:25:14.527+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.423 seconds
[2025-04-07T16:25:44.981+0000] {processor.py:186} INFO - Started process (PID=852) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:25:44.982+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:25:44.985+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:25:44.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:25:45.260+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:25:45.289+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:25:45.288+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:25:45.306+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:25:45.306+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:25:45.336+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-07T16:26:15.690+0000] {processor.py:186} INFO - Started process (PID=920) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:26:15.692+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:26:15.694+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:26:15.694+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:26:15.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:26:15.994+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:26:15.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:26:16.017+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:26:16.017+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:26:16.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-07T16:26:46.759+0000] {processor.py:186} INFO - Started process (PID=990) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:26:46.760+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:26:46.763+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:26:46.763+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:26:47.058+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:26:47.097+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:26:47.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:26:47.124+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:26:47.124+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:26:47.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.409 seconds
[2025-04-07T16:27:17.312+0000] {processor.py:186} INFO - Started process (PID=1059) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:27:17.313+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:27:17.316+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:27:17.316+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:27:17.544+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:27:17.572+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:27:17.572+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:27:17.586+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:27:17.586+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:27:17.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.310 seconds
[2025-04-07T16:27:48.100+0000] {processor.py:186} INFO - Started process (PID=1128) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:27:48.102+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:27:48.104+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:27:48.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:27:48.353+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:27:48.387+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:27:48.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:27:48.402+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:27:48.402+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:27:48.430+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.336 seconds
[2025-04-07T16:28:19.056+0000] {processor.py:186} INFO - Started process (PID=1197) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:28:19.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:28:19.061+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:28:19.060+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:28:19.325+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:28:19.529+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:28:19.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:28:19.551+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:28:19.551+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:28:19.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.538 seconds
[2025-04-07T16:28:49.685+0000] {processor.py:186} INFO - Started process (PID=1266) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:28:49.687+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:28:49.690+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:28:49.689+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:28:50.115+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:28:50.144+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:28:50.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:28:50.159+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:28:50.159+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:28:50.189+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.512 seconds
[2025-04-07T16:29:20.697+0000] {processor.py:186} INFO - Started process (PID=1335) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:29:20.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:29:20.701+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:29:20.700+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:29:21.168+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:29:21.204+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:29:21.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:29:21.222+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:29:21.222+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:29:21.254+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.564 seconds
[2025-04-07T16:29:51.453+0000] {processor.py:186} INFO - Started process (PID=1403) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:29:51.455+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:29:51.459+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:29:51.458+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:29:52.050+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:29:52.079+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:29:52.078+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:29:52.102+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:29:52.102+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:29:52.136+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.693 seconds
[2025-04-07T16:30:23.202+0000] {processor.py:186} INFO - Started process (PID=1474) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:30:23.204+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:30:23.207+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:30:23.207+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:30:23.715+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:30:23.742+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:30:23.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:30:23.756+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:30:23.756+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:30:23.781+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.603 seconds
[2025-04-07T16:30:54.333+0000] {processor.py:186} INFO - Started process (PID=1543) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:30:54.334+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:30:54.337+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:30:54.337+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:30:54.943+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:30:54.978+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:30:54.978+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:30:54.996+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:30:54.996+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:30:55.358+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.034 seconds
[2025-04-07T16:31:26.348+0000] {processor.py:186} INFO - Started process (PID=1621) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:31:26.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:31:26.353+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:31:26.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:31:26.812+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:31:26.839+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:31:26.839+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:31:26.859+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:31:26.858+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:31:26.899+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.559 seconds
[2025-04-07T16:31:57.090+0000] {processor.py:186} INFO - Started process (PID=1694) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:31:57.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:31:57.094+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:31:57.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:31:57.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:31:57.674+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:31:57.673+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:31:57.699+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:31:57.699+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:31:57.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.654 seconds
[2025-04-07T16:32:28.160+0000] {processor.py:186} INFO - Started process (PID=1763) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:32:28.162+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:32:28.165+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:32:28.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:32:28.651+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:32:28.681+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:32:28.680+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:32:28.700+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:32:28.700+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:32:28.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.582 seconds
[2025-04-07T16:32:58.934+0000] {processor.py:186} INFO - Started process (PID=1831) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:32:58.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:32:58.938+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:32:58.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:32:59.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:32:59.454+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:32:59.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:32:59.472+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:32:59.472+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:32:59.504+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.583 seconds
[2025-04-07T16:33:30.074+0000] {processor.py:186} INFO - Started process (PID=1903) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:33:30.076+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:33:30.078+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:33:30.078+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:33:30.537+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:33:30.568+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:33:30.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:33:30.582+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:33:30.582+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:33:30.605+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.537 seconds
[2025-04-07T16:34:01.322+0000] {processor.py:186} INFO - Started process (PID=1974) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:34:01.323+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:34:01.326+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:34:01.325+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:34:01.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:34:01.833+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:34:01.833+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:34:01.847+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:34:01.847+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:34:01.879+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.564 seconds
[2025-04-07T16:34:32.251+0000] {processor.py:186} INFO - Started process (PID=2043) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:34:32.253+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:34:32.256+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:34:32.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:34:32.699+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:34:32.726+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:34:32.725+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:34:32.739+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:34:32.739+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:34:32.769+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.525 seconds
[2025-04-07T16:35:03.121+0000] {processor.py:186} INFO - Started process (PID=2112) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:35:03.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:35:03.128+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:35:03.127+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:35:03.715+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:35:03.751+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:35:03.751+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:35:03.766+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:35:03.766+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:35:03.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.686 seconds
[2025-04-07T16:35:34.260+0000] {processor.py:186} INFO - Started process (PID=2177) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:35:34.261+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:35:34.264+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:35:34.263+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:35:34.718+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:35:34.747+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:35:34.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:35:34.761+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:35:34.761+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:35:34.790+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.540 seconds
[2025-04-07T16:36:05.223+0000] {processor.py:186} INFO - Started process (PID=2243) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:36:05.224+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:36:05.227+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:36:05.227+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:36:05.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:36:05.711+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:36:05.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:36:05.727+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:36:05.727+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:36:05.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.541 seconds
[2025-04-07T16:36:36.966+0000] {processor.py:186} INFO - Started process (PID=2313) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:36:36.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:36:36.970+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:36:36.969+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:36:37.464+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:36:37.498+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:36:37.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:36:37.514+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:36:37.514+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:36:37.546+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.590 seconds
[2025-04-07T16:37:07.986+0000] {processor.py:186} INFO - Started process (PID=2382) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:37:07.987+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:37:07.990+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:37:07.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:37:08.257+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:37:08.292+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:37:08.292+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:37:08.310+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:37:08.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:37:08.335+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-07T16:37:38.832+0000] {processor.py:186} INFO - Started process (PID=2451) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:37:38.833+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:37:38.837+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:37:38.837+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:37:39.131+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:37:39.172+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:37:39.172+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:37:39.192+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:37:39.192+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:37:39.227+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.404 seconds
[2025-04-07T16:38:09.400+0000] {processor.py:186} INFO - Started process (PID=2520) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:38:09.401+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:38:09.405+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:38:09.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:38:09.671+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:38:09.700+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:38:09.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:38:09.715+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:38:09.715+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:38:09.744+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T16:38:40.138+0000] {processor.py:186} INFO - Started process (PID=2589) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:38:40.140+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:38:40.142+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:38:40.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:38:40.459+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:38:40.490+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:38:40.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:38:40.506+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:38:40.506+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:38:40.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-07T16:39:11.065+0000] {processor.py:186} INFO - Started process (PID=2658) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:39:11.066+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:39:11.069+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:39:11.069+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:39:11.325+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:39:11.356+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:39:11.356+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:39:11.373+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:39:11.373+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:39:11.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-07T16:41:31.972+0000] {processor.py:186} INFO - Started process (PID=89) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:41:31.974+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:41:31.976+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:41:31.976+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:41:32.240+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:41:32.274+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:41:32.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:41:32.291+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:41:32.290+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:41:32.320+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-07T16:42:04.354+0000] {processor.py:186} INFO - Started process (PID=158) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:42:04.356+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:42:04.358+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:42:04.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:42:04.638+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:42:04.676+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:42:04.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:42:04.692+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:42:04.692+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:42:04.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-07T16:42:35.001+0000] {processor.py:186} INFO - Started process (PID=227) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:42:35.002+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:42:35.005+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:42:35.005+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:42:35.247+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:42:35.275+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:42:35.274+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:42:35.289+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:42:35.288+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:42:35.318+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-07T16:43:05.430+0000] {processor.py:186} INFO - Started process (PID=297) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:43:05.431+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:43:05.434+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:43:05.434+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:43:05.682+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:43:05.713+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:43:05.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:43:05.729+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:43:05.728+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:43:05.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-07T16:43:36.452+0000] {processor.py:186} INFO - Started process (PID=366) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:43:36.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:43:36.456+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:43:36.456+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:43:36.682+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:43:36.709+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:43:36.708+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:43:36.724+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:43:36.724+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:43:36.753+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.307 seconds
[2025-04-07T16:44:06.968+0000] {processor.py:186} INFO - Started process (PID=436) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:44:06.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:44:06.972+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:44:06.972+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:44:07.199+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:44:07.227+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:44:07.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:44:07.242+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:44:07.242+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:44:07.270+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.308 seconds
[2025-04-07T16:44:38.295+0000] {processor.py:186} INFO - Started process (PID=505) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:44:38.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:44:38.299+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:44:38.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:44:38.662+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:44:38.704+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:44:38.704+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:44:38.720+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:44:38.720+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:44:38.747+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.458 seconds
[2025-04-07T16:45:09.566+0000] {processor.py:186} INFO - Started process (PID=580) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:45:09.567+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:45:09.570+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:45:09.569+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:45:09.893+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:45:09.926+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:45:09.926+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:45:09.944+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:45:09.944+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:45:09.972+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.415 seconds
[2025-04-07T16:45:40.217+0000] {processor.py:186} INFO - Started process (PID=649) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:45:40.218+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:45:40.221+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:45:40.221+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:45:40.489+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:45:40.518+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:45:40.518+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:45:40.535+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:45:40.535+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:45:40.566+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-07T16:46:11.600+0000] {processor.py:186} INFO - Started process (PID=718) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:46:11.601+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:46:11.603+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:46:11.603+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:46:11.858+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:46:11.902+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:46:11.901+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:46:11.918+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:46:11.918+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:46:11.948+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-07T16:46:42.072+0000] {processor.py:186} INFO - Started process (PID=787) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:46:42.073+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:46:42.076+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:46:42.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:46:42.376+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:46:42.409+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:46:42.409+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:46:42.428+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:46:42.427+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:46:42.463+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.400 seconds
[2025-04-07T16:47:13.052+0000] {processor.py:186} INFO - Started process (PID=856) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:47:13.054+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:47:13.056+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:47:13.056+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:47:13.329+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:47:13.361+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:47:13.361+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:47:13.383+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:47:13.382+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:47:13.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-07T16:47:43.503+0000] {processor.py:186} INFO - Started process (PID=925) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:47:43.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:47:43.507+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:47:43.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:47:43.782+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:47:43.826+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:47:43.826+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:47:43.848+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:47:43.847+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:47:43.873+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-07T16:48:14.631+0000] {processor.py:186} INFO - Started process (PID=994) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:48:14.632+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:48:14.636+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:48:14.635+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:48:14.944+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:48:14.975+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:48:14.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:48:14.993+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:48:14.992+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:48:15.020+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.398 seconds
[2025-04-07T16:48:45.656+0000] {processor.py:186} INFO - Started process (PID=1063) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:48:45.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:48:45.662+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:48:45.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:48:45.966+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:48:45.997+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:48:45.996+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:48:46.021+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:48:46.020+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:48:46.050+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.403 seconds
[2025-04-07T16:49:19.226+0000] {processor.py:186} INFO - Started process (PID=1132) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:49:19.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:49:19.231+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:49:19.230+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:49:19.532+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:49:19.564+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:49:19.563+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:49:19.582+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:49:19.582+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:49:19.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.636 seconds
[2025-04-07T16:49:50.999+0000] {processor.py:186} INFO - Started process (PID=1201) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:49:51.000+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:49:51.004+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:49:51.004+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:49:51.304+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:49:51.344+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:49:51.343+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:49:51.365+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:49:51.365+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:49:51.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.415 seconds
[2025-04-07T16:50:22.099+0000] {processor.py:186} INFO - Started process (PID=1270) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:50:22.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:50:22.105+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:50:22.105+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:50:22.468+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:50:22.498+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:50:22.498+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:50:22.523+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:50:22.522+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:50:22.549+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.459 seconds
[2025-04-07T16:50:53.272+0000] {processor.py:186} INFO - Started process (PID=1341) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:50:53.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:50:53.276+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:50:53.276+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:50:53.562+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:50:53.594+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:50:53.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:50:53.614+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:50:53.614+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:50:53.649+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-07T16:51:24.351+0000] {processor.py:186} INFO - Started process (PID=1411) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:51:24.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:51:24.356+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:51:24.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:51:24.659+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:51:24.694+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:51:24.694+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:51:24.716+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:51:24.716+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:51:24.748+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.407 seconds
[2025-04-07T16:52:01.800+0000] {processor.py:186} INFO - Started process (PID=1479) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:52:01.801+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:52:01.804+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:52:01.804+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:52:02.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:52:02.312+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:52:02.312+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:52:02.353+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:52:02.353+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:52:02.401+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.613 seconds
[2025-04-07T16:52:32.958+0000] {processor.py:186} INFO - Started process (PID=1548) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:52:32.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:52:32.962+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:52:32.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:52:33.271+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:52:33.304+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:52:33.303+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:52:33.328+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:52:33.328+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:52:33.545+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.597 seconds
[2025-04-07T16:53:04.032+0000] {processor.py:186} INFO - Started process (PID=1617) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:53:04.035+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:53:04.039+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:53:04.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:53:04.409+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:53:04.438+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:53:04.438+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:53:04.627+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:53:04.627+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:53:04.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.640 seconds
[2025-04-07T16:53:40.725+0000] {processor.py:186} INFO - Started process (PID=1687) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:53:40.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:53:40.729+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:53:40.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:53:41.318+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:53:41.374+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:53:41.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:53:41.575+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:53:41.575+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:53:41.604+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.887 seconds
[2025-04-07T16:54:12.346+0000] {processor.py:186} INFO - Started process (PID=1756) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:54:12.347+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:54:12.350+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:54:12.350+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:54:12.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:54:12.782+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:54:12.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:54:13.007+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:54:13.007+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:54:13.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.702 seconds
[2025-04-07T16:54:43.403+0000] {processor.py:186} INFO - Started process (PID=1826) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:54:43.404+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:54:43.406+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:54:43.406+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:54:43.665+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:54:43.700+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:54:43.699+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:54:43.931+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:54:43.930+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:54:43.956+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.561 seconds
[2025-04-07T16:55:14.279+0000] {processor.py:186} INFO - Started process (PID=1895) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:55:14.281+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:55:14.284+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:55:14.284+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:55:14.554+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:55:14.757+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:55:14.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:55:14.771+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:55:14.771+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:55:14.800+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.530 seconds
[2025-04-07T16:55:47.017+0000] {processor.py:186} INFO - Started process (PID=1971) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:55:47.022+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:55:47.027+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:55:47.026+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:55:48.836+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:55:48.866+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:55:48.866+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:55:48.887+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:55:48.887+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:55:48.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.917 seconds
[2025-04-07T16:56:19.775+0000] {processor.py:186} INFO - Started process (PID=2040) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:56:19.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:56:19.780+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:56:19.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:56:20.249+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:56:20.281+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:56:20.280+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:56:20.295+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:56:20.295+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:56:20.322+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.559 seconds
[2025-04-07T16:56:50.535+0000] {processor.py:186} INFO - Started process (PID=2109) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:56:50.537+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:56:50.540+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:56:50.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:56:51.014+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:56:51.044+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:56:51.043+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:56:51.060+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:56:51.060+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:56:51.092+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.569 seconds
[2025-04-07T16:57:21.410+0000] {processor.py:186} INFO - Started process (PID=2178) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:57:21.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:57:21.415+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:57:21.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:57:21.916+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:57:21.945+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:57:21.944+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:57:21.970+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:57:21.970+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:57:22.016+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.619 seconds
[2025-04-07T16:57:52.347+0000] {processor.py:186} INFO - Started process (PID=2249) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:57:52.348+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:57:52.351+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:57:52.351+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:57:52.848+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:57:52.877+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:57:52.877+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:57:52.894+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:57:52.894+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:57:52.924+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.591 seconds
[2025-04-07T16:58:23.031+0000] {processor.py:186} INFO - Started process (PID=2318) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:58:23.033+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:58:23.036+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:58:23.035+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:58:23.499+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:58:23.530+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:58:23.529+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:58:23.546+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:58:23.546+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:58:23.575+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.552 seconds
[2025-04-07T16:58:54.194+0000] {processor.py:186} INFO - Started process (PID=2387) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:58:54.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:58:54.198+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:58:54.198+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:58:54.805+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:58:54.846+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:58:54.845+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:58:54.863+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:58:54.863+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:58:54.888+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.701 seconds
[2025-04-07T16:59:25.841+0000] {processor.py:186} INFO - Started process (PID=2457) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:59:25.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:59:25.846+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:59:25.845+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:59:26.165+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:59:26.194+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:59:26.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:59:26.213+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:59:26.213+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:59:26.253+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.423 seconds
[2025-04-07T16:59:57.034+0000] {processor.py:186} INFO - Started process (PID=2526) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:59:57.036+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T16:59:57.039+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:59:57.039+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:59:57.442+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T16:59:57.487+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:59:57.486+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T16:59:57.511+0000] {logging_mixin.py:190} INFO - [2025-04-07T16:59:57.511+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T16:59:57.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.526 seconds
[2025-04-07T17:00:16.952+0000] {processor.py:186} INFO - Started process (PID=2591) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:00:16.975+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:00:16.979+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:00:16.978+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:00:17.440+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:00:17.480+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:00:17.479+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:00:17.501+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:00:17.501+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:00:17.561+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.617 seconds
[2025-04-07T17:00:48.290+0000] {processor.py:186} INFO - Started process (PID=2660) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:00:48.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:00:48.295+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:00:48.294+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:00:48.629+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:00:48.664+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:00:48.663+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:00:48.684+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:00:48.684+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:00:48.718+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.439 seconds
[2025-04-07T17:01:05.756+0000] {processor.py:186} INFO - Started process (PID=2695) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:01:05.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:01:05.761+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:01:05.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:01:06.107+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:01:06.140+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:01:06.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:01:06.163+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:01:06.163+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:01:06.304+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.560 seconds
[2025-04-07T17:01:45.613+0000] {processor.py:186} INFO - Started process (PID=2768) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:01:45.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:01:45.629+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:01:45.626+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:01:48.263+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:01:48.442+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:01:48.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:01:48.478+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:01:48.478+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:01:48.689+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 3.112 seconds
[2025-04-07T17:02:24.599+0000] {processor.py:186} INFO - Started process (PID=2801) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:02:24.602+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:02:24.608+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:02:24.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:02:42.094+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:02:43.140+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:02:43.139+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:02:43.228+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:02:43.227+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:02:43.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 18.720 seconds
[2025-04-07T17:06:32.362+0000] {processor.py:186} INFO - Started process (PID=2856) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:06:32.395+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:06:32.399+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:06:32.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:06:36.886+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:06:36.954+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:06:36.954+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:06:37.001+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:06:37.001+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:06:37.073+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 4.730 seconds
[2025-04-07T17:07:07.954+0000] {processor.py:186} INFO - Started process (PID=2925) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:07:07.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:07:07.961+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:07:07.960+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:07:08.399+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:07:08.460+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:07:08.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:07:08.500+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:07:08.500+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:07:08.550+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.613 seconds
[2025-04-07T17:07:39.395+0000] {processor.py:186} INFO - Started process (PID=2994) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:07:39.396+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:07:39.398+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:07:39.398+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:07:39.789+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:07:39.824+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:07:39.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:07:39.849+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:07:39.849+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:07:39.878+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.492 seconds
[2025-04-07T17:08:10.122+0000] {processor.py:186} INFO - Started process (PID=3063) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:10.123+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:08:10.126+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:10.125+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:10.555+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:10.610+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:10.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:08:10.641+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:10.641+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:08:10.679+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.564 seconds
[2025-04-07T17:08:21.982+0000] {processor.py:186} INFO - Started process (PID=3090) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:21.983+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:08:21.986+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:21.985+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:22.392+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:22.443+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:22.442+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:08:22.503+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:22.503+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:08:22.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.616 seconds
[2025-04-07T17:08:57.387+0000] {processor.py:186} INFO - Started process (PID=3174) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:57.390+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:08:57.393+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:57.392+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:59.806+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:08:59.865+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:59.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:08:59.906+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:08:59.905+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:08:59.947+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 4.389 seconds
[2025-04-07T17:09:31.191+0000] {processor.py:186} INFO - Started process (PID=3244) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:09:31.370+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:09:31.372+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:09:31.372+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:09:36.877+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:09:36.984+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:09:36.981+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:09:37.134+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:09:37.134+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:09:37.222+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 6.180 seconds
[2025-04-07T17:10:07.840+0000] {processor.py:186} INFO - Started process (PID=3318) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:10:07.842+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:10:07.844+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:10:07.844+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:10:08.624+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:10:08.707+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:10:08.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:10:08.752+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:10:08.752+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:10:08.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.984 seconds
[2025-04-07T17:10:38.935+0000] {processor.py:186} INFO - Started process (PID=3387) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:10:38.936+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:10:38.938+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:10:38.937+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:10:39.263+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:10:39.302+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:10:39.301+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:10:39.328+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:10:39.328+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:10:39.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.434 seconds
[2025-04-07T17:11:10.173+0000] {processor.py:186} INFO - Started process (PID=3458) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:11:10.174+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-07T17:11:10.176+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:11:10.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:11:10.450+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-07T17:11:10.491+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:11:10.491+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-07T17:11:10.513+0000] {logging_mixin.py:190} INFO - [2025-04-07T17:11:10.513+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-07T17:11:10.730+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.564 seconds
