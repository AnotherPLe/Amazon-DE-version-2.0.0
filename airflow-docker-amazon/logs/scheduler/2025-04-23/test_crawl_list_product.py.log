[2025-04-23T14:23:43.294+0000] {processor.py:186} INFO - Started process (PID=88) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:23:43.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:23:43.300+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:23:43.299+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:23:43.849+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:23:43.894+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:23:43.893+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:23:43.922+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:23:43.921+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:23:43.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.674 seconds
[2025-04-23T14:24:14.838+0000] {processor.py:186} INFO - Started process (PID=157) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:24:14.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:24:14.842+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:24:14.841+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:24:15.097+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:24:15.124+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:24:15.124+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:24:15.143+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:24:15.142+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:24:15.176+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-23T14:24:45.349+0000] {processor.py:186} INFO - Started process (PID=226) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:24:45.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:24:45.369+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:24:45.368+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:24:45.682+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:24:45.718+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:24:45.718+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:24:45.740+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:24:45.739+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:24:45.777+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.435 seconds
[2025-04-23T14:25:16.348+0000] {processor.py:186} INFO - Started process (PID=295) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:25:16.349+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:25:16.353+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:25:16.352+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:25:16.635+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:25:16.667+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:25:16.666+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:25:16.687+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:25:16.686+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:25:16.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-23T14:25:47.373+0000] {processor.py:186} INFO - Started process (PID=364) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:25:47.376+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:25:47.381+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:25:47.381+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:25:47.762+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:25:47.794+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:25:47.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:25:47.810+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:25:47.810+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:25:47.834+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.474 seconds
[2025-04-23T14:26:17.913+0000] {processor.py:186} INFO - Started process (PID=433) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:26:17.914+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:26:17.917+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:26:17.917+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:26:18.191+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:26:18.222+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:26:18.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:26:18.241+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:26:18.240+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:26:18.268+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-23T14:26:48.678+0000] {processor.py:186} INFO - Started process (PID=502) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:26:48.679+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:26:48.682+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:26:48.682+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:26:48.939+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:26:48.968+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:26:48.968+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:26:48.990+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:26:48.989+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:26:49.019+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-23T14:27:19.806+0000] {processor.py:186} INFO - Started process (PID=572) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:27:19.807+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:27:19.810+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:27:19.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:27:20.071+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:27:20.122+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:27:20.122+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:27:20.155+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:27:20.155+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:27:20.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.398 seconds
[2025-04-23T14:27:50.510+0000] {processor.py:186} INFO - Started process (PID=641) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:27:50.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:27:50.515+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:27:50.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:27:50.795+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:27:50.829+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:27:50.829+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:27:50.849+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:27:50.849+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:27:50.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T14:28:21.797+0000] {processor.py:186} INFO - Started process (PID=710) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:28:21.799+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:28:21.803+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:28:21.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:28:22.076+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:28:22.105+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:28:22.104+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:28:22.122+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:28:22.121+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:28:22.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-23T14:28:52.826+0000] {processor.py:186} INFO - Started process (PID=779) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:28:52.827+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:28:52.831+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:28:52.830+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:28:53.076+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:28:53.107+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:28:53.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:28:53.123+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:28:53.123+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:28:53.154+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-23T14:29:23.255+0000] {processor.py:186} INFO - Started process (PID=848) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:29:23.256+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:29:23.260+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:29:23.259+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:29:23.510+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:29:23.542+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:29:23.541+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:29:23.560+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:29:23.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:29:23.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-23T14:29:54.152+0000] {processor.py:186} INFO - Started process (PID=917) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:29:54.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:29:54.157+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:29:54.156+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:29:54.420+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:29:54.448+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:29:54.448+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:29:54.468+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:29:54.468+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:29:54.498+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-23T14:30:24.708+0000] {processor.py:186} INFO - Started process (PID=986) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:30:24.710+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:30:24.717+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:30:24.716+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:30:25.156+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:30:25.194+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:30:25.193+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:30:25.232+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:30:25.232+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:30:25.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.584 seconds
[2025-04-23T14:30:55.374+0000] {processor.py:186} INFO - Started process (PID=1055) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:30:55.375+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:30:55.378+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:30:55.378+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:30:55.615+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:30:55.647+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:30:55.646+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:30:55.666+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:30:55.666+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:30:55.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-23T14:31:26.060+0000] {processor.py:186} INFO - Started process (PID=1124) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:31:26.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:31:26.064+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:31:26.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:31:26.346+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:31:26.381+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:31:26.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:31:26.401+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:31:26.400+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:31:26.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.376 seconds
[2025-04-23T14:31:56.620+0000] {processor.py:186} INFO - Started process (PID=1193) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:31:56.622+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:31:56.626+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:31:56.625+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:31:56.922+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:31:56.967+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:31:56.967+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:31:56.993+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:31:56.993+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:31:57.017+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.406 seconds
[2025-04-23T14:32:27.226+0000] {processor.py:186} INFO - Started process (PID=1262) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:32:27.227+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:32:27.231+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:32:27.231+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:32:27.519+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:32:27.559+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:32:27.559+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:32:27.579+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:32:27.579+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:32:27.620+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.402 seconds
[2025-04-23T14:32:57.765+0000] {processor.py:186} INFO - Started process (PID=1333) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:32:57.774+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:32:57.787+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:32:57.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:32:58.277+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:32:58.315+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:32:58.314+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:32:58.340+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:32:58.340+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:32:58.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.636 seconds
[2025-04-23T14:33:28.955+0000] {processor.py:186} INFO - Started process (PID=1402) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:33:28.956+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:33:28.959+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:33:28.959+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:33:29.212+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:33:29.388+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:33:29.388+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:33:29.402+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:33:29.402+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:33:29.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.484 seconds
[2025-04-23T14:34:00.338+0000] {processor.py:186} INFO - Started process (PID=1471) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:34:00.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:34:00.344+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:34:00.344+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:34:00.833+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:34:00.869+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:34:00.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:34:00.889+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:34:00.888+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:34:00.920+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.589 seconds
[2025-04-23T14:34:31.059+0000] {processor.py:186} INFO - Started process (PID=1540) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:34:31.061+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:34:31.065+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:34:31.064+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:34:31.508+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:34:31.533+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:34:31.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:34:31.548+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:34:31.548+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:34:31.576+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.523 seconds
[2025-04-23T14:35:02.125+0000] {processor.py:186} INFO - Started process (PID=1609) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:35:02.127+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:35:02.131+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:35:02.130+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:35:02.560+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:35:02.586+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:35:02.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:35:02.599+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:35:02.599+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:35:02.626+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.508 seconds
[2025-04-23T14:35:33.405+0000] {processor.py:186} INFO - Started process (PID=1678) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:35:33.407+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:35:33.411+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:35:33.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:35:33.857+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:35:33.884+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:35:33.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:35:33.900+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:35:33.900+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:35:33.930+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.532 seconds
[2025-04-23T14:36:04.647+0000] {processor.py:186} INFO - Started process (PID=1747) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:36:04.649+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:36:04.653+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:36:04.652+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:36:05.125+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:36:05.156+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:36:05.155+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:36:05.171+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:36:05.170+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:36:05.202+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.565 seconds
[2025-04-23T14:36:35.614+0000] {processor.py:186} INFO - Started process (PID=1822) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:36:35.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:36:35.620+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:36:35.620+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:36:36.081+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:36:36.107+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:36:36.106+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:36:36.124+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:36:36.124+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:36:36.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.549 seconds
[2025-04-23T14:37:06.488+0000] {processor.py:186} INFO - Started process (PID=1891) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:37:06.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:37:06.495+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:37:06.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:37:07.091+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:37:07.121+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:37:07.120+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:37:07.141+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:37:07.140+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:37:07.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.698 seconds
[2025-04-23T14:37:37.456+0000] {processor.py:186} INFO - Started process (PID=1960) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:37:37.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:37:37.462+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:37:37.461+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:37:38.050+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:37:38.087+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:37:38.086+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:37:38.108+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:37:38.108+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:37:38.148+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.698 seconds
[2025-04-23T14:38:08.703+0000] {processor.py:186} INFO - Started process (PID=2029) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:38:08.704+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:38:08.707+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:38:08.707+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:38:08.959+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:38:08.991+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:38:08.990+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:38:09.008+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:38:09.007+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:38:09.043+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-23T14:38:39.369+0000] {processor.py:186} INFO - Started process (PID=2098) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:38:39.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:38:39.374+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:38:39.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:38:39.648+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:38:39.687+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:38:39.686+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:38:39.704+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:38:39.703+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:38:39.729+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-23T14:39:10.195+0000] {processor.py:186} INFO - Started process (PID=2167) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:39:10.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:39:10.200+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:39:10.199+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:39:10.461+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:39:10.494+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:39:10.493+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:39:10.511+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:39:10.511+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:39:10.544+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-23T14:39:40.897+0000] {processor.py:186} INFO - Started process (PID=2236) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:39:40.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:39:40.903+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:39:40.902+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:39:41.221+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:39:41.260+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:39:41.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:39:41.284+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:39:41.283+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:39:41.312+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.424 seconds
[2025-04-23T14:40:11.794+0000] {processor.py:186} INFO - Started process (PID=2305) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:40:11.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:40:11.799+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:40:11.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:40:12.067+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:40:12.097+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:40:12.096+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:40:12.113+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:40:12.113+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:40:12.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-23T14:40:42.511+0000] {processor.py:186} INFO - Started process (PID=2374) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:40:42.512+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:40:42.517+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:40:42.516+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:40:42.793+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:40:42.829+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:40:42.828+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:40:42.848+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:40:42.847+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:40:42.880+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-23T14:41:13.266+0000] {processor.py:186} INFO - Started process (PID=2443) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:41:13.268+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:41:13.272+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:41:13.271+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:41:13.525+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:41:13.557+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:41:13.556+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:41:13.575+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:41:13.574+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:41:13.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-23T14:41:43.962+0000] {processor.py:186} INFO - Started process (PID=2512) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:41:43.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:41:43.968+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:41:43.967+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:41:44.230+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:41:44.262+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:41:44.261+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:41:44.279+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:41:44.278+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:41:44.308+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-23T14:42:14.827+0000] {processor.py:186} INFO - Started process (PID=2581) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:42:14.829+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:42:14.833+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:42:14.832+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:42:15.101+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:42:15.130+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:42:15.130+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:42:15.145+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:42:15.145+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:42:15.178+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-23T14:42:45.550+0000] {processor.py:186} INFO - Started process (PID=2650) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:42:45.551+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:42:45.554+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:42:45.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:42:45.811+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:42:45.841+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:42:45.841+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:42:45.859+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:42:45.859+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:42:45.884+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.341 seconds
[2025-04-23T14:43:16.332+0000] {processor.py:186} INFO - Started process (PID=2719) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:43:16.333+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:43:16.336+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:43:16.336+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:43:16.582+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:43:16.610+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:43:16.609+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:43:16.625+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:43:16.624+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:43:16.654+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.328 seconds
[2025-04-23T14:43:46.877+0000] {processor.py:186} INFO - Started process (PID=2787) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:43:46.878+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:43:46.881+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:43:46.881+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:43:47.102+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:43:47.130+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:43:47.129+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:43:47.146+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:43:47.146+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:43:47.177+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.306 seconds
[2025-04-23T14:44:17.533+0000] {processor.py:186} INFO - Started process (PID=2854) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:44:17.534+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:44:17.537+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:44:17.536+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:44:17.781+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:44:17.809+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:44:17.809+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:44:17.827+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:44:17.827+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:44:17.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-23T14:44:47.976+0000] {processor.py:186} INFO - Started process (PID=2924) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:44:47.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:44:47.980+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:44:47.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:44:48.288+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:44:48.335+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:44:48.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:44:48.374+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:44:48.374+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:44:48.442+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.472 seconds
[2025-04-23T14:45:18.609+0000] {processor.py:186} INFO - Started process (PID=2993) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:45:18.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:45:18.614+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:45:18.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:45:18.863+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:45:18.890+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:45:18.890+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:45:18.905+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:45:18.905+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:45:18.936+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-23T14:45:49.042+0000] {processor.py:186} INFO - Started process (PID=3062) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:45:49.044+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:45:49.047+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:45:49.047+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:45:49.289+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:45:49.318+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:45:49.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:45:49.333+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:45:49.333+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:45:49.357+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.323 seconds
[2025-04-23T14:46:19.707+0000] {processor.py:186} INFO - Started process (PID=3130) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:46:19.708+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:46:19.711+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:46:19.711+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:46:19.952+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:46:19.978+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:46:19.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:46:19.993+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:46:19.993+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:46:20.022+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.322 seconds
[2025-04-23T14:46:50.182+0000] {processor.py:186} INFO - Started process (PID=3197) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:46:50.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:46:50.186+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:46:50.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:46:50.474+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:46:50.505+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:46:50.504+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:46:50.523+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:46:50.523+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:46:50.567+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.395 seconds
[2025-04-23T14:47:21.467+0000] {processor.py:186} INFO - Started process (PID=3267) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:47:21.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:47:21.471+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:47:21.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:47:21.752+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:47:21.779+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:47:21.779+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:47:21.795+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:47:21.794+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:47:21.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-23T14:47:52.151+0000] {processor.py:186} INFO - Started process (PID=3336) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:47:52.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:47:52.156+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:47:52.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:47:52.405+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:47:52.433+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:47:52.432+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:47:52.447+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:47:52.447+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:47:52.480+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-23T14:48:22.577+0000] {processor.py:186} INFO - Started process (PID=3406) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:48:22.580+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:48:22.582+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:48:22.582+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:48:22.825+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:48:22.853+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:48:22.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:48:22.868+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:48:22.867+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:48:22.897+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.328 seconds
[2025-04-23T14:48:52.958+0000] {processor.py:186} INFO - Started process (PID=3475) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:48:52.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:48:52.961+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:48:52.961+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:48:53.185+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:48:53.211+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:48:53.211+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:48:53.225+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:48:53.225+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:48:53.255+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.304 seconds
[2025-04-23T14:49:23.350+0000] {processor.py:186} INFO - Started process (PID=3544) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:49:23.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:49:23.357+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:49:23.356+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:49:23.636+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:49:23.666+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:49:23.665+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:49:23.683+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:49:23.682+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:49:23.710+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-23T14:49:53.784+0000] {processor.py:186} INFO - Started process (PID=3614) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:49:53.785+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:49:53.788+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:49:53.787+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:49:54.035+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:49:54.071+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:49:54.070+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:49:54.088+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:49:54.088+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:49:54.120+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-23T14:50:24.583+0000] {processor.py:186} INFO - Started process (PID=3681) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:50:24.584+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:50:24.587+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:50:24.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:50:24.865+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:50:24.895+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:50:24.894+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:50:24.913+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:50:24.913+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:50:24.944+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-23T14:50:55.351+0000] {processor.py:186} INFO - Started process (PID=3750) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:50:55.352+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:50:55.355+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:50:55.355+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:50:55.636+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:50:55.675+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:50:55.675+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:50:55.694+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:50:55.693+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:50:55.720+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.376 seconds
[2025-04-23T14:51:26.143+0000] {processor.py:186} INFO - Started process (PID=3819) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:51:26.145+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:51:26.148+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:51:26.148+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:51:26.398+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:51:26.426+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:51:26.425+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:51:26.442+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:51:26.441+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:51:26.471+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-23T14:51:56.568+0000] {processor.py:186} INFO - Started process (PID=3890) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:51:56.570+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:51:56.572+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:51:56.572+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:51:56.810+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:51:56.837+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:51:56.837+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:51:56.852+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:51:56.852+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:51:56.881+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.318 seconds
[2025-04-23T14:52:27.106+0000] {processor.py:186} INFO - Started process (PID=3957) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:52:27.107+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:52:27.110+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:52:27.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:52:27.387+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:52:27.416+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:52:27.415+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:52:27.432+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:52:27.432+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:52:27.465+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-23T14:52:57.645+0000] {processor.py:186} INFO - Started process (PID=4028) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:52:57.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:52:57.648+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:52:57.648+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:52:57.896+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:52:57.925+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:52:57.924+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:52:57.940+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:52:57.940+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:52:57.970+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-23T14:53:28.326+0000] {processor.py:186} INFO - Started process (PID=4099) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:53:28.327+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:53:28.329+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:53:28.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:53:28.571+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:53:28.604+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:53:28.603+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:53:28.622+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:53:28.622+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:53:28.663+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-23T14:53:58.804+0000] {processor.py:186} INFO - Started process (PID=4168) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:53:58.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:53:58.809+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:53:58.808+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:53:59.146+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:53:59.175+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:53:59.175+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:53:59.192+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:53:59.192+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:53:59.224+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.429 seconds
[2025-04-23T14:54:30.078+0000] {processor.py:186} INFO - Started process (PID=4237) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:54:30.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:54:30.082+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:54:30.082+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:54:30.350+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:54:30.379+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:54:30.379+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:54:30.396+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:54:30.396+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:54:30.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-23T14:55:00.582+0000] {processor.py:186} INFO - Started process (PID=4308) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:55:00.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:55:00.586+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:55:00.585+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:55:00.848+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:55:00.877+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:55:00.876+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:55:00.893+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:55:00.892+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:55:00.922+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-23T14:55:32.008+0000] {processor.py:186} INFO - Started process (PID=4377) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:55:32.010+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:55:32.013+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:55:32.012+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:55:32.317+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:55:32.345+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:55:32.344+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:55:32.363+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:55:32.363+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:55:32.390+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.392 seconds
[2025-04-23T14:56:02.563+0000] {processor.py:186} INFO - Started process (PID=4448) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:56:02.564+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:56:02.566+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:56:02.566+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:56:02.814+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:56:02.844+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:56:02.844+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:56:02.861+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:56:02.861+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:56:02.889+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-23T14:56:32.969+0000] {processor.py:186} INFO - Started process (PID=4515) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:56:32.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:56:32.973+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:56:32.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:56:33.238+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:56:33.268+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:56:33.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:56:33.286+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:56:33.286+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:56:33.314+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-23T14:57:03.502+0000] {processor.py:186} INFO - Started process (PID=4584) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:57:03.503+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:57:03.506+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:57:03.506+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:57:03.817+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:57:03.853+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:57:03.852+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:57:03.873+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:57:03.872+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:57:03.905+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-23T14:57:34.028+0000] {processor.py:186} INFO - Started process (PID=4655) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:57:34.029+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:57:34.032+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:57:34.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:57:34.267+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:57:34.295+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:57:34.294+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:57:34.309+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:57:34.309+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:57:34.337+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.316 seconds
[2025-04-23T14:58:04.428+0000] {processor.py:186} INFO - Started process (PID=4724) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:58:04.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:58:04.432+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:58:04.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:58:04.714+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:58:04.743+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:58:04.742+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:58:04.762+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:58:04.761+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:58:04.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-23T14:58:35.012+0000] {processor.py:186} INFO - Started process (PID=4791) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:58:35.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:58:35.017+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:58:35.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:58:35.298+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:58:35.329+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:58:35.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:58:35.346+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:58:35.346+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:58:35.376+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-23T14:59:05.434+0000] {processor.py:186} INFO - Started process (PID=4862) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:59:05.435+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:59:05.438+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:59:05.437+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:59:05.771+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:59:05.797+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:59:05.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:59:05.820+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:59:05.819+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:59:05.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.420 seconds
[2025-04-23T14:59:36.762+0000] {processor.py:186} INFO - Started process (PID=4932) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:59:36.764+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T14:59:36.768+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:59:36.767+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:59:37.032+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T14:59:37.060+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:59:37.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T14:59:37.079+0000] {logging_mixin.py:190} INFO - [2025-04-23T14:59:37.079+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T14:59:37.109+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-23T15:00:07.338+0000] {processor.py:186} INFO - Started process (PID=5001) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:00:07.339+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:00:07.342+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:00:07.342+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:00:07.768+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:00:07.807+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:00:07.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:00:07.826+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:00:07.826+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:00:07.853+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.522 seconds
[2025-04-23T15:00:38.152+0000] {processor.py:186} INFO - Started process (PID=5076) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:00:38.153+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:00:38.156+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:00:38.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:00:38.589+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:00:38.615+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:00:38.614+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:00:38.629+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:00:38.629+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:00:38.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.515 seconds
[2025-04-23T15:01:08.834+0000] {processor.py:186} INFO - Started process (PID=5148) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:01:08.835+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:01:08.839+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:01:08.838+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:01:09.382+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:01:09.414+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:01:09.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:01:09.429+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:01:09.429+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:01:09.449+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.622 seconds
[2025-04-23T15:01:39.524+0000] {processor.py:186} INFO - Started process (PID=5218) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:01:39.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:01:39.529+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:01:39.528+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:01:40.049+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:01:40.084+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:01:40.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:01:40.100+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:01:40.100+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:01:40.129+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.612 seconds
[2025-04-23T15:02:10.794+0000] {processor.py:186} INFO - Started process (PID=5287) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:02:10.796+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:02:10.800+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:02:10.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:02:11.226+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:02:11.267+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:02:11.266+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:02:11.284+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:02:11.284+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:02:11.313+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.526 seconds
[2025-04-23T15:02:41.479+0000] {processor.py:186} INFO - Started process (PID=5357) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:02:41.480+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:02:41.483+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:02:41.482+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:02:41.745+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:02:41.783+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:02:41.782+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:02:41.803+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:02:41.803+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:02:41.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-23T15:03:11.968+0000] {processor.py:186} INFO - Started process (PID=5426) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:03:11.970+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:03:11.975+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:03:11.974+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:03:12.546+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:03:12.589+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:03:12.589+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:03:12.608+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:03:12.608+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:03:12.638+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.681 seconds
[2025-04-23T15:03:43.272+0000] {processor.py:186} INFO - Started process (PID=5495) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:03:43.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:03:43.278+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:03:43.278+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:03:43.719+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:03:43.746+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:03:43.746+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:03:43.761+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:03:43.761+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:03:43.789+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.524 seconds
[2025-04-23T15:04:14.214+0000] {processor.py:186} INFO - Started process (PID=5564) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:04:14.216+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:04:14.221+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:04:14.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:04:14.687+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:04:14.714+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:04:14.713+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:04:14.734+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:04:14.734+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:04:14.761+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.558 seconds
[2025-04-23T15:04:45.165+0000] {processor.py:186} INFO - Started process (PID=5633) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:04:45.167+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:04:45.172+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:04:45.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:04:45.641+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:04:45.669+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:04:45.669+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:04:45.685+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:04:45.685+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:04:45.716+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.558 seconds
[2025-04-23T15:05:15.967+0000] {processor.py:186} INFO - Started process (PID=5702) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:05:15.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:05:15.973+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:05:15.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:05:16.472+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:05:16.502+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:05:16.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:05:16.517+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:05:16.517+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:05:16.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.592 seconds
[2025-04-23T15:05:47.216+0000] {processor.py:186} INFO - Started process (PID=5771) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:05:47.219+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:05:47.223+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:05:47.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:05:47.748+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:05:47.781+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:05:47.781+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:05:47.801+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:05:47.801+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:05:47.832+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.624 seconds
[2025-04-23T15:06:17.931+0000] {processor.py:186} INFO - Started process (PID=5840) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:06:17.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:06:17.936+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:06:17.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:06:18.375+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:06:18.410+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:06:18.410+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:06:18.426+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:06:18.426+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:06:18.464+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.544 seconds
[2025-04-23T15:06:48.646+0000] {processor.py:186} INFO - Started process (PID=5909) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:06:48.648+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:06:48.653+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:06:48.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:06:49.105+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:06:49.134+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:06:49.133+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:06:49.152+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:06:49.152+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:06:49.188+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.553 seconds
[2025-04-23T15:07:19.295+0000] {processor.py:186} INFO - Started process (PID=5978) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:07:19.297+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:07:19.302+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:07:19.301+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:07:19.931+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:07:19.959+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:07:19.959+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:07:19.976+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:07:19.976+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:07:20.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.731 seconds
[2025-04-23T15:07:50.512+0000] {processor.py:186} INFO - Started process (PID=6047) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:07:50.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:07:50.516+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:07:50.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:07:50.966+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:07:50.996+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:07:50.995+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:07:51.015+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:07:51.015+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:07:51.046+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.543 seconds
[2025-04-23T15:08:21.463+0000] {processor.py:186} INFO - Started process (PID=6117) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:08:21.468+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:08:21.472+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:08:21.471+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:08:22.057+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:08:22.092+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:08:22.091+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:08:22.116+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:08:22.116+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:08:22.160+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.709 seconds
[2025-04-23T15:08:52.465+0000] {processor.py:186} INFO - Started process (PID=6186) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:08:52.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:08:52.469+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:08:52.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:08:52.902+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:08:52.928+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:08:52.928+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:08:52.945+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:08:52.945+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:08:52.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.516 seconds
[2025-04-23T15:09:23.511+0000] {processor.py:186} INFO - Started process (PID=6255) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:09:23.513+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:09:23.516+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:09:23.515+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:09:23.789+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:09:23.820+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:09:23.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:09:23.840+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:09:23.839+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:09:23.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-23T15:09:54.491+0000] {processor.py:186} INFO - Started process (PID=6324) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:09:54.492+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:09:54.496+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:09:54.495+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:09:54.897+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:09:54.936+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:09:54.936+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:09:54.960+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:09:54.959+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:09:55.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.524 seconds
[2025-04-23T15:10:25.554+0000] {processor.py:186} INFO - Started process (PID=6392) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:10:25.555+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:10:25.559+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:10:25.558+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:10:25.855+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:10:25.887+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:10:25.887+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:10:25.906+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:10:25.905+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:10:25.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.388 seconds
[2025-04-23T15:10:56.348+0000] {processor.py:186} INFO - Started process (PID=6461) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:10:56.350+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:10:56.353+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:10:56.353+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:10:56.645+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:10:56.674+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:10:56.674+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:10:56.691+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:10:56.691+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:10:56.724+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.385 seconds
[2025-04-23T15:11:27.287+0000] {processor.py:186} INFO - Started process (PID=6530) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:11:27.289+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:11:27.292+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:11:27.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:11:27.565+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:11:27.606+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:11:27.605+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:11:27.631+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:11:27.631+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:11:27.678+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.398 seconds
[2025-04-23T15:11:58.100+0000] {processor.py:186} INFO - Started process (PID=6599) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:11:58.101+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:11:58.104+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:11:58.104+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:11:58.358+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:11:58.387+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:11:58.386+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:11:58.402+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:11:58.402+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:11:58.433+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-23T15:12:28.688+0000] {processor.py:186} INFO - Started process (PID=6665) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:12:28.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:12:28.692+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:12:28.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:12:29.021+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:12:29.049+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:12:29.049+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:12:29.065+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:12:29.065+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:12:29.094+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-23T15:12:59.239+0000] {processor.py:186} INFO - Started process (PID=6735) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:12:59.240+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:12:59.243+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:12:59.243+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:12:59.516+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:12:59.549+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:12:59.549+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:12:59.579+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:12:59.578+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:12:59.615+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T15:13:30.519+0000] {processor.py:186} INFO - Started process (PID=6804) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:13:30.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:13:30.524+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:13:30.523+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:13:30.799+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:13:30.827+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:13:30.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:13:30.844+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:13:30.844+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:13:30.876+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-23T15:14:01.473+0000] {processor.py:186} INFO - Started process (PID=6873) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:14:01.475+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:14:01.479+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:14:01.478+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:14:01.739+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:14:01.778+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:14:01.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:14:01.796+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:14:01.796+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:14:01.825+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-23T15:14:32.777+0000] {processor.py:186} INFO - Started process (PID=6942) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:14:32.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:14:32.783+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:14:32.782+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:14:33.030+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:14:33.062+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:14:33.061+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:14:33.077+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:14:33.077+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:14:33.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-23T15:15:03.215+0000] {processor.py:186} INFO - Started process (PID=7011) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:15:03.217+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:15:03.220+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:15:03.220+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:15:03.481+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:15:03.510+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:15:03.510+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:15:03.526+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:15:03.526+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:15:03.557+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-23T15:15:34.018+0000] {processor.py:186} INFO - Started process (PID=7080) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:15:34.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:15:34.023+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:15:34.023+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:15:34.287+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:15:34.318+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:15:34.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:15:34.333+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:15:34.333+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:15:34.359+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T15:16:04.774+0000] {processor.py:186} INFO - Started process (PID=7149) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:16:04.776+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:16:04.781+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:16:04.780+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:16:05.053+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:16:05.083+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:16:05.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:16:05.099+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:16:05.099+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:16:05.130+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-23T15:16:35.327+0000] {processor.py:186} INFO - Started process (PID=7218) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:16:35.328+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:16:35.332+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:16:35.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:16:35.679+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:16:35.712+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:16:35.711+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:16:35.732+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:16:35.732+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:16:35.770+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.453 seconds
[2025-04-23T15:17:06.427+0000] {processor.py:186} INFO - Started process (PID=7288) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:17:06.429+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:17:06.433+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:17:06.432+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:17:06.752+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:17:06.788+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:17:06.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:17:06.811+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:17:06.811+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:17:06.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.429 seconds
[2025-04-23T15:17:36.996+0000] {processor.py:186} INFO - Started process (PID=7357) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:17:36.998+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:17:37.001+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:17:37.001+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:17:37.285+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:17:37.321+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:17:37.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:17:37.339+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:17:37.338+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:17:37.371+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T15:18:08.167+0000] {processor.py:186} INFO - Started process (PID=7426) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:18:08.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:18:08.172+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:18:08.172+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:18:08.424+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:18:08.455+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:18:08.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:18:08.471+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:18:08.471+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:18:08.500+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-23T15:18:38.672+0000] {processor.py:186} INFO - Started process (PID=7495) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:18:38.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:18:38.677+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:18:38.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:18:38.937+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:18:38.970+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:18:38.969+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:18:38.987+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:18:38.987+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:18:39.012+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-23T15:19:10.027+0000] {processor.py:186} INFO - Started process (PID=7570) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:19:10.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:19:10.033+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:19:10.033+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:19:10.365+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:19:10.393+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:19:10.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:19:10.417+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:19:10.417+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:19:10.451+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.441 seconds
[2025-04-23T15:19:40.662+0000] {processor.py:186} INFO - Started process (PID=7639) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:19:40.664+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:19:40.667+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:19:40.667+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:19:40.944+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:19:40.976+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:19:40.975+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:19:40.996+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:19:40.996+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:19:41.028+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-23T15:20:11.137+0000] {processor.py:186} INFO - Started process (PID=7708) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:20:11.139+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:20:11.143+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:20:11.142+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:20:11.496+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:20:11.535+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:20:11.534+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:20:11.559+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:20:11.559+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:20:12.326+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.200 seconds
[2025-04-23T15:20:42.558+0000] {processor.py:186} INFO - Started process (PID=7777) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:20:42.560+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:20:42.564+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:20:42.564+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:20:43.042+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:20:43.084+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:20:43.084+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:20:43.111+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:20:43.110+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:20:43.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.599 seconds
[2025-04-23T15:21:13.613+0000] {processor.py:186} INFO - Started process (PID=7847) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:21:13.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:21:13.618+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:21:13.618+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:21:13.909+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:21:13.940+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:21:13.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:21:13.957+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:21:13.956+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:21:13.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T15:21:44.164+0000] {processor.py:186} INFO - Started process (PID=7915) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:21:44.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:21:44.171+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:21:44.170+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:21:44.489+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:21:44.517+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:21:44.517+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:21:44.537+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:21:44.536+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:21:44.568+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-23T15:22:15.087+0000] {processor.py:186} INFO - Started process (PID=7984) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:22:15.092+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:22:15.096+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:22:15.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:22:15.540+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:22:15.584+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:22:15.583+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:22:15.610+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:22:15.609+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:22:15.669+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.599 seconds
[2025-04-23T15:22:45.805+0000] {processor.py:186} INFO - Started process (PID=8053) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:22:45.806+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:22:45.809+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:22:45.809+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:22:46.072+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:22:46.102+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:22:46.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:22:46.117+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:22:46.117+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:22:46.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-23T15:23:16.212+0000] {processor.py:186} INFO - Started process (PID=8122) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:23:16.214+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:23:16.217+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:23:16.217+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:23:16.501+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:23:16.533+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:23:16.533+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:23:16.553+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:23:16.553+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:23:16.587+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T15:23:47.093+0000] {processor.py:186} INFO - Started process (PID=8191) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:23:47.094+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:23:47.097+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:23:47.097+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:23:47.432+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:23:47.473+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:23:47.472+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:23:47.495+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:23:47.494+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:23:47.529+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.445 seconds
[2025-04-23T15:24:17.743+0000] {processor.py:186} INFO - Started process (PID=8262) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:24:17.744+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:24:17.748+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:24:17.747+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:24:18.034+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:24:18.064+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:24:18.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:24:18.086+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:24:18.086+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:24:18.118+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.384 seconds
[2025-04-23T15:24:49.124+0000] {processor.py:186} INFO - Started process (PID=8331) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:24:49.125+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:24:49.129+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:24:49.128+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:24:49.426+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:24:49.460+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:24:49.459+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:24:49.481+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:24:49.481+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:24:49.516+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.401 seconds
[2025-04-23T15:25:20.404+0000] {processor.py:186} INFO - Started process (PID=8400) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:25:20.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:25:20.411+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:25:20.410+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:25:20.842+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:25:20.892+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:25:20.892+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:25:20.919+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:25:20.918+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:25:20.958+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.565 seconds
[2025-04-23T15:25:51.093+0000] {processor.py:186} INFO - Started process (PID=8469) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:25:51.095+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:25:51.099+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:25:51.098+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:25:51.377+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:25:51.586+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:25:51.585+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:25:51.601+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:25:51.600+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:25:51.629+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.544 seconds
[2025-04-23T15:26:22.502+0000] {processor.py:186} INFO - Started process (PID=8538) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:26:22.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:26:22.509+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:26:22.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:26:22.772+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:26:22.981+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:26:22.980+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:26:22.996+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:26:22.996+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:26:23.026+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.531 seconds
[2025-04-23T15:26:53.585+0000] {processor.py:186} INFO - Started process (PID=8607) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:26:53.586+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:26:53.590+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:26:53.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:26:54.312+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:26:54.351+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:26:54.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:26:54.374+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:26:54.374+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:26:54.404+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.828 seconds
[2025-04-23T15:27:24.854+0000] {processor.py:186} INFO - Started process (PID=8677) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:27:24.855+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:27:24.857+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:27:24.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:27:25.208+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:27:25.236+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:27:25.235+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:27:25.254+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:27:25.253+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:27:25.280+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.434 seconds
[2025-04-23T15:27:55.420+0000] {processor.py:186} INFO - Started process (PID=8746) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:27:55.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:27:55.425+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:27:55.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:27:55.691+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:27:55.725+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:27:55.724+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:27:55.741+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:27:55.741+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:27:55.772+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-23T15:28:26.364+0000] {processor.py:186} INFO - Started process (PID=8817) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:28:26.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:28:26.368+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:28:26.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:28:26.651+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:28:26.685+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:28:26.684+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:28:26.702+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:28:26.701+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:28:26.735+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-23T15:28:56.844+0000] {processor.py:186} INFO - Started process (PID=8885) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:28:56.845+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:28:56.849+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:28:56.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:28:57.330+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:28:57.356+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:28:57.355+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:28:57.373+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:28:57.372+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:28:57.402+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.568 seconds
[2025-04-23T15:29:28.407+0000] {processor.py:186} INFO - Started process (PID=8957) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:29:28.409+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:29:28.411+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:29:28.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:29:28.849+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:29:28.874+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:29:28.874+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:29:28.890+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:29:28.890+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:29:28.919+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.522 seconds
[2025-04-23T15:29:59.041+0000] {processor.py:186} INFO - Started process (PID=9024) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:29:59.043+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:29:59.047+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:29:59.046+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:29:59.524+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:29:59.558+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:29:59.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:29:59.576+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:29:59.575+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:29:59.603+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.570 seconds
[2025-04-23T15:30:30.380+0000] {processor.py:186} INFO - Started process (PID=9093) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:30:30.381+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:30:30.385+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:30:30.384+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:30:30.869+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:30:30.896+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:30:30.896+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:30:30.912+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:30:30.912+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:30:30.938+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.566 seconds
[2025-04-23T15:31:01.280+0000] {processor.py:186} INFO - Started process (PID=9162) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:31:01.282+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:31:01.288+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:31:01.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:31:01.788+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:31:01.823+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:31:01.822+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:31:01.842+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:31:01.842+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:31:01.869+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.597 seconds
[2025-04-23T15:31:32.022+0000] {processor.py:186} INFO - Started process (PID=9231) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:31:32.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:31:32.028+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:31:32.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:31:32.473+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:31:32.501+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:31:32.501+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:31:32.516+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:31:32.516+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:31:32.547+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.533 seconds
[2025-04-23T15:32:03.151+0000] {processor.py:186} INFO - Started process (PID=9300) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:32:03.152+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:32:03.156+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:32:03.155+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:32:03.666+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:32:03.698+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:32:03.698+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:32:03.714+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:32:03.714+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:32:03.745+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.604 seconds
[2025-04-23T15:32:34.383+0000] {processor.py:186} INFO - Started process (PID=9369) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:32:34.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:32:34.388+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:32:34.387+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:32:34.879+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:32:34.910+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:32:34.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:32:34.927+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:32:34.927+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:32:34.965+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.589 seconds
[2025-04-23T15:33:05.668+0000] {processor.py:186} INFO - Started process (PID=9438) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:33:05.669+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:33:05.675+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:33:05.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:33:06.209+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:33:06.239+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:33:06.238+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:33:06.257+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:33:06.256+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:33:06.286+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.625 seconds
[2025-04-23T15:33:37.196+0000] {processor.py:186} INFO - Started process (PID=9507) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:33:37.198+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:33:37.201+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:33:37.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:33:37.703+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:33:37.748+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:33:37.747+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:33:37.771+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:33:37.770+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:33:37.809+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.622 seconds
[2025-04-23T15:34:07.960+0000] {processor.py:186} INFO - Started process (PID=9576) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:34:07.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:34:07.964+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:34:07.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:34:08.431+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:34:08.465+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:34:08.464+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:34:08.481+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:34:08.481+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:34:08.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.562 seconds
[2025-04-23T15:34:39.272+0000] {processor.py:186} INFO - Started process (PID=9646) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:34:39.273+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:34:39.278+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:34:39.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:34:39.591+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:34:39.621+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:34:39.621+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:34:39.643+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:34:39.642+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:34:39.676+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-23T15:35:10.295+0000] {processor.py:186} INFO - Started process (PID=9715) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:35:10.296+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:35:10.300+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:35:10.300+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:35:10.571+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:35:10.601+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:35:10.601+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:35:10.618+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:35:10.618+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:35:10.644+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-23T15:35:40.802+0000] {processor.py:186} INFO - Started process (PID=9784) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:35:40.804+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:35:40.807+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:35:40.807+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:35:41.059+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:35:41.103+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:35:41.103+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:35:41.123+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:35:41.122+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:35:41.151+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-23T15:36:11.726+0000] {processor.py:186} INFO - Started process (PID=9853) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:36:11.727+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:36:11.730+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:36:11.729+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:36:12.006+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:36:12.035+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:36:12.035+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:36:12.052+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:36:12.052+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:36:12.097+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.379 seconds
[2025-04-23T15:36:42.470+0000] {processor.py:186} INFO - Started process (PID=9928) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:36:42.472+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:36:42.477+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:36:42.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:36:42.762+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:36:42.793+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:36:42.793+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:36:42.816+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:36:42.816+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:36:42.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-23T15:37:13.011+0000] {processor.py:186} INFO - Started process (PID=9997) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:37:13.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:37:13.016+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:37:13.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:37:13.278+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:37:13.308+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:37:13.307+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:37:13.324+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:37:13.324+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:37:13.355+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-23T15:37:43.655+0000] {processor.py:186} INFO - Started process (PID=10066) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:37:43.657+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:37:43.661+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:37:43.660+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:37:43.927+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:37:43.958+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:37:43.958+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:37:43.975+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:37:43.974+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:37:44.006+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-23T15:38:14.317+0000] {processor.py:186} INFO - Started process (PID=10135) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:38:14.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:38:14.330+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:38:14.330+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:38:14.677+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:38:14.707+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:38:14.706+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:38:14.724+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:38:14.723+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:38:14.749+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.452 seconds
[2025-04-23T15:38:44.961+0000] {processor.py:186} INFO - Started process (PID=10204) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:38:44.963+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:38:44.966+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:38:44.966+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:38:45.239+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:38:45.272+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:38:45.271+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:38:45.291+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:38:45.291+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:38:45.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-23T15:39:16.250+0000] {processor.py:186} INFO - Started process (PID=10273) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:39:16.251+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:39:16.256+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:39:16.255+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:39:16.531+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:39:16.564+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:39:16.564+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:39:16.581+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:39:16.581+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:39:16.607+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-23T15:39:46.794+0000] {processor.py:186} INFO - Started process (PID=10342) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:39:46.795+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:39:46.800+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:39:46.799+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:39:47.072+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:39:47.106+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:39:47.105+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:39:47.123+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:39:47.123+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:39:47.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-23T15:40:17.406+0000] {processor.py:186} INFO - Started process (PID=10411) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:40:17.408+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:40:17.412+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:40:17.411+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:40:17.701+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:40:17.732+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:40:17.731+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:40:17.751+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:40:17.751+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:40:17.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.384 seconds
[2025-04-23T15:40:48.023+0000] {processor.py:186} INFO - Started process (PID=10481) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:40:48.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:40:48.029+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:40:48.028+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:40:48.322+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:40:48.352+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:40:48.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:40:48.371+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:40:48.371+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:40:48.398+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-23T15:41:18.858+0000] {processor.py:186} INFO - Started process (PID=10550) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:41:18.859+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:41:18.862+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:41:18.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:41:19.119+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:41:19.151+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:41:19.150+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:41:19.167+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:41:19.167+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:41:19.198+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T15:41:49.384+0000] {processor.py:186} INFO - Started process (PID=10619) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:41:49.385+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:41:49.388+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:41:49.388+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:41:49.661+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:41:49.690+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:41:49.689+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:41:49.707+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:41:49.707+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:41:49.731+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-23T15:42:20.209+0000] {processor.py:186} INFO - Started process (PID=10688) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:42:20.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:42:20.214+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:42:20.214+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:42:20.488+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:42:20.520+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:42:20.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:42:20.538+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:42:20.537+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:42:20.571+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-23T15:42:50.806+0000] {processor.py:186} INFO - Started process (PID=10755) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:42:50.808+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:42:50.812+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:42:50.811+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:42:51.096+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:42:51.126+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:42:51.125+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:42:51.145+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:42:51.144+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:42:51.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.376 seconds
[2025-04-23T15:43:21.318+0000] {processor.py:186} INFO - Started process (PID=10824) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:43:21.319+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:43:21.324+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:43:21.323+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:43:21.622+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:43:21.654+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:43:21.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:43:21.673+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:43:21.672+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:43:21.702+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.392 seconds
[2025-04-23T15:43:52.077+0000] {processor.py:186} INFO - Started process (PID=10893) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:43:52.078+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:43:52.082+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:43:52.081+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:43:52.345+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:43:52.378+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:43:52.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:43:52.395+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:43:52.395+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:43:52.425+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-23T15:44:22.553+0000] {processor.py:186} INFO - Started process (PID=10960) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:44:22.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:44:22.557+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:44:22.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:44:22.809+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:44:22.853+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:44:22.853+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:44:22.875+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:44:22.874+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:44:22.906+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-23T15:44:53.637+0000] {processor.py:186} INFO - Started process (PID=11029) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:44:53.638+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:44:53.642+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:44:53.641+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:44:53.902+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:44:53.934+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:44:53.933+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:44:53.950+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:44:53.950+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:44:53.982+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-23T15:45:24.488+0000] {processor.py:186} INFO - Started process (PID=11098) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:45:24.490+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:45:24.493+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:45:24.493+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:45:24.749+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:45:24.780+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:45:24.780+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:45:24.797+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:45:24.796+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:45:24.831+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-23T15:45:55.113+0000] {processor.py:186} INFO - Started process (PID=11167) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:45:55.114+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:45:55.118+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:45:55.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:45:55.401+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:45:55.437+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:45:55.436+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:45:55.454+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:45:55.454+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:45:55.487+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T15:46:26.165+0000] {processor.py:186} INFO - Started process (PID=11236) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:46:26.166+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:46:26.169+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:46:26.169+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:46:26.432+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:46:26.464+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:46:26.463+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:46:26.482+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:46:26.482+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:46:26.514+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-23T15:46:56.705+0000] {processor.py:186} INFO - Started process (PID=11305) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:46:56.706+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:46:56.710+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:46:56.710+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:46:56.990+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:46:57.020+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:46:57.019+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:46:57.036+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:46:57.036+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:46:57.067+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-23T15:47:27.414+0000] {processor.py:186} INFO - Started process (PID=11374) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:47:27.415+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:47:27.419+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:47:27.418+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:47:27.676+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:47:27.707+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:47:27.707+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:47:27.725+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:47:27.725+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:47:27.751+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-23T15:47:58.390+0000] {processor.py:186} INFO - Started process (PID=11443) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:47:58.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:47:58.394+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:47:58.394+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:47:58.655+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:47:58.686+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:47:58.685+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:47:58.703+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:47:58.703+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:47:58.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-23T15:48:29.390+0000] {processor.py:186} INFO - Started process (PID=11512) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:48:29.391+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:48:29.395+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:48:29.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:48:29.799+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:48:29.824+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:48:29.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:48:29.836+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:48:29.836+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:48:29.863+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.480 seconds
[2025-04-23T15:49:00.010+0000] {processor.py:186} INFO - Started process (PID=11581) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:49:00.012+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:49:00.016+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:49:00.015+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:49:00.298+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:49:00.326+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:49:00.326+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:49:00.344+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:49:00.344+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:49:00.374+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-23T15:49:30.585+0000] {processor.py:186} INFO - Started process (PID=11650) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:49:30.587+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:49:30.591+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:49:30.590+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:49:31.091+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:49:31.117+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:49:31.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:49:31.131+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:49:31.131+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:49:31.156+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.579 seconds
[2025-04-23T15:50:01.629+0000] {processor.py:186} INFO - Started process (PID=11719) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:50:01.630+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:50:01.634+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:50:01.634+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:50:02.074+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:50:02.100+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:50:02.100+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:50:02.115+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:50:02.115+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:50:02.146+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.524 seconds
[2025-04-23T15:50:32.743+0000] {processor.py:186} INFO - Started process (PID=11788) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:50:32.745+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:50:32.749+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:50:32.748+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:50:33.158+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:50:33.184+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:50:33.184+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:50:33.201+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:50:33.201+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:50:33.229+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.493 seconds
[2025-04-23T15:51:03.454+0000] {processor.py:186} INFO - Started process (PID=11857) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:51:03.456+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:51:03.460+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:51:03.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:51:03.887+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:51:03.920+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:51:03.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:51:03.937+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:51:03.937+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:51:03.967+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.520 seconds
[2025-04-23T15:51:34.435+0000] {processor.py:186} INFO - Started process (PID=11926) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:51:34.437+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:51:34.441+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:51:34.441+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:51:34.944+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:51:34.971+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:51:34.971+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:51:34.985+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:51:34.985+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:51:35.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.587 seconds
[2025-04-23T15:52:05.410+0000] {processor.py:186} INFO - Started process (PID=11995) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:52:05.412+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:52:05.416+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:52:05.415+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:52:05.875+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:52:05.906+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:52:05.906+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:52:05.922+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:52:05.921+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:52:05.949+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.546 seconds
[2025-04-23T15:52:36.110+0000] {processor.py:186} INFO - Started process (PID=12063) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:52:36.111+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:52:36.114+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:52:36.114+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:52:36.518+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:52:36.543+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:52:36.542+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:52:36.557+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:52:36.557+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:52:36.584+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.483 seconds
[2025-04-23T15:53:06.890+0000] {processor.py:186} INFO - Started process (PID=12132) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:53:06.891+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:53:06.896+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:53:06.895+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:53:07.313+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:53:07.341+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:53:07.341+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:53:07.359+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:53:07.359+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:53:07.391+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.507 seconds
[2025-04-23T15:53:38.414+0000] {processor.py:186} INFO - Started process (PID=12201) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:53:38.416+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:53:38.419+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:53:38.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:53:38.842+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:53:38.869+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:53:38.869+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:53:38.883+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:53:38.883+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:53:38.914+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.513 seconds
[2025-04-23T15:54:09.603+0000] {processor.py:186} INFO - Started process (PID=12270) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:54:09.604+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:54:09.608+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:54:09.607+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:54:10.031+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:54:10.060+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:54:10.060+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:54:10.075+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:54:10.075+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:54:10.103+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.507 seconds
[2025-04-23T15:54:40.958+0000] {processor.py:186} INFO - Started process (PID=12339) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:54:40.960+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:54:40.964+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:54:40.963+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:54:41.371+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:54:41.405+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:54:41.404+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:54:41.423+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:54:41.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:54:41.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.503 seconds
[2025-04-23T15:55:11.812+0000] {processor.py:186} INFO - Started process (PID=12408) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:55:11.814+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:55:11.818+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:55:11.817+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:55:12.070+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:55:12.101+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:55:12.101+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:55:12.117+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:55:12.117+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:55:12.147+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T15:55:42.696+0000] {processor.py:186} INFO - Started process (PID=12477) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:55:42.698+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:55:42.702+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:55:42.701+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:55:42.971+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:55:43.003+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:55:43.003+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:55:43.020+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:55:43.020+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:55:43.055+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-23T15:56:13.391+0000] {processor.py:186} INFO - Started process (PID=12546) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:56:13.392+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:56:13.396+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:56:13.395+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:56:13.658+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:56:13.689+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:56:13.688+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:56:13.705+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:56:13.705+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:56:13.734+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-23T15:56:44.283+0000] {processor.py:186} INFO - Started process (PID=12621) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:56:44.284+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:56:44.289+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:56:44.288+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:56:44.568+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:56:44.599+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:56:44.599+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:56:44.618+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:56:44.617+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:56:44.647+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-23T15:57:14.875+0000] {processor.py:186} INFO - Started process (PID=12690) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:57:14.877+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:57:14.879+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:57:14.879+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:57:15.117+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:57:15.154+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:57:15.153+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:57:15.170+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:57:15.170+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:57:15.195+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.326 seconds
[2025-04-23T15:57:45.332+0000] {processor.py:186} INFO - Started process (PID=12759) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:57:45.340+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:57:45.343+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:57:45.343+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:57:45.584+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:57:45.615+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:57:45.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:57:45.631+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:57:45.631+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:57:45.660+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-23T15:58:16.024+0000] {processor.py:186} INFO - Started process (PID=12828) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:58:16.025+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:58:16.030+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:58:16.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:58:16.289+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:58:16.319+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:58:16.318+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:58:16.336+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:58:16.336+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:58:16.372+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-23T15:58:46.651+0000] {processor.py:186} INFO - Started process (PID=12897) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:58:46.652+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:58:46.655+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:58:46.654+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:58:46.916+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:58:46.952+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:58:46.951+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:58:46.970+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:58:46.969+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:58:47.004+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-23T15:59:17.385+0000] {processor.py:186} INFO - Started process (PID=12966) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:59:17.386+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:59:17.390+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:59:17.389+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:59:17.646+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:59:17.677+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:59:17.677+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:59:17.694+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:59:17.694+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:59:17.725+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T15:59:48.161+0000] {processor.py:186} INFO - Started process (PID=13035) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:59:48.163+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T15:59:48.167+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:59:48.166+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:59:48.455+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T15:59:48.485+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:59:48.485+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T15:59:48.501+0000] {logging_mixin.py:190} INFO - [2025-04-23T15:59:48.501+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T15:59:48.532+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-23T16:00:18.977+0000] {processor.py:186} INFO - Started process (PID=13104) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:00:18.978+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:00:18.981+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:00:18.980+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:00:19.217+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:00:19.251+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:00:19.251+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:00:19.268+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:00:19.267+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:00:19.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-23T16:00:49.790+0000] {processor.py:186} INFO - Started process (PID=13173) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:00:49.792+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:00:49.795+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:00:49.795+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:00:50.061+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:00:50.089+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:00:50.089+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:00:50.105+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:00:50.105+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:00:50.132+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-23T16:01:20.520+0000] {processor.py:186} INFO - Started process (PID=13242) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:01:20.521+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:01:20.526+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:01:20.525+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:01:20.776+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:01:20.806+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:01:20.806+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:01:20.822+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:01:20.821+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:01:20.847+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-23T16:01:51.255+0000] {processor.py:186} INFO - Started process (PID=13311) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:01:51.257+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:01:51.260+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:01:51.260+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:01:51.526+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:01:51.558+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:01:51.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:01:51.574+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:01:51.574+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:01:51.602+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-23T16:02:22.133+0000] {processor.py:186} INFO - Started process (PID=13380) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:02:22.134+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:02:22.138+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:02:22.137+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:02:22.391+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:02:22.422+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:02:22.421+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:02:22.438+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:02:22.437+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:02:22.469+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-23T16:02:53.503+0000] {processor.py:186} INFO - Started process (PID=13449) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:02:53.505+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:02:53.509+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:02:53.508+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:02:53.768+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:02:53.797+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:02:53.796+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:02:53.812+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:02:53.812+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:02:53.845+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.349 seconds
[2025-04-23T16:03:24.157+0000] {processor.py:186} INFO - Started process (PID=13518) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:03:24.159+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:03:24.163+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:03:24.162+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:03:24.433+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:03:24.462+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:03:24.461+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:03:24.478+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:03:24.478+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:03:24.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-23T16:03:54.939+0000] {processor.py:186} INFO - Started process (PID=13587) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:03:54.941+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:03:54.943+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:03:54.943+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:03:55.212+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:03:55.242+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:03:55.242+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:03:55.260+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:03:55.259+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:03:55.290+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-23T16:04:25.486+0000] {processor.py:186} INFO - Started process (PID=13656) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:04:25.487+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:04:25.490+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:04:25.490+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:04:25.814+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:04:25.868+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:04:25.867+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:04:25.910+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:04:25.909+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:04:25.950+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.480 seconds
[2025-04-23T16:04:56.606+0000] {processor.py:186} INFO - Started process (PID=13725) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:04:56.608+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:04:56.611+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:04:56.611+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:04:56.911+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:04:56.939+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:04:56.938+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:04:56.955+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:04:56.955+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:04:56.987+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.389 seconds
[2025-04-23T16:05:27.193+0000] {processor.py:186} INFO - Started process (PID=13794) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:05:27.195+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:05:27.198+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:05:27.197+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:05:27.465+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:05:27.495+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:05:27.495+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:05:27.511+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:05:27.511+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:05:27.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-23T16:05:58.166+0000] {processor.py:186} INFO - Started process (PID=13863) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:05:58.168+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:05:58.172+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:05:58.171+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:05:58.492+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:05:58.523+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:05:58.522+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:05:58.545+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:05:58.544+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:05:58.578+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.424 seconds
[2025-04-23T16:06:28.933+0000] {processor.py:186} INFO - Started process (PID=13932) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:06:28.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:06:28.939+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:06:28.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:06:29.224+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:06:29.254+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:06:29.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:06:29.271+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:06:29.271+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:06:29.295+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-23T16:07:00.328+0000] {processor.py:186} INFO - Started process (PID=14001) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:07:00.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:07:00.335+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:07:00.334+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:07:00.618+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:07:00.654+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:07:00.653+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:07:00.678+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:07:00.678+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:07:00.713+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-23T16:07:30.966+0000] {processor.py:186} INFO - Started process (PID=14070) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:07:30.968+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:07:30.972+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:07:30.971+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:07:31.233+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:07:31.269+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:07:31.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:07:31.292+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:07:31.292+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:07:31.329+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.371 seconds
[2025-04-23T16:08:01.533+0000] {processor.py:186} INFO - Started process (PID=14139) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:08:01.535+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:08:01.539+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:08:01.539+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:08:01.806+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:08:01.835+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:08:01.834+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:08:01.850+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:08:01.850+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:08:01.882+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-23T16:08:31.964+0000] {processor.py:186} INFO - Started process (PID=14208) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:08:31.967+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:08:31.974+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:08:31.973+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:08:32.238+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:08:32.271+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:08:32.270+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:08:32.294+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:08:32.294+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:08:32.697+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.750 seconds
[2025-04-23T16:09:03.080+0000] {processor.py:186} INFO - Started process (PID=14277) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:09:03.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:09:03.085+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:09:03.085+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:09:03.352+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:09:03.380+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:09:03.380+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:09:03.398+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:09:03.397+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:09:03.426+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-23T16:09:34.023+0000] {processor.py:186} INFO - Started process (PID=14347) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:09:34.024+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:09:34.028+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:09:34.027+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:09:34.299+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:09:34.335+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:09:34.335+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:09:34.358+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:09:34.358+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:09:34.387+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-23T16:10:05.069+0000] {processor.py:186} INFO - Started process (PID=14416) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:10:05.070+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:10:05.074+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:10:05.073+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:10:05.345+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:10:05.374+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:10:05.374+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:10:05.392+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:10:05.392+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:10:05.429+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-23T16:10:35.593+0000] {processor.py:186} INFO - Started process (PID=14485) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:10:35.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:10:35.601+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:10:35.601+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:10:35.868+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:10:35.899+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:10:35.899+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:10:35.917+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:10:35.916+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:10:35.951+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-23T16:11:06.026+0000] {processor.py:186} INFO - Started process (PID=14554) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:11:06.027+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:11:06.030+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:11:06.029+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:11:06.351+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:11:06.379+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:11:06.378+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:11:06.395+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:11:06.395+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:11:06.422+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.404 seconds
[2025-04-23T16:11:36.927+0000] {processor.py:186} INFO - Started process (PID=14624) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:11:36.929+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:11:36.933+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:11:36.932+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:11:37.203+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:11:37.232+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:11:37.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:11:37.248+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:11:37.248+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:11:37.281+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-23T16:12:07.914+0000] {processor.py:186} INFO - Started process (PID=14693) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:12:07.916+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:12:07.920+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:12:07.919+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:12:08.190+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:12:08.227+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:12:08.226+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:12:08.246+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:12:08.245+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:12:08.276+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-23T16:12:39.027+0000] {processor.py:186} INFO - Started process (PID=14762) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:12:39.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:12:39.032+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:12:39.032+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:12:39.279+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:12:39.309+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:12:39.309+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:12:39.326+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:12:39.326+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:12:39.351+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.331 seconds
[2025-04-23T16:13:10.302+0000] {processor.py:186} INFO - Started process (PID=14831) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:13:10.303+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:13:10.307+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:13:10.307+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:13:10.548+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:13:10.579+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:13:10.578+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:13:10.596+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:13:10.596+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:13:10.622+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-23T16:13:41.235+0000] {processor.py:186} INFO - Started process (PID=14900) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:13:41.236+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:13:41.240+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:13:41.239+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:13:41.489+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:13:41.524+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:13:41.524+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:13:41.544+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:13:41.543+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:13:41.577+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.353 seconds
[2025-04-23T16:14:12.159+0000] {processor.py:186} INFO - Started process (PID=14969) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:14:12.161+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:14:12.165+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:14:12.164+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:14:12.433+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:14:12.465+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:14:12.465+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:14:12.483+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:14:12.483+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:14:12.510+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.360 seconds
[2025-04-23T16:14:42.672+0000] {processor.py:186} INFO - Started process (PID=15038) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:14:42.673+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:14:42.677+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:14:42.676+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:14:43.091+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:14:43.120+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:14:43.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:14:43.134+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:14:43.134+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:14:43.163+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.499 seconds
[2025-04-23T16:15:13.618+0000] {processor.py:186} INFO - Started process (PID=15108) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:15:13.619+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:15:13.623+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:15:13.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:15:14.043+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:15:14.069+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:15:14.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:15:14.083+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:15:14.083+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:15:14.107+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.496 seconds
[2025-04-23T16:15:44.409+0000] {processor.py:186} INFO - Started process (PID=15176) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:15:44.410+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:15:44.414+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:15:44.413+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:15:44.882+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:15:44.910+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:15:44.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:15:44.926+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:15:44.925+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:15:44.954+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.552 seconds
[2025-04-23T16:16:15.460+0000] {processor.py:186} INFO - Started process (PID=15245) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:16:15.462+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:16:15.465+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:16:15.465+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:16:15.945+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:16:15.971+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:16:15.970+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:16:15.985+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:16:15.985+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:16:16.018+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.568 seconds
[2025-04-23T16:16:46.328+0000] {processor.py:186} INFO - Started process (PID=15314) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:16:46.330+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:16:46.334+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:16:46.333+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:16:46.794+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:16:46.820+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:16:46.820+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:16:46.839+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:16:46.839+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:16:46.874+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.559 seconds
[2025-04-23T16:17:17.182+0000] {processor.py:186} INFO - Started process (PID=15389) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:17:17.184+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:17:17.187+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:17:17.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:17:17.617+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:17:17.646+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:17:17.645+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:17:17.664+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:17:17.664+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:17:17.690+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.514 seconds
[2025-04-23T16:17:48.614+0000] {processor.py:186} INFO - Started process (PID=15458) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:17:48.616+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:17:48.620+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:17:48.619+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:17:49.043+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:17:49.069+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:17:49.068+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:17:49.083+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:17:49.083+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:17:49.112+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.505 seconds
[2025-04-23T16:18:19.797+0000] {processor.py:186} INFO - Started process (PID=15527) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:18:19.798+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:18:19.802+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:18:19.802+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:18:20.055+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:18:20.084+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:18:20.083+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:18:20.099+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:18:20.099+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:18:20.127+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.337 seconds
[2025-04-23T16:18:50.679+0000] {processor.py:186} INFO - Started process (PID=15596) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:18:50.681+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:18:50.685+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:18:50.684+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:18:50.969+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:18:51.000+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:18:51.000+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:18:51.020+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:18:51.019+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:18:51.051+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-23T16:19:21.298+0000] {processor.py:186} INFO - Started process (PID=15665) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:19:21.299+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:19:21.302+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:19:21.302+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:19:21.548+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:19:21.578+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:19:21.577+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:19:21.594+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:19:21.594+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:19:21.624+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-23T16:19:52.286+0000] {processor.py:186} INFO - Started process (PID=15734) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:19:52.291+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:19:52.296+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:19:52.295+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:19:52.668+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:19:52.703+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:19:52.702+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:19:52.725+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:19:52.725+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:19:52.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.484 seconds
[2025-04-23T16:20:23.195+0000] {processor.py:186} INFO - Started process (PID=15803) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:20:23.197+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:20:23.201+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:20:23.201+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:20:23.455+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:20:23.489+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:20:23.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:20:23.505+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:20:23.505+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:20:23.536+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.354 seconds
[2025-04-23T16:20:54.078+0000] {processor.py:186} INFO - Started process (PID=15872) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:20:54.080+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:20:54.084+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:20:54.083+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:20:54.363+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:20:54.396+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:20:54.395+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:20:54.418+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:20:54.417+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:20:54.457+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-23T16:21:25.249+0000] {processor.py:186} INFO - Started process (PID=15941) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:21:25.250+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:21:25.254+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:21:25.253+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:21:25.503+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:21:25.532+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:21:25.532+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:21:25.548+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:21:25.548+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:21:25.579+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.339 seconds
[2025-04-23T16:21:55.933+0000] {processor.py:186} INFO - Started process (PID=16010) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:21:55.935+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:21:55.939+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:21:55.938+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:21:56.239+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:21:56.272+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:21:56.272+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:21:56.292+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:21:56.292+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:21:56.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.398 seconds
[2025-04-23T16:22:26.984+0000] {processor.py:186} INFO - Started process (PID=16079) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:22:26.986+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:22:26.990+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:22:26.989+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:22:27.237+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:22:27.268+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:22:27.268+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:22:27.288+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:22:27.287+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:22:27.323+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-23T16:22:57.664+0000] {processor.py:186} INFO - Started process (PID=16148) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:22:57.666+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:22:57.670+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:22:57.669+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:22:58.090+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:22:58.145+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:22:58.145+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:22:58.172+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:22:58.171+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:22:58.220+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.567 seconds
[2025-04-23T16:23:28.458+0000] {processor.py:186} INFO - Started process (PID=16217) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:23:28.459+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:23:28.463+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:23:28.462+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:23:28.748+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:23:28.778+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:23:28.777+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:23:28.796+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:23:28.796+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:23:28.822+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-23T16:23:59.378+0000] {processor.py:186} INFO - Started process (PID=16286) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:23:59.380+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:23:59.385+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:23:59.385+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:23:59.672+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:23:59.706+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:23:59.705+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:23:59.724+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:23:59.724+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:23:59.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.387 seconds
[2025-04-23T16:24:30.126+0000] {processor.py:186} INFO - Started process (PID=16355) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:24:30.128+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:24:30.131+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:24:30.131+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:24:30.409+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:24:30.455+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:24:30.454+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:24:30.476+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:24:30.475+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:24:30.509+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.392 seconds
[2025-04-23T16:25:01.119+0000] {processor.py:186} INFO - Started process (PID=16424) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:25:01.120+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:25:01.124+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:25:01.124+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:25:01.478+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:25:01.510+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:25:01.509+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:25:01.532+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:25:01.532+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:25:01.573+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.464 seconds
[2025-04-23T16:25:31.912+0000] {processor.py:186} INFO - Started process (PID=16493) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:25:31.913+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:25:31.917+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:25:31.916+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:25:32.188+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:25:32.220+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:25:32.219+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:25:32.239+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:25:32.238+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:25:32.269+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-23T16:26:02.452+0000] {processor.py:186} INFO - Started process (PID=16562) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:26:02.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:26:02.457+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:26:02.457+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:26:02.717+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:26:02.758+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:26:02.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:26:02.777+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:26:02.777+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:26:02.808+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-23T16:26:33.132+0000] {processor.py:186} INFO - Started process (PID=16632) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:26:33.133+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:26:33.136+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:26:33.136+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:26:33.384+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:26:33.412+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:26:33.411+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:26:33.429+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:26:33.428+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:26:33.458+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-23T16:27:03.835+0000] {processor.py:186} INFO - Started process (PID=16701) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:27:03.837+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:27:03.840+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:27:03.839+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:27:04.134+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:27:04.166+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:27:04.165+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:27:04.185+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:27:04.185+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:27:04.214+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.387 seconds
[2025-04-23T16:27:35.181+0000] {processor.py:186} INFO - Started process (PID=16772) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:27:35.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:27:35.186+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:27:35.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:27:35.484+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:27:35.522+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:27:35.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:27:35.546+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:27:35.546+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:27:35.583+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.411 seconds
[2025-04-23T16:28:06.286+0000] {processor.py:186} INFO - Started process (PID=16841) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:28:06.287+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:28:06.291+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:28:06.291+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:28:06.723+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:28:06.777+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:28:06.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:28:06.807+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:28:06.806+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:28:06.842+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.566 seconds
[2025-04-23T16:28:37.056+0000] {processor.py:186} INFO - Started process (PID=16908) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:28:37.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:28:37.062+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:28:37.061+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:28:37.318+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:28:37.347+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:28:37.346+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:28:37.363+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:28:37.363+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:28:37.395+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-23T16:29:08.184+0000] {processor.py:186} INFO - Started process (PID=16977) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:29:08.185+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:29:08.189+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:29:08.189+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:29:08.453+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:29:08.488+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:29:08.487+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:29:08.505+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:29:08.505+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:29:08.535+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-23T16:29:38.619+0000] {processor.py:186} INFO - Started process (PID=17046) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:29:38.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:29:38.623+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:29:38.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:29:38.882+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:29:38.920+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:29:38.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:29:38.937+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:29:38.936+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:29:38.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-23T16:30:09.595+0000] {processor.py:186} INFO - Started process (PID=17115) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:30:09.596+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:30:09.600+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:30:09.600+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:30:09.892+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:30:09.930+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:30:09.930+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:30:09.951+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:30:09.950+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:30:09.985+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.397 seconds
[2025-04-23T16:30:40.282+0000] {processor.py:186} INFO - Started process (PID=17184) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:30:40.283+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:30:40.288+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:30:40.287+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:30:41.000+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:30:41.089+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:30:41.088+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:30:41.171+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:30:41.170+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:30:41.250+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.981 seconds
[2025-04-23T16:31:11.465+0000] {processor.py:186} INFO - Started process (PID=17252) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:31:11.466+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:31:11.469+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:31:11.469+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:31:11.740+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:31:11.774+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:31:11.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:31:11.791+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:31:11.791+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:31:11.817+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-23T16:31:42.500+0000] {processor.py:186} INFO - Started process (PID=17321) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:31:42.502+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:31:42.504+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:31:42.504+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:31:42.744+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:31:42.774+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:31:42.773+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:31:42.791+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:31:42.791+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:31:42.826+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.333 seconds
[2025-04-23T16:32:13.089+0000] {processor.py:186} INFO - Started process (PID=17389) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:32:13.091+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:32:13.095+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:32:13.094+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:32:13.371+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:32:13.401+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:32:13.400+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:32:13.422+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:32:13.421+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:32:13.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.655 seconds
[2025-04-23T16:32:44.527+0000] {processor.py:186} INFO - Started process (PID=17459) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:32:44.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:32:44.531+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:32:44.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:32:44.798+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:32:44.827+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:32:44.827+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:32:44.845+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:32:44.845+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:32:44.875+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-23T16:33:15.382+0000] {processor.py:186} INFO - Started process (PID=17528) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:33:15.383+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:33:15.386+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:33:15.386+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:33:15.648+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:33:15.676+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:33:15.676+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:33:15.694+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:33:15.694+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:33:15.723+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
[2025-04-23T16:33:46.140+0000] {processor.py:186} INFO - Started process (PID=17597) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:33:46.141+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:33:46.144+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:33:46.144+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:33:46.399+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:33:46.434+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:33:46.433+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:33:46.454+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:33:46.453+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:33:46.481+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T16:34:16.645+0000] {processor.py:186} INFO - Started process (PID=17666) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:34:16.646+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:34:16.649+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:34:16.649+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:34:17.010+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:34:17.045+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:34:17.045+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:34:17.061+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:34:17.060+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:34:17.088+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.452 seconds
[2025-04-23T16:34:47.852+0000] {processor.py:186} INFO - Started process (PID=17735) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:34:47.854+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:34:47.857+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:34:47.857+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:34:48.184+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:34:48.225+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:34:48.224+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:34:48.243+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:34:48.243+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:34:48.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.432 seconds
[2025-04-23T16:35:18.777+0000] {processor.py:186} INFO - Started process (PID=17804) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:35:18.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:35:18.784+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:35:18.783+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:35:19.098+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:35:19.127+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:35:19.126+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:35:19.143+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:35:19.142+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:35:19.175+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.409 seconds
[2025-04-23T16:35:49.320+0000] {processor.py:186} INFO - Started process (PID=17879) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:35:49.321+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:35:49.325+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:35:49.324+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:35:49.599+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:35:49.635+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:35:49.634+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:35:49.652+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:35:49.652+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:35:49.820+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.510 seconds
[2025-04-23T16:36:20.548+0000] {processor.py:186} INFO - Started process (PID=17948) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:36:20.550+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:36:20.554+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:36:20.553+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:36:20.857+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:36:20.898+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:36:20.897+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:36:20.921+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:36:20.921+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:36:20.957+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.417 seconds
[2025-04-23T16:36:51.363+0000] {processor.py:186} INFO - Started process (PID=18016) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:36:51.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:36:51.370+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:36:51.369+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:36:51.637+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:36:51.665+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:36:51.664+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:36:51.683+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:36:51.683+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:36:51.712+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-23T16:37:21.868+0000] {processor.py:186} INFO - Started process (PID=18085) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:37:21.869+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:37:21.873+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:37:21.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:37:22.160+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:37:22.192+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:37:22.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:37:22.209+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:37:22.209+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:37:22.275+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.416 seconds
[2025-04-23T16:37:53.052+0000] {processor.py:186} INFO - Started process (PID=18154) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:37:53.053+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:37:53.057+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:37:53.057+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:37:53.335+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:37:53.369+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:37:53.369+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:37:53.385+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:37:53.384+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:37:53.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.369 seconds
[2025-04-23T16:38:24.299+0000] {processor.py:186} INFO - Started process (PID=18223) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:38:24.301+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:38:24.306+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:38:24.305+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:38:24.590+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:38:24.620+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:38:24.619+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:38:24.635+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:38:24.635+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:38:24.665+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-23T16:38:55.019+0000] {processor.py:186} INFO - Started process (PID=18292) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:38:55.020+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:38:55.025+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:38:55.024+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:38:55.329+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:38:55.357+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:38:55.357+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:38:55.373+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:38:55.373+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:38:55.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.394 seconds
[2025-04-23T16:39:26.115+0000] {processor.py:186} INFO - Started process (PID=18361) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:39:26.117+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:39:26.121+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:39:26.120+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:39:26.471+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:39:26.507+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:39:26.507+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:39:26.529+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:39:26.528+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:39:26.555+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.451 seconds
[2025-04-23T16:39:57.088+0000] {processor.py:186} INFO - Started process (PID=18430) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:39:57.090+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:39:57.096+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:39:57.095+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:39:57.390+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:39:57.422+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:39:57.422+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:39:57.442+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:39:57.441+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:39:57.475+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.398 seconds
[2025-04-23T16:40:28.242+0000] {processor.py:186} INFO - Started process (PID=18499) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:40:28.244+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:40:28.248+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:40:28.248+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:40:28.538+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:40:28.568+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:40:28.567+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:40:28.589+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:40:28.588+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:40:28.619+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.391 seconds
[2025-04-23T16:40:58.959+0000] {processor.py:186} INFO - Started process (PID=18568) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:40:58.961+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:40:58.964+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:40:58.964+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:40:59.216+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:40:59.248+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:40:59.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:40:59.263+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:40:59.263+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:40:59.292+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-23T16:41:29.366+0000] {processor.py:186} INFO - Started process (PID=18637) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:41:29.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:41:29.371+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:41:29.371+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:41:29.671+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:41:29.703+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:41:29.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:41:29.722+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:41:29.722+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:41:29.755+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.396 seconds
[2025-04-23T16:41:59.947+0000] {processor.py:186} INFO - Started process (PID=18706) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:41:59.949+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:41:59.953+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:41:59.952+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:42:00.217+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:42:00.249+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:42:00.248+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:42:00.266+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:42:00.266+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:42:00.297+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.359 seconds
[2025-04-23T16:42:31.341+0000] {processor.py:186} INFO - Started process (PID=18775) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:42:31.342+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:42:31.346+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:42:31.345+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:42:31.679+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:42:31.723+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:42:31.722+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:42:31.749+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:42:31.748+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:42:31.783+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.449 seconds
[2025-04-23T16:43:01.909+0000] {processor.py:186} INFO - Started process (PID=18844) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:43:01.910+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:43:01.913+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:43:01.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:43:02.204+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:43:02.231+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:43:02.231+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:43:02.248+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:43:02.247+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:43:02.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.373 seconds
[2025-04-23T16:43:33.195+0000] {processor.py:186} INFO - Started process (PID=18913) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:43:33.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:43:33.200+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:43:33.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:43:33.490+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:43:33.522+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:43:33.521+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:43:33.544+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:43:33.543+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:43:33.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.383 seconds
[2025-04-23T16:44:04.207+0000] {processor.py:186} INFO - Started process (PID=18982) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:44:04.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:44:04.213+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:44:04.212+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:44:04.500+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:44:04.540+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:44:04.540+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:44:04.560+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:44:04.560+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:44:04.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.393 seconds
[2025-04-23T16:44:35.524+0000] {processor.py:186} INFO - Started process (PID=19051) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:44:35.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:44:35.529+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:44:35.529+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:44:35.886+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:44:35.916+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:44:35.915+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:44:35.933+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:44:35.932+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:44:35.962+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.447 seconds
[2025-04-23T16:45:06.082+0000] {processor.py:186} INFO - Started process (PID=19120) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:45:06.084+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:45:06.086+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:45:06.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:45:06.374+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:45:06.406+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:45:06.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:45:06.429+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:45:06.428+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:45:06.470+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.395 seconds
[2025-04-23T16:45:37.147+0000] {processor.py:186} INFO - Started process (PID=19189) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:45:37.149+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:45:37.153+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:45:37.153+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:45:37.462+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:45:37.500+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:45:37.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:45:37.520+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:45:37.520+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:45:37.551+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-23T16:46:07.893+0000] {processor.py:186} INFO - Started process (PID=19258) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:46:07.894+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:46:07.899+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:46:07.898+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:46:08.181+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:46:08.214+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:46:08.214+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:46:08.232+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:46:08.232+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:46:08.265+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.381 seconds
[2025-04-23T16:46:38.608+0000] {processor.py:186} INFO - Started process (PID=19327) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:46:38.610+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:46:38.614+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:46:38.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:46:38.891+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:46:38.921+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:46:38.921+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:46:38.940+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:46:38.940+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:46:38.973+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-23T16:47:09.168+0000] {processor.py:186} INFO - Started process (PID=19396) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:47:09.169+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:47:09.173+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:47:09.173+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:47:09.421+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:47:09.620+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:47:09.620+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:47:09.634+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:47:09.634+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:47:09.664+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.503 seconds
[2025-04-23T16:47:40.181+0000] {processor.py:186} INFO - Started process (PID=19465) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:47:40.182+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:47:40.186+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:47:40.185+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:47:40.465+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:47:40.711+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:47:40.710+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:47:40.731+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:47:40.731+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:47:40.758+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.585 seconds
[2025-04-23T16:48:10.908+0000] {processor.py:186} INFO - Started process (PID=19534) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:48:10.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:48:10.913+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:48:10.912+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:48:11.225+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:48:11.263+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:48:11.262+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:48:11.571+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:48:11.571+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:48:12.015+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.116 seconds
[2025-04-23T16:48:42.314+0000] {processor.py:186} INFO - Started process (PID=19603) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:48:42.315+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:48:42.319+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:48:42.319+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:48:42.567+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:48:42.598+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:48:42.597+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:48:42.777+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:48:42.777+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:48:42.807+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.502 seconds
[2025-04-23T16:49:12.907+0000] {processor.py:186} INFO - Started process (PID=19672) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:49:12.909+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:49:12.913+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:49:12.913+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:49:13.220+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:49:13.258+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:49:13.257+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:49:13.439+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:49:13.439+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:49:13.462+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.564 seconds
[2025-04-23T16:49:44.080+0000] {processor.py:186} INFO - Started process (PID=19741) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:49:44.082+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:49:44.085+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:49:44.084+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:49:44.362+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:49:44.393+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:49:44.393+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:49:44.576+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:49:44.575+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:49:44.601+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.528 seconds
[2025-04-23T16:50:14.755+0000] {processor.py:186} INFO - Started process (PID=19810) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:50:14.757+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:50:14.761+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:50:14.761+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:50:15.047+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:50:15.083+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:50:15.082+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:50:15.304+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:50:15.304+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:50:15.333+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.586 seconds
[2025-04-23T16:50:46.070+0000] {processor.py:186} INFO - Started process (PID=19879) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:50:46.072+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:50:46.077+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:50:46.076+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:50:46.335+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:50:46.528+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:50:46.528+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:50:46.543+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:50:46.543+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:50:46.569+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.510 seconds
[2025-04-23T16:51:17.174+0000] {processor.py:186} INFO - Started process (PID=19949) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:51:17.176+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:51:17.180+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:51:17.180+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:51:17.587+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:51:17.615+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:51:17.615+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:51:17.629+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:51:17.629+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:51:17.659+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.492 seconds
[2025-04-23T16:51:48.029+0000] {processor.py:186} INFO - Started process (PID=20018) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:51:48.030+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:51:48.034+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:51:48.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:51:48.464+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:51:48.490+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:51:48.489+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:51:48.504+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:51:48.504+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:51:48.538+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.516 seconds
[2025-04-23T16:52:18.809+0000] {processor.py:186} INFO - Started process (PID=20088) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:52:18.811+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:52:18.815+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:52:18.814+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:52:19.358+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:52:19.384+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:52:19.384+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:52:19.400+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:52:19.399+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:52:19.428+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.626 seconds
[2025-04-23T16:52:49.503+0000] {processor.py:186} INFO - Started process (PID=20157) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:52:49.504+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:52:49.507+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:52:49.507+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:52:49.881+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:52:49.906+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:52:49.905+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:52:49.918+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:52:49.918+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:52:49.946+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.449 seconds
[2025-04-23T16:53:20.104+0000] {processor.py:186} INFO - Started process (PID=20226) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:53:20.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:53:20.109+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:53:20.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:53:20.360+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:53:20.388+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:53:20.387+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:53:20.403+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:53:20.403+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:53:20.431+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.335 seconds
[2025-04-23T16:53:50.523+0000] {processor.py:186} INFO - Started process (PID=20295) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:53:50.525+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:53:50.528+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:53:50.527+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:53:50.780+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:53:50.812+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:53:50.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:53:50.829+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:53:50.829+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:53:50.855+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-23T16:54:21.370+0000] {processor.py:186} INFO - Started process (PID=20370) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:54:21.371+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:54:21.375+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:54:21.374+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:54:21.702+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:54:21.730+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:54:21.729+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:54:21.749+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:54:21.749+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:54:21.776+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.417 seconds
[2025-04-23T16:54:51.911+0000] {processor.py:186} INFO - Started process (PID=20441) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:54:51.912+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:54:51.915+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:54:51.915+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:54:52.189+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:54:52.223+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:54:52.222+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:54:52.239+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:54:52.239+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:54:52.272+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.370 seconds
[2025-04-23T16:55:22.354+0000] {processor.py:186} INFO - Started process (PID=20511) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:55:22.355+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:55:22.358+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:55:22.358+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:55:22.618+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:55:22.652+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:55:22.651+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:55:22.669+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:55:22.668+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:55:22.699+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-23T16:55:53.209+0000] {processor.py:186} INFO - Started process (PID=20579) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:55:53.211+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:55:53.214+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:55:53.213+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:55:53.529+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:55:53.566+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:55:53.566+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:55:53.583+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:55:53.583+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:55:53.616+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.416 seconds
[2025-04-23T16:56:24.082+0000] {processor.py:186} INFO - Started process (PID=20648) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:56:24.083+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:56:24.086+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:56:24.086+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:56:24.375+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:56:24.420+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:56:24.420+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:56:24.439+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:56:24.438+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:56:24.466+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.395 seconds
[2025-04-23T16:56:54.604+0000] {processor.py:186} INFO - Started process (PID=20719) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:56:54.605+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:56:54.608+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:56:54.608+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:56:54.886+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:56:54.917+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:56:54.916+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:56:54.934+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:56:54.934+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:56:54.963+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-23T16:57:25.420+0000] {processor.py:186} INFO - Started process (PID=20786) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:57:25.422+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:57:25.424+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:57:25.424+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:57:25.701+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:57:25.731+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:57:25.730+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:57:25.753+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:57:25.753+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:57:25.785+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.372 seconds
[2025-04-23T16:57:55.957+0000] {processor.py:186} INFO - Started process (PID=20854) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:57:55.959+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:57:55.963+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:57:55.962+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:57:56.245+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:57:56.276+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:57:56.275+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:57:56.293+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:57:56.292+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:57:56.324+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.375 seconds
[2025-04-23T16:58:26.463+0000] {processor.py:186} INFO - Started process (PID=20922) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:58:26.464+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:58:26.467+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:58:26.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:58:26.724+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:58:26.754+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:58:26.754+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:58:26.772+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:58:26.771+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:58:26.802+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T16:58:57.113+0000] {processor.py:186} INFO - Started process (PID=20991) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:58:57.115+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:58:57.118+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:58:57.118+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:58:57.383+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:58:57.414+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:58:57.414+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:58:57.431+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:58:57.431+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:58:57.456+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-23T16:59:27.595+0000] {processor.py:186} INFO - Started process (PID=21062) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:59:27.597+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:59:27.599+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:59:27.599+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:59:27.841+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:59:27.871+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:59:27.870+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:59:27.887+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:59:27.886+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:59:27.915+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.326 seconds
[2025-04-23T16:59:58.002+0000] {processor.py:186} INFO - Started process (PID=21129) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:59:58.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T16:59:58.007+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:59:58.007+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:59:58.305+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T16:59:58.334+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:59:58.334+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T16:59:58.351+0000] {logging_mixin.py:190} INFO - [2025-04-23T16:59:58.351+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T16:59:58.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.389 seconds
[2025-04-23T17:00:28.537+0000] {processor.py:186} INFO - Started process (PID=21200) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:00:28.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:00:28.541+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:00:28.541+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:00:28.792+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:00:28.824+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:00:28.823+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:00:28.840+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:00:28.840+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:00:28.871+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.342 seconds
[2025-04-23T17:00:58.986+0000] {processor.py:186} INFO - Started process (PID=21271) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:00:58.988+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:00:58.991+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:00:58.990+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:00:59.234+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:00:59.265+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:00:59.265+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:00:59.286+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:00:59.286+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:00:59.321+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-23T17:01:29.649+0000] {processor.py:186} INFO - Started process (PID=21340) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:01:29.650+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:01:29.653+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:01:29.653+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:01:29.896+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:01:29.924+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:01:29.923+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:01:29.940+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:01:29.940+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:01:29.969+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.327 seconds
[2025-04-23T17:02:00.182+0000] {processor.py:186} INFO - Started process (PID=21404) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:02:00.183+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:02:00.186+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:02:00.186+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:02:00.467+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:02:00.499+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:02:00.499+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:02:00.517+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:02:00.516+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:02:00.542+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-23T17:02:30.684+0000] {processor.py:186} INFO - Started process (PID=21472) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:02:30.685+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:02:30.688+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:02:30.688+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:02:30.962+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:02:30.992+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:02:30.991+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:02:31.008+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:02:31.008+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:02:31.038+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-23T17:03:01.293+0000] {processor.py:186} INFO - Started process (PID=21541) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:03:01.294+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:03:01.297+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:03:01.296+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:03:01.562+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:03:01.596+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:03:01.596+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:03:01.615+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:03:01.615+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:03:01.648+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-23T17:03:31.944+0000] {processor.py:186} INFO - Started process (PID=21610) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:03:31.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:03:31.948+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:03:31.948+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:03:32.206+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:03:32.240+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:03:32.239+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:03:32.256+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:03:32.256+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:03:32.288+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.352 seconds
[2025-04-23T17:04:02.462+0000] {processor.py:186} INFO - Started process (PID=21681) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:04:02.463+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:04:02.466+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:04:02.466+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:04:02.744+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:04:02.774+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:04:02.774+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:04:02.794+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:04:02.793+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:04:02.823+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.368 seconds
[2025-04-23T17:04:32.930+0000] {processor.py:186} INFO - Started process (PID=21748) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:04:32.932+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:04:32.934+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:04:32.934+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:04:33.224+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:04:33.255+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:04:33.255+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:04:33.272+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:04:33.272+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:04:33.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-23T17:05:03.508+0000] {processor.py:186} INFO - Started process (PID=21817) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:05:03.509+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:05:03.511+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:05:03.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:05:03.766+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:05:03.798+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:05:03.797+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:05:03.815+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:05:03.815+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:05:03.843+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.344 seconds
[2025-04-23T17:05:34.030+0000] {processor.py:186} INFO - Started process (PID=21888) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:05:34.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:05:34.034+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:05:34.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:05:34.312+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:05:34.352+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:05:34.351+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:05:34.372+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:05:34.372+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:05:34.405+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-23T17:06:04.537+0000] {processor.py:186} INFO - Started process (PID=21958) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:06:04.538+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:06:04.540+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:06:04.540+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:06:04.840+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:06:04.868+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:06:04.868+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:06:04.885+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:06:04.884+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:06:04.921+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.392 seconds
[2025-04-23T17:06:35.048+0000] {processor.py:186} INFO - Started process (PID=22029) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:06:35.049+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:06:35.051+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:06:35.051+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:06:35.292+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:06:35.320+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:06:35.320+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:06:35.338+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:06:35.337+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:06:35.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.324 seconds
[2025-04-23T17:07:05.618+0000] {processor.py:186} INFO - Started process (PID=22098) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:07:05.620+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:07:05.623+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:07:05.622+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:07:05.888+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:07:05.920+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:07:05.920+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:07:05.938+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:07:05.938+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:07:05.971+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-23T17:07:37.011+0000] {processor.py:186} INFO - Started process (PID=22166) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:07:37.013+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:07:37.016+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:07:37.016+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:07:37.313+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:07:37.503+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:07:37.502+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:07:37.519+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:07:37.519+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:07:37.548+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.549 seconds
[2025-04-23T17:08:07.735+0000] {processor.py:186} INFO - Started process (PID=22237) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:08:07.737+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:08:07.739+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:08:07.739+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:08:07.979+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:08:08.006+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:08:08.006+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:08:08.021+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:08:08.020+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:08:08.048+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.319 seconds
[2025-04-23T17:08:38.864+0000] {processor.py:186} INFO - Started process (PID=22306) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:08:38.865+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:08:38.868+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:08:38.867+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:08:39.164+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:08:39.192+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:08:39.191+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:08:39.209+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:08:39.209+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:08:39.239+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-23T17:09:09.405+0000] {processor.py:186} INFO - Started process (PID=22375) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:09:09.406+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:09:09.409+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:09:09.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:09:09.681+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:09:09.713+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:09:09.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:09:09.730+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:09:09.729+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:09:09.756+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-23T17:09:39.812+0000] {processor.py:186} INFO - Started process (PID=22444) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:09:39.813+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:09:39.817+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:09:39.816+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:09:40.104+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:09:40.131+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:09:40.131+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:09:40.149+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:09:40.149+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:09:40.342+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.538 seconds
[2025-04-23T17:10:11.207+0000] {processor.py:186} INFO - Started process (PID=22515) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:10:11.208+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:10:11.211+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:10:11.211+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:10:11.477+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:10:11.516+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:10:11.515+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:10:11.542+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:10:11.541+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:10:11.732+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.532 seconds
[2025-04-23T17:10:41.859+0000] {processor.py:186} INFO - Started process (PID=22587) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:10:41.860+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:10:41.862+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:10:41.862+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:10:42.133+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:10:42.163+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:10:42.162+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:10:42.349+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:10:42.349+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:10:42.380+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.530 seconds
[2025-04-23T17:11:12.587+0000] {processor.py:186} INFO - Started process (PID=22659) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:11:12.589+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:11:12.593+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:11:12.592+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:11:12.882+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:11:12.914+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:11:12.914+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:11:13.162+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:11:13.161+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:11:13.197+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.622 seconds
[2025-04-23T17:11:43.869+0000] {processor.py:186} INFO - Started process (PID=22729) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:11:43.870+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:11:43.873+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:11:43.872+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:11:44.132+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:11:44.318+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:11:44.317+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:11:44.335+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:11:44.334+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:11:44.365+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.503 seconds
[2025-04-23T17:12:14.527+0000] {processor.py:186} INFO - Started process (PID=22800) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:12:14.528+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:12:14.531+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:12:14.531+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:12:15.078+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:12:15.111+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:12:15.110+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:12:15.127+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:12:15.126+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:12:15.155+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.636 seconds
[2025-04-23T17:12:45.305+0000] {processor.py:186} INFO - Started process (PID=22867) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:12:45.307+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:12:45.312+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:12:45.311+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:12:45.762+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:12:45.787+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:12:45.787+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:12:45.805+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:12:45.804+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:12:45.833+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.537 seconds
[2025-04-23T17:13:15.927+0000] {processor.py:186} INFO - Started process (PID=22938) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:13:15.928+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:13:15.930+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:13:15.930+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:13:16.341+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:13:16.367+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:13:16.366+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:13:16.381+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:13:16.381+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:13:16.413+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.493 seconds
[2025-04-23T17:13:46.752+0000] {processor.py:186} INFO - Started process (PID=23005) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:13:46.753+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:13:46.756+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:13:46.756+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:13:47.197+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:13:47.223+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:13:47.223+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:13:47.237+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:13:47.237+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:13:47.266+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.522 seconds
[2025-04-23T17:14:17.367+0000] {processor.py:186} INFO - Started process (PID=23076) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:14:17.368+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:14:17.371+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:14:17.370+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:14:17.751+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:14:17.776+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:14:17.776+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:14:17.792+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:14:17.791+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:14:17.819+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.459 seconds
[2025-04-23T17:14:48.613+0000] {processor.py:186} INFO - Started process (PID=23145) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:14:48.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:14:48.617+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:14:48.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:14:49.001+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:14:49.024+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:14:49.024+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:14:49.037+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:14:49.037+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:14:49.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.459 seconds
[2025-04-23T17:15:19.248+0000] {processor.py:186} INFO - Started process (PID=23214) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:15:19.249+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:15:19.253+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:15:19.252+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:15:19.708+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:15:19.744+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:15:19.744+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:15:19.764+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:15:19.764+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:15:19.794+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.555 seconds
[2025-04-23T17:15:51.325+0000] {processor.py:186} INFO - Started process (PID=23281) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:15:51.326+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:15:51.330+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:15:51.329+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:15:51.878+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:15:51.935+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:15:51.934+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:15:51.952+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:15:51.951+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:15:51.980+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.666 seconds
[2025-04-23T17:16:22.061+0000] {processor.py:186} INFO - Started process (PID=23352) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:16:22.062+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:16:22.065+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:16:22.065+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:16:22.580+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:16:22.607+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:16:22.607+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:16:22.623+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:16:22.623+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:16:22.655+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.603 seconds
[2025-04-23T17:16:52.781+0000] {processor.py:186} INFO - Started process (PID=23423) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:16:52.782+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:16:52.785+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:16:52.784+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:16:53.033+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:16:53.064+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:16:53.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:16:53.079+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:16:53.079+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:16:53.108+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-23T17:17:23.170+0000] {processor.py:186} INFO - Started process (PID=23489) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:17:23.172+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:17:23.175+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:17:23.175+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:17:23.481+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:17:23.521+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:17:23.520+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:17:23.542+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:17:23.542+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:17:23.591+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.428 seconds
[2025-04-23T17:17:54.614+0000] {processor.py:186} INFO - Started process (PID=23564) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:17:54.615+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:17:54.618+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:17:54.617+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:17:54.910+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:17:54.941+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:17:54.940+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:17:54.960+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:17:54.960+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:17:55.002+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.397 seconds
[2025-04-23T17:18:25.156+0000] {processor.py:186} INFO - Started process (PID=23634) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:18:25.157+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:18:25.160+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:18:25.160+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:18:25.515+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:18:25.545+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:18:25.545+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:18:25.570+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:18:25.570+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:18:25.608+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.462 seconds
[2025-04-23T17:18:55.773+0000] {processor.py:186} INFO - Started process (PID=23701) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:18:55.775+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:18:55.779+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:18:55.779+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:18:56.070+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:18:56.103+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:18:56.102+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:18:56.125+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:18:56.124+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:18:56.158+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.396 seconds
[2025-04-23T17:19:26.437+0000] {processor.py:186} INFO - Started process (PID=23760) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:19:26.438+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:19:26.441+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:19:26.440+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:19:26.712+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:19:26.741+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:19:26.741+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:19:26.762+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:19:26.762+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:19:26.793+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-23T17:19:58.445+0000] {processor.py:186} INFO - Started process (PID=23828) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:19:58.453+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:19:58.460+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:19:58.459+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:19:59.396+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:19:59.498+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:19:59.497+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:19:59.573+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:19:59.573+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:19:59.698+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 1.275 seconds
[2025-04-23T17:20:30.140+0000] {processor.py:186} INFO - Started process (PID=23896) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:20:30.142+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:20:30.147+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:20:30.146+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:20:30.450+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:20:30.489+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:20:30.488+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:20:30.507+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:20:30.507+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:20:30.537+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.407 seconds
[2025-04-23T17:21:00.769+0000] {processor.py:186} INFO - Started process (PID=23965) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:21:00.771+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:21:00.774+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:21:00.773+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:21:01.088+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:21:01.120+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:21:01.119+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:21:01.146+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:21:01.145+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:21:01.181+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.422 seconds
[2025-04-23T17:21:31.277+0000] {processor.py:186} INFO - Started process (PID=24036) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:21:31.279+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:21:31.281+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:21:31.281+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:21:31.531+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:21:31.558+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:21:31.558+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:21:31.573+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:21:31.573+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:21:31.600+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.332 seconds
[2025-04-23T17:22:02.328+0000] {processor.py:186} INFO - Started process (PID=24105) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:22:02.329+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:22:02.332+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:22:02.331+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:22:02.592+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:22:02.626+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:22:02.626+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:22:02.646+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:22:02.646+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:22:02.681+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.361 seconds
[2025-04-23T17:22:32.975+0000] {processor.py:186} INFO - Started process (PID=24175) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:22:32.976+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:22:32.979+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:22:32.979+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:22:33.227+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:22:33.254+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:22:33.254+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:22:33.270+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:22:33.270+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:22:33.299+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.334 seconds
[2025-04-23T17:23:03.423+0000] {processor.py:186} INFO - Started process (PID=24244) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:23:03.424+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:23:03.428+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:23:03.427+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:23:03.684+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:23:03.712+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:23:03.712+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:23:03.729+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:23:03.728+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:23:03.757+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.345 seconds
[2025-04-23T17:23:33.961+0000] {processor.py:186} INFO - Started process (PID=24313) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:23:33.964+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:23:33.969+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:23:33.968+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:23:34.225+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:23:34.253+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:23:34.253+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:23:34.269+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:23:34.269+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:23:34.623+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.688 seconds
[2025-04-23T17:24:04.779+0000] {processor.py:186} INFO - Started process (PID=24382) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:24:04.780+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:24:04.785+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:24:04.785+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:24:05.088+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:24:05.115+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:24:05.114+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:24:05.132+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:24:05.132+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:24:05.182+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.415 seconds
[2025-04-23T17:24:36.056+0000] {processor.py:186} INFO - Started process (PID=24452) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:24:36.058+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:24:36.062+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:24:36.062+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:24:36.330+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:24:36.360+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:24:36.359+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:24:36.378+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:24:36.377+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:24:36.414+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.365 seconds
[2025-04-23T17:25:06.610+0000] {processor.py:186} INFO - Started process (PID=24521) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:25:06.611+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:25:06.615+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:25:06.614+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:25:06.945+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:25:06.995+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:25:06.994+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:25:07.013+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:25:07.013+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:25:07.040+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.440 seconds
[2025-04-23T17:25:38.036+0000] {processor.py:186} INFO - Started process (PID=24591) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:25:38.037+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:25:38.041+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:25:38.040+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:25:38.296+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:25:38.333+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:25:38.333+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:25:38.352+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:25:38.352+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:25:38.384+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.357 seconds
[2025-04-23T17:26:08.607+0000] {processor.py:186} INFO - Started process (PID=24662) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:26:08.609+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:26:08.614+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:26:08.613+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:26:08.883+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:26:08.911+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:26:08.910+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:26:08.929+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:26:08.929+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:26:08.959+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-23T17:26:39.104+0000] {processor.py:186} INFO - Started process (PID=24733) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:26:39.106+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:26:39.108+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:26:39.108+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:26:39.374+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:26:39.406+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:26:39.405+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:26:39.423+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:26:39.423+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:26:39.454+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-23T17:27:09.553+0000] {processor.py:186} INFO - Started process (PID=24803) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:27:09.554+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:27:09.557+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:27:09.557+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:27:09.826+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:27:09.856+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:27:09.856+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:27:09.878+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:27:09.878+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:27:09.910+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-23T17:27:40.047+0000] {processor.py:186} INFO - Started process (PID=24874) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:27:40.048+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:27:40.051+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:27:40.050+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:27:40.321+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:27:40.352+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:27:40.352+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:27:40.370+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:27:40.370+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:27:40.403+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.364 seconds
[2025-04-23T17:28:10.613+0000] {processor.py:186} INFO - Started process (PID=24945) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:28:10.614+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:28:10.617+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:28:10.616+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:28:10.941+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:28:10.978+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:28:10.977+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:28:10.996+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:28:10.995+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:28:11.032+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.428 seconds
[2025-04-23T17:28:41.986+0000] {processor.py:186} INFO - Started process (PID=25013) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:28:41.996+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:28:41.999+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:28:41.999+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:28:42.302+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:28:42.339+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:28:42.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:28:42.359+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:28:42.358+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:28:42.392+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.414 seconds
[2025-04-23T17:29:12.766+0000] {processor.py:186} INFO - Started process (PID=25081) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:29:12.768+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:29:12.771+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:29:12.770+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:29:13.021+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:29:13.050+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:29:13.050+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:29:13.067+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:29:13.066+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:29:13.098+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.340 seconds
[2025-04-23T17:29:43.400+0000] {processor.py:186} INFO - Started process (PID=25146) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:29:43.402+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:29:43.405+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:29:43.405+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:29:43.705+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:29:43.741+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:29:43.740+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:29:43.762+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:29:43.762+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:29:43.806+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.417 seconds
[2025-04-23T17:30:14.195+0000] {processor.py:186} INFO - Started process (PID=25214) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:30:14.196+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:30:14.201+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:30:14.200+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:30:14.506+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:30:14.544+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:30:14.544+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:30:14.563+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:30:14.563+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:30:14.588+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.402 seconds
[2025-04-23T17:30:45.103+0000] {processor.py:186} INFO - Started process (PID=25283) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:30:45.105+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:30:45.111+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:30:45.110+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:30:45.518+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:30:45.551+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:30:45.551+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:30:45.569+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:30:45.569+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:30:45.599+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.509 seconds
[2025-04-23T17:31:16.027+0000] {processor.py:186} INFO - Started process (PID=25352) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:31:16.028+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:31:16.032+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:31:16.031+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:31:16.314+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:31:16.343+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:31:16.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:31:16.360+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:31:16.360+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:31:16.393+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.377 seconds
[2025-04-23T17:31:46.563+0000] {processor.py:186} INFO - Started process (PID=25423) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:31:46.565+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:31:46.567+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:31:46.567+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:31:46.851+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:31:46.887+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:31:46.886+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:31:46.907+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:31:46.906+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:31:46.932+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-23T17:32:17.767+0000] {processor.py:186} INFO - Started process (PID=25494) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:32:17.769+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:32:17.773+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:32:17.772+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:32:18.074+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:32:18.118+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:32:18.117+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:32:18.141+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:32:18.141+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:32:18.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.419 seconds
[2025-04-23T17:32:48.404+0000] {processor.py:186} INFO - Started process (PID=25565) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:32:48.405+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:32:48.408+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:32:48.408+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:32:48.685+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:32:48.720+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:32:48.719+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:32:48.740+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:32:48.740+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:32:48.773+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.378 seconds
[2025-04-23T17:33:18.932+0000] {processor.py:186} INFO - Started process (PID=25631) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:33:18.933+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:33:18.937+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:33:18.936+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:33:19.399+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:33:19.441+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:33:19.441+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:33:19.467+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:33:19.466+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:33:19.503+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.581 seconds
[2025-04-23T17:33:49.745+0000] {processor.py:186} INFO - Started process (PID=25701) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:33:49.746+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:33:49.749+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:33:49.749+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:33:50.035+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:33:50.063+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:33:50.063+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:33:50.082+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:33:50.081+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:33:50.110+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.374 seconds
[2025-04-23T17:34:21.446+0000] {processor.py:186} INFO - Started process (PID=25770) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:34:21.457+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:34:21.461+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:34:21.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:34:21.821+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:34:21.863+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:34:21.863+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:34:21.881+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:34:21.881+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:34:22.249+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.811 seconds
[2025-04-23T17:34:52.490+0000] {processor.py:186} INFO - Started process (PID=25838) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:34:52.491+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:34:52.494+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:34:52.494+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:34:52.763+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:34:52.791+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:34:52.791+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:34:52.808+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:34:52.808+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:34:52.838+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.356 seconds
[2025-04-23T17:35:22.944+0000] {processor.py:186} INFO - Started process (PID=25907) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:35:22.945+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:35:22.948+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:35:22.947+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:35:23.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:35:23.260+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:35:23.260+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:35:23.278+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:35:23.277+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:35:23.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.363 seconds
[2025-04-23T17:35:53.473+0000] {processor.py:186} INFO - Started process (PID=25978) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:35:53.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:35:53.477+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:35:53.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:35:53.728+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:35:53.758+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:35:53.757+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:35:53.775+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:35:53.775+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:35:53.804+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.338 seconds
[2025-04-23T17:36:24.220+0000] {processor.py:186} INFO - Started process (PID=26045) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:36:24.221+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:36:24.223+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:36:24.223+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:36:24.514+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:36:24.544+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:36:24.543+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:36:24.560+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:36:24.560+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:36:24.592+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.382 seconds
[2025-04-23T17:36:54.733+0000] {processor.py:186} INFO - Started process (PID=26117) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:36:54.734+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:36:54.738+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:36:54.737+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:36:55.019+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:36:55.048+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:36:55.047+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:36:55.066+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:36:55.065+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:36:55.091+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-23T17:37:25.376+0000] {processor.py:186} INFO - Started process (PID=26184) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:37:25.377+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:37:25.382+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:37:25.382+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:37:25.657+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:37:25.692+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:37:25.691+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:37:25.708+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:37:25.708+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:37:25.733+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-23T17:37:55.837+0000] {processor.py:186} INFO - Started process (PID=26251) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:37:55.839+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:37:55.842+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:37:55.842+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:37:56.166+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:37:56.205+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:37:56.204+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:37:56.225+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:37:56.224+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:37:56.256+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.429 seconds
[2025-04-23T17:38:26.364+0000] {processor.py:186} INFO - Started process (PID=26320) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:38:26.365+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:38:26.367+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:38:26.367+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:38:26.620+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:38:26.648+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:38:26.648+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:38:26.664+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:38:26.664+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:38:26.687+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.330 seconds
[2025-04-23T17:38:57.706+0000] {processor.py:186} INFO - Started process (PID=26395) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:38:57.707+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:38:57.710+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:38:57.709+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:38:57.963+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:38:57.994+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:38:57.993+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:38:58.011+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:38:58.011+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:38:58.041+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-23T17:39:29.030+0000] {processor.py:186} INFO - Started process (PID=26464) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:39:29.031+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:39:29.034+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:39:29.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:39:29.313+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:39:29.342+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:39:29.342+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:39:29.359+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:39:29.359+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:39:29.388+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.367 seconds
[2025-04-23T17:39:59.725+0000] {processor.py:186} INFO - Started process (PID=26533) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:39:59.726+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:39:59.728+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:39:59.728+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:39:59.995+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:40:00.031+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:40:00.030+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:40:00.048+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:40:00.047+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:40:00.077+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-23T17:40:30.551+0000] {processor.py:186} INFO - Started process (PID=26602) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:40:30.552+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:40:30.555+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:40:30.554+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:40:30.814+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:40:30.847+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:40:30.847+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:40:30.863+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:40:30.863+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:40:30.893+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.350 seconds
[2025-04-23T17:41:01.068+0000] {processor.py:186} INFO - Started process (PID=26672) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:41:01.069+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:41:01.072+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:41:01.072+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:41:01.349+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:41:01.377+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:41:01.377+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:41:01.396+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:41:01.395+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:41:01.520+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.458 seconds
[2025-04-23T17:41:32.130+0000] {processor.py:186} INFO - Started process (PID=26742) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:41:32.131+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:41:32.134+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:41:32.133+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:41:32.425+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:41:32.454+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:41:32.453+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:41:32.473+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:41:32.473+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:41:32.505+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.388 seconds
[2025-04-23T17:42:02.688+0000] {processor.py:186} INFO - Started process (PID=26813) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:42:02.689+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:42:02.692+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:42:02.692+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:42:02.982+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:42:03.016+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:42:03.016+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:42:03.037+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:42:03.037+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:42:03.065+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.386 seconds
[2025-04-23T17:42:33.308+0000] {processor.py:186} INFO - Started process (PID=26880) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:42:33.309+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:42:33.312+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:42:33.312+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:42:33.566+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:42:33.595+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:42:33.594+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:42:33.613+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:42:33.613+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:42:33.646+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.348 seconds
[2025-04-23T17:43:03.778+0000] {processor.py:186} INFO - Started process (PID=26951) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:43:03.779+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:43:03.782+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:43:03.781+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:43:04.201+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:43:04.230+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:43:04.229+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:43:04.245+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:43:04.245+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:43:04.274+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.504 seconds
[2025-04-23T17:43:34.426+0000] {processor.py:186} INFO - Started process (PID=27023) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:43:34.427+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:43:34.429+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:43:34.429+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:43:34.865+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:43:34.920+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:43:34.919+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:43:35.015+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:43:35.014+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:43:35.095+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.676 seconds
[2025-04-23T17:44:05.670+0000] {processor.py:186} INFO - Started process (PID=27092) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:44:05.671+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:44:05.674+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:44:05.674+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:44:06.115+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:44:06.143+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:44:06.143+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:44:06.157+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:44:06.157+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:44:06.185+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.521 seconds
[2025-04-23T17:44:36.444+0000] {processor.py:186} INFO - Started process (PID=27159) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:44:36.445+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:44:36.448+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:44:36.447+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:44:36.858+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:44:36.883+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:44:36.883+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:44:36.899+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:44:36.899+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:44:36.926+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.491 seconds
[2025-04-23T17:45:07.224+0000] {processor.py:186} INFO - Started process (PID=27231) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:45:07.226+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:45:07.228+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:45:07.228+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:45:07.607+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:45:07.631+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:45:07.630+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:45:07.645+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:45:07.645+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:45:07.674+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.460 seconds
[2025-04-23T17:45:37.863+0000] {processor.py:186} INFO - Started process (PID=27297) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:45:37.864+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:45:37.867+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:45:37.866+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:45:38.308+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:45:38.339+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:45:38.339+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:45:38.357+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:45:38.357+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:45:38.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.532 seconds
[2025-04-23T17:46:08.708+0000] {processor.py:186} INFO - Started process (PID=27369) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:46:08.709+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:46:08.712+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:46:08.712+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:46:09.112+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:46:09.137+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:46:09.137+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:46:09.152+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:46:09.151+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:46:09.179+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.479 seconds
[2025-04-23T17:46:39.273+0000] {processor.py:186} INFO - Started process (PID=27439) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:46:39.274+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:46:39.277+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:46:39.277+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:46:39.666+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:46:39.693+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:46:39.692+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:46:39.713+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:46:39.712+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:46:39.736+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.470 seconds
[2025-04-23T17:47:09.922+0000] {processor.py:186} INFO - Started process (PID=27508) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:47:09.923+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:47:09.925+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:47:09.925+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:47:10.324+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:47:10.348+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:47:10.348+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:47:10.360+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:47:10.360+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:47:10.386+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.472 seconds
[2025-04-23T17:47:40.846+0000] {processor.py:186} INFO - Started process (PID=27577) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:47:40.847+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:47:40.850+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:47:40.849+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:47:41.231+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:47:41.259+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:47:41.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:47:41.273+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:47:41.272+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:47:41.300+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.461 seconds
[2025-04-23T17:48:11.449+0000] {processor.py:186} INFO - Started process (PID=27646) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:48:11.450+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:48:11.453+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:48:11.453+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:48:11.840+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:48:11.866+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:48:11.865+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:48:11.879+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:48:11.879+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:48:11.907+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.466 seconds
[2025-04-23T17:48:42.003+0000] {processor.py:186} INFO - Started process (PID=27715) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:48:42.004+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:48:42.007+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:48:42.006+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:48:42.232+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:48:42.259+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:48:42.259+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:48:42.275+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:48:42.274+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:48:42.302+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.306 seconds
[2025-04-23T17:49:12.472+0000] {processor.py:186} INFO - Started process (PID=27784) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:49:12.474+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:49:12.476+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:49:12.476+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:49:12.741+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:49:12.768+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:49:12.767+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:49:12.782+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:49:12.782+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:49:12.811+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.346 seconds
[2025-04-23T17:49:42.904+0000] {processor.py:186} INFO - Started process (PID=27849) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:49:42.905+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:49:42.908+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:49:42.907+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:49:43.185+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:49:43.215+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:49:43.215+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:49:43.232+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:49:43.232+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:49:43.258+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.362 seconds
[2025-04-23T17:50:13.438+0000] {processor.py:186} INFO - Started process (PID=27919) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:50:13.440+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:50:13.442+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:50:13.442+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:50:13.703+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:50:13.733+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:50:13.733+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:50:13.750+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:50:13.750+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:50:13.774+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.343 seconds
[2025-04-23T17:50:43.898+0000] {processor.py:186} INFO - Started process (PID=27990) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:50:43.899+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:50:43.902+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:50:43.901+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:50:44.168+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:50:44.199+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:50:44.198+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:50:44.216+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:50:44.216+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:50:44.248+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.358 seconds
[2025-04-23T17:51:14.582+0000] {processor.py:186} INFO - Started process (PID=28057) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:51:14.583+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:51:14.586+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:51:14.586+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:51:14.862+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:51:14.892+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:51:14.891+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:51:14.911+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:51:14.911+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:51:14.940+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.366 seconds
[2025-04-23T17:51:45.507+0000] {processor.py:186} INFO - Started process (PID=28126) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:51:45.508+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:51:45.511+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:51:45.511+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:51:45.772+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:51:45.801+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:51:45.801+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:51:45.818+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:51:45.818+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:51:45.848+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.351 seconds
[2025-04-23T17:52:16.031+0000] {processor.py:186} INFO - Started process (PID=28197) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:52:16.032+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:52:16.035+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:52:16.034+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:52:16.296+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:52:16.329+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:52:16.328+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:52:16.346+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:52:16.346+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:52:16.377+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.355 seconds
[2025-04-23T17:52:46.456+0000] {processor.py:186} INFO - Started process (PID=28264) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:52:46.458+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:52:46.461+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:52:46.460+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:52:46.785+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:52:46.811+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:52:46.811+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:52:46.827+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:52:46.826+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:52:46.857+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.410 seconds
[2025-04-23T17:53:17.415+0000] {processor.py:186} INFO - Started process (PID=28333) to work on /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:53:17.417+0000] {processor.py:914} INFO - Processing file /opt/airflow/dags/test_crawl_list_product.py for tasks to queue
[2025-04-23T17:53:17.419+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:53:17.419+0000] {dagbag.py:588} INFO - Filling up the DagBag from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:53:17.676+0000] {processor.py:925} INFO - DAG(s) 'scrape_amazon_dag' retrieved from /opt/airflow/dags/test_crawl_list_product.py
[2025-04-23T17:53:17.704+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:53:17.703+0000] {dag.py:3239} INFO - Sync 1 DAGs
[2025-04-23T17:53:17.721+0000] {logging_mixin.py:190} INFO - [2025-04-23T17:53:17.720+0000] {dag.py:4180} INFO - Setting next_dagrun for scrape_amazon_dag to None, run_after=None
[2025-04-23T17:53:17.754+0000] {processor.py:208} INFO - Processing /opt/airflow/dags/test_crawl_list_product.py took 0.347 seconds
